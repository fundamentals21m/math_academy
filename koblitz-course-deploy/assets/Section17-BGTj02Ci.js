import{j as e}from"./vendor-animation-0o8UKZ_1.js";import{L as r,D as s,T as n,E as l,C as t}from"./Callout-DzP_hyKf.js";import{M as i}from"./MathBlock-DHMt0FrA.js";import"./vendor-react-Drj8qL0h.js";import"./index-BWUjVAcL.js";import"./vendor-math-p018AHG0.js";import"./vendor-firebase-core-BXWtuYvb.js";import"./quizMap-CQDzgGif.js";function j(){return e.jsxs(r,{sectionId:17,children:[e.jsx("h2",{children:"The Quadratic Sieve Method"}),e.jsx("p",{children:"The Quadratic Sieve (QS) was the fastest general-purpose factoring algorithm from 1981 until approximately 1993, when the Number Field Sieve surpassed it for very large numbers. QS remains competitive for numbers under ~100 digits and is conceptually simpler."}),e.jsx("h3",{children:"The Basic Idea"}),e.jsxs("p",{children:["Like CFRAC, QS seeks smooth values of ",e.jsx(i,{math:"Q(x) = x^2 - n",inline:!0})," for"," ",e.jsx(i,{math:"x",inline:!0})," near ",e.jsx(i,{math:"\\sqrt{n}",inline:!0}),". The key innovation is ",e.jsx("strong",{children:"sieving"}),": instead of testing each value for smoothness, we use the structure of primes to identify smooth values efficiently."]}),e.jsxs(s,{title:"Sieving Interval",children:["Choose ",e.jsx(i,{math:"m = \\lceil \\sqrt{n} \\rceil",inline:!0}),". For the polynomial"," ",e.jsx(i,{math:"Q(x) = (m + x)^2 - n",inline:!0}),", evaluate at ",e.jsx(i,{math:"x \\in [-M, M]",inline:!0})," ","for some bound ",e.jsx("em",{children:"M"}),". Values ",e.jsx(i,{math:"Q(x)",inline:!0})," are approximately linear near 0:",e.jsx(i,{math:"Q(x) \\approx 2mx \\text{ for small } x"})]}),e.jsx("h3",{children:"The Sieving Process"}),e.jsxs(n,{title:"Sieving Principle",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["We prove the periodicity of divisibility by ",e.jsx("em",{children:"p"})," for the polynomial ",e.jsx(i,{math:"Q(x) = (m+x)^2 - n",inline:!0}),"."]}),e.jsxs("p",{children:["Suppose ",e.jsx(i,{math:"p \\mid Q(x_0)",inline:!0}),", i.e., ",e.jsx(i,{math:"(m + x_0)^2 \\equiv n \\pmod{p}",inline:!0}),". For any integer ",e.jsx("em",{children:"k"}),":"]}),e.jsx(i,{math:"Q(x_0 + kp) = (m + x_0 + kp)^2 - n"}),e.jsx(i,{math:"= (m + x_0)^2 + 2(m + x_0)(kp) + (kp)^2 - n"}),e.jsx(i,{math:"\\equiv (m + x_0)^2 - n \\equiv 0 \\pmod{p}"}),e.jsxs("p",{children:["since both ",e.jsx(i,{math:"2(m + x_0)(kp)",inline:!0})," and ",e.jsx(i,{math:"(kp)^2",inline:!0})," are divisible by ",e.jsx("em",{children:"p"}),"."]}),e.jsxs("p",{children:["For the root-finding step: ",e.jsx(i,{math:"p \\mid Q(x)",inline:!0})," iff ",e.jsx(i,{math:"(m+x)^2 \\equiv n \\pmod{p}",inline:!0}),". If ",e.jsx("em",{children:"n"})," is a quadratic residue mod ",e.jsx("em",{children:"p"})," (i.e., ",e.jsx(i,{math:"(n/p) = 1",inline:!0}),"), there exist exactly two solutions ",e.jsx(i,{math:"m + x \\equiv \\pm\\sqrt{n} \\pmod{p}",inline:!0}),", giving:"]}),e.jsx(i,{math:"x_1 \\equiv \\sqrt{n} - m \\pmod{p}, \\quad x_2 \\equiv -\\sqrt{n} - m \\pmod{p}"}),e.jsxs("p",{children:["If ",e.jsx(i,{math:"(n/p) = -1",inline:!0}),", there are no solutions, so ",e.jsx("em",{children:"p"})," is excluded from the factor base. If ",e.jsx(i,{math:"p \\mid n",inline:!0}),", there is one solution (but this means ",e.jsx("em",{children:"p"})," divides ",e.jsx("em",{children:"n"}),", so we have already found a factor)."]})]}),children:["If prime ",e.jsx("em",{children:"p"})," divides ",e.jsx(i,{math:"Q(x_0)",inline:!0}),", then ",e.jsx("em",{children:"p"})," divides"," ",e.jsx(i,{math:"Q(x_0 + kp)",inline:!0})," for all integers ",e.jsx("em",{children:"k"}),". We can find all"," ",e.jsx("em",{children:"x"})," where ",e.jsx(i,{math:"p \\mid Q(x)",inline:!0})," by:",e.jsxs("ol",{className:"list-decimal list-inside mt-2 space-y-1",children:[e.jsxs("li",{children:["Solve ",e.jsx(i,{math:"(m + x)^2 \\equiv n \\pmod{p}",inline:!0})," for roots ",e.jsx(i,{math:"x_1, x_2",inline:!0})]}),e.jsxs("li",{children:["Mark positions ",e.jsx(i,{math:"x_1, x_1 + p, x_1 + 2p, \\ldots",inline:!0})," and same for ",e.jsx(i,{math:"x_2",inline:!0})]})]})]}),e.jsxs("div",{className:"bg-dark-800/50 rounded-xl p-4 border border-dark-700 my-4",children:[e.jsx("h4",{className:"text-lg font-semibold text-primary-400 mb-3",children:"QS Algorithm"}),e.jsxs("ol",{className:"list-decimal list-inside space-y-2 text-dark-300",children:[e.jsxs("li",{children:["Choose factor base ",e.jsx(i,{math:"\\mathcal{F} = \\{p : (n/p) = 1, p \\leq B\\}",inline:!0})]}),e.jsxs("li",{children:["Initialize array ",e.jsx(i,{math:"S[x] = \\log|Q(x)|",inline:!0})," for ",e.jsx(i,{math:"x \\in [-M, M]",inline:!0})]}),e.jsxs("li",{children:["For each ",e.jsx(i,{math:"p \\in \\mathcal{F}",inline:!0}),": subtract ",e.jsx(i,{math:"\\log p",inline:!0})," at positions where ",e.jsx(i,{math:"p \\mid Q(x)",inline:!0})]}),e.jsxs("li",{children:["After sieving, ",e.jsx(i,{math:"S[x] \\approx 0",inline:!0})," means ",e.jsx(i,{math:"Q(x)",inline:!0})," is smooth"]}),e.jsxs("li",{children:["For smooth ",e.jsx(i,{math:"Q(x)",inline:!0}),", factor completely to get exponent vector"]}),e.jsx("li",{children:"Use linear algebra to find dependency mod 2"})]})]}),e.jsxs(l,{title:"Sieving Illustration",children:[e.jsxs("p",{children:["Factor ",e.jsx(i,{math:"n = 15347",inline:!0}),", ",e.jsx(i,{math:"m = 124",inline:!0})]}),e.jsx("p",{className:"mt-2",children:e.jsx(i,{math:"Q(x) = (124 + x)^2 - 15347",inline:!0})}),e.jsxs("p",{className:"mt-2",children:["For ",e.jsx(i,{math:"p = 7",inline:!0}),": solve ",e.jsx(i,{math:"124 + x \\equiv \\pm \\sqrt{15347} \\pmod{7}",inline:!0})]}),e.jsxs("p",{children:[e.jsx(i,{math:"15347 \\equiv 2 \\pmod{7}",inline:!0}),", and ",e.jsx(i,{math:"3^2 \\equiv 2 \\pmod{7}",inline:!0}),", so roots are ",e.jsx(i,{math:"x \\equiv 3 - 124 \\equiv 4 \\pmod{7}",inline:!0})," and ",e.jsx(i,{math:"x \\equiv -3 - 124 \\equiv 0 \\pmod{7}",inline:!0})]}),e.jsxs("p",{className:"mt-2",children:["Sieve: subtract ",e.jsx(i,{math:"\\log 7",inline:!0})," at positions 0, 4, 7, 11, 14, ..."]})]}),e.jsx("h3",{children:"Multiple Polynomial QS (MPQS)"}),e.jsxs(s,{title:"MPQS",children:["Use multiple polynomials of the form:",e.jsx(i,{math:"Q_A(x) = (Ax + B)^2 - n = A^2 x^2 + 2ABx + (B^2 - n)"}),"where ",e.jsx(i,{math:"A^2 \\mid (B^2 - n)",inline:!0}),". Each polynomial provides a fresh sieving interval, and the work can be parallelized."]}),e.jsxs("p",{children:["Choosing ",e.jsx(i,{math:"A \\approx \\sqrt{2n}/M",inline:!0})," gives values of size"," ",e.jsx(i,{math:"\\sqrt{n/2}",inline:!0})," in the sieving interval, maintaining small residues."]}),e.jsx("h3",{children:"Complexity Analysis"}),e.jsxs(n,{title:"QS Complexity",proof:e.jsxs(e.Fragment,{children:[e.jsx("p",{children:"We analyze the complexity of the Quadratic Sieve by balancing relation collection against linear algebra costs."}),e.jsxs("p",{children:["Let ",e.jsx(i,{math:"L(n) = e^{\\sqrt{\\ln n \\ln \\ln n}}",inline:!0})," and write ",e.jsx(i,{math:"B = L(n)^\\alpha",inline:!0})," for the smoothness bound."]}),e.jsxs("p",{children:[e.jsx("strong",{children:"Relation collection:"})," Values ",e.jsx(i,{math:"Q(x) \\approx 2Mx",inline:!0})," for ",e.jsx(i,{math:"x \\in [-M, M]",inline:!0}),". With ",e.jsx(i,{math:"M \\approx \\sqrt{n}",inline:!0}),", we have ",e.jsx(i,{math:"|Q(x)| \\approx \\sqrt{n}",inline:!0}),"."]}),e.jsxs("p",{children:["The probability that ",e.jsx(i,{math:"Q(x)",inline:!0})," is ",e.jsx("em",{children:"B"}),"-smooth is approximately ",e.jsx(i,{math:"u^{-u}",inline:!0})," where:"]}),e.jsx(i,{math:"u = \\frac{\\ln \\sqrt{n}}{\\ln B} = \\frac{\\ln n}{2\\alpha \\sqrt{\\ln n \\ln \\ln n}}"}),e.jsxs("p",{children:["We need ",e.jsx(i,{math:"\\pi(B) \\approx B/\\ln B",inline:!0})," relations. The sieving interval must contain this many smooth values, requiring:"]}),e.jsx(i,{math:"M \\cdot u^{-u} \\geq B / \\ln B"}),e.jsxs("p",{children:[e.jsx("strong",{children:"Sieving cost:"})," For each prime ",e.jsx(i,{math:"p \\leq B",inline:!0}),", we mark ",e.jsx(i,{math:"2M/p",inline:!0})," positions. Total sieving work is ",e.jsx(i,{math:"\\sum_{p \\leq B} 2M/p \\approx 2M \\ln \\ln B",inline:!0}),"."]}),e.jsxs("p",{children:[e.jsx("strong",{children:"Linear algebra:"})," Solving a ",e.jsx(i,{math:"B \\times B",inline:!0})," sparse matrix costs ",e.jsx(i,{math:"O(B^2)",inline:!0})," with structured methods."]}),e.jsxs("p",{children:["Optimizing: set ",e.jsx(i,{math:"\\alpha = 1/2",inline:!0}),". Then ",e.jsx(i,{math:"u = \\sqrt{\\ln n / \\ln \\ln n}",inline:!0}),", and:"]}),e.jsx(i,{math:"u^u = \\exp\\left(\\sqrt{\\ln n / \\ln \\ln n} \\cdot \\frac{1}{2}\\ln(\\ln n / \\ln \\ln n)\\right) = L(n)^{1/2 + o(1)}"}),e.jsxs("p",{children:["With ",e.jsx(i,{math:"M = L(n)^{1/2}",inline:!0}),", sieving costs ",e.jsx(i,{math:"L(n)^{1/2} \\cdot L(n)^{1/2} = L(n)^{1+o(1)}",inline:!0}),". Linear algebra is ",e.jsx(i,{math:"L(n)^{1+o(1)}",inline:!0}),". Total: ",e.jsx(i,{math:"L(n)^{1+o(1)}",inline:!0}),"."]})]}),children:["The Quadratic Sieve factors ",e.jsx("em",{children:"n"})," in time:",e.jsx(i,{math:"L(n)^{1 + o(1)} = e^{(1 + o(1))\\sqrt{\\ln n \\ln \\ln n}}"}),"with optimal factor base bound ",e.jsx(i,{math:"B = L(n)^{1/2}",inline:!0})," and sieving interval ",e.jsx(i,{math:"M = L(n)^{1/2}",inline:!0}),"."]}),e.jsxs(t,{type:"info",children:[e.jsx("strong",{children:"Relation Count:"})," We need approximately ",e.jsx(i,{math:"\\pi(B) + 1",inline:!0})," ","smooth values. With ",e.jsx(i,{math:"B = L(n)^{1/2}",inline:!0}),", this is about"," ",e.jsx(i,{math:"L(n)^{1/2}",inline:!0})," relations, each requiring smoothness testing over the factor base."]}),e.jsx("h3",{children:"Large Prime Variation"}),e.jsxs(s,{title:"Large Prime Variation",children:["Allow relations with one or two primes larger than ",e.jsx("em",{children:"B"})," (but still small):",e.jsxs("ul",{className:"list-disc list-inside mt-2 space-y-1",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Single large prime:"})," If ",e.jsx(i,{math:"Q(x) = (\\text{smooth}) \\times p",inline:!0})," for ",e.jsx(i,{math:"p > B",inline:!0}),", save it"]}),e.jsx("li",{children:"Two relations with same large prime combine to eliminate it"}),e.jsxs("li",{children:[e.jsx("strong",{children:"Double large prime:"})," Allow two unfactored primes; more combinations possible"]})]}),"This can double the effective relation collection rate."]}),e.jsx("h3",{children:"Linear Algebra Phase"}),e.jsxs("p",{children:["After collecting enough relations, solve a sparse system over ",e.jsx(i,{math:"\\mathbb{F}_2",inline:!0}),":"]}),e.jsxs("div",{className:"bg-dark-800/50 rounded-xl p-4 border border-dark-700 my-4",children:[e.jsx("h4",{className:"text-lg font-semibold text-primary-400 mb-3",children:"Matrix Structure"}),e.jsxs("ul",{className:"list-disc list-inside space-y-2 text-dark-300",children:[e.jsxs("li",{children:["Rows: relations (one per smooth ",e.jsx(i,{math:"Q(x)",inline:!0}),")"]}),e.jsx("li",{children:"Columns: factor base primes"}),e.jsxs("li",{children:["Entry ",e.jsx(i,{math:"(i, j)",inline:!0}),": exponent of ",e.jsx(i,{math:"p_j",inline:!0})," in relation ",e.jsx("em",{children:"i"}),", mod 2"]}),e.jsxs("li",{children:["Dimension: ",e.jsx(i,{math:"\\sim L(n)^{1/2} \\times L(n)^{1/2}",inline:!0})]}),e.jsxs("li",{children:["Sparsity: each row has ",e.jsx(i,{math:"O(\\log n / \\log\\log n)",inline:!0})," nonzeros"]})]})]}),e.jsxs(n,{title:"Efficient Linear Algebra",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["We analyze the complexity of finding null vectors in the exponent matrix over ",e.jsx(i,{math:"\\mathbb{F}_2",inline:!0}),"."]}),e.jsxs("p",{children:["The matrix has dimensions ",e.jsx(i,{math:"r \\times c",inline:!0})," where ",e.jsx(i,{math:"r \\approx c \\approx \\pi(B) \\approx L(n)^{1/2}",inline:!0}),". Each row has at most ",e.jsx(i,{math:"O(\\log n / \\log \\log n)",inline:!0})," non-zero entries (the number of prime factors of a smooth number)."]}),e.jsxs("p",{children:[e.jsx("strong",{children:"Naive Gaussian elimination:"})," ",e.jsx(i,{math:"O(r^2 c) = O(L(n)^{3/2})",inline:!0}),", which dominates relation collection."]}),e.jsxs("p",{children:[e.jsx("strong",{children:"Block Lanczos method:"})," Finds the null space of ",e.jsx(i,{math:"A^T A",inline:!0})," by computing the sequence:"]}),e.jsx(i,{math:"v, Av, A^2v, \\ldots, A^k v"}),e.jsxs("p",{children:["until a linear dependency is found. Each matrix-vector product costs ",e.jsx(i,{math:"O(r \\cdot \\text{density})",inline:!0})," where density is ",e.jsx(i,{math:"O(\\log n / \\log \\log n)",inline:!0})," per row."]}),e.jsxs("p",{children:["The number of iterations needed is ",e.jsx(i,{math:"O(r)",inline:!0})," (dimension of the null space is ",e.jsx(i,{math:"r - c + 1",inline:!0}),"). Total cost:"]}),e.jsx(i,{math:"O(r \\times r \\times \\log n / \\log \\log n) = O(L(n)^1 \\times (\\log n)^{O(1)}) = O(L(n)^{1+o(1)})"}),e.jsxs("p",{children:[e.jsx("strong",{children:"Block Wiedemann method:"})," Uses a similar Krylov subspace approach but is better suited for parallel computation. The asymptotic complexity is the same."]}),e.jsxs("p",{children:["Both methods exploit the sparse structure to achieve cost proportional to ",e.jsx(i,{math:"(\\text{rows})^2 \\times \\text{average density}",inline:!0}),"."]})]}),children:["Block Lanczos or Block Wiedemann algorithms find null vectors in time"," ",e.jsx(i,{math:"O((\\text{rows})^2 \\times \\text{density})",inline:!0}),", exploiting sparsity. For QS, this is ",e.jsx(i,{math:"O(L(n)^{1 + o(1)})",inline:!0}),"."]}),e.jsx("h3",{children:"Historical Factorizations"}),e.jsx("div",{className:"bg-dark-800/50 rounded-xl p-4 border border-dark-700 my-4",children:e.jsxs("table",{className:"w-full text-dark-300",children:[e.jsx("thead",{children:e.jsxs("tr",{className:"border-b border-dark-700",children:[e.jsx("th",{className:"text-left py-2",children:"Number"}),e.jsx("th",{className:"text-left py-2",children:"Digits"}),e.jsx("th",{className:"text-left py-2",children:"Year"}),e.jsx("th",{className:"text-left py-2",children:"Method"})]})}),e.jsxs("tbody",{children:[e.jsxs("tr",{className:"border-b border-dark-700",children:[e.jsx("td",{className:"py-2",children:"RSA-100"}),e.jsx("td",{className:"py-2",children:"100"}),e.jsx("td",{className:"py-2",children:"1991"}),e.jsx("td",{className:"py-2",children:"QS"})]}),e.jsxs("tr",{className:"border-b border-dark-700",children:[e.jsx("td",{className:"py-2",children:"RSA-110"}),e.jsx("td",{className:"py-2",children:"110"}),e.jsx("td",{className:"py-2",children:"1992"}),e.jsx("td",{className:"py-2",children:"QS"})]}),e.jsxs("tr",{className:"border-b border-dark-700",children:[e.jsx("td",{className:"py-2",children:"RSA-120"}),e.jsx("td",{className:"py-2",children:"120"}),e.jsx("td",{className:"py-2",children:"1993"}),e.jsx("td",{className:"py-2",children:"QS"})]}),e.jsxs("tr",{children:[e.jsx("td",{className:"py-2",children:"RSA-129"}),e.jsx("td",{className:"py-2",children:"129"}),e.jsx("td",{className:"py-2",children:"1994"}),e.jsx("td",{className:"py-2",children:"QS (last)"})]})]})]})}),e.jsxs(t,{type:"success",children:[e.jsx("strong",{children:"Self-Initializing QS:"})," Modern implementations (SIQS) automatically choose good polynomial parameters, making QS practical for numbers up to ~100 digits on a single computer, or ~120 digits with distributed computing."]}),e.jsx("h3",{children:"Comparison: QS vs NFS"}),e.jsxs("p",{children:["The Number Field Sieve (NFS) has complexity ",e.jsx(i,{math:"L(n)^{c}",inline:!0})," with"," ",e.jsx(i,{math:"c \\approx 1.9",inline:!0})," for QS vs ",e.jsx(i,{math:"c \\approx 1.5",inline:!0})," for NFS. The crossover point is around 100-110 digits; above this, NFS dominates."]})]})}export{j as default};
