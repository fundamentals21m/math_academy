import{j as e}from"./vendor-animation-CmxkKU9r.js";import{L as a,C as d,D as r,T as t,E as s,S as l}from"./SectionQuiz-CnZF8yUl.js";import{I as i,M as n}from"./MathBlock-DHvxKvdn.js";import"./vendor-react-DamxDR2H.js";import"./index-Buvxgqcy.js";import"./vendor-math-p018AHG0.js";const c={easy:[{id:"s30-e01",question:"det(I) where I is the n × n identity matrix equals:",options:["0","1","n","n!"],correctIndex:1,difficulty:"easy",explanation:"The determinant of the identity matrix is 1 (normalization condition)."},{id:"s30-e02",question:"If A has two identical rows, then det(A) equals:",options:["1","-1","0","Undefined"],correctIndex:2,difficulty:"easy",explanation:"The alternating property implies det = 0 when two rows are equal."},{id:"s30-e03",question:"det of a 2 × 2 matrix [[a,b],[c,d]] equals:",options:["a + d","ac + bd","ad - bc","ab - cd"],correctIndex:2,difficulty:"easy",explanation:"det([[a,b],[c,d]]) = ad - bc."},{id:"s30-e04",question:"A square matrix with determinant 0 is called:",options:["Invertible","Singular","Orthogonal","Unitary"],correctIndex:1,difficulty:"easy",explanation:"A singular matrix has determinant zero and is not invertible."},{id:"s30-e05",question:"The determinant of an upper triangular matrix is:",options:["0","1","The product of diagonal entries","The sum of diagonal entries"],correctIndex:2,difficulty:"easy",explanation:"For triangular matrices, det = product of diagonal entries."},{id:"s30-e06",question:"If we swap two rows of matrix A, the determinant:",options:["Stays the same","Changes sign","Doubles","Becomes zero"],correctIndex:1,difficulty:"easy",explanation:"Swapping two rows negates the determinant (alternating property)."}],medium:[{id:"s30-m01",question:"A determinant function D on n × n matrices is:",options:["Linear in each row","Alternating and multilinear","Always positive","Equal to the trace"],correctIndex:1,difficulty:"medium",explanation:"The determinant is multilinear (linear in each row) and alternating (changes sign when rows are swapped)."},{id:"s30-m02",question:"If we multiply one row of A by scalar c, the determinant becomes:",options:["c·det(A)","det(A)/c","det(A) + c","c²·det(A)"],correctIndex:0,difficulty:"medium",explanation:"Multilinearity: scaling one row by c scales the determinant by c."},{id:"s30-m03",question:"det(AB) equals:",options:["det(A) + det(B)","det(A) · det(B)","det(A)/det(B)","det(A + B)"],correctIndex:1,difficulty:"medium",explanation:"The determinant is multiplicative: det(AB) = det(A)det(B)."},{id:"s30-m04",question:"det(Aᵀ) equals:",options:["1/det(A)","-det(A)","det(A)","(det(A))²"],correctIndex:2,difficulty:"medium",explanation:"The determinant of the transpose equals the original determinant."},{id:"s30-m05",question:"A is invertible if and only if:",options:["det(A) = 1","det(A) ≠ 0","det(A) > 0","det(A) = n"],correctIndex:1,difficulty:"medium",explanation:"A matrix is invertible iff its determinant is non-zero."},{id:"s30-m06",question:"det(cA) for an n × n matrix A equals:",options:["c·det(A)","cⁿ·det(A)","det(A)/c","c + det(A)"],correctIndex:1,difficulty:"medium",explanation:"Each of n rows is multiplied by c, so det(cA) = cⁿ det(A)."}],hard:[{id:"s30-h01",question:"A k-linear function on V^k is:",options:["Degree k polynomial","Linear in each of k arguments","A function to F^k","Always symmetric"],correctIndex:1,difficulty:"hard",explanation:"A k-linear (multilinear) function is linear in each of its k arguments separately."},{id:"s30-h02",question:"An alternating multilinear function satisfies:",options:["f(v, v, ...) = 0 when any two arguments are equal","f is symmetric","f(v₁, ..., vₖ) = f(v₁) + ... + f(vₖ)","f is constant"],correctIndex:0,difficulty:"hard",explanation:"Alternating means f = 0 when two arguments coincide, equivalently, swapping arguments negates f."},{id:"s30-h03",question:"The cofactor Cᵢⱼ of entry aᵢⱼ is:",options:["aᵢⱼ","(-1)^{i+j} times the (i,j) minor","The (i,j) minor","det(A)/aᵢⱼ"],correctIndex:1,difficulty:"hard",explanation:"Cᵢⱼ = (-1)^{i+j} Mᵢⱼ where Mᵢⱼ is the determinant of the (n-1)×(n-1) submatrix."},{id:"s30-h04",question:"Cramer's rule expresses the solution of Ax = b in terms of:",options:["Inverses only","Ratios of determinants","Eigenvalues","Traces"],correctIndex:1,difficulty:"hard",explanation:"xᵢ = det(Aᵢ)/det(A) where Aᵢ has the i-th column replaced by b."},{id:"s30-h05",question:"The adjugate (classical adjoint) of A satisfies:",options:["A · adj(A) = det(A) · I","adj(A) = A⁻¹","adj(A) = Aᵀ","A + adj(A) = I"],correctIndex:0,difficulty:"hard",explanation:"A · adj(A) = adj(A) · A = det(A) · I."},{id:"s30-h06",question:"The determinant of an n × n matrix A can be expressed as a sum over:",options:["n terms","n² terms","n! terms","2ⁿ terms"],correctIndex:2,difficulty:"hard",explanation:"det(A) = Σ_{σ ∈ Sₙ} sgn(σ) A_{1,σ(1)} ··· A_{n,σ(n)} has n! terms."}]};function u(){return e.jsxs(a,{sectionId:9,children:[e.jsx("h2",{children:"Determinants: Measuring Volume and Orientation"}),e.jsxs("p",{children:["The ",e.jsx("strong",{children:"determinant"})," is a scalar value associated with a square matrix that encodes fundamental geometric and algebraic information: invertibility, volume scaling, and orientation."]}),e.jsxs(d,{type:"info",children:[e.jsx("strong",{children:"Geometric Meaning:"})," For a matrix ",e.jsx(i,{children:"A"}),", ",e.jsx(i,{children:"|\\det(A)|"})," gives the factor by which ",e.jsx(i,{children:"A"})," scales volumes, and ",e.jsxs(i,{children:["\\text{sign}","(\\det(A))"]})," indicates whether ",e.jsx(i,{children:"A"})," preserves or reverses orientation."]}),e.jsx("h2",{children:"Axiomatic Definition"}),e.jsxs(r,{title:"Determinant (Axiomatic)",children:[e.jsxs("p",{children:["The ",e.jsx("strong",{children:"determinant"})," is the unique function ",e.jsx(i,{children:"\\det: M_n(F) \\to F"})," satisfying:"]}),e.jsxs("ol",{className:"list-decimal list-inside text-dark-300 mt-2",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Multilinear in columns:"})," Linear in each column when others are fixed"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Alternating:"})," ",e.jsx(i,{children:"\\det(A) = 0"})," if two columns are equal"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Normalized:"})," ",e.jsx(i,{children:"\\det(I) = 1"})]})]})]}),e.jsxs(t,{title:"Consequences of the Axioms",proof:e.jsxs(e.Fragment,{children:[e.jsx("p",{children:e.jsx("strong",{children:"Swapping columns negates det:"})}),e.jsxs("p",{className:"mt-2",children:["Let ",e.jsx(i,{children:"a"})," and ",e.jsx(i,{children:"b"})," be columns. By multilinearity and alternating:"]}),e.jsx(n,{children:"0 = \\det(\\ldots, a+b, \\ldots, a+b, \\ldots) = \\det(\\ldots, a, \\ldots, a, \\ldots) + \\det(\\ldots, a, \\ldots, b, \\ldots)"}),e.jsx(n,{children:"+ \\det(\\ldots, b, \\ldots, a, \\ldots) + \\det(\\ldots, b, \\ldots, b, \\ldots)"}),e.jsxs("p",{className:"mt-2",children:["The first and last terms are 0 (alternating), so ",e.jsx(i,{children:"\\det(...,a,...,b,...) = -\\det(...,b,...,a,...)"}),"."]}),e.jsx("p",{className:"mt-4",children:e.jsx("strong",{children:"Column replacement doesn't change det:"})}),e.jsx("p",{className:"mt-2",children:e.jsx(i,{children:"\\det(..., a + cb, ..., b, ...) = \\det(..., a, ..., b, ...) + c\\det(..., b, ..., b, ...) = \\det(..., a, ..., b, ...)"})}),e.jsxs("p",{className:"mt-4",children:[e.jsx("strong",{children:"Scaling:"})," Direct from multilinearity in that column."]}),e.jsxs("p",{className:"mt-4",children:[e.jsx("strong",{children:"Zero column:"})," ",e.jsxs(i,{children:["\\det(..., ","\\mathbf{0}",", ...) = \\det(..., 0 \\cdot ","\\mathbf{0}",", ...) = 0 \\cdot \\det(..., ","\\mathbf{0}",", ...) = 0"]}),"."]})]}),children:[e.jsx("p",{children:"From the three axioms, we can derive:"}),e.jsxs("ul",{className:"list-disc list-inside text-dark-300 mt-2 space-y-1",children:[e.jsx("li",{children:"Swapping two columns negates the determinant"}),e.jsx("li",{children:"Adding a multiple of one column to another doesn't change det"}),e.jsxs("li",{children:["Scaling a column by ",e.jsx(i,{children:"c"})," scales det by ",e.jsx(i,{children:"c"})]}),e.jsxs("li",{children:["If any column is zero, ",e.jsx(i,{children:"\\det = 0"})]})]})]}),e.jsx("h2",{children:"Computing Determinants"}),e.jsxs(s,{title:"2×2 Determinant",children:[e.jsx(n,{children:"\\det\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = ad - bc"}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"Geometric interpretation:"})," This is the signed area of the parallelogram spanned by ",e.jsx(i,{children:"(a, c)"})," and ",e.jsx(i,{children:"(b, d)"}),"."]})]}),e.jsxs(s,{title:"3×3 Determinant",children:[e.jsx(n,{children:"\\det\\begin{pmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{pmatrix} = a(ei - fh) - b(di - fg) + c(dh - eg)"}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"Geometric interpretation:"})," This is the signed volume of the parallelepiped spanned by the three column vectors."]})]}),e.jsx(r,{title:"Cofactor Expansion",children:e.jsxs("p",{children:["The ",e.jsx("strong",{children:"cofactor"})," of entry ",e.jsxs(i,{children:["a_","ij"]})," is ",e.jsxs(i,{children:["C_","ij"," = (-1)^","{i+j}"," M_","ij"]}),", where ",e.jsxs(i,{children:["M_","ij"]})," is the ",e.jsx("strong",{children:"minor"})," — the determinant of the ",e.jsx(i,{children:"(n-1) \\times (n-1)"}),"matrix obtained by deleting row ",e.jsx(i,{children:"i"})," and column ",e.jsx(i,{children:"j"}),"."]})}),e.jsxs(t,{title:"Cofactor Expansion",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["We prove by induction that any function satisfying multilinearity, alternating, and ",e.jsx(i,{children:"\\det(I) = 1"})," admits cofactor expansion."]}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"Base case:"})," For ",e.jsx(i,{children:"n = 1"}),", ",e.jsx(i,{children:"\\det(a) = a"})," (normalization)."]}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"Inductive step:"})," By multilinearity in column 1:"]}),e.jsx(n,{children:"\\det(A) = \\det\\left(\\sum_{i=1}^n a_{i1} e_i, a_2, \\ldots, a_n\\right) = \\sum_{i=1}^n a_{i1} \\det(e_i, a_2, \\ldots, a_n)"}),e.jsxs("p",{className:"mt-2",children:["For each term ",e.jsx(i,{children:"\\det(e_i, a_2, \\ldots, a_n)"}),", expand using alternating property: moving row ",e.jsx(i,{children:"i"})," to position 1 requires ",e.jsx(i,{children:"i-1"})," swaps, giving factor ",e.jsxs(i,{children:["(-1)^","{i-1}"]}),"."]}),e.jsxs("p",{className:"mt-2",children:["The remaining ",e.jsx(i,{children:"(n-1) \\times (n-1)"})," determinant is ",e.jsxs(i,{children:["M_","{i1}"]}),". So ",e.jsxs(i,{children:["\\det(e_i, a_2, \\ldots, a_n) = (-1)^","{i+1}"," M_","{i1}"]}),"."]}),e.jsxs("p",{className:"mt-2",children:["Expansion along any row or column follows by transposition (since ",e.jsx(i,{children:"\\det(A^T) = \\det(A)"}),")."]})]}),children:[e.jsxs("p",{children:["The determinant can be computed by expansion along any row ",e.jsx(i,{children:"i"}),":"]}),e.jsx(n,{children:"\\det(A) = \\sum_{j=1}^n a_{ij} C_{ij} = \\sum_{j=1}^n a_{ij} (-1)^{i+j} M_{ij}"}),e.jsxs("p",{className:"mt-2",children:["Or along any column ",e.jsx(i,{children:"j"}),":"]}),e.jsx(n,{children:"\\det(A) = \\sum_{i=1}^n a_{ij} C_{ij}"})]}),e.jsxs(s,{title:"Cofactor Expansion Example",children:[e.jsx("p",{children:"Compute using expansion along row 1:"}),e.jsx(n,{children:"\\det\\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix}"}),e.jsx(n,{children:"= 1 \\cdot \\det\\begin{pmatrix} 5 & 6 \\\\ 8 & 9 \\end{pmatrix} - 2 \\cdot \\det\\begin{pmatrix} 4 & 6 \\\\ 7 & 9 \\end{pmatrix} + 3 \\cdot \\det\\begin{pmatrix} 4 & 5 \\\\ 7 & 8 \\end{pmatrix}"}),e.jsx(n,{children:"= 1(45 - 48) - 2(36 - 42) + 3(32 - 35)"}),e.jsx(n,{children:"= 1(-3) - 2(-6) + 3(-3) = -3 + 12 - 9 = 0"}),e.jsx("p",{className:"mt-2",children:"(The rows are linearly dependent, so det = 0.)"})]}),e.jsx("h2",{children:"Key Properties"}),e.jsx(t,{title:"Determinant of Transpose",proof:e.jsx(e.Fragment,{children:e.jsxs("p",{children:["Both ",e.jsx(i,{children:"\\det(A)"})," and ",e.jsx(i,{children:"\\det(A^T)"})," can be computed using the same permutation formula. The symmetry of the formula gives equality."]})}),children:e.jsx("p",{children:e.jsx(i,{children:"\\det(A^T) = \\det(A)"})})}),e.jsx(t,{title:"Determinant Product Rule",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["Consider ",e.jsx(i,{children:"\\phi(A) = \\det(AB) / \\det(B)"})," when ",e.jsx(i,{children:"\\det(B) \\neq 0"}),"."]}),e.jsxs("p",{className:"mt-2",children:[e.jsx(i,{children:"\\phi"})," is multilinear and alternating in the columns of ",e.jsx(i,{children:"A"}),"."]}),e.jsxs("p",{className:"mt-2",children:["Since ",e.jsx(i,{children:"\\phi(I) = \\det(B)/\\det(B) = 1"}),", by uniqueness: ",e.jsx(i,{children:"\\phi(A) = \\det(A)"}),"."]}),e.jsxs("p",{className:"mt-2",children:["So ",e.jsx(i,{children:"\\det(AB) = \\det(A)\\det(B)"}),"."]})]}),children:e.jsx("p",{children:e.jsx(i,{children:"\\det(AB) = \\det(A) \\det(B)"})})}),e.jsx(t,{title:"Invertibility Criterion",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:[e.jsx("strong",{children:"(⇒)"})," If ",e.jsx(i,{children:"A"})," is invertible, then ",e.jsxs(i,{children:["AA^","{-1}"," = I"]}),"."]}),e.jsx(n,{children:"\\det(A)\\det(A^{-1}) = \\det(I) = 1"}),e.jsxs("p",{children:["So ",e.jsx(i,{children:"\\det(A) \\neq 0"}),"."]}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"(⇐)"})," If ",e.jsx(i,{children:"\\det(A) \\neq 0"}),", the columns are linearly independent (otherwise ",e.jsx(i,{children:"\\det = 0"}),"), so ",e.jsx(i,{children:"A"})," has full rank and is invertible."]})]}),children:e.jsxs("p",{children:["A square matrix ",e.jsx(i,{children:"A"})," is invertible if and only if ",e.jsx(i,{children:"\\det(A) \\neq 0"}),"."]})}),e.jsx(t,{title:"Determinant of Inverse",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["If ",e.jsx(i,{children:"A"})," is invertible, then ",e.jsxs(i,{children:["AA^","{-1}"," = I"]}),". By the product rule:"]}),e.jsx(n,{children:"\\det(A)\\det(A^{-1}) = \\det(AA^{-1}) = \\det(I) = 1"}),e.jsxs("p",{className:"mt-2",children:["Since ",e.jsx(i,{children:"A"})," is invertible, ",e.jsx(i,{children:"\\det(A) \\neq 0"}),". Dividing both sides by ",e.jsx(i,{children:"\\det(A)"}),":"]}),e.jsx(n,{children:"\\det(A^{-1}) = \\frac{1}{\\det(A)}"})]}),children:e.jsxs("p",{children:["If ",e.jsx(i,{children:"A"})," is invertible: ",e.jsxs(i,{children:["\\det(A^","{-1}",") = 1/\\det(A)"]})]})}),e.jsx("h2",{children:"The Adjugate Matrix"}),e.jsxs(r,{title:"Adjugate (Classical Adjoint)",children:[e.jsxs("p",{children:["The ",e.jsx("strong",{children:"adjugate"})," of ",e.jsx(i,{children:"A"}),", denoted ",e.jsxs(i,{children:["\\text{adj}","(A)"]}),", is the transpose of the cofactor matrix:"]}),e.jsx(n,{children:"\\text{adj}(A)_{ij} = C_{ji}"})]}),e.jsxs(t,{title:"Inverse via Adjugate",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["The ",e.jsx(i,{children:"(i,j)"})," entry of ",e.jsxs(i,{children:["A \\cdot ","\\text{adj}","(A)"]})," is:"]}),e.jsx(n,{children:"\\sum_{k=1}^n a_{ik} (\\text{adj}(A))_{kj} = \\sum_{k=1}^n a_{ik} C_{jk}"}),e.jsxs("p",{className:"mt-2",children:[e.jsxs("strong",{children:["Case ",e.jsx(i,{children:"i = j"}),":"]})," This is ",e.jsxs(i,{children:["\\sum_k a_",ik," C_",ik]}),", which is cofactor expansion along row ",e.jsx(i,{children:"i"}),", giving ",e.jsx(i,{children:"\\det(A)"}),"."]}),e.jsxs("p",{className:"mt-2",children:[e.jsxs("strong",{children:["Case ",e.jsx(i,{children:"i \\neq j"}),":"]})," This is cofactor expansion of a matrix with row ",e.jsx(i,{children:"j"})," replaced by row ",e.jsx(i,{children:"i"}),", which has two identical rows. By the alternating property, this equals 0."]}),e.jsxs("p",{className:"mt-2",children:["Therefore ",e.jsxs(i,{children:["A \\cdot ","\\text{adj}","(A) = \\det(A) \\cdot I"]}),"."]}),e.jsxs("p",{className:"mt-2",children:["If ",e.jsx(i,{children:"\\det(A) \\neq 0"}),", divide by ",e.jsx(i,{children:"\\det(A)"}),": ",e.jsxs(i,{children:["A \\cdot \\frac",1,"\\det(A)","\\text{adj}","(A) = I"]}),", so ",e.jsxs(i,{children:["A^","{-1}"," = \\frac",1,"\\det(A)","\\text{adj}","(A)"]}),"."]})]}),children:[e.jsx("p",{children:e.jsxs(i,{children:["A \\cdot ","\\text{adj}","(A) = \\det(A) \\cdot I"]})}),e.jsxs("p",{className:"mt-2",children:["If ",e.jsx(i,{children:"A"})," is invertible:"]}),e.jsx(n,{children:"A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A)"})]}),e.jsx("h2",{children:"Cramer's Rule"}),e.jsxs(t,{title:"Cramer's Rule",proof:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["Let ",e.jsx(i,{children:"A_i"})," be ",e.jsx(i,{children:"A"})," with column ",e.jsx(i,{children:"i"})," replaced by ",e.jsx(i,{children:"\\mathbf{b}"}),"."]}),e.jsxs("p",{className:"mt-2",children:["Using the adjugate formula for ",e.jsxs(i,{children:["A^","{-1}"]}),":"]}),e.jsx(n,{children:"x_i = (A^{-1}\\mathbf{b})_i = \\frac{1}{\\det(A)} \\sum_j (\\text{adj}(A))_{ij} b_j = \\frac{1}{\\det(A)} \\sum_j C_{ji} b_j"}),e.jsxs("p",{className:"mt-2",children:["The sum ",e.jsxs(i,{children:["\\sum_j C_","ji"," b_j"]})," is exactly the cofactor expansion of ",e.jsx(i,{children:"\\det(A_i)"}),"along column ",e.jsx(i,{children:"i"}),"."]})]}),children:[e.jsxs("p",{children:["If ",e.jsx(i,{children:"A"})," is invertible and ",e.jsxs(i,{children:["A","\\mathbf{x}"," = ","\\mathbf{b}"]}),", then:"]}),e.jsx(n,{children:"x_i = \\frac{\\det(A_i)}{\\det(A)}"}),e.jsxs("p",{className:"mt-2",children:["where ",e.jsx(i,{children:"A_i"})," is ",e.jsx(i,{children:"A"})," with column ",e.jsx(i,{children:"i"})," replaced by ",e.jsx(i,{children:"\\mathbf{b}"}),"."]})]}),e.jsxs(s,{title:"Cramer's Rule Application",children:[e.jsx("p",{children:"Solve:"}),e.jsx(n,{children:"\\begin{cases} 2x + y = 5 \\\\ x + 3y = 5 \\end{cases}"}),e.jsx(n,{children:"A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 5 \\\\ 5 \\end{pmatrix}"}),e.jsx(n,{children:"\\det(A) = 6 - 1 = 5"}),e.jsx(n,{children:"x = \\frac{\\det\\begin{pmatrix} 5 & 1 \\\\ 5 & 3 \\end{pmatrix}}{5} = \\frac{15 - 5}{5} = 2"}),e.jsx(n,{children:"y = \\frac{\\det\\begin{pmatrix} 2 & 5 \\\\ 1 & 5 \\end{pmatrix}}{5} = \\frac{10 - 5}{5} = 1"})]}),e.jsxs(d,{type:"warning",children:[e.jsx("strong",{children:"Practical Note:"})," Cramer's Rule is elegant but computationally expensive (",e.jsx(i,{children:"O(n!)"})," naive, ",e.jsx(i,{children:"O(n^4)"})," with smart cofactor computation). For practical computation, Gaussian elimination (",e.jsx(i,{children:"O(n^3)"}),") is preferred."]}),e.jsx("h2",{children:"Special Matrices"}),e.jsx(t,{title:"Determinant of Special Matrices",proof:e.jsxs(e.Fragment,{children:[e.jsx("p",{children:e.jsx("strong",{children:"Triangular matrix:"})}),e.jsx("p",{className:"mt-2",children:"Use cofactor expansion along the first column (for lower triangular) or first row (for upper triangular). Only one entry is nonzero, giving a recursion that yields the product of diagonal entries."}),e.jsx("p",{className:"mt-4",children:e.jsx("strong",{children:"Block triangular:"})}),e.jsxs("p",{className:"mt-2",children:["By row operations on the block structure (or cofactor expansion), the determinant factors as ",e.jsx(i,{children:"\\det(A)\\det(B)"}),". The off-diagonal block doesn't contribute to the determinant."]}),e.jsx("p",{className:"mt-4",children:e.jsx("strong",{children:"Orthogonal matrix:"})}),e.jsxs("p",{className:"mt-2",children:["If ",e.jsx(i,{children:"Q^T Q = I"}),", then:"]}),e.jsx(n,{children:"\\det(Q^T)\\det(Q) = \\det(I) = 1"}),e.jsxs("p",{className:"mt-2",children:["Since ",e.jsx(i,{children:"\\det(Q^T) = \\det(Q)"}),", we have ",e.jsx(i,{children:"\\det(Q)^2 = 1"}),", so ",e.jsx(i,{children:"\\det(Q) = \\pm 1"}),"."]})]}),children:e.jsxs("ul",{className:"list-disc list-inside text-dark-300 mt-2 space-y-2",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Triangular matrix:"})," ",e.jsx(i,{children:"\\det = "})," product of diagonal entries"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Diagonal matrix:"})," ",e.jsx(i,{children:"\\det = "})," product of diagonal entries"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Block triangular:"})," ",e.jsxs(i,{children:["\\det\\begin","{pmatrix}"," A & * \\\\ 0 & B \\end","{pmatrix}"," = \\det(A) \\det(B)"]})]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Orthogonal matrix:"})," ",e.jsx(i,{children:"\\det = \\pm 1"})]})]})}),e.jsxs("div",{className:"mt-8 p-4 rounded-xl bg-dark-800/50 border border-dark-700",children:[e.jsx("h3",{className:"text-lg font-semibold text-dark-100 mb-2",children:"Key Takeaways"}),e.jsxs("ul",{className:"list-disc list-inside text-dark-300 space-y-1",children:[e.jsxs("li",{children:["Determinant is multilinear, alternating, normalized (",e.jsx(i,{children:"\\det(I) = 1"}),")"]}),e.jsx("li",{children:"Cofactor expansion works along any row or column"}),e.jsxs("li",{children:[e.jsx(i,{children:"\\det(AB) = \\det(A)\\det(B)"})," and ",e.jsx(i,{children:"\\det(A^T) = \\det(A)"})]}),e.jsxs("li",{children:[e.jsx(i,{children:"A"})," is invertible iff ",e.jsx(i,{children:"\\det(A) \\neq 0"})]}),e.jsxs("li",{children:["Cramer's Rule: ",e.jsx(i,{children:"x_i = \\det(A_i) / \\det(A)"})]}),e.jsxs("li",{children:[e.jsx(i,{children:"|\\det(A)|"})," = volume scaling factor; sign = orientation"]})]})]}),e.jsx(l,{sectionId:9,questions:c,title:"Determinants Quiz"})]})}export{u as default};
