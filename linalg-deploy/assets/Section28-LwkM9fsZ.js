import{j as s}from"./vendor-animation-6GFvN5rC.js";import{L as l,D as a,T as r,E as n}from"./ContentBlocks-ByGNY4hF.js";import{I as e,M as i}from"./MathBlock-BTK9YHZB.js";import"./vendor-react-ByzHzWFU.js";import"./index-CIaFkRw9.js";import"./vendor-math-ClxlXyPc.js";import"./vendor-firebase-core-DIJkQv9Q.js";import"./index-Djvuv9mj.js";function g(){return s.jsxs(l,{sectionId:28,children:[s.jsxs("p",{children:[s.jsx("strong",{children:"Image processing"})," is a perfect application of linear algebra. A grayscale image is simply a matrix of pixel values, and operations like compression, denoising, and filtering are matrix operations."]}),s.jsx("h2",{children:"Images as Matrices"}),s.jsxs(a,{title:"Image Matrix",className:"my-6",children:[s.jsxs("p",{children:["A grayscale image with ",s.jsx(e,{children:"m"})," rows and ",s.jsx(e,{children:"n"})," columns is an ",s.jsx(e,{children:"m \\times n"})," matrix:"]}),s.jsx(i,{children:"A = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix}"}),s.jsxs("p",{className:"mt-2",children:["Each entry ",s.jsx(e,{children:"a_{ij}"})," is a pixel intensity (0 = black, 255 = white for 8-bit images)."]})]}),s.jsx("h2",{children:"The Singular Value Decomposition"}),s.jsxs(r,{title:"SVD for Images",className:"my-6",proof:s.jsxs(s.Fragment,{children:[s.jsxs("p",{children:["The SVD exists for any matrix. The construction uses eigenvalues of ",s.jsx(e,{children:"A^TA"})," and ",s.jsx(e,{children:"AA^T"}),":"]}),s.jsxs("p",{className:"mt-2",children:[s.jsx("strong",{children:"Step 1:"})," ",s.jsx(e,{children:"A^TA"})," is symmetric and positive semidefinite, so it has orthonormal eigenvectors ",s.jsx(e,{children:"v_i"})," with eigenvalues ",s.jsx(e,{children:"\\lambda_i \\geq 0"}),"."]}),s.jsxs("p",{className:"mt-2",children:[s.jsx("strong",{children:"Step 2:"})," Define ",s.jsx(e,{children:"\\sigma_i = \\sqrt{\\lambda_i}"})," and order so ",s.jsx(e,{children:"\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq 0"}),"."]}),s.jsxs("p",{className:"mt-2",children:[s.jsx("strong",{children:"Step 3:"})," For nonzero ",s.jsx(e,{children:"\\sigma_i"}),", define ",s.jsx(e,{children:"u_i = Av_i/\\sigma_i"}),". These are orthonormal since:"]}),s.jsx(i,{children:"u_i^T u_j = \\frac{(Av_i)^T(Av_j)}{\\sigma_i\\sigma_j} = \\frac{v_i^T A^T A v_j}{\\sigma_i\\sigma_j} = \\frac{\\lambda_j v_i^T v_j}{\\sigma_i\\sigma_j} = \\delta_{ij}"}),s.jsxs("p",{className:"mt-2",children:[s.jsx("strong",{children:"Step 4:"})," Extend ",s.jsx(e,{children:"\\{u_1, \\ldots, u_r\\}"})," to an orthonormal basis of ",s.jsx(e,{children:"\\mathbb{R}^m"}),". Then ",s.jsx(e,{children:"AV = U\\Sigma"}),", giving ",s.jsx(e,{children:"A = U\\Sigma V^T"}),"."]})]}),children:[s.jsxs("p",{children:["Any ",s.jsx(e,{children:"m \\times n"})," matrix ",s.jsx(e,{children:"A"})," can be factored as:"]}),s.jsx(i,{children:"A = U\\Sigma V^T"}),s.jsx("p",{className:"mt-2",children:"where:"}),s.jsxs("ul",{className:"list-disc list-inside space-y-1",children:[s.jsxs("li",{children:[s.jsx(e,{children:"U"})," is ",s.jsx(e,{children:"m \\times m"})," orthogonal (left singular vectors)"]}),s.jsxs("li",{children:[s.jsx(e,{children:"\\Sigma"})," is ",s.jsx(e,{children:"m \\times n"})," diagonal (singular values ",s.jsx(e,{children:"\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq 0"}),")"]}),s.jsxs("li",{children:[s.jsx(e,{children:"V"})," is ",s.jsx(e,{children:"n \\times n"})," orthogonal (right singular vectors)"]})]})]}),s.jsx("h2",{children:"Low-Rank Approximation"}),s.jsxs(r,{title:"Eckart-Young Theorem",className:"my-6",proof:s.jsxs(s.Fragment,{children:[s.jsxs("p",{children:["We prove this for the Frobenius norm. For any rank-",s.jsx(e,{children:"k"})," matrix ",s.jsx(e,{children:"B"}),":"]}),s.jsx(i,{children:"\\|A - B\\|_F^2 = \\sum_{i,j}(a_{ij} - b_{ij})^2"}),s.jsxs("p",{className:"mt-2",children:["Using orthogonal invariance of the Frobenius norm and the SVD ",s.jsx(e,{children:"A = U\\Sigma V^T"}),":"]}),s.jsx(i,{children:"\\|A - B\\|_F^2 = \\|U^T(A-B)V\\|_F^2 = \\|\\Sigma - U^TBV\\|_F^2"}),s.jsxs("p",{className:"mt-2",children:["Let ",s.jsx(e,{children:"C = U^TBV"}),". Since ",s.jsx(e,{children:"B"})," has rank ",s.jsx(e,{children:"k"}),", so does ",s.jsx(e,{children:"C"}),"."]}),s.jsxs("p",{className:"mt-2",children:["The minimum ",s.jsx(e,{children:"\\|\\Sigma - C\\|_F^2"})," over rank-",s.jsx(e,{children:"k"})," matrices ",s.jsx(e,{children:"C"})," is achieved when ",s.jsx(e,{children:"C"})," keeps the first ",s.jsx(e,{children:"k"})," diagonal entries of ",s.jsx(e,{children:"\\Sigma"})," and zeros the rest:"]}),s.jsx(i,{children:"\\|A - A_k\\|_F^2 = \\sigma_{k+1}^2 + \\cdots + \\sigma_r^2"})]}),children:[s.jsxs("p",{children:["The best rank-",s.jsx(e,{children:"k"})," approximation to ",s.jsx(e,{children:"A"})," uses the first ",s.jsx(e,{children:"k"})," singular values:"]}),s.jsx(i,{children:"A_k = \\sum_{i=1}^{k} \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T"}),s.jsxs("p",{className:"mt-2",children:["This minimizes ",s.jsx(e,{children:"\\|A - A_k\\|"})," over all rank-",s.jsx(e,{children:"k"})," matrices."]})]}),s.jsxs(n,{title:"Image Compression",className:"my-6",children:[s.jsx("p",{children:"A 1000×1000 image requires 1,000,000 numbers to store."}),s.jsx("p",{className:"mt-2",children:"With rank-50 SVD approximation, we store:"}),s.jsxs("ul",{className:"list-disc list-inside mt-2",children:[s.jsx("li",{children:"50 singular values"}),s.jsxs("li",{children:["50 columns of ",s.jsx(e,{children:"U"})," (50,000 numbers)"]}),s.jsxs("li",{children:["50 columns of ",s.jsx(e,{children:"V"})," (50,000 numbers)"]})]}),s.jsx("p",{className:"mt-2 text-primary-400",children:"Total: ~100,000 numbers = 90% compression!"})]}),s.jsx("h2",{children:"Sum of Rank-One Matrices"}),s.jsxs(a,{title:"Outer Product Form",className:"my-6",children:[s.jsxs("p",{children:["The SVD writes ",s.jsx(e,{children:"A"})," as a sum of rank-one matrices:"]}),s.jsx(i,{children:"A = \\sigma_1 \\mathbf{u}_1 \\mathbf{v}_1^T + \\sigma_2 \\mathbf{u}_2 \\mathbf{v}_2^T + \\cdots + \\sigma_r \\mathbf{u}_r \\mathbf{v}_r^T"}),s.jsxs("p",{className:"mt-2",children:["Each ",s.jsx(e,{children:"\\mathbf{u}_i \\mathbf{v}_i^T"})," is an ",s.jsx(e,{children:"m \\times n"})," matrix with rank 1. The singular values tell us the importance of each component."]})]}),s.jsxs("div",{className:"bg-dark-800/50 rounded-xl p-4 my-6 border border-primary-500/20",children:[s.jsx("p",{className:"font-semibold text-primary-400 mb-2",children:"Image Processing Applications"}),s.jsxs("ul",{className:"list-disc list-inside text-dark-300 text-sm space-y-1",children:[s.jsxs("li",{children:[s.jsx("strong",{children:"Compression:"})," Keep only large singular values"]}),s.jsxs("li",{children:[s.jsx("strong",{children:"Denoising:"})," Small singular values often represent noise"]}),s.jsxs("li",{children:[s.jsx("strong",{children:"Face recognition:"}),' "Eigenfaces" from SVD of face images']}),s.jsxs("li",{children:[s.jsx("strong",{children:"Background removal:"})," Separate foreground from low-rank background"]})]})]}),s.jsx("h2",{children:"Computing the SVD"}),s.jsxs(r,{title:"SVD from Eigenvalues",className:"my-6",proof:s.jsxs(s.Fragment,{children:[s.jsxs("p",{children:["From the SVD ",s.jsx(e,{children:"A = U\\Sigma V^T"}),", compute ",s.jsx(e,{children:"A^TA"})," and ",s.jsx(e,{children:"AA^T"}),":"]}),s.jsx(i,{children:"A^TA = (V\\Sigma^T U^T)(U\\Sigma V^T) = V\\Sigma^T\\Sigma V^T"}),s.jsxs("p",{className:"mt-2",children:["Since ",s.jsx(e,{children:"U^TU = I"}),". The matrix ",s.jsx(e,{children:"\\Sigma^T\\Sigma"})," is diagonal with entries ",s.jsx(e,{children:"\\\\sigma_i^2"}),"."]}),s.jsxs("p",{className:"mt-2",children:["Thus ",s.jsx(e,{children:"A^TAV = V(\\\\Sigma^T\\\\Sigma)"}),", showing that columns of ",s.jsx(e,{children:"V"})," are eigenvectors of ",s.jsx(e,{children:"A^TA"})," with eigenvalues ",s.jsx(e,{children:"\\\\sigma_i^2"}),"."]}),s.jsx("p",{className:"mt-2",children:"Similarly:"}),s.jsx(i,{children:"AA^T = (U\\Sigma V^T)(V\\Sigma^T U^T) = U\\Sigma\\Sigma^T U^T"}),s.jsxs("p",{className:"mt-2",children:["So columns of ",s.jsx(e,{children:"U"})," are eigenvectors of ",s.jsx(e,{children:"AA^T"})," with the same eigenvalues ",s.jsx(e,{children:"\\\\sigma_i^2"}),"."]})]}),children:[s.jsx("p",{children:"The SVD is computed using eigenvalues:"}),s.jsxs("ul",{className:"list-disc list-inside space-y-2",children:[s.jsxs("li",{children:[s.jsx(e,{children:"A^TA = V\\Sigma^T\\Sigma V^T"})," — the ",s.jsx(e,{children:"v_i"})," are eigenvectors of ",s.jsx(e,{children:"A^TA"})]}),s.jsxs("li",{children:[s.jsx(e,{children:"AA^T = U\\Sigma\\Sigma^T U^T"})," — the ",s.jsx(e,{children:"u_i"})," are eigenvectors of ",s.jsx(e,{children:"AA^T"})]}),s.jsxs("li",{children:[s.jsx(e,{children:"\\sigma_i = \\sqrt{\\lambda_i}"})," where ",s.jsx(e,{children:"\\lambda_i"})," are eigenvalues of ",s.jsx(e,{children:"A^TA"})]})]})]}),s.jsxs(n,{title:"2×2 SVD",className:"my-6",children:[s.jsx(i,{children:"A = \\begin{bmatrix} 4 & 0 \\\\ 3 & -5 \\end{bmatrix}"}),s.jsx("p",{className:"mt-2",children:s.jsx(e,{children:"A^TA = \\begin{bmatrix} 25 & -15 \\\\\\\\ -15 & 25 \\end{bmatrix}"})}),s.jsxs("p",{className:"mt-2",children:["Eigenvalues of ",s.jsx(e,{children:"A^TA"}),": ",s.jsx(e,{children:"\\lambda_1 = 40"}),", ",s.jsx(e,{children:"\\lambda_2 = 10"})]}),s.jsxs("p",{className:"mt-2",children:["Singular values: ",s.jsx(e,{children:"\\sigma_1 = \\sqrt{40} \\approx 6.32"}),", ",s.jsx(e,{children:"\\sigma_2 = \\sqrt{10} \\approx 3.16"})]})]}),s.jsx("h2",{children:"Key Ideas"}),s.jsx("div",{className:"bg-gradient-to-br from-primary-500/10 to-dark-800/50 rounded-xl p-6 my-6 border border-primary-500/20",children:s.jsxs("ul",{className:"space-y-3 text-dark-200",children:[s.jsxs("li",{className:"flex items-start gap-3",children:[s.jsx("span",{className:"text-primary-400 font-bold",children:"1."}),s.jsx("span",{children:"Images are matrices; pixel values are matrix entries."})]}),s.jsxs("li",{className:"flex items-start gap-3",children:[s.jsx("span",{className:"text-primary-400 font-bold",children:"2."}),s.jsxs("span",{children:[s.jsx(e,{children:"A = U\\Sigma V^T"})," decomposes any matrix into orthogonal and diagonal parts."]})]}),s.jsxs("li",{className:"flex items-start gap-3",children:[s.jsx("span",{className:"text-primary-400 font-bold",children:"3."}),s.jsxs("span",{children:["The best rank-",s.jsx(e,{children:"k"})," approximation uses the ",s.jsx(e,{children:"k"})," largest singular values."]})]}),s.jsxs("li",{className:"flex items-start gap-3",children:[s.jsx("span",{className:"text-primary-400 font-bold",children:"4."}),s.jsx("span",{children:"SVD enables image compression by discarding small singular values."})]}),s.jsxs("li",{className:"flex items-start gap-3",children:[s.jsx("span",{className:"text-primary-400 font-bold",children:"5."}),s.jsxs("span",{children:["Singular values come from eigenvalues of ",s.jsx(e,{children:"A^TA"}),"."]})]})]})})]})}export{g as default};
