const t=[{id:1,type:"multiple-choice",question:"How many axioms define a linear space?",options:["6","8","10","12"],correctIndex:2,difficulty:"easy",explanation:"A linear space is defined by 10 axioms: 2 closure axioms, 4 axioms for addition, and 4 axioms for multiplication by scalars."},{id:2,type:"multiple-choice",question:"Which axiom guarantees that $x + y = y + x$ for all elements in a linear space?",options:["Associative law","Commutative law","Distributive law","Closure axiom"],correctIndex:1,difficulty:"easy",explanation:"The commutative law (Axiom 3) states that $x + y = y + x$ for all $x$ and $y$ in the linear space $V$."},{id:3,type:"multiple-choice",question:"In a linear space $V$, the element $(-1)x$ satisfies which property?",options:["$x + (-1)x = 0$","$x + (-1)x = x$","$(-1)x = x$","$(-1)x = 1$"],correctIndex:0,difficulty:"medium",explanation:"Axiom 6 (existence of negatives) states that for every $x$ in $V$, the element $(-1)x$ satisfies $x + (-1)x = 0$."},{id:4,type:"multiple-choice",question:"Which of the following is NOT a requirement for closure under scalar multiplication?",options:["The result must be in $V$","The scalar must be nonzero","The scalar must be real (for a real linear space)","The element $x$ must be in $V$"],correctIndex:1,difficulty:"medium",explanation:"Closure under scalar multiplication requires that for every $x$ in $V$ and every real number $a$ (including zero), the product $ax$ is in $V$. The scalar can be zero."},{id:5,type:"multiple-choice",question:"What distinguishes a complex linear space from a real linear space?",options:["The elements are complex numbers","There are more axioms","The scalars are complex numbers","The zero element is different"],correctIndex:2,difficulty:"medium",explanation:"A complex linear space uses complex numbers as scalars, while a real linear space uses real numbers as scalars. The nature of the elements can be the same in both cases."}],i=[{id:1,type:"multiple-choice",question:"Which of the following is an example of a real linear space?",options:["The set of all polynomials of degree exactly $n$","The set of solutions to $y'' + y = 1$","The set of all functions $f$ with $f(1) = 5$","The set of all polynomials of degree $\\leq n$"],correctIndex:3,difficulty:"medium",explanation:"The set of polynomials of degree $\\leq n$ forms a linear space. The sum of two such polynomials has degree $\\leq n$, and scalar multiples have degree $\\leq n$. The other options fail closure axioms."},{id:2,type:"multiple-choice",question:"Why is the set of all polynomials of degree exactly $n$ NOT a linear space?",options:["Addition of two degree-$n$ polynomials may not have degree $n$","It lacks a zero element","It is not closed under scalar multiplication","It contains infinitely many elements"],correctIndex:0,difficulty:"medium",explanation:"The sum of two polynomials of degree $n$ may have degree less than $n$ if the leading coefficients cancel. For example, $(x^n + x) + (-x^n + 1) = x + 1$ has degree 1, not $n$."},{id:3,type:"multiple-choice",question:"In the function space definition, how is $(f + g)(x)$ defined?",options:["$f(g(x))$","$f(x) + g(x)$","$f(x) \\cdot g(x)$","$f(x + g(x))$"],correctIndex:1,difficulty:"easy",explanation:"In function spaces, the sum of two functions $f$ and $g$ is defined pointwise: $(f + g)(x) = f(x) + g(x)$ for every $x$ in the intersection of their domains."},{id:4,type:"multiple-choice",question:"The set of all solutions to the homogeneous differential equation $y'' + ay' + by = 0$ forms a linear space. What happens if we consider $y'' + ay' + by = c$ where $c \\neq 0$?",options:["It forms a different linear space","It forms the same linear space","It fails to be a linear space","It depends on the values of $a$ and $b$"],correctIndex:2,difficulty:"hard",explanation:"The set of solutions to a nonhomogeneous equation does not form a linear space because it fails the closure axioms. If $y_1$ and $y_2$ are solutions, then $y_1 + y_2$ satisfies $y'' + ay' + by = 2c \\neq c$."},{id:5,type:"multiple-choice",question:"Which of the following is the zero element in the function space of all continuous functions on $[a, b]$?",options:["The empty function","The function $f(x) = 1$","The function $f(x) = x$","The function $f(x) = 0$ for all $x$"],correctIndex:3,difficulty:"easy",explanation:"The zero element in a function space is the function whose value is 0 for every $x$ in its domain. This satisfies $f + 0 = f$ for all functions $f$."}],n=[{id:1,type:"multiple-choice",question:"In any linear space, how many zero elements exist?",options:["None","Exactly one","At least one","Infinitely many"],correctIndex:1,difficulty:"easy",explanation:"Theorem 1.1 proves that in any linear space there is one and only one zero element. If there were two, say $O_1$ and $O_2$, then $O_1 = O_1 + O_2 = O_2$."},{id:2,type:"multiple-choice",question:"If $0 \\cdot x = z$ for an element $x$ in a linear space, what is $z$?",options:["$x$","$-x$","$0$ (the zero element)","$1$"],correctIndex:2,difficulty:"easy",explanation:"Theorem 1.3(a) states that $0 \\cdot x = 0$ (the zero element) for any element $x$ in a linear space. This follows from $z + z = (0 + 0)x = 0 \\cdot x = z$, so $z = 0$."},{id:3,type:"multiple-choice",question:"If $ax = 0$ in a linear space, what can we conclude?",options:["Either $a = 0$ or $x = 0$","$x = 0$","$a = 0$","Both $a = 0$ and $x = 0$"],correctIndex:0,difficulty:"medium",explanation:"Theorem 1.3(d) states that if $ax = 0$, then either $a = 0$ or $x = 0$ (or both). This is analogous to the zero product property for real numbers."},{id:4,type:"multiple-choice",question:"If $ax = ay$ and $a \\neq 0$, what can we conclude?",options:["$a = 0$","$x = y$","$x = -y$","Nothing"],correctIndex:1,difficulty:"medium",explanation:"Theorem 1.3(e) states that if $ax = ay$ and $a \\neq 0$, then $x = y$. This is the cancellation law for scalar multiplication."},{id:5,type:"multiple-choice",question:"What is $(-a)x$ equal to in a linear space?",options:["$ax$","Both $-(ax)$ and $a(-x)$","$a(-x)$","$-(ax)$"],correctIndex:1,difficulty:"medium",explanation:"Theorem 1.3(c) states that $(-a)x = -(ax) = a(-x)$. All three expressions represent the same element, which is the negative of $ax$."}],a=[{id:1,type:"multiple-choice",question:"What must a nonempty subset $S$ of a linear space $V$ satisfy to be a subspace?",options:["All 10 linear space axioms","Only the axioms involving the zero element","Only the closure axioms","None of the axioms (it is automatic)"],correctIndex:2,difficulty:"medium",explanation:"Theorem 1.4 states that a nonempty subset $S$ is a subspace if and only if it satisfies the closure axioms. The other axioms are inherited from the parent space $V$."},{id:2,type:"multiple-choice",question:"If $S$ is a subspace of $V$, which element must $S$ contain?",options:["Every element of $V$","At least one nonzero element","All unit vectors","The zero element"],correctIndex:3,difficulty:"easy",explanation:"If $S$ is a subspace and $x \\in S$, then $0 \\cdot x = 0$ must be in $S$ by closure under scalar multiplication. So every subspace contains the zero element."},{id:3,type:"multiple-choice",question:"What is the linear span $L(S)$ of a set $S$ in a linear space?",options:["The smallest subspace containing $S$","The largest subspace contained in $S$","The set $S$ itself","The complement of $S$ in $V$"],correctIndex:0,difficulty:"medium",explanation:"The linear span $L(S)$ is the set of all finite linear combinations of elements in $S$. It is the smallest subspace containing $S$."},{id:4,type:"multiple-choice",question:"Which of the following sets spans the space of polynomials of degree $\\leq 2$?",options:["$\\{1, t\\}$","$\\{1, t, t^2\\}$","$\\{t, t^2, t^3\\}$","$\\{1\\}$"],correctIndex:1,difficulty:"easy",explanation:"The set $\\{1, t, t^2\\}$ spans all polynomials of degree $\\leq 2$ because any such polynomial $a_0 + a_1t + a_2t^2$ is a linear combination of these three polynomials."},{id:5,type:"multiple-choice",question:"What is $L(\\emptyset)$, the linear span of the empty set?",options:["The entire space $V$","The empty set","$\\{0\\}$, the set containing only the zero element","Undefined"],correctIndex:2,difficulty:"medium",explanation:"By convention, $L(\\emptyset) = \\{0\\}$, the trivial subspace containing only the zero element. This is the smallest possible subspace."}],o=[{id:1,type:"multiple-choice",question:"A set $S$ is called dependent if there exist elements $x_1, \\ldots, x_k$ in $S$ and scalars $c_1, \\ldots, c_k$ such that $\\sum_{i=1}^k c_i x_i = 0$. What additional condition must hold?",options:["All $c_i = 0$","At least one $c_i > 0$","All $c_i = 1$","Not all $c_i = 0$"],correctIndex:3,difficulty:"medium",explanation:"For a set to be dependent, there must exist a nontrivial linear combination equal to zero, meaning not all coefficients $c_i$ are zero."},{id:2,type:"multiple-choice",question:"If a set $S$ contains the zero element, what can we conclude about $S$?",options:["$S$ is dependent","$S$ is independent","$S$ spans the entire space","Nothing specific"],correctIndex:0,difficulty:"easy",explanation:"If $0 \\in S$, then $1 \\cdot 0 = 0$ is a nontrivial representation of zero (since the coefficient 1 is nonzero), so $S$ is dependent."},{id:3,type:"multiple-choice",question:"If $T$ is a subset of $S$ and $T$ is dependent, what can we conclude about $S$?",options:["$S$ is independent","$S$ is dependent","$S$ is a subspace","Nothing specific"],correctIndex:1,difficulty:"medium",explanation:"If a subset $T$ of $S$ is dependent, then $S$ is also dependent because the nontrivial linear combination in $T$ is also a nontrivial linear combination in $S$."},{id:4,type:"multiple-choice",question:"Are the functions $u_1(t) = \\cos^2 t$, $u_2(t) = \\sin^2 t$, and $u_3(t) = 1$ dependent or independent?",options:["Independent","Dependent, because $u_1 = u_2$","Dependent, because $u_1 + u_2 - u_3 = 0$","It depends on the domain"],correctIndex:2,difficulty:"medium",explanation:"By the Pythagorean identity, $\\cos^2 t + \\sin^2 t = 1$ for all $t$, so $u_1 + u_2 - u_3 = 0$. This is a nontrivial linear combination equal to zero, so the functions are dependent."},{id:5,type:"multiple-choice",question:"According to Theorem 1.5, if $S = \\{x_1, \\ldots, x_k\\}$ is an independent set spanning subspace $L(S)$, what can we say about any set of $k+1$ elements in $L(S)$?",options:["It is always independent","It may or may not be dependent","It always spans $L(S)$","It is always dependent"],correctIndex:3,difficulty:"hard",explanation:'Theorem 1.5 states that every set of $k + 1$ elements in $L(S)$ is dependent. This fundamental result limits the "size" of independent sets in a subspace.'}],s=[{id:1,type:"multiple-choice",question:"A finite set $S$ is a basis for $V$ if and only if:",options:["$S$ is independent and spans $V$","$S$ spans $V$","$S$ is independent","$S$ contains the zero element"],correctIndex:0,difficulty:"easy",explanation:"A finite basis must satisfy two conditions: (1) the elements are linearly independent, and (2) the elements span the entire space $V$."},{id:2,type:"numeric",question:"What is the dimension of the space of all polynomials of degree $\\leq 4$?",correctAnswer:5,numericRange:{min:0,max:20,precision:0},difficulty:"easy",explanation:"A basis is $\\{1, t, t^2, t^3, t^4\\}$, which has 5 elements. Therefore $\\dim V = 5$."},{id:3,type:"multiple-choice",question:"If $V$ has dimension $n$ and $S$ is an independent set with $n$ elements, what is $S$?",options:["A proper subset of some basis","A basis for $V$","Larger than any basis","It depends on the specific elements"],correctIndex:1,difficulty:"medium",explanation:"Theorem 1.7(b) states that any set of $n$ independent elements in an $n$-dimensional space is automatically a basis."},{id:4,type:"multiple-choice",question:"The components of an element $x$ relative to an ordered basis $(e_1, \\ldots, e_n)$ are:",options:["Always positive","The same for all bases","Uniquely determined by $x$","Not well-defined"],correctIndex:2,difficulty:"medium",explanation:"If $x = \\sum c_i e_i$, the coefficients $(c_1, \\ldots, c_n)$ are uniquely determined because the basis elements are independent. Different representations would imply dependence."},{id:5,type:"numeric",question:"The solution space of the differential equation $y'' - 2y' - 3y = 0$ has what dimension?",correctAnswer:2,numericRange:{min:0,max:10,precision:0},difficulty:"medium",explanation:"The solution space is spanned by $\\{e^{-x}, e^{3x}\\}$, which are linearly independent. Therefore the dimension is 2."}],r=[{id:1,type:"multiple-choice",question:"Which of the following is NOT one of the four axioms for an inner product?",options:["Symmetry: $(x, y) = (y, x)$","Additivity: $(x + y, z) = (x, z) + (y, z)$","Positivity: $(x, x) \\geq 0$ with equality iff $x = 0$","Associativity: $((x, y), z) = (x, (y, z))$"],correctIndex:3,difficulty:"medium",explanation:"The four axioms are symmetry, additivity, homogeneity $(cx, y) = c(x, y)$, and positivity. There is no associativity axiom for inner products, as the result of an inner product is a scalar, not an element of $V$."},{id:2,type:"multiple-choice",question:"In the standard inner product on $V_n$, what is $(x, y)$?",options:["$\\sum_{i=1}^n x_i y_i$","$\\sum_{i=1}^n x_i + y_i$","$\\sum_{i=1}^n |x_i - y_i|$","$\\max_i |x_i y_i|$"],correctIndex:0,difficulty:"easy",explanation:"The standard inner product (dot product) on $V_n$ is defined as $(x, y) = \\sum_{i=1}^n x_i y_i$."},{id:3,type:"multiple-choice",question:"What does the Cauchy-Schwarz inequality state about an inner product?",options:["$|(x, y)| = \\|x\\| \\|y\\|$","$|(x, y)|^2 \\leq (x, x)(y, y)$","$(x, y) \\geq 0$","$|(x, y)| > (x, x)$"],correctIndex:1,difficulty:"medium",explanation:"The Cauchy-Schwarz inequality states $|(x, y)|^2 \\leq (x, x)(y, y)$, or equivalently $|(x, y)| \\leq \\|x\\| \\|y\\|$. Equality holds iff $x$ and $y$ are dependent."},{id:4,type:"multiple-choice",question:"How is the norm $\\|x\\|$ defined in a Euclidean space?",options:["$\\|x\\| = (x, x)$","$\\|x\\| = |(x, x)|$","$\\|x\\| = (x, x)^{1/2}$","$\\|x\\| = (x, x)^2$"],correctIndex:2,difficulty:"easy",explanation:"The norm is defined as $\\|x\\| = (x, x)^{1/2} = \\sqrt{(x, x)}$, the square root of the inner product of $x$ with itself."},{id:5,type:"multiple-choice",question:"The angle $\\theta$ between two nonzero elements $x$ and $y$ satisfies:",options:["$\\sin \\theta = \\frac{(x, y)}{\\|x\\| \\|y\\|}$","$\\theta = \\frac{(x, y)}{\\|x\\| \\|y\\|}$","$\\tan \\theta = \\frac{(x, y)}{\\|x\\| \\|y\\|}$","$\\cos \\theta = \\frac{(x, y)}{\\|x\\| \\|y\\|}$"],correctIndex:3,difficulty:"easy",explanation:"The angle between $x$ and $y$ is defined by $\\cos \\theta = \\frac{(x, y)}{\\|x\\| \\|y\\|}$, where $0 \\leq \\theta \\leq \\pi$."}],$=[{id:1,type:"multiple-choice",question:"Two elements $x$ and $y$ in a Euclidean space are orthogonal if:",options:["$(x, y) = 0$","$(x, y) = 1$","$\\|x\\| = \\|y\\|$","$x = y$"],correctIndex:0,difficulty:"easy",explanation:"Two elements are orthogonal (perpendicular) if and only if their inner product is zero: $(x, y) = 0$."},{id:2,type:"multiple-choice",question:"An orthonormal set is an orthogonal set where each element has:",options:["Norm 0","Norm 1","The same norm","Integer norm"],correctIndex:1,difficulty:"easy",explanation:"An orthonormal set is an orthogonal set where every element has norm 1, i.e., $\\|e_i\\| = 1$ for all elements in the set."},{id:3,type:"multiple-choice",question:"If $\\{e_1, \\ldots, e_n\\}$ is an orthogonal set of nonzero elements, what can we conclude?",options:["The set is dependent","The set spans $V$","The set is independent","The set contains the zero element"],correctIndex:2,difficulty:"medium",explanation:"Theorem 1.10 states that every orthogonal set of nonzero elements is linearly independent. To prove dependence, we would need $(x_i, x_j) \\neq 0$ for some $i \\neq j$."},{id:4,type:"multiple-choice",question:"If $\\{e_1, \\ldots, e_n\\}$ is an orthonormal basis and $x = \\sum c_i e_i$, then $c_j$ equals:",options:["$\\|x\\|$","$\\frac{(x, e_j)}{(e_j, e_j)}$","$(e_j, e_j)$","$(x, e_j)$"],correctIndex:3,difficulty:"medium",explanation:"For an orthonormal basis, the component $c_j = (x, e_j)$ because $(e_j, e_j) = 1$. For a general orthogonal basis, $c_j = \\frac{(x, e_j)}{(e_j, e_j)}$."},{id:5,type:"multiple-choice",question:"Parseval's formula for an orthonormal basis states that $\\|x\\|^2$ equals:",options:["$\\sum_i |(x, e_i)|^2$","$\\sum_i (x, e_i)$","$\\max_i |(x, e_i)|$","$\\prod_i (x, e_i)$"],correctIndex:0,difficulty:"medium",explanation:"Parseval's formula states $\\|x\\|^2 = \\sum_{i=1}^n |(x, e_i)|^2$. This generalizes the Pythagorean theorem: the square of the norm equals the sum of squares of the components."}],l=[{id:1,type:"multiple-choice",question:"The Gram-Schmidt process takes a sequence of elements and produces:",options:["A dependent sequence","An orthogonal sequence spanning the same subspaces","A sequence of unit vectors","A sequence of zero vectors"],correctIndex:1,difficulty:"medium",explanation:"The Gram-Schmidt process transforms a sequence $x_1, x_2, \\ldots$ into an orthogonal sequence $y_1, y_2, \\ldots$ such that $L(y_1, \\ldots, y_k) = L(x_1, \\ldots, x_k)$ for each $k$."},{id:2,type:"multiple-choice",question:"In the Gram-Schmidt process, $y_{r+1}$ is computed by:",options:["$y_{r+1} = x_{r+1}$","$y_{r+1} = \\sum_{i=1}^r x_i$","$y_{r+1} = x_{r+1} - \\sum_{i=1}^r \\frac{(x_{r+1}, y_i)}{(y_i, y_i)} y_i$","$y_{r+1} = x_{r+1} / \\|x_{r+1}\\|$"],correctIndex:2,difficulty:"hard",explanation:"The formula subtracts from $x_{r+1}$ its projections along each of the previously computed orthogonal vectors $y_1, \\ldots, y_r$."},{id:3,type:"multiple-choice",question:"What is the projection of $x$ along $y$ (assuming $y \\neq 0$)?",options:["$(x, y)$","$(x, y) y$","$\\frac{(x, y)}{\\|y\\|}$","$\\frac{(x, y)}{(y, y)} y$"],correctIndex:3,difficulty:"medium",explanation:"The projection of $x$ along $y$ is $\\frac{(x, y)}{(y, y)} y$. This is the component of $x$ in the direction of $y$."},{id:4,type:"multiple-choice",question:"If the Gram-Schmidt process yields $y_k = 0$ at some step, what does this indicate?",options:["The original vectors $x_1, \\ldots, x_k$ are dependent","The process has failed","The original vectors are orthogonal","The inner product is zero"],correctIndex:0,difficulty:"medium",explanation:"If $y_k = 0$ during Gram-Schmidt, it means $x_k$ lies in the span of $x_1, \\ldots, x_{k-1}$, so these vectors are linearly dependent."},{id:5,type:"multiple-choice",question:"The Legendre polynomials are obtained by applying Gram-Schmidt to $\\{1, t, t^2, \\ldots\\}$ with which inner product?",options:["$(f, g) = f(0)g(0)$","$(f, g) = \\int_{-1}^1 fg\\, dt$","$(f, g) = \\int_0^1 fg\\, dt$","$(f, g) = f(1)g(1) + f(-1)g(-1)$"],correctIndex:1,difficulty:"hard",explanation:"The Legendre polynomials are obtained using the inner product $(f, g) = \\int_{-1}^1 f(t)g(t)\\, dt$ on the space of polynomials."}],c=[{id:1,type:"multiple-choice",question:"The orthogonal complement $S^\\perp$ of a subset $S$ consists of:",options:["All elements equal to elements in $S$","The largest subspace containing $S$","All elements orthogonal to every element of $S$","The intersection of $S$ with itself"],correctIndex:2,difficulty:"easy",explanation:"$S^\\perp$ is the set of all elements that are orthogonal to every element of $S$. It is always a subspace, even if $S$ is not."},{id:2,type:"multiple-choice",question:"The Orthogonal Decomposition Theorem states that every $x \\in V$ can be written uniquely as:",options:["$x = s$ where $s \\in S$","$x = s - s^\\perp$ where $s \\in S$ and $s^\\perp \\in S^\\perp$","$x = 2s$ where $s \\in S$","$x = s + s^\\perp$ where $s \\in S$ and $s^\\perp \\in S^\\perp$"],correctIndex:3,difficulty:"medium",explanation:"Every element can be decomposed uniquely into a component in $S$ and a component orthogonal to $S$. The norm satisfies $\\|x\\|^2 = \\|s\\|^2 + \\|s^\\perp\\|^2$ (Pythagorean formula)."},{id:3,type:"multiple-choice",question:"The projection of $x$ onto a finite-dimensional subspace $S$ with orthonormal basis $\\{e_1, \\ldots, e_n\\}$ is:",options:["$\\sum_{i=1}^n (x, e_i) e_i$","$\\sum_{i=1}^n e_i$","$\\sum_{i=1}^n (e_i, e_i) x$","$(x, x)$"],correctIndex:0,difficulty:"medium",explanation:"The projection is $s = \\sum_{i=1}^n (x, e_i) e_i$, which is the sum of the projections of $x$ along each basis vector."},{id:4,type:"multiple-choice",question:"According to the Approximation Theorem, the element of $S$ nearest to $x$ is:",options:["Any element of $S$","The projection of $x$ onto $S$","The zero element","The element of $S$ with largest norm"],correctIndex:1,difficulty:"medium",explanation:"The best approximation theorem states that the projection of $x$ onto $S$ is the unique element of $S$ that minimizes the distance $\\|x - t\\|$ over all $t \\in S$."},{id:5,type:"multiple-choice",question:"Fourier coefficients $a_k = \\frac{1}{\\pi}\\int_0^{2\\pi} f(x)\\cos kx\\, dx$ arise from projecting $f$ onto:",options:["The space of all functions","The space of polynomials","The subspace spanned by trigonometric functions","The zero subspace"],correctIndex:2,difficulty:"hard",explanation:"Fourier coefficients come from projecting $f$ onto the subspace spanned by $\\{1, \\cos x, \\sin x, \\cos 2x, \\sin 2x, \\ldots\\}$, which form an orthogonal set in $C(0, 2\\pi)$."}],d=[{id:1,type:"multiple-choice",question:"A function $T: V \\to W$ is a linear transformation if it satisfies:",options:["$T(x + y) = T(x) + T(y)$ only","$T(cx) = cT(x)$ only","$T(x) = x$ for all $x$","Both $T(x + y) = T(x) + T(y)$ and $T(cx) = cT(x)$"],correctIndex:3,difficulty:"easy",explanation:"A linear transformation must satisfy both additivity $T(x + y) = T(x) + T(y)$ and homogeneity $T(cx) = cT(x)$ for all elements and scalars."},{id:2,type:"multiple-choice",question:"What does a linear transformation $T$ map the zero element of $V$ to?",options:["The zero element of $W$","Any element of $W$","The identity element","It is undefined"],correctIndex:0,difficulty:"easy",explanation:"For any linear transformation, $T(0) = T(0 \\cdot x) = 0 \\cdot T(x) = 0$. The zero of $V$ always maps to the zero of $W$."},{id:3,type:"multiple-choice",question:"The null space (kernel) of a linear transformation $T: V \\to W$ is:",options:["The set of all outputs of $T$","The set of all $x$ such that $T(x) = 0$","The set $\\{0\\}$ only","The entire space $V$"],correctIndex:1,difficulty:"medium",explanation:"The null space $N(T) = \\{x \\in V : T(x) = 0\\}$ consists of all elements that $T$ maps to zero. It is always a subspace of $V$."},{id:4,type:"multiple-choice",question:"Which of the following is a linear transformation?",options:["$T(x) = x + 1$ on $\\mathbb{R}$","$T(x) = x^2$ on $\\mathbb{R}$","$T(f) = f'$ (differentiation) on differentiable functions","$T(x) = |x|$ on $\\mathbb{R}$"],correctIndex:2,difficulty:"medium",explanation:"Differentiation is linear because $(f + g)' = f' + g'$ and $(cf)' = cf'$. The others fail: $T(x) = x + 1$ fails $T(0) = 0$; $T(x) = x^2$ fails $(2x)^2 \\neq 2(x^2)$; $|x|$ fails $|-x| = |x| \\neq -|x|$."},{id:5,type:"multiple-choice",question:"The range $T(V)$ of a linear transformation $T: V \\to W$ is:",options:["Always equal to $W$","Always $\\{0\\}$","A subspace of $V$","A subspace of $W$"],correctIndex:3,difficulty:"medium",explanation:"Theorem 2.1 states that the range $T(V)$ of any linear transformation is a subspace of $W$. It may or may not equal all of $W$."}],h=[{id:1,type:"multiple-choice",question:"The nullity of a linear transformation $T$ is defined as:",options:["The dimension of the null space $N(T)$","The dimension of the range $T(V)$","The dimension of $V$","The number of eigenvalues"],correctIndex:0,difficulty:"easy",explanation:"The nullity is $\\dim N(T)$, the dimension of the null space (kernel) of the transformation."},{id:2,type:"multiple-choice",question:"The rank of a linear transformation $T$ is defined as:",options:["The dimension of the null space","The dimension of the range $T(V)$","The dimension of the domain $V$","The number of zeros in the matrix"],correctIndex:1,difficulty:"easy",explanation:"The rank is $\\dim T(V)$, the dimension of the range (image) of the transformation."},{id:3,type:"multiple-choice",question:"The Nullity Plus Rank Theorem states that for $T: V \\to W$ with $\\dim V = n$:",options:["$\\text{nullity} \\times \\text{rank} = n$","$\\text{nullity} - \\text{rank} = n$","$\\text{nullity} + \\text{rank} = n$","$\\text{nullity} = \\text{rank}$"],correctIndex:2,difficulty:"medium",explanation:"The fundamental theorem states $\\dim N(T) + \\dim T(V) = \\dim V$. Information lost (nullity) plus information preserved (rank) equals the original dimension."},{id:4,type:"numeric",question:"If $T: \\mathbb{R}^5 \\to \\mathbb{R}^3$ has nullity 2, what is the rank of $T$?",correctAnswer:3,numericRange:{min:0,max:10,precision:0},difficulty:"medium",explanation:"By the Nullity Plus Rank Theorem: $\\text{nullity} + \\text{rank} = \\dim V$, so $2 + \\text{rank} = 5$, giving $\\text{rank} = 3$."},{id:5,type:"multiple-choice",question:"For the zero transformation $T(x) = 0$ on an $n$-dimensional space:",options:["Nullity is 0, rank is $n$","Nullity and rank are both undefined","Nullity is $n/2$, rank is $n/2$","Nullity is $n$, rank is 0"],correctIndex:3,difficulty:"medium",explanation:"The zero transformation maps everything to 0, so $N(T) = V$ and $T(V) = \\{0\\}$. Thus nullity = $n$ and rank = 0."}],f=[{id:1,type:"multiple-choice",question:"If $S$ and $T$ are linear transformations from $V$ to $W$, then $(S + T)(x)$ is defined as:",options:["$S(x) + T(x)$","$S(T(x))$","$S(x) \\cdot T(x)$","$S(x + T(x))$"],correctIndex:0,difficulty:"easy",explanation:"The sum of two linear transformations is defined pointwise: $(S + T)(x) = S(x) + T(x)$ for all $x$ in $V$."},{id:2,type:"multiple-choice",question:"The composition $ST$ of transformations $T: U \\to V$ and $S: V \\to W$ is defined by:",options:["$(ST)(x) = S(x) + T(x)$","$(ST)(x) = S(T(x))$","$(ST)(x) = T(S(x))$","$(ST)(x) = S(x)T(x)$"],correctIndex:1,difficulty:"medium",explanation:"The composition $ST$ first applies $T$, then applies $S$ to the result: $(ST)(x) = S[T(x)]$."},{id:3,type:"multiple-choice",question:"If $T: U \\to V$ and $S: V \\to W$ are both linear, then the composition $ST$ is:",options:["Never linear","Linear only if $S = T$","Always linear","Linear only if one is the identity"],correctIndex:2,difficulty:"medium",explanation:"Theorem 2.6 states that the composition of two linear transformations is linear. This follows from $(ST)(ax + by) = S[aT(x) + bT(y)] = a(ST)(x) + b(ST)(y)$."},{id:4,type:"multiple-choice",question:"The associative law for composition states:",options:["$R(ST) = (ST)R$","$R + ST = RS + T$","$RST = TSR$","$R(ST) = (RS)T$"],correctIndex:3,difficulty:"medium",explanation:"Composition is associative: $R(ST) = (RS)T$. Both expressions represent applying $T$ first, then $S$, then $R$."},{id:5,type:"multiple-choice",question:"The set $\\mathcal{L}(V, W)$ of all linear transformations from $V$ to $W$ is itself:",options:["A linear space","Not a linear space","Only a subset of $V$","Equal to $V \\times W$"],correctIndex:0,difficulty:"medium",explanation:"Theorem 2.4 states that $\\mathcal{L}(V, W)$ is a linear space with the operations of addition and scalar multiplication defined for transformations."}],u=[{id:1,type:"multiple-choice",question:"A function $T: V \\to W$ is one-to-one (injective) if:",options:["$T(x) = T(y)$ for all $x, y$","$T(x) = T(y)$ implies $x = y$","$T(V) = W$","$T(0) = 0$"],correctIndex:1,difficulty:"easy",explanation:"A function is one-to-one if different inputs give different outputs, or equivalently, if $T(x) = T(y)$ implies $x = y$."},{id:2,type:"multiple-choice",question:"A linear transformation $T$ is one-to-one if and only if:",options:["$T(V) = W$","$N(T) = V$","$N(T) = \\{0\\}$","$T = I$"],correctIndex:2,difficulty:"medium",explanation:"Theorem 2.10 states that $T$ is one-to-one iff $N(T) = \\{0\\}$, meaning the only element mapping to zero is zero itself."},{id:3,type:"multiple-choice",question:"If a linear transformation $T$ is one-to-one, what can we say about its inverse $T^{-1}$?",options:["$T^{-1}$ does not exist","$T^{-1}$ exists but may not be linear","$T^{-1} = T$","$T^{-1}$ exists and is linear"],correctIndex:3,difficulty:"medium",explanation:"Theorem 2.10 states that if $T$ is a one-to-one linear transformation, then $T^{-1}$ exists and is automatically linear."},{id:4,type:"multiple-choice",question:"If $T: V \\to W$ is linear with $\\dim V = n$ and $T$ is one-to-one, then $\\dim T(V)$ equals:",options:["$n$","0","$n - 1$","It depends on $W$"],correctIndex:0,difficulty:"medium",explanation:"If $T$ is one-to-one, then $N(T) = \\{0\\}$ so nullity = 0. By the Nullity Plus Rank Theorem, rank = $n$, meaning $\\dim T(V) = n$."},{id:5,type:"multiple-choice",question:"If $\\{e_1, \\ldots, e_n\\}$ is a basis for $V$ and $T$ is one-to-one, then $\\{T(e_1), \\ldots, T(e_n)\\}$ is:",options:["A dependent set","A basis for $T(V)$","Equal to $\\{e_1, \\ldots, e_n\\}$","Always orthonormal"],correctIndex:1,difficulty:"hard",explanation:"Theorem 2.11(d) states that if $T$ is one-to-one and $\\{e_1, \\ldots, e_n\\}$ is a basis for $V$, then $\\{T(e_1), \\ldots, T(e_n)\\}$ is a basis for $T(V)$."}],p=[{id:1,type:"multiple-choice",question:"The matrix representation of a linear transformation $T: V \\to W$ depends on:",options:["Only the transformation $T$","Only the dimensions of $V$ and $W$","The choice of bases for $V$ and $W$","Nothing; it is unique"],correctIndex:2,difficulty:"medium",explanation:"The matrix representation depends on the ordered bases chosen for both the domain $V$ and codomain $W$. Different bases give different matrices."},{id:2,type:"multiple-choice",question:"If $T: V \\to W$ with $\\dim V = n$ and $\\dim W = m$, the matrix of $T$ has size:",options:["$n \\times n$","$n \\times m$","$m \\times m$","$m \\times n$"],correctIndex:3,difficulty:"medium",explanation:"The matrix is $m \\times n$: $m$ rows (one for each basis element in $W$) and $n$ columns (one for each basis element in $V$)."},{id:3,type:"multiple-choice",question:"The $k$th column of the matrix representation of $T$ contains:",options:["The components of $T(e_k)$ relative to the basis of $W$","The components of $e_k$","The eigenvalues of $T$","All zeros"],correctIndex:0,difficulty:"medium",explanation:"Column $k$ contains the components of $T(e_k)$ expressed as a linear combination of the basis elements of $W$."},{id:4,type:"multiple-choice",question:"If the differentiation operator $D$ maps polynomials of degree $\\leq 3$ to polynomials of degree $\\leq 2$ using standard bases, what is the entry in row 1, column 2?",options:["0","1","2","3"],correctIndex:1,difficulty:"hard",explanation:"With basis $(1, x, x^2, x^3)$ for domain and $(1, x, x^2)$ for codomain: $D(x) = 1$, so column 2 is $(1, 0, 0)^T$. The entry in row 1, column 2 is 1."},{id:5,type:"multiple-choice",question:"Given matrix $A$ of $T$ and components $(x_1, \\ldots, x_n)$ of $x$, the components of $T(x)$ are given by:",options:["Adding the components","Taking the transpose $A^T$","Matrix-vector multiplication $AX$","Finding the determinant"],correctIndex:2,difficulty:"medium",explanation:"If $X$ is the column vector of components, then the components of $T(x)$ form the column vector $Y = AX$, computed by matrix-vector multiplication."}],m=[{id:1,type:"multiple-choice",question:"Two $m \\times n$ matrices $A$ and $B$ are equal if and only if:",options:["They have the same size","They have the same determinant","They represent the same transformation","$a_{ik} = b_{ik}$ for all $i, k$"],correctIndex:3,difficulty:"easy",explanation:"Matrices are equal if and only if they have the same size AND all corresponding entries are equal: $a_{ik} = b_{ik}$ for all $i, k$."},{id:2,type:"numeric",question:"What is the dimension of the space of all $3 \\times 4$ matrices?",correctAnswer:12,numericRange:{min:0,max:50,precision:0},difficulty:"easy",explanation:"The space of $m \\times n$ matrices has dimension $mn$. For $3 \\times 4$ matrices, the dimension is $3 \\times 4 = 12$."},{id:3,type:"multiple-choice",question:"A $1 \\times n$ matrix is called a:",options:["Row vector","Column vector","Square matrix","Diagonal matrix"],correctIndex:0,difficulty:"easy",explanation:"A $1 \\times n$ matrix (1 row, $n$ columns) is called a row vector. An $m \\times 1$ matrix is a column vector."},{id:4,type:"multiple-choice",question:"The transpose of an $m \\times n$ matrix $A$ is:",options:["An $m \\times n$ matrix","An $n \\times m$ matrix","An $m \\times m$ matrix","An $n \\times n$ matrix"],correctIndex:1,difficulty:"easy",explanation:"The transpose $A^T$ interchanges rows and columns, so an $m \\times n$ matrix becomes an $n \\times m$ matrix."},{id:5,type:"multiple-choice",question:"Which property does $(A^T)^T$ satisfy?",options:["$(A^T)^T = A^T$","$(A^T)^T = I$","$(A^T)^T = A$","$(A^T)^T = 0$"],correctIndex:2,difficulty:"easy",explanation:"Taking the transpose twice returns the original matrix: $(A^T)^T = A$."}],y=[{id:1,type:"multiple-choice",question:"The product $AB$ of an $m \\times n$ matrix $A$ and an $n \\times p$ matrix $B$ has size:",options:["$m \\times n$","$n \\times p$","$n \\times n$","$m \\times p$"],correctIndex:3,difficulty:"easy",explanation:"When multiplying $A$ ($m \\times n$) by $B$ ($n \\times p$), the result $AB$ has size $m \\times p$. The inner dimensions ($n$) must match."},{id:2,type:"multiple-choice",question:"The $(i, k)$ entry of the product $AB$ is computed by:",options:["The dot product of row $i$ of $A$ and column $k$ of $B$","Adding row $i$ of $A$ and column $k$ of $B$","Multiplying $a_{ik}$ and $b_{ik}$","The determinant of a submatrix"],correctIndex:0,difficulty:"medium",explanation:"The entry $c_{ik} = \\sum_{j=1}^n a_{ij}b_{jk}$, which is the dot product of row $i$ of $A$ with column $k$ of $B$."},{id:3,type:"multiple-choice",question:"Matrix multiplication is:",options:["Commutative and associative","Associative but not commutative","Commutative but not associative","Neither commutative nor associative"],correctIndex:1,difficulty:"medium",explanation:"Matrix multiplication is associative: $(AB)C = A(BC)$. However, it is generally NOT commutative: $AB \\neq BA$ in general."},{id:4,type:"multiple-choice",question:"The identity matrix $I_n$ satisfies:",options:["$I_n A = A$ for any $n \\times m$ matrix $A$","$AI_n = A$ for any $m \\times n$ matrix $A$","Both of the above","$I_n A = AI_n$ for all $A$"],correctIndex:2,difficulty:"medium",explanation:"The identity matrix is a two-sided identity: $I_m A = A$ when $A$ is $m \\times n$, and $AI_n = A$ when $A$ is $m \\times n$."},{id:5,type:"multiple-choice",question:"The transpose of a product satisfies:",options:["$(AB)^T = A^T B^T$","$(AB)^T = BA$","$(AB)^T = AB$","$(AB)^T = B^T A^T$"],correctIndex:3,difficulty:"medium",explanation:"The transpose of a product reverses the order: $(AB)^T = B^T A^T$. This mirrors the formula for inverses: $(AB)^{-1} = B^{-1}A^{-1}$."}],x=[{id:1,type:"multiple-choice",question:"A system of $m$ linear equations in $n$ unknowns can be written in matrix form as:",options:["$AX = B$","$A + X = B$","$XA = B$","$A = XB$"],correctIndex:0,difficulty:"easy",explanation:"The matrix equation $AX = B$ represents the system, where $A$ is the $m \\times n$ coefficient matrix, $X$ is the column of unknowns, and $B$ is the column of constants."},{id:2,type:"multiple-choice",question:"A homogeneous system $AX = 0$:",options:["Never has solutions","Always has at least the trivial solution $X = 0$","Has exactly one solution","Has infinitely many solutions"],correctIndex:1,difficulty:"easy",explanation:"A homogeneous system always has at least the trivial solution $X = 0$. It may have additional nontrivial solutions if the columns of $A$ are dependent."},{id:3,type:"multiple-choice",question:"If $m < n$ (fewer equations than unknowns), a homogeneous system $AX = 0$:",options:["Has only the trivial solution","Has no solutions","Always has nontrivial solutions","May or may not have nontrivial solutions"],correctIndex:2,difficulty:"medium",explanation:"If $m < n$, then rank$(A) \\leq m < n$, so nullity = $n$ - rank $\\geq n - m > 0$. This means there are nontrivial solutions."},{id:4,type:"multiple-choice",question:"The general solution to $AX = B$ (when solutions exist) has the form:",options:["$X = X_h$ (homogeneous solution only)","$X = X_p - X_h$","$X = X_p \\cdot X_h$","$X = X_p + X_h$ (particular plus homogeneous)"],correctIndex:3,difficulty:"medium",explanation:"If $X_p$ is a particular solution to $AX = B$, then the general solution is $X = X_p + X_h$ where $X_h$ is any solution to $AX = 0$."},{id:5,type:"multiple-choice",question:"For an $n \\times n$ matrix $A$, the system $AX = B$ has a unique solution for every $B$ if and only if:",options:["The columns of $A$ are linearly independent","$A$ has all positive entries","$A$ is symmetric","$A$ has rank less than $n$"],correctIndex:0,difficulty:"medium",explanation:"Unique solutions for all $B$ require $A$ to be invertible, which happens iff the columns are independent, iff rank$(A) = n$, iff $AX = 0$ has only the trivial solution."}],b=[{id:1,type:"multiple-choice",question:"Which of the following is NOT an elementary row operation?",options:["Interchange two rows","Multiply two rows together","Add a multiple of one row to another","Multiply a row by a nonzero scalar"],correctIndex:1,difficulty:"easy",explanation:"The three elementary row operations are: (I) interchange rows, (II) multiply a row by a nonzero scalar, (III) add a multiple of one row to another. Multiplying rows is not an elementary operation."},{id:2,type:"multiple-choice",question:"A matrix is in row echelon form if:",options:["All entries are zero","All entries are positive","Zero rows are at the bottom and pivots move right as you go down","It is a square matrix"],correctIndex:2,difficulty:"medium",explanation:"Row echelon form requires: (a) all zero rows at bottom, (b) each leading entry (pivot) is to the right of the pivot in the row above."},{id:3,type:"multiple-choice",question:"What effect does adding a multiple of one row to another have on the solution set of $AX = B$?",options:["It changes the solutions","It adds new solutions","It eliminates all solutions","It leaves the solution set unchanged"],correctIndex:3,difficulty:"medium",explanation:"Elementary row operations do not change the solution set. They correspond to applying invertible transformations to both sides of the equation."},{id:4,type:"multiple-choice",question:"The rank of a matrix equals:",options:["The number of pivot rows in its row echelon form","The number of columns","The number of rows","The total number of nonzero entries"],correctIndex:0,difficulty:"medium",explanation:"The rank equals the number of nonzero rows (pivot rows) in the row echelon form. This counts the number of linearly independent rows."},{id:5,type:"multiple-choice",question:"In Gaussian elimination, the augmented matrix $[A | B]$ is used to:",options:["Find the determinant only","Solve $AX = B$ and find the null space","Compute the transpose","Find eigenvalues"],correctIndex:1,difficulty:"medium",explanation:"The augmented matrix $[A | B]$ combines the coefficient matrix and constants. Reducing it to echelon form allows solving the system and identifying free variables."}],g=[{id:1,type:"multiple-choice",question:"A square matrix $A$ is invertible if there exists a matrix $A^{-1}$ such that:",options:["$AA^{-1} = I$ only","$A^{-1}A = I$ only","$AA^{-1} = A^{-1}A = I$","$A + A^{-1} = I$"],correctIndex:2,difficulty:"easy",explanation:"An invertible matrix must satisfy both $AA^{-1} = I$ and $A^{-1}A = I$. The inverse is unique."},{id:2,type:"multiple-choice",question:"Which of the following is equivalent to $A$ being invertible?",options:["The rows of $A$ are dependent","rank$(A) < n$","$A$ has some zero entries","$AX = 0$ has only the trivial solution"],correctIndex:3,difficulty:"medium",explanation:"A matrix is invertible iff its columns (or rows) are independent, iff rank$(A) = n$, iff $AX = 0$ has only $X = 0$ as solution, iff the reduced echelon form is $I$."},{id:3,type:"multiple-choice",question:"To compute $A^{-1}$ using row operations, we reduce the augmented matrix:",options:["$[A | I]$ to $[I | A^{-1}]$","$[A | A]$ to $[I | I]$","$[A | 0]$ to $[I | A^{-1}]$","$[I | A]$ to $[A^{-1} | I]$"],correctIndex:0,difficulty:"medium",explanation:"We form $[A | I]$ and apply row operations until the left side becomes $I$. The right side then contains $A^{-1}$."},{id:4,type:"multiple-choice",question:"If $A$ and $B$ are both invertible $n \\times n$ matrices, then $(AB)^{-1}$ equals:",options:["$A^{-1}B^{-1}$","$B^{-1}A^{-1}$","$AB$","$(A^{-1})(B^{-1})^T$"],correctIndex:1,difficulty:"medium",explanation:"The inverse of a product reverses the order: $(AB)^{-1} = B^{-1}A^{-1}$. This can be verified by $(AB)(B^{-1}A^{-1}) = A(BB^{-1})A^{-1} = AIA^{-1} = I$."},{id:5,type:"multiple-choice",question:"If $A$ is invertible, the unique solution to $AX = B$ is:",options:["$X = AB$","$X = BA^{-1}$","$X = A^{-1}B$","$X = B - A$"],correctIndex:2,difficulty:"easy",explanation:"Multiplying both sides of $AX = B$ by $A^{-1}$ on the left gives $X = A^{-1}B$."}],v=[{id:1,type:"multiple-choice",question:"What is the determinant of the matrix $\\begin{bmatrix} 3 & 5 \\\\ 2 & 4 \\end{bmatrix}$?",options:["$2$","$7$","$22$","$-2$"],correctIndex:0,difficulty:"easy",explanation:"For a $2 \\times 2$ matrix $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$, the determinant is $ad - bc = 3 \\cdot 4 - 5 \\cdot 2 = 12 - 10 = 2$."},{id:2,type:"multiple-choice",question:"The absolute value of the determinant of a $3 \\times 3$ matrix with row vectors $A_1, A_2, A_3$ represents:",options:["The sum of the vector lengths","The area of a triangle","The perimeter of the region enclosed","The volume of the parallelepiped formed by the vectors"],correctIndex:3,difficulty:"medium",explanation:"The scalar triple product $A_1 \\times A_2 \\cdot A_3$, which equals the determinant, gives the signed volume of the parallelepiped determined by the three vectors."},{id:3,type:"multiple-choice",question:"If the rows of a $3 \\times 3$ matrix are linearly dependent, what is the determinant?",options:["$1$","$-1$","$0$","Cannot be determined"],correctIndex:2,difficulty:"easy",explanation:"When rows are linearly dependent, the parallelepiped degenerates to a plane figure of zero volume, so the determinant is zero."},{id:4,type:"multiple-choice",question:"The determinant of a $3 \\times 3$ matrix is defined in terms of:",options:["$2 \\times 2$ determinants","$3 \\times 3$ determinants","$4 \\times 4$ determinants","Only the diagonal elements"],correctIndex:0,difficulty:"medium",explanation:"The $3 \\times 3$ determinant is defined recursively using cofactor expansion along a row or column, expressing it as a sum of products with $2 \\times 2$ determinants."},{id:5,type:"multiple-choice",question:"A negative determinant for a linear transformation indicates:",options:["The transformation is not invertible","An orientation reversal","The transformation scales by a factor less than 1","The rows are dependent"],correctIndex:1,difficulty:"hard",explanation:"The sign of the determinant indicates whether the transformation preserves or reverses orientation. A negative determinant means the transformation reverses orientation (like a reflection)."}],_=[{id:1,type:"multiple-choice",question:"How many axioms define a determinant function?",options:["2","3","4","5"],correctIndex:2,difficulty:"easy",explanation:"A determinant function is defined by 4 axioms: homogeneity, additivity, vanishing (when two rows are equal), and normalization (value 1 on identity)."},{id:2,type:"multiple-choice",question:"The homogeneity axiom states that $d(\\ldots, tA_k, \\ldots) = $",options:["$d(\\ldots, A_k, \\ldots)$","$t^2 \\cdot d(\\ldots, A_k, \\ldots)$","$t \\cdot d(\\ldots, A_k, \\ldots)$","$t^n \\cdot d(\\ldots, A_k, \\ldots)$"],correctIndex:2,difficulty:"easy",explanation:"The homogeneity axiom states that scaling one row by $t$ scales the determinant by $t$: $d(\\ldots, tA_k, \\ldots) = t \\cdot d(\\ldots, A_k, \\ldots)$."},{id:3,type:"multiple-choice",question:"What happens to the determinant when two adjacent rows are interchanged?",options:["It stays the same","It doubles","It becomes zero","It changes sign"],correctIndex:3,difficulty:"medium",explanation:"Interchanging two adjacent rows reverses the sign of the determinant. This follows from the axioms by considering the determinant of a matrix with both rows equal to $A_k + A_{k+1}$."},{id:4,type:"multiple-choice",question:"The axioms imply that if any row of a matrix is the zero vector, then the determinant is:",options:["$1$","$0$","$-1$","Undefined"],correctIndex:1,difficulty:"medium",explanation:"By homogeneity, $d(\\ldots, 0, \\ldots) = d(\\ldots, 0 \\cdot A, \\ldots) = 0 \\cdot d(\\ldots, A, \\ldots) = 0$ for any vector $A$."},{id:5,type:"multiple-choice",question:"A function satisfying axioms 1, 2, and 3 is called:",options:["Multilinear and alternating","Linear","Bijective","Continuous"],correctIndex:0,difficulty:"hard",explanation:"Axioms 1 and 2 make the function linear in each row (multilinear), while axiom 3 (vanishing when rows are equal) makes it alternating. This multilinear, alternating property characterizes determinant functions."}],T=[{id:1,type:"multiple-choice",question:"The determinant of a diagonal matrix equals:",options:["The sum of diagonal elements","The product of diagonal elements","The largest diagonal element","Zero"],correctIndex:1,difficulty:"easy",explanation:"The determinant of a diagonal matrix is the product of its diagonal elements: $\\det \\text{diag}(a_{11}, \\ldots, a_{nn}) = a_{11} \\cdot a_{22} \\cdots a_{nn}$."},{id:2,type:"multiple-choice",question:"What is the determinant of the upper triangular matrix $\\begin{bmatrix} 2 & 3 & 1 \\\\ 0 & -1 & 4 \\\\ 0 & 0 & 5 \\end{bmatrix}$?",options:["$-10$","$10$","$6$","$-6$"],correctIndex:0,difficulty:"easy",explanation:"For an upper triangular matrix, the determinant is the product of diagonal elements: $2 \\cdot (-1) \\cdot 5 = -10$."},{id:3,type:"multiple-choice",question:"Adding a multiple of one row to another row:",options:["Doubles the determinant","Reverses the sign of the determinant","Leaves the determinant unchanged","Sets the determinant to zero"],correctIndex:2,difficulty:"medium",explanation:"Adding a multiple of one row to another is a row operation that leaves the determinant unchanged, making it ideal for reduction to triangular form."},{id:4,type:"multiple-choice",question:"If we multiply one row of a matrix by a nonzero scalar $c$, the determinant is multiplied by:",options:["$c^2$","$c^n$","$c$","$1/c$"],correctIndex:2,difficulty:"medium",explanation:"By the homogeneity axiom, scaling one row by $c$ multiplies the determinant by $c$."},{id:5,type:"multiple-choice",question:"The computational complexity of computing determinants via Gauss-Jordan elimination is:",options:["$O(n!)$","$O(n^2)$","$O(n^3)$","$O(2^n)$"],correctIndex:2,difficulty:"hard",explanation:"The Gauss-Jordan method has $O(n^3)$ complexity, which is much better than the $O(n!)$ complexity of naive cofactor expansion."}],A=[{id:1,type:"multiple-choice",question:"The product formula for determinants states that $\\det(AB) = $",options:["$\\det A + \\det B$","$\\det(A + B)$","$\\det A - \\det B$","$(\\det A)(\\det B)$"],correctIndex:3,difficulty:"easy",explanation:"The fundamental product formula states that $\\det(AB) = (\\det A)(\\det B)$ for any two $n \\times n$ matrices $A$ and $B$."},{id:2,type:"multiple-choice",question:"A matrix $A$ is invertible if and only if:",options:["$\\det A \\neq 0$","$\\det A = -1$","$\\det A = 1$","$\\det A > 0$"],correctIndex:0,difficulty:"easy",explanation:"A matrix is invertible if and only if its determinant is nonzero. When $\\det A = 0$, the rows are linearly dependent and no inverse exists."},{id:3,type:"multiple-choice",question:"If $A$ is invertible, then $\\det(A^{-1}) = $",options:["$\\det A$","$(\\det A)^{-1}$","$-\\det A$","$(\\det A)^2$"],correctIndex:1,difficulty:"medium",explanation:"Since $AA^{-1} = I$ and $\\det I = 1$, we have $(\\det A)(\\det A^{-1}) = 1$, so $\\det(A^{-1}) = (\\det A)^{-1}$."},{id:4,type:"multiple-choice",question:"If $\\det A = 3$ and $\\det B = 4$, then $\\det(AB) = $",options:["$7$","$12$","$1$","$-1$"],correctIndex:1,difficulty:"medium",explanation:"By the product formula, $\\det(AB) = (\\det A)(\\det B) = 3 \\cdot 4 = 12$."},{id:5,type:"multiple-choice",question:"The uniqueness theorem states that there is exactly one function satisfying all four determinant axioms. What does this imply?",options:["Determinants can be computed in multiple ways","The determinant depends on the choice of basis","Any function satisfying axioms 1-3 equals $c \\cdot \\det$ for some constant $c$","Determinants only exist for $2 \\times 2$ matrices"],correctIndex:2,difficulty:"hard",explanation:"The uniqueness theorem shows that any function $f$ satisfying axioms 1, 2, 3 equals $\\det$ times the constant $f(I_1, \\ldots, I_n)$. Adding axiom 4 (normalization) forces this constant to be 1."}],q=[{id:1,type:"multiple-choice",question:"The cofactor of entry $a_{ij}$ is defined as:",options:["$\\det A_{ij}$","$a_{ij} \\det A_{ij}$","$(-1)^{ij} \\det A_{ij}$","$(-1)^{i+j} \\det A_{ij}$"],correctIndex:3,difficulty:"easy",explanation:"The cofactor of $a_{ij}$ is $\\text{cof} \\, a_{ij} = (-1)^{i+j} \\det A_{ij}$, where $A_{ij}$ is the minor obtained by deleting row $i$ and column $j$."},{id:2,type:"multiple-choice",question:"The sign pattern $(-1)^{i+j}$ in cofactor expansion follows which pattern?",options:["Checkerboard (alternating $+$ and $-$)","All negative","All positive","First row positive, rest negative"],correctIndex:0,difficulty:"easy",explanation:"The sign $(-1)^{i+j}$ alternates in a checkerboard pattern: $+$ when $i+j$ is even, $-$ when $i+j$ is odd."},{id:3,type:"multiple-choice",question:"The transpose theorem states that for any square matrix $A$:",options:["$\\det A^T = -\\det A$","$\\det A^T = \\det A$","$\\det A^T = (\\det A)^{-1}$","$\\det A^T = (\\det A)^2$"],correctIndex:1,difficulty:"medium",explanation:"The transpose theorem states $\\det A = \\det A^T$. This establishes symmetry between row and column properties of determinants."},{id:4,type:"multiple-choice",question:"Cofactor expansion along any row or column of a matrix gives:",options:["Different values depending on the row/column chosen","The trace of the matrix","The same value (the determinant)","The rank of the matrix"],correctIndex:2,difficulty:"medium",explanation:"The cofactor expansion formula gives the same result regardless of which row or column is used for expansion. This is the determinant of the matrix."},{id:5,type:"multiple-choice",question:"The existence of determinants for $n \\times n$ matrices is proved by:",options:["Direct calculation","Matrix diagonalization","The Cayley-Hamilton theorem","Induction using cofactor expansion"],correctIndex:3,difficulty:"hard",explanation:"Existence is proved by induction: the base case is $n=1$ where $\\det[a_{11}] = a_{11}$, and the inductive step defines the $n \\times n$ determinant via cofactor expansion using $(n-1) \\times (n-1)$ determinants."}],I=[{id:1,type:"multiple-choice",question:"The identity $A(\\text{cof} \\, A)^T = (\\det A) \\cdot I$ implies that when $\\det A \\neq 0$:",options:["$A^{-1} = \\frac{1}{\\det A}(\\text{cof} \\, A)^T$","$A^{-1} = (\\text{cof} \\, A)^T$","$A^{-1} = (\\det A)(\\text{cof} \\, A)^T$","$A^{-1} = (\\text{cof} \\, A)$"],correctIndex:0,difficulty:"medium",explanation:"From $A(\\text{cof} \\, A)^T = (\\det A) I$, dividing by $\\det A$ gives $A^{-1} = \\frac{1}{\\det A}(\\text{cof} \\, A)^T$."},{id:2,type:"multiple-choice",question:"The matrix $(\\text{cof} \\, A)^T$ is also called the:",options:["Transpose","Adjugate (classical adjoint)","Inverse","Conjugate"],correctIndex:1,difficulty:"easy",explanation:"The transpose of the cofactor matrix, $(\\text{cof} \\, A)^T$, is called the adjugate or classical adjoint of $A$."},{id:3,type:"multiple-choice",question:"In Cramer's rule for the system $AX = B$, the solution for $x_j$ is:",options:["$\\frac{\\det A}{\\det C_j}$","$\\det A \\cdot \\det C_j$","$\\frac{\\det C_j}{\\det A}$","$\\det C_j - \\det A$"],correctIndex:2,difficulty:"medium",explanation:"Cramer's rule gives $x_j = \\frac{\\det C_j}{\\det A}$, where $C_j$ is the matrix $A$ with column $j$ replaced by $B$."},{id:4,type:"multiple-choice",question:"For large systems, Cramer's rule is computationally:",options:["More efficient than Gaussian elimination","About as efficient as Gaussian elimination","The only valid method","Less efficient than Gaussian elimination"],correctIndex:3,difficulty:"medium",explanation:"Cramer's rule requires computing $n+1$ determinants of size $n$, making it far slower than Gaussian elimination for large $n$. It is mainly useful for theoretical analysis or small systems."},{id:5,type:"multiple-choice",question:"For a $2 \\times 2$ system $ax + by = e$, $cx + dy = f$ with $ad - bc \\neq 0$, the solution for $x$ is:",options:["$\\frac{ed - bf}{ad - bc}$","$\\frac{af - ce}{ad - bc}$","$\\frac{ae - cf}{ad - bc}$","$\\frac{ad - bc}{ed - bf}$"],correctIndex:0,difficulty:"hard",explanation:"By Cramer's rule, $x = \\frac{\\det \\begin{bmatrix} e & b \\\\ f & d \\end{bmatrix}}{\\det \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}} = \\frac{ed - bf}{ad - bc}$."}],w=[{id:1,type:"multiple-choice",question:"A scalar $\\lambda$ is an eigenvalue of $T$ if there exists a nonzero $x$ such that:",options:["$T(x) = x$","$T(x) = \\lambda x$","$T(x) = 0$","$T(\\lambda) = x$"],correctIndex:1,difficulty:"easy",explanation:"By definition, $\\lambda$ is an eigenvalue of $T$ if $T(x) = \\lambda x$ for some nonzero vector $x$, called an eigenvector."},{id:2,type:"multiple-choice",question:"Why is the zero vector excluded from being an eigenvector?",options:["$T(0)$ is undefined","The zero vector is not in the domain of $T$","The zero vector would have infinitely many eigenvalues","Eigenvalues must be positive"],correctIndex:2,difficulty:"medium",explanation:"Since $T(0) = \\lambda \\cdot 0 = 0$ for any $\\lambda$, the zero vector would satisfy the eigenvector equation for every scalar. Excluding it ensures each eigenvector has a unique eigenvalue."},{id:3,type:"multiple-choice",question:"The eigenspace $E(\\lambda)$ is:",options:["The set of all eigenvalues","The set of all eigenvectors with eigenvalue $\\lambda$","The null space of $T - \\lambda I$","Both B and C are correct"],correctIndex:3,difficulty:"medium",explanation:"The eigenspace $E(\\lambda)$ consists of all $x$ such that $T(x) = \\lambda x$, which is equivalent to $(T - \\lambda I)(x) = 0$. Thus $E(\\lambda)$ is the null space of $T - \\lambda I$, and includes all eigenvectors for $\\lambda$ plus the zero vector."},{id:4,type:"multiple-choice",question:"If $0$ is an eigenvalue of $T$, what can we conclude?",options:["$T$ has a nontrivial null space","$T$ is the identity transformation","$T$ is invertible","All vectors are eigenvectors"],correctIndex:0,difficulty:"medium",explanation:"If $0$ is an eigenvalue, then $T(x) = 0$ for some nonzero $x$, meaning the null space of $T$ contains nonzero vectors (is nontrivial)."},{id:5,type:"multiple-choice",question:"A linear transformation $T: V \\to V$ has a diagonal matrix representation if and only if:",options:["$T$ has at least one eigenvalue","$V$ has a basis of eigenvectors of $T$","$\\det T \\neq 0$","All eigenvalues are distinct"],correctIndex:1,difficulty:"hard",explanation:"A transformation has a diagonal matrix representation if and only if there exists a basis consisting entirely of eigenvectors. The matrix is then diagonal with eigenvalues on the diagonal."}],k=[{id:1,type:"multiple-choice",question:"The characteristic polynomial of an $n \\times n$ matrix $A$ is:",options:["$\\det(A - \\lambda I)$","$\\det A - \\lambda$","$\\det(\\lambda I - A)$","$\\lambda^n - \\det A$"],correctIndex:2,difficulty:"easy",explanation:"The characteristic polynomial is defined as $f(\\lambda) = \\det(\\lambda I - A)$. Note: $\\det(A - \\lambda I) = (-1)^n \\det(\\lambda I - A)$ gives the same roots."},{id:2,type:"multiple-choice",question:"The degree of the characteristic polynomial of an $n \\times n$ matrix is:",options:["$n-1$","$n$","$n+1$","$2n$"],correctIndex:1,difficulty:"easy",explanation:"The characteristic polynomial $\\det(\\lambda I - A)$ is a polynomial of degree $n$ with leading term $\\lambda^n$."},{id:3,type:"multiple-choice",question:"The product of all eigenvalues of a matrix $A$ equals:",options:["$\\text{tr} \\, A$","$n$","$\\text{rank} \\, A$","$\\det A$"],correctIndex:3,difficulty:"medium",explanation:"From the factored form $f(\\lambda) = (\\lambda - \\lambda_1) \\cdots (\\lambda - \\lambda_n)$, setting $\\lambda = 0$ gives $f(0) = (-1)^n \\lambda_1 \\cdots \\lambda_n = (-1)^n \\det A$, so the product of eigenvalues equals $\\det A$."},{id:4,type:"multiple-choice",question:"The sum of all eigenvalues of a matrix $A$ equals:",options:["$\\text{tr} \\, A$","$\\det A$","$\\text{rank} \\, A$","$n \\cdot \\det A$"],correctIndex:0,difficulty:"medium",explanation:"Comparing coefficients of $\\lambda^{n-1}$ in the characteristic polynomial shows that the sum of eigenvalues equals the trace $\\text{tr} \\, A = a_{11} + a_{22} + \\cdots + a_{nn}$."},{id:5,type:"multiple-choice",question:"Over $\\mathbb{C}$, an $n \\times n$ matrix has:",options:["At most $n$ eigenvalues","Exactly $n$ eigenvalues (counting multiplicity)","At least $n$ eigenvalues","An infinite number of eigenvalues"],correctIndex:1,difficulty:"hard",explanation:"By the fundamental theorem of algebra, the degree-$n$ characteristic polynomial has exactly $n$ complex roots (counting multiplicity), so every $n \\times n$ complex matrix has exactly $n$ eigenvalues."}],F=[{id:1,type:"multiple-choice",question:"To find eigenvectors for eigenvalue $\\lambda$, we solve:",options:["$AX = X$","$AX = \\lambda$","$(\\lambda I - A)X = 0$","$\\det(A - X) = \\lambda$"],correctIndex:2,difficulty:"easy",explanation:"Eigenvectors satisfy $AX = \\lambda X$, which rearranges to $(\\lambda I - A)X = 0$. We find nontrivial solutions to this homogeneous system."},{id:2,type:"multiple-choice",question:"Eigenvectors corresponding to distinct eigenvalues are:",options:["Parallel","Orthogonal","Equal","Linearly independent"],correctIndex:3,difficulty:"medium",explanation:"A fundamental theorem states that eigenvectors corresponding to distinct eigenvalues are linearly independent. This is key for diagonalization."},{id:3,type:"multiple-choice",question:"If an eigenvalue has algebraic multiplicity 2, its eigenspace:",options:["Has dimension 1 or 2","Must have dimension 1","Must have dimension 2","Has dimension 0"],correctIndex:0,difficulty:"medium",explanation:"The geometric multiplicity (dimension of eigenspace) is at least 1 and at most the algebraic multiplicity. So for algebraic multiplicity 2, the eigenspace dimension is 1 or 2."},{id:4,type:"multiple-choice",question:"A matrix with $n$ distinct eigenvalues is:",options:["Always singular","Always diagonalizable","Never diagonalizable","Always the identity"],correctIndex:1,difficulty:"medium",explanation:"When all $n$ eigenvalues are distinct, the $n$ corresponding eigenvectors are linearly independent, forming a basis. The matrix is then diagonalizable."},{id:5,type:"multiple-choice",question:"If $A = \\begin{bmatrix} 2 & 1 \\\\ 0 & 2 \\end{bmatrix}$, the eigenspace for $\\lambda = 2$ has dimension:",options:["$0$","$1$","$2$","Undefined"],correctIndex:1,difficulty:"hard",explanation:"The matrix $(2I - A) = \\begin{bmatrix} 0 & -1 \\\\ 0 & 0 \\end{bmatrix}$ has rank 1, so its null space has dimension $2 - 1 = 1$. Despite $\\lambda = 2$ having multiplicity 2, the eigenspace is only 1-dimensional."}],P=[{id:1,type:"multiple-choice",question:"Two matrices $A$ and $B$ are similar if:",options:["$A = B$","$\\det A = \\det B$","$B = C^{-1}AC$ for some nonsingular $C$","$A$ and $B$ have the same size"],correctIndex:2,difficulty:"easy",explanation:"By definition, $A$ and $B$ are similar if there exists a nonsingular matrix $C$ such that $B = C^{-1}AC$."},{id:2,type:"multiple-choice",question:"Similar matrices represent:",options:["Different linear transformations","Transformations with the same determinant","Orthogonal transformations","The same transformation in different bases"],correctIndex:3,difficulty:"easy",explanation:"Similar matrices are different matrix representations of the same linear transformation, relative to different choices of basis."},{id:3,type:"multiple-choice",question:"Similar matrices have:",options:["The same eigenvalues","Different eigenvalues","Opposite eigenvalues","Eigenvalues that sum to zero"],correctIndex:0,difficulty:"medium",explanation:"Similar matrices have the same characteristic polynomial, hence the same eigenvalues. This follows from $\\det(\\lambda I - C^{-1}AC) = \\det(C^{-1}(\\lambda I - A)C) = \\det(\\lambda I - A)$."},{id:4,type:"multiple-choice",question:"Which property is NOT preserved by similarity?",options:["Eigenvalues","Individual matrix entries","Trace","Determinant"],correctIndex:1,difficulty:"medium",explanation:"Similar matrices share eigenvalues, determinant, trace, rank, and characteristic polynomial. However, individual entries generally differ (that is the point of changing basis)."},{id:5,type:"multiple-choice",question:"An $n \\times n$ matrix $A$ is diagonalizable if and only if:",options:["$\\det A \\neq 0$","$A$ has $n$ distinct eigenvalues","$A$ has $n$ linearly independent eigenvectors","$A$ is symmetric"],correctIndex:2,difficulty:"hard",explanation:"A matrix is diagonalizable if and only if it has $n$ linearly independent eigenvectors (which form a basis). Having $n$ distinct eigenvalues is sufficient but not necessary for this."}],S=[{id:1,type:"multiple-choice",question:"What is the trace of the matrix $A = \\begin{bmatrix} 3 & 1 & 2 \\\\ 0 & 5 & -1 \\\\ 4 & 2 & 7 \\end{bmatrix}$?",options:["$8$","$15$","$12$","$10$"],correctIndex:1,difficulty:"easy",explanation:"The trace is the sum of diagonal elements: $\\text{tr}\\, A = 3 + 5 + 7 = 15$."},{id:2,type:"multiple-choice",question:'Which property of the trace is known as the "cyclic property"?',options:["$\\text{tr}(A + B) = \\text{tr}\\, A + \\text{tr}\\, B$","$\\text{tr}(cA) = c \\cdot \\text{tr}\\, A$","$\\text{tr}(A^T) = \\text{tr}\\, A$","$\\text{tr}(AB) = \\text{tr}(BA)$"],correctIndex:3,difficulty:"medium",explanation:"The cyclic property $\\text{tr}(AB) = \\text{tr}(BA)$ allows shifting matrices cyclically within a trace without changing the value."},{id:3,type:"multiple-choice",question:"If $A$ has eigenvalues $\\lambda_1 = 2$, $\\lambda_2 = -3$, and $\\lambda_3 = 5$, what is $\\text{tr}\\, A$?",options:["$0$","$4$","$-30$","$10$"],correctIndex:1,difficulty:"medium",explanation:"The trace equals the sum of eigenvalues: $\\text{tr}\\, A = \\lambda_1 + \\lambda_2 + \\lambda_3 = 2 + (-3) + 5 = 4$."},{id:4,type:"multiple-choice",question:"If $B = C^{-1}AC$ (similar matrices), what is the relationship between $\\text{tr}\\, A$ and $\\text{tr}\\, B$?",options:["$\\text{tr}\\, B = \\text{tr}\\, A$","$\\text{tr}\\, B = \\text{tr}\\, A + \\text{tr}\\, C$","$\\text{tr}\\, B = \\text{tr}\\, A \\cdot \\text{tr}\\, C$","$\\text{tr}\\, B = (\\text{tr}\\, A)^{-1}$"],correctIndex:0,difficulty:"medium",explanation:"Similar matrices have the same trace. This follows from the cyclic property: $\\text{tr}(C^{-1}AC) = \\text{tr}(ACC^{-1}) = \\text{tr}\\, A$."},{id:5,type:"multiple-choice",question:"For the commutator $[A, B] = AB - BA$, what is $\\text{tr}[A, B]$?",options:["$\\text{tr}\\, A - \\text{tr}\\, B$","$0$","$\\text{tr}(AB)$","$\\text{tr}\\, A + \\text{tr}\\, B$"],correctIndex:1,difficulty:"hard",explanation:"By the cyclic property, $\\text{tr}[A, B] = \\text{tr}(AB) - \\text{tr}(BA) = \\text{tr}(AB) - \\text{tr}(AB) = 0$."}],z=[{id:1,type:"multiple-choice",question:"A square matrix $A$ is nonsingular if and only if:",options:["$0$ is an eigenvalue of $A$","All eigenvalues of $A$ are positive","$0$ is not an eigenvalue of $A$","The trace of $A$ is nonzero"],correctIndex:2,difficulty:"medium",explanation:"A matrix is nonsingular iff $\\det A \\neq 0$ iff $Ax = 0$ has only the trivial solution iff $0$ is not an eigenvalue."},{id:2,type:"multiple-choice",question:"If $A$ is nonsingular with eigenvalue $\\lambda = 4$, what is the corresponding eigenvalue of $A^{-1}$?",options:["$-4$","$4$","$1/4$","$-1/4$"],correctIndex:2,difficulty:"easy",explanation:"If $Ax = \\lambda x$, then $x = A^{-1}(\\lambda x) = \\lambda A^{-1}x$, so $A^{-1}x = (1/\\lambda)x$. Thus $A^{-1}$ has eigenvalue $1/4$."},{id:3,type:"multiple-choice",question:"If $x$ is an eigenvector of $T$ with eigenvalue $\\lambda$, then $x$ is an eigenvector of $T^3$ with eigenvalue:",options:["$3\\lambda$","$\\lambda^3$","$\\lambda + 3$","$\\sqrt[3]{\\lambda}$"],correctIndex:1,difficulty:"medium",explanation:"By induction, $T^n(x) = \\lambda^n x$. So $T^3(x) = \\lambda^3 x$, meaning the eigenvalue is $\\lambda^3$."},{id:4,type:"multiple-choice",question:"If $A$ is a real matrix with $A^2 = -I$, which of the following must be true?",options:["$A$ is singular","$A$ has a real eigenvalue","$\\det A = -1$","The dimension $n$ must be even"],correctIndex:3,difficulty:"hard",explanation:"If $A^2 = -I$, any eigenvalue $\\lambda$ satisfies $\\lambda^2 = -1$, so no real eigenvalues exist. Complex eigenvalues come in conjugate pairs, so $n$ must be even."},{id:5,type:"multiple-choice",question:"A subspace $U$ is invariant under $T$ if:",options:["$T$ maps every vector in $U$ to a vector in $U$","$T$ maps every vector in $U$ to zero","$T$ is the identity on $U$","$U$ is the entire space"],correctIndex:0,difficulty:"easy",explanation:"A subspace $U$ is invariant under $T$ if $T(u) \\in U$ for all $u \\in U$. In particular, every eigenspace is an invariant subspace."}],B=[{id:1,type:"multiple-choice",question:"In a complex Euclidean space, the inner product satisfies $(x, y) = \\overline{(y, x)}$. This property is called:",options:["Symmetry","Hermitian symmetry","Linearity","Positive definiteness"],correctIndex:1,difficulty:"easy",explanation:"Hermitian symmetry generalizes symmetry to complex spaces: $(x, y) = \\overline{(y, x)}$, ensuring $(x, x)$ is always real."},{id:2,type:"multiple-choice",question:"If $T(x) = \\lambda x$ where $x$ is an eigenvector, then $\\lambda = $?",options:["$\\frac{(x, T(x))}{(x, x)}$","$\\frac{(x, x)}{(T(x), x)}$","$\\frac{(T(x), x)}{(x, x)}$","$(T(x), T(x))$"],correctIndex:2,difficulty:"medium",explanation:"From $T(x) = \\lambda x$, we get $(T(x), x) = (\\lambda x, x) = \\lambda(x, x)$, so $\\lambda = \\frac{(T(x), x)}{(x, x)}$."},{id:3,type:"multiple-choice",question:"The conjugate of an eigenvalue $\\lambda$ can be expressed as:",options:["$\\bar{\\lambda} = \\frac{(T(x), x)}{(x, x)}$","$\\bar{\\lambda} = (T(x), T(x))$","$\\bar{\\lambda} = \\frac{(x, x)}{(T(x), T(x))}$","$\\bar{\\lambda} = \\frac{(x, T(x))}{(x, x)}$"],correctIndex:3,difficulty:"medium",explanation:"From Hermitian symmetry, $\\bar{\\lambda} = \\overline{\\frac{(T(x), x)}{(x, x)}} = \\frac{\\overline{(T(x), x)}}{(x, x)} = \\frac{(x, T(x))}{(x, x)}$."},{id:4,type:"multiple-choice",question:"An eigenvalue $\\lambda$ is real if and only if:",options:["$(T(x), x) = (x, T(x))$","$(T(x), x) = -(x, T(x))$","$(T(x), x) = 0$","$(x, T(x)) = 0$"],correctIndex:0,difficulty:"hard",explanation:"$\\lambda$ is real iff $\\lambda = \\bar{\\lambda}$ iff $\\frac{(T(x), x)}{(x, x)} = \\frac{(x, T(x))}{(x, x)}$ iff $(T(x), x) = (x, T(x))$."}],Q=[{id:1,type:"multiple-choice",question:"A linear transformation $T$ is Hermitian if for all $x, y$ in the domain:",options:["$(T(x), y) = -(x, T(y))$","$(T(x), y) = (x, T(y))$","$(T(x), y) = (y, T(x))$","$(T(x), y) = 0$"],correctIndex:1,difficulty:"easy",explanation:'A Hermitian operator satisfies $(T(x), y) = (x, T(y))$, meaning $T$ can be "shifted" between factors without changing the inner product.'},{id:2,type:"multiple-choice",question:"In a real Euclidean space, Hermitian transformations are called:",options:["Unitary","Orthogonal","Symmetric","Normal"],correctIndex:2,difficulty:"easy",explanation:"In real spaces, the Hermitian condition $(T(x), y) = (x, T(y))$ is called symmetry, so Hermitian operators are called symmetric."},{id:3,type:"multiple-choice",question:"The differentiation operator $D(f) = f'$ on $C(a, b)$ with periodic boundary conditions $f(a) = f(b)$ is:",options:["Symmetric","Unitary","Hermitian","Skew-symmetric"],correctIndex:3,difficulty:"medium",explanation:"The integrand in the skew-symmetry condition is $(fg)' = f'g + fg'$. Integrating gives $[fg]_a^b = 0$ due to periodicity, proving $D$ is skew-symmetric."},{id:4,type:"multiple-choice",question:"The Sturm-Liouville operator $T(f) = (pf')'+ qf$ is symmetric with respect to which inner product?",options:["$(f, g) = \\int_a^b f(t)g(t)\\, dt$","$(f, g) = \\int_a^b f(t) + g(t)\\, dt$","$(f, g) = f(a)g(a) + f(b)g(b)$","$(f, g) = f'(a)g'(b)$"],correctIndex:0,difficulty:"medium",explanation:"The Sturm-Liouville operator is symmetric with respect to the standard $L^2$ inner product $(f, g) = \\int_a^b f(t)g(t)\\, dt$."},{id:5,type:"multiple-choice",question:"A skew-Hermitian transformation satisfies:",options:["$(T(x), y) = (x, T(y))$","$(T(x), y) = -(x, T(y))$","$(T(x), y) = (T(y), x)$","$(T(x), y) = i(x, T(y))$"],correctIndex:1,difficulty:"easy",explanation:"A skew-Hermitian operator satisfies $(T(x), y) = -(x, T(y))$; shifting $T$ between factors introduces a sign change."}],C=[{id:1,type:"multiple-choice",question:"If $T$ is a Hermitian operator and $\\lambda$ is an eigenvalue of $T$, then $\\lambda$ is:",options:["Pure imaginary","Complex with nonzero imaginary part","Real","Zero"],correctIndex:2,difficulty:"easy",explanation:"For Hermitian operators, $(T(x), x) = (x, T(x))$, so $\\lambda = \\bar{\\lambda}$, meaning $\\lambda$ is real."},{id:2,type:"multiple-choice",question:"If $T$ is a skew-Hermitian operator and $\\lambda$ is an eigenvalue, then $\\lambda$ is:",options:["Real","Negative real","Positive real","Pure imaginary"],correctIndex:3,difficulty:"medium",explanation:"For skew-Hermitian operators, $(T(x), x) = -(x, T(x))$, so $\\lambda = -\\bar{\\lambda}$, meaning $\\lambda$ is purely imaginary."},{id:3,type:"multiple-choice",question:"In a real Euclidean space, all eigenvalues of a skew-symmetric operator must be:",options:["Zero","Real and negative","Real and positive","Complex (non-real)"],correctIndex:0,difficulty:"hard",explanation:"Eigenvalues must be both real (since the space is real) and purely imaginary (skew-symmetric). The only number that is both is zero."},{id:4,type:"multiple-choice",question:"In quantum mechanics, physical observables are represented by Hermitian operators because:",options:["Hermitian operators are always invertible","Hermitian operators have real eigenvalues (measurement outcomes)","Hermitian operators are easy to compute","Hermitian operators have orthonormal eigenvectors"],correctIndex:1,difficulty:"medium",explanation:"Physical measurements must yield real values. Hermitian operators guarantee real eigenvalues, which represent possible measurement outcomes."},{id:5,type:"multiple-choice",question:"The Pauli matrices $\\sigma_1, \\sigma_2, \\sigma_3$ are all Hermitian. This means their eigenvalues are:",options:["Complex conjugate pairs","Purely imaginary","Real numbers","All equal to 1"],correctIndex:2,difficulty:"easy",explanation:"Since Pauli matrices are Hermitian, their eigenvalues must be real. In fact, each has eigenvalues $+1$ and $-1$."}],j=[{id:1,type:"multiple-choice",question:"For a Hermitian operator, eigenvectors corresponding to distinct eigenvalues are:",options:["Parallel","Linearly dependent","Equal in magnitude","Orthogonal"],correctIndex:3,difficulty:"easy",explanation:"If $T$ is Hermitian with distinct eigenvalues $\\lambda \\neq \\mu$ and eigenvectors $x, y$, then $(\\lambda - \\mu)(x, y) = 0$. Since $\\lambda \\neq \\mu$, we have $(x, y) = 0$."},{id:2,type:"multiple-choice",question:"The orthogonality theorem for Hermitian operators applies to:",options:["Eigenvectors corresponding to distinct eigenvalues","Only eigenvectors with the same eigenvalue","All eigenvectors","Only unit eigenvectors"],correctIndex:0,difficulty:"medium",explanation:"The theorem guarantees orthogonality specifically for eigenvectors with different eigenvalues. Eigenvectors for the same eigenvalue need not be orthogonal."},{id:3,type:"multiple-choice",question:"The orthogonality relation $\\int_0^\\pi \\sin nt \\cdot \\sin mt\\, dt = 0$ for $m \\neq n$ follows from:",options:["The Sturm-Liouville operator being Hermitian","The Sturm-Liouville operator being symmetric","The functions being bounded","The interval being finite"],correctIndex:1,difficulty:"medium",explanation:"The functions $\\sin nt$ are eigenfunctions of the Sturm-Liouville operator with distinct eigenvalues $-n^2$. Since this operator is symmetric, the orthogonality theorem applies."},{id:4,type:"multiple-choice",question:"Geometrically, a Hermitian operator stretches space along:",options:["Random directions","A single direction","Mutually perpendicular axes defined by eigenvectors","Parallel lines"],correctIndex:2,difficulty:"medium",explanation:"Eigenvectors of Hermitian operators are orthogonal, defining perpendicular principal axes. Each eigenvalue gives the stretch factor along its axis."},{id:5,type:"multiple-choice",question:"The orthogonality of eigenvectors for Hermitian operators is stronger than linear independence because:",options:["Orthogonal vectors are always unit vectors","Orthogonal vectors have the same eigenvalue","Orthogonal vectors are always real","Orthogonal vectors provide a geometrically nice basis"],correctIndex:3,difficulty:"hard",explanation:"While any set of eigenvectors for distinct eigenvalues is linearly independent, orthogonality ensures they span the space in a geometrically nice way that simplifies computations."}],X=[{id:1,type:"multiple-choice",question:"The Spectral Theorem for Hermitian operators states that there exist $n$ eigenvectors forming:",options:["An orthonormal basis","A linearly independent set","A set spanning only a subspace","A non-orthogonal basis"],correctIndex:0,difficulty:"easy",explanation:"The Spectral Theorem guarantees that a Hermitian operator on an $n$-dimensional space has $n$ eigenvectors forming an orthonormal basis."},{id:2,type:"multiple-choice",question:"According to the Spectral Theorem, the matrix of a Hermitian operator relative to an orthonormal eigenbasis is:",options:["Upper triangular","A diagonal matrix","The identity matrix","A symmetric matrix"],correctIndex:1,difficulty:"medium",explanation:"Relative to an orthonormal basis of eigenvectors, the matrix is $\\Lambda = \\text{diag}(\\lambda_1, \\ldots, \\lambda_n)$ with eigenvalues on the diagonal."},{id:3,type:"multiple-choice",question:"In the proof of the Spectral Theorem, the orthogonal complement $S^\\perp$ is used because:",options:["It has dimension $n$","It contains only zero","It is invariant under $T$ for Hermitian $T$","It equals the original space"],correctIndex:2,difficulty:"hard",explanation:"If $u_1$ is an eigenvector, then $T$ maps $S^\\perp = \\{x : (x, u_1) = 0\\}$ into itself because $(T(x), u_1) = (x, T(u_1)) = \\bar{\\lambda_1}(x, u_1) = 0$."},{id:4,type:"multiple-choice",question:"The Spectral Theorem applies to finite-dimensional complex spaces because:",options:["All matrices are diagonalizable","Hermitian operators are always invertible","Complex spaces have no eigenvalues","The characteristic polynomial always has complex roots"],correctIndex:3,difficulty:"medium",explanation:"By the Fundamental Theorem of Algebra, every polynomial has a complex root, so eigenvalues always exist on complex spaces."},{id:5,type:"multiple-choice",question:"In principal component analysis (PCA), the Spectral Theorem is used because:",options:["Covariance matrices are symmetric and can be diagonalized orthogonally","Covariance matrices are skew-symmetric","Covariance matrices are upper triangular","PCA does not use eigenvalues"],correctIndex:0,difficulty:"medium",explanation:"Covariance matrices are symmetric, so by the Spectral Theorem they can be diagonalized by an orthogonal matrix. The principal components are the orthonormal eigenvectors."}],Y=[{id:1,type:"multiple-choice",question:"If $(e_1, \\ldots, e_n)$ is a basis for $V$ and $T$ is Hermitian, then $T$ is Hermitian if and only if:",options:["$(T(e_i), T(e_j)) = 0$ for $i \\neq j$","$(T(e_j), e_i) = (e_j, T(e_i))$ for all $i, j$","$T(e_i) = \\lambda_i e_i$ for all $i$","$(e_i, e_j) = \\delta_{ij}$"],correctIndex:1,difficulty:"medium",explanation:"The Hermitian condition $(T(x), y) = (x, T(y))$ for all $x, y$ is equivalent to checking it on basis elements only."},{id:2,type:"multiple-choice",question:"For an orthonormal basis, $T$ is Hermitian if and only if its matrix $A = (a_{ij})$ satisfies:",options:["$a_{ij} = a_{ji}$","$a_{ij} = -\\bar{a}_{ji}$","$a_{ij} = \\bar{a}_{ji}$","$a_{ij} = 0$ for $i \\neq j$"],correctIndex:2,difficulty:"easy",explanation:"Relative to an orthonormal basis, $a_{ij} = (T(e_j), e_i)$. The Hermitian condition translates to $a_{ij} = \\bar{a}_{ji}$."},{id:3,type:"multiple-choice",question:"If the matrix $A = \\begin{bmatrix} 3 & 2+i \\\\ 2-i & 5 \\end{bmatrix}$ represents $T$ in an orthonormal basis, then $T$ is:",options:["Skew-Hermitian","Unitary","Neither Hermitian nor skew-Hermitian","Hermitian"],correctIndex:3,difficulty:"medium",explanation:"Check: $a_{12} = 2+i$ and $\\bar{a}_{21} = \\overline{2-i} = 2+i$. Since $a_{ij} = \\bar{a}_{ji}$ for all entries, $A$ is Hermitian."},{id:4,type:"multiple-choice",question:"For an orthonormal basis, $T$ is skew-Hermitian if and only if its matrix satisfies:",options:["$a_{ij} = -\\bar{a}_{ji}$","$a_{ij} = \\bar{a}_{ji}$","$a_{ij} = a_{ji}$","$a_{ii} = 1$"],correctIndex:0,difficulty:"medium",explanation:"The skew-Hermitian condition $(T(x), y) = -(x, T(y))$ translates to $a_{ij} = -\\bar{a}_{ji}$ for the matrix relative to an orthonormal basis."},{id:5,type:"multiple-choice",question:"The matrix characterization theorem requires an orthonormal basis because:",options:["Only orthonormal bases exist","The inner product formula $(T(e_j), e_i) = a_{ij}$ uses orthonormality","Non-orthonormal bases are linearly dependent","Hermitian matrices are always diagonal"],correctIndex:1,difficulty:"hard",explanation:"When the basis is orthonormal, $(T(e_j), e_i) = \\sum_k a_{kj}(e_k, e_i) = a_{ij}$. This simple formula fails without orthonormality."}],D=[{id:1,type:"multiple-choice",question:"A square matrix $A$ is Hermitian if and only if:",options:["$A = A^t$","$A = \\bar{A}$","$A = \\bar{A}^t$","$A = -\\bar{A}^t$"],correctIndex:2,difficulty:"easy",explanation:"A Hermitian matrix satisfies $a_{ij} = \\bar{a}_{ji}$, which is equivalent to $A = \\bar{A}^t$ (the transpose of the conjugate)."},{id:2,type:"multiple-choice",question:"All diagonal elements of a Hermitian matrix are:",options:["Pure imaginary","Zero","Unit complex numbers","Real"],correctIndex:3,difficulty:"easy",explanation:"For diagonal elements, $a_{ii} = \\bar{a}_{ii}$, which means $a_{ii}$ equals its own conjugate, so it must be real."},{id:3,type:"multiple-choice",question:"All diagonal elements of a skew-Hermitian matrix are:",options:["Pure imaginary","Real","Positive real","Negative real"],correctIndex:0,difficulty:"medium",explanation:"For skew-Hermitian, $a_{ii} = -\\bar{a}_{ii}$, so $a_{ii} + \\bar{a}_{ii} = 0$, meaning $2\\text{Re}(a_{ii}) = 0$. Thus $a_{ii}$ is purely imaginary."},{id:4,type:"multiple-choice",question:"For any square matrix $A$, the matrix $B = \\frac{1}{2}(A + A^*)$ is:",options:["Skew-Hermitian","Hermitian","Unitary","Nilpotent"],correctIndex:1,difficulty:"medium",explanation:"$B^* = \\frac{1}{2}(A^* + A) = B$, so $B$ is Hermitian. This is the Hermitian part of any matrix $A$."},{id:5,type:"multiple-choice",question:"Which of the following is a skew-Hermitian matrix?",options:["$\\begin{bmatrix} 1 & 2 \\\\ 2 & 3 \\end{bmatrix}$","$\\begin{bmatrix} 1 & i \\\\ -i & 1 \\end{bmatrix}$","$\\begin{bmatrix} i & -2 \\\\ 2 & 3i \\end{bmatrix}$","$\\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}$"],correctIndex:2,difficulty:"hard",explanation:"Check: $a_{11} = i = -\\bar{i}$, $a_{22} = 3i = -\\overline{3i}$, $a_{12} = -2 = -\\overline{2}$, $a_{21} = 2 = -\\overline{-2}$. All satisfy $a_{ij} = -\\bar{a}_{ji}$."}],R=[{id:1,type:"multiple-choice",question:"The adjoint of a matrix $A$, denoted $A^*$, is defined as:",options:["The transpose of $A$","The conjugate of $A$","The inverse of $A$","The transpose of the conjugate of $A$"],correctIndex:3,difficulty:"easy",explanation:"The adjoint $A^* = \\bar{A}^t$ is obtained by taking the complex conjugate of each entry and then transposing."},{id:2,type:"multiple-choice",question:"A matrix is self-adjoint if:",options:["$A = A^*$","$A = A^{-1}$","$A = -A^*$","$A^* = I$"],correctIndex:0,difficulty:"easy",explanation:"Self-adjoint means $A = A^*$. This is another name for a Hermitian matrix."},{id:3,type:"multiple-choice",question:"For any matrices $A$ and $B$, $(AB)^* = $?",options:["$A^* B^*$","$B^* A^*$","$(A^* B^*)^{-1}$","$A B^*$"],correctIndex:1,difficulty:"medium",explanation:"The adjoint reverses the order: $(AB)^* = B^* A^*$. This follows from $(AB)^t = B^t A^t$ and conjugation being element-wise."},{id:4,type:"multiple-choice",question:"The adjoint is characterized by $(Ax, y) = (x, A^*y)$ for which inner product on $\\mathbb{C}^n$?",options:["$(x, y) = \\sum x_i y_i$","$(x, y) = \\sum |x_i y_i|$","$(x, y) = \\sum x_i \\bar{y_i}$","$(x, y) = x^t y$"],correctIndex:2,difficulty:"medium",explanation:"The standard inner product on $\\mathbb{C}^n$ is $(x, y) = \\sum x_i \\bar{y_i}$. With this inner product, $(Ax, y) = (x, A^*y)$."},{id:5,type:"multiple-choice",question:"If $A = \\begin{bmatrix} 1 & 2-i \\\\ 4+2i & 5i \\end{bmatrix}$, what is the $(2,1)$ entry of $A^*$?",options:["$2-i$","$-5i$","$4-2i$","$2+i$"],correctIndex:3,difficulty:"medium",explanation:"$A^* = \\bar{A}^t$, so $(A^*)_{21} = \\overline{a_{12}} = \\overline{2-i} = 2+i$."}],W=[{id:1,type:"multiple-choice",question:"According to the Diagonalization Theorem for Hermitian matrices, every Hermitian matrix $A$ satisfies:",options:["$\\Lambda = C^{-1}AC$ where $C^{-1} = C^*$","$A = C \\Lambda C$ where $\\Lambda$ is diagonal","$A = \\Lambda C$ where $\\Lambda$ is diagonal","$C = A \\Lambda A^{-1}$"],correctIndex:0,difficulty:"medium",explanation:"The theorem states $\\Lambda = C^{-1}AC$ where $\\Lambda$ is diagonal and the diagonalizing matrix satisfies $C^{-1} = C^*$ (unitary)."},{id:2,type:"multiple-choice",question:"To find the diagonalizing matrix $C$ for a Hermitian matrix:",options:["Use the eigenvalues as columns","Use orthonormal eigenvectors as columns","Use the matrix $A$ itself","Use the identity matrix"],correctIndex:1,difficulty:"easy",explanation:"The columns of $C$ are orthonormal eigenvectors $u_1, \\ldots, u_n$. The orthonormality gives $C^{-1} = C^*$."},{id:3,type:"multiple-choice",question:"For the real symmetric matrix $A = \\begin{bmatrix} 2 & 2 \\\\ 2 & 5 \\end{bmatrix}$, the eigenvalues are $1$ and $6$. What is $\\text{tr}\\, A$?",options:["$5$","$6$","$7$","$8$"],correctIndex:2,difficulty:"easy",explanation:"The trace equals the sum of eigenvalues: $\\text{tr}\\, A = 1 + 6 = 7$. We can verify: $2 + 5 = 7$."},{id:4,type:"multiple-choice",question:"Every real symmetric matrix can be diagonalized by:",options:["Any invertible matrix","A unitary matrix only","A real orthogonal matrix","A diagonal matrix"],correctIndex:2,difficulty:"medium",explanation:"Real symmetric matrices have real eigenvalues and can have real orthonormal eigenvectors, so the diagonalizing matrix can be real orthogonal."},{id:5,type:"multiple-choice",question:"The condition $C^{-1} = C^*$ means that the diagonalizing transformation:",options:["Is not invertible","Has determinant zero","Is the identity","Preserves inner products"],correctIndex:3,difficulty:"hard",explanation:"$C^{-1} = C^*$ defines a unitary matrix. Unitary matrices preserve inner products: $(Cx, Cy) = (x, C^*Cy) = (x, y)$."}],L=[{id:1,type:"multiple-choice",question:"A square matrix $A$ is unitary if:",options:["$A A^* = I$","$A A^t = I$","$A^2 = I$","$A + A^* = I$"],correctIndex:0,difficulty:"easy",explanation:"A unitary matrix satisfies $AA^* = I$, which means $A^{-1} = A^*$."},{id:2,type:"multiple-choice",question:"A matrix is unitary if and only if its columns form:",options:["A linearly dependent set","An orthonormal set","An orthogonal set","A basis for $\\mathbb{R}^n$"],correctIndex:1,difficulty:"medium",explanation:"The condition $AA^* = I$ is equivalent to $(c_i, c_j) = \\delta_{ij}$ for columns $c_i$, meaning the columns are orthonormal."},{id:3,type:"multiple-choice",question:"If $A$ is unitary, then $|\\det A| = $?",options:["$0$","$-1$","$1$","$n$"],correctIndex:2,difficulty:"medium",explanation:"$1 = \\det(AA^*) = \\det A \\cdot \\overline{\\det A} = |\\det A|^2$, so $|\\det A| = 1$."},{id:4,type:"multiple-choice",question:"Unitary matrices preserve:",options:["Only the determinant","Only the trace","Only eigenvalues","Inner products, lengths, and angles"],correctIndex:3,difficulty:"medium",explanation:"For unitary $A$: $(Ax, Ay) = (x, A^*Ay) = (x, y)$. This preserves inner products, hence lengths and angles."},{id:5,type:"multiple-choice",question:"The Fourier matrix $F_n = \\frac{1}{\\sqrt{n}}[\\omega^{jk}]$ where $\\omega = e^{2\\pi i/n}$ is:",options:["Unitary","Skew-Hermitian","Hermitian","Orthogonal"],correctIndex:0,difficulty:"hard",explanation:"The normalized Fourier matrix is unitary: $F_n F_n^* = I$. Its columns form an orthonormal basis of complex exponentials."}],E=[{id:1,type:"multiple-choice",question:"A real square matrix $A$ is orthogonal if:",options:["$A A^* = I$","$A A^t = I$","$A^2 = I$","$A = A^t$"],correctIndex:1,difficulty:"easy",explanation:"An orthogonal matrix satisfies $AA^t = I$, which means $A^{-1} = A^t$."},{id:2,type:"multiple-choice",question:"For an orthogonal matrix, $\\det A = $?",options:["$0$ or $1$","Any real number","$1$ or $-1$","$1$ only"],correctIndex:2,difficulty:"easy",explanation:"$(\\det A)^2 = \\det(AA^t) = \\det I = 1$, so $\\det A = \\pm 1$."},{id:3,type:"multiple-choice",question:"A proper orthogonal matrix (rotation) has:",options:["$\\det A = -1$","$A = I$","$\\det A = 0$","$\\det A = 1$"],correctIndex:3,difficulty:"medium",explanation:"A proper orthogonal matrix (rotation) has $\\det A = +1$. An improper one (reflection) has $\\det A = -1$."},{id:4,type:"multiple-choice",question:"The $2 \\times 2$ rotation matrix $\\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}$ is:",options:["Orthogonal and proper","Only orthogonal","Orthogonal and improper","Not orthogonal"],correctIndex:0,difficulty:"medium",explanation:"The columns are orthonormal, so it's orthogonal. $\\det = \\cos^2\\theta + \\sin^2\\theta = 1 > 0$, so it's proper (a rotation)."},{id:5,type:"multiple-choice",question:"Every real symmetric matrix can be diagonalized by:",options:["Any matrix","A real orthogonal matrix","A complex unitary matrix only","A diagonal matrix"],correctIndex:1,difficulty:"medium",explanation:"Real symmetric matrices have real eigenvalues and real eigenvectors, so the diagonalizing orthonormal eigenvector matrix is real orthogonal."}],V=[{id:1,type:"multiple-choice",question:"The quadratic form associated with a symmetric operator $T$ is defined as:",options:["$Q(x) = (x, x)$","$Q(x) = T(x)$","$Q(x) = (T(x), x)$","$Q(x) = (T(x), T(x))$"],correctIndex:2,difficulty:"easy",explanation:"The quadratic form is $Q(x) = (T(x), x)$, giving a scalar value for each vector $x$."},{id:2,type:"multiple-choice",question:"In matrix form, the quadratic form for symmetric matrix $A$ can be written as:",options:["$Q(x) = Ax$","$Q(x) = x A$","$Q(x) = A^t x$","$Q(x) = x^t A x$"],correctIndex:3,difficulty:"easy",explanation:"Using column vector notation, $Q(x) = x^t A x = \\sum_{i,j} a_{ij} x_i x_j$."},{id:3,type:"multiple-choice",question:"The quadratic form $Q(x,y) = ax^2 + 2bxy + cy^2$ corresponds to which symmetric matrix?",options:["$\\begin{bmatrix} a & b \\\\ b & c \\end{bmatrix}$","$\\begin{bmatrix} a & 2b \\\\ 2b & c \\end{bmatrix}$","$\\begin{bmatrix} a & b \\\\ 2b & c \\end{bmatrix}$","$\\begin{bmatrix} 2a & b \\\\ b & 2c \\end{bmatrix}$"],correctIndex:0,difficulty:"medium",explanation:"The coefficient of $xy$ is $2b = a_{12} + a_{21} = 2a_{12}$ for symmetric $A$, so $a_{12} = a_{21} = b$."},{id:4,type:"multiple-choice",question:"The equation $Q(x, y) = 1$ describes an ellipse when the eigenvalues of the associated matrix are:",options:["Both negative","Both positive","Of opposite signs","One is zero"],correctIndex:1,difficulty:"medium",explanation:"Both positive eigenvalues give an ellipse. Opposite signs give a hyperbola, one zero gives a parabola."},{id:5,type:"multiple-choice",question:"After diagonalizing a symmetric matrix $A = C \\Lambda C^t$, the quadratic form becomes:",options:["$\\sum_{i=1}^n y_i^2$","$\\sum_{i=1}^n \\lambda_i y_i$","$\\sum_{i=1}^n \\lambda_i y_i^2$","$\\sum_{i=1}^n y_i$"],correctIndex:2,difficulty:"hard",explanation:"In new coordinates $y = C^t x$, we have $Q = x^t A x = y^t \\Lambda y = \\sum_i \\lambda_i y_i^2$. The eigenvalues are the coefficients."}],N=[{id:1,type:"multiple-choice",question:"The first systematic procedures for solving differential equations were developed primarily by:",options:["Newton and Leibniz only","Bernoulli only","Cauchy alone","Euler, Lagrange, and Laplace"],correctIndex:3,difficulty:"easy",explanation:"While early work was by Newton, Leibniz, and the Bernoullis, more systematic procedures were developed during the 18th century by Euler, Lagrange, and Laplace."},{id:2,type:"multiple-choice",question:"Cauchy's existence theorem in the 1820s proved that every first-order equation $y' = f(x, y)$ has a solution when:",options:["$f$ satisfies certain general conditions","$f$ is continuous","$f$ is always positive","$f$ is a polynomial"],correctIndex:0,difficulty:"medium",explanation:"Cauchy proved existence when $f(x, y)$ satisfies certain conditions (continuity and Lipschitz condition), not just any function."},{id:3,type:"multiple-choice",question:"The Ricatti equation has the form:",options:["$y' = P(x)y$","$y' = P(x)y^2 + Q(x)y + R(x)$","$y'' + P(x)y = 0$","$y' = y^3$"],correctIndex:1,difficulty:"medium",explanation:"The Ricatti equation is $y' = P(x)y^2 + Q(x)y + R(x)$, a nonlinear first-order equation that is generally not solvable by elementary means."},{id:4,type:"multiple-choice",question:"When elementary methods fail to solve a differential equation, mathematicians began to ask:",options:["Whether to use only polynomial solutions","Whether to abandon the equation","Whether solutions exist and what properties they have","Whether the equation is wrong"],correctIndex:2,difficulty:"easy",explanation:"The modern approach focuses on existence and uniqueness theorems, and studying qualitative properties of solutions from the equation itself."},{id:5,type:"multiple-choice",question:"Linear differential equations are particularly important because:",options:["They are the only solvable equations","They were invented by Cauchy","They have no applications","They are tractable and arise in many scientific problems"],correctIndex:3,difficulty:"easy",explanation:"Linear differential equations are amenable to systematic analysis while still capturing essential physical phenomena in a wide variety of applications."}],O=[{id:1,type:"multiple-choice",question:"The general form of a first-order linear differential equation is:",options:["$y' + P(x)y = Q(x)$","$y' = y^2 + P(x)$","$y'' + P(x)y' = 0$","$y' = P(x)y^2$"],correctIndex:0,difficulty:"easy",explanation:"A first-order linear equation has the form $y' + P(x)y = Q(x)$, linear in both $y$ and $y'$."},{id:2,type:"multiple-choice",question:"For the first-order linear equation $y' + P(x)y = Q(x)$ with initial condition $f(a) = b$, Theorem 6.1 guarantees:",options:["No solutions exist","One and only one solution","Infinitely many solutions","At most two solutions"],correctIndex:1,difficulty:"medium",explanation:"The existence-uniqueness theorem guarantees exactly one solution when $P$ and $Q$ are continuous on an open interval containing $a$."},{id:3,type:"multiple-choice",question:"The integrating factor for $y' + P(x)y = Q(x)$ is:",options:["$e^{P(x)}$","$P(x)$","$e^{\\int P(x)\\,dx}$","$Q(x)$"],correctIndex:2,difficulty:"medium",explanation:"The integrating factor is $e^{A(x)}$ where $A(x) = \\int P(x)\\,dx$. Multiplying by it makes the left side an exact derivative."},{id:4,type:"multiple-choice",question:"For the equation $y' - 3y = e^{2x}$, the integrating factor is:",options:["$e^{3x}$","$3$","$e^{2x}$","$e^{-3x}$"],correctIndex:3,difficulty:"medium",explanation:"Here $P(x) = -3$, so the integrating factor is $e^{\\int -3\\,dx} = e^{-3x}$."},{id:5,type:"multiple-choice",question:"The solution formula $f(x) = be^{-A(x)} + e^{-A(x)}\\int_a^x Q(t)e^{A(t)}\\,dt$ consists of:",options:["The homogeneous solution plus a particular solution","Two particular solutions","Two homogeneous solutions","Only the particular solution"],correctIndex:0,difficulty:"hard",explanation:"The first term $be^{-A(x)}$ is the homogeneous solution with initial value $b$; the integral term is a particular solution of the nonhomogeneous equation."}],H=[{id:1,type:"multiple-choice",question:"The characteristic equation of $y'' + ay' + by = 0$ is:",options:["$r + a + b = 0$","$r^2 + ar + b = 0$","$r^2 - ar - b = 0$","$r^2 = ab$"],correctIndex:1,difficulty:"easy",explanation:"The characteristic equation is $r^2 + ar + b = 0$, obtained by substituting $y = e^{rx}$ into the differential equation."},{id:2,type:"multiple-choice",question:"If the discriminant $d = a^2 - 4b < 0$, the solutions involve:",options:["Distinct real exponentials","Repeated real roots","Trigonometric functions with exponential decay/growth","Polynomials only"],correctIndex:2,difficulty:"medium",explanation:"When $d < 0$, the roots are complex conjugates $r = -a/2 \\pm ik$ giving solutions $e^{-ax/2}(c_1\\cos kx + c_2\\sin kx)$."},{id:3,type:"multiple-choice",question:"For $y'' + \\omega^2 y = 0$ (simple harmonic motion), the general solution is:",options:["$y = c_1 e^{\\omega x} + c_2 e^{-\\omega x}$","$y = c_1 x + c_2$","$y = (c_1 + c_2 x)e^{\\omega x}$","$y = c_1 \\cos \\omega x + c_2 \\sin \\omega x$"],correctIndex:3,difficulty:"easy",explanation:"With $a = 0$ and $b = \\omega^2$, the discriminant is $-4\\omega^2 < 0$, giving oscillatory solutions with $\\cos$ and $\\sin$."},{id:4,type:"multiple-choice",question:"When the discriminant $d = 0$ (repeated root $r = -a/2$), the general solution is:",options:["$y = (c_1 + c_2 x)e^{rx}$","$y = c_1 e^{rx} + c_2 e^{-rx}$","$y = c_1 \\cos rx + c_2 \\sin rx$","$y = c_1 + c_2 x$"],correctIndex:0,difficulty:"medium",explanation:"A repeated root gives only one exponential solution. The second independent solution is $xe^{rx}$, so $y = (c_1 + c_2 x)e^{rx}$."},{id:5,type:"numeric",question:"For $y'' - 5y' + 6y = 0$, what is the sum of the roots of the characteristic equation?",correctAnswer:5,numericRange:{min:0,max:20,precision:0},difficulty:"easy",explanation:"The characteristic equation is $r^2 - 5r + 6 = 0$. By Vieta's formulas, the sum of roots equals $5$ (negative of coefficient of $r$)."}],G=[{id:1,type:"multiple-choice",question:"A linear differential equation of order $n$ has the form:",options:["$P_0(x)y^n + P_1(x)y^{n-1} + \\cdots + P_n(x)y = R(x)$","$P_0(x)y^{(n)} + P_1(x)y^{(n-1)} + \\cdots + P_n(x)y = R(x)$","$y^n + y^{n-1} + \\cdots + y = R(x)$","$y^{(n)} = P(x)$"],correctIndex:1,difficulty:"easy",explanation:"Linear means linear in $y$ and its derivatives $y', y'', \\ldots, y^{(n)}$. The notation $y^{(k)}$ denotes the $k$-th derivative."},{id:2,type:"multiple-choice",question:"Points where the leading coefficient $P_0(x) = 0$ are called:",options:["Regular points","Critical points","Singular points","Inflection points"],correctIndex:2,difficulty:"easy",explanation:"Singular points are where $P_0(x) = 0$, which can cause complications in the solution theory."},{id:3,type:"multiple-choice",question:"Using operator notation, the equation $y^{(n)} + P_1y^{(n-1)} + \\cdots + P_ny = R$ can be written as:",options:["$Dy = R$","$D^n y = R$","$y = L(R)$","$L(y) = R$"],correctIndex:3,difficulty:"medium",explanation:"The linear operator $L = D^n + P_1D^{n-1} + \\cdots + P_n$ acts on $y$ to give $L(y) = R$."},{id:4,type:"multiple-choice",question:"The equation $L(y) = 0$ is called:",options:["Homogeneous","Nonhomogeneous","Particular","Characteristic"],correctIndex:0,difficulty:"easy",explanation:"The equation is homogeneous when the right-hand side is zero. With $R \\neq 0$, it's nonhomogeneous."},{id:5,type:"multiple-choice",question:"The solution space $N(L)$ of an $n$th-order homogeneous linear equation has dimension:",options:["$1$","$n$","$n-1$","Infinite"],correctIndex:1,difficulty:"medium",explanation:"The Dimensionality Theorem states $\\dim N(L) = n$, so $n$ independent solutions form a basis."}],U=[{id:1,type:"multiple-choice",question:"The Existence-Uniqueness Theorem for $L(y) = 0$ guarantees a unique solution when:",options:["Initial value $y(x_0)$ is given","No initial conditions are given","Initial values $y(x_0), y'(x_0), \\ldots, y^{(n-1)}(x_0)$ are given","Only $y^{(n)}(x_0)$ is given"],correctIndex:2,difficulty:"medium",explanation:"An $n$th-order equation requires $n$ initial conditions: the value and first $n-1$ derivatives at a point."},{id:2,type:"multiple-choice",question:"The initial-value vector of a function $f$ at $x_0$ is:",options:["$(f(x_0))$","$(f(x_0), f'(x_0))$","$(f'(x_0), f''(x_0), \\ldots, f^{(n)}(x_0))$","$(f(x_0), f'(x_0), \\ldots, f^{(n-1)}(x_0))$"],correctIndex:3,difficulty:"easy",explanation:"The initial-value vector contains the value and first $n-1$ derivatives at $x_0$, which are the $n$ pieces of information needed."},{id:3,type:"multiple-choice",question:"For a second-order equation, the initial-value vector lives in:",options:["$\\mathbb{R}^2$","$\\mathbb{R}$","$\\mathbb{R}^3$","$\\mathbb{R}^n$"],correctIndex:0,difficulty:"easy",explanation:"For $n = 2$, we need $f(x_0)$ and $f'(x_0)$, a vector in 2-space."},{id:4,type:"multiple-choice",question:"The solution guaranteed by the theorem exists on:",options:["A small neighborhood of $x_0$ only","The entire interval $J$ where coefficients are continuous","Only at the point $x_0$","An interval depending on initial conditions"],correctIndex:1,difficulty:"hard",explanation:"Unlike nonlinear equations, linear equations have global solutions: the solution exists on the entire interval $J$ of continuity."},{id:5,type:"multiple-choice",question:"Compared to nonlinear equations, linear equations avoid which pathology?",options:["Having real-valued solutions","Having continuous solutions","Blow-up in finite time","Having polynomial solutions"],correctIndex:2,difficulty:"medium",explanation:"Nonlinear solutions may blow up in finite time (fail to exist globally). Linear equations with continuous coefficients always have global solutions."}],J=[{id:1,type:"multiple-choice",question:"The Dimensionality Theorem states that for an $n$th-order linear operator $L$:",options:["$\\dim N(L) = n - 1$","$\\dim N(L) = \\infty$","$\\dim N(L) = n + 1$","$\\dim N(L) = n$"],correctIndex:3,difficulty:"easy",explanation:"The solution space of $L(y) = 0$ has dimension exactly $n$, the order of the equation."},{id:2,type:"multiple-choice",question:"The proof of the Dimensionality Theorem uses a map $T$ from $N(L)$ to:",options:["The space of $n$-tuples (initial-value vectors)","The real numbers","The space of polynomials","The space of continuous functions"],correctIndex:0,difficulty:"medium",explanation:"$T(f) = (f(x_0), f'(x_0), \\ldots, f^{(n-1)}(x_0))$ maps each solution to its initial-value vector in $\\mathbb{R}^n$."},{id:3,type:"multiple-choice",question:"The map $T$ in the proof is one-to-one because:",options:["All solutions are constant","The uniqueness theorem says $T(f) = 0$ implies $f = 0$","The space is finite-dimensional","$T$ is a polynomial"],correctIndex:1,difficulty:"hard",explanation:"If $T(f) = 0$, all initial conditions are zero. By uniqueness, the only solution with these conditions is $f \\equiv 0$."},{id:4,type:"multiple-choice",question:"If $u_1, \\ldots, u_n$ are $n$ independent solutions of $L(y) = 0$, the general solution is:",options:["$y = u_1 + u_2 + \\cdots + u_n$","$y = u_1 u_2 \\cdots u_n$","$y = c_1 u_1 + c_2 u_2 + \\cdots + c_n u_n$","$y = u_1/u_n$"],correctIndex:2,difficulty:"easy",explanation:"Any solution is a linear combination of the basis solutions with arbitrary constants $c_1, \\ldots, c_n$."},{id:5,type:"numeric",question:"A 4th-order linear homogeneous ODE has how many linearly independent solutions?",correctAnswer:4,numericRange:{min:1,max:10,precision:0},difficulty:"easy",explanation:"By the Dimensionality Theorem, $\\dim N(L) = n = 4$ for a 4th-order equation."}],M=[{id:1,type:"multiple-choice",question:"A constant-coefficient operator has the form:",options:["$a_0 D^n + a_1(x) D^{n-1} + \\cdots$","$x^n D^n$","$D + x$","$a_0 D^n + a_1 D^{n-1} + \\cdots + a_n$ with $a_i$ constant"],correctIndex:3,difficulty:"easy",explanation:"Constant-coefficient means all the $a_i$ are real constants, not functions of $x$."},{id:2,type:"multiple-choice",question:"Constant-coefficient operators commute, meaning:",options:["$AB = BA$","$AB = -BA$","$AB = 0$","$A + B = BA$"],correctIndex:0,difficulty:"easy",explanation:"Since $D^r D^s = D^s D^r = D^{r+s}$, products of constant-coefficient operators commute."},{id:3,type:"multiple-choice",question:"The characteristic polynomial $p_A(r)$ of operator $A = a_0 D^n + a_1 D^{n-1} + \\cdots + a_n$ is:",options:["$a_0 + a_1 r + \\cdots + a_n r^n$","$a_0 r^n + a_1 r^{n-1} + \\cdots + a_n$","$r^n$","$a_0 a_1 \\cdots a_n$"],correctIndex:1,difficulty:"medium",explanation:"The characteristic polynomial has the same coefficients as the operator, with $r$ replacing $D$."},{id:4,type:"multiple-choice",question:"If $p_A(r) = p_B(r) \\cdot p_C(r)$, then:",options:["$A = B + C$","$A = B - C$","$A = B C$","$A = B / C$"],correctIndex:2,difficulty:"medium",explanation:"Multiplication of polynomials corresponds to composition of operators: $p_{AB} = p_A \\cdot p_B$."},{id:5,type:"multiple-choice",question:"The operator $D^2 - 5D + 6$ factors as:",options:["$(D - 1)(D - 6)$","$(D - 5)(D - 1)$","$(D + 2)(D + 3)$","$(D - 2)(D - 3)$"],correctIndex:3,difficulty:"easy",explanation:"$r^2 - 5r + 6 = (r - 2)(r - 3)$, so $D^2 - 5D + 6 = (D - 2)(D - 3)$."}],Z=[{id:1,type:"multiple-choice",question:"If $L = A_1 A_2 \\cdots A_k$, then the null space of $L$ contains:",options:["The null space of each factor $A_i$","Only the zero function","Only the null space of $A_1$","No functions"],correctIndex:0,difficulty:"medium",explanation:"If $A_i(u) = 0$, then $L(u) = 0$ because the operators commute. So $N(A_i) \\subseteq N(L)$ for each $i$."},{id:2,type:"multiple-choice",question:"The first-order operator $(D - r)$ annihilates:",options:["$e^{-rx}$","$e^{rx}$","$\\sin(rx)$","$r^x$"],correctIndex:1,difficulty:"easy",explanation:"$(D - r)(e^{rx}) = re^{rx} - re^{rx} = 0$."},{id:3,type:"multiple-choice",question:"For $(D^3 - 7D + 6)y = 0$ which factors as $(D-1)(D-2)(D+3)y = 0$, the basis of solutions is:",options:["$\\{e^x, e^{2x}, e^{3x}\\}$","$\\{1, x, x^2\\}$","$\\{e^x, e^{2x}, e^{-3x}\\}$","$\\{\\sin x, \\cos x, e^x\\}$"],correctIndex:2,difficulty:"medium",explanation:"Each factor $(D - r_k)$ contributes $e^{r_k x}$: roots $1, 2, -3$ give $e^x, e^{2x}, e^{-3x}$."},{id:4,type:"multiple-choice",question:"Exponentials $e^{r_1 x}, e^{r_2 x}, \\ldots, e^{r_n x}$ with distinct $r_k$ are:",options:["Always linearly dependent","Equal","Orthogonal","Always linearly independent"],correctIndex:3,difficulty:"medium",explanation:"Exponentials with distinct exponents are always linearly independent, providing a complete basis for distinct-root cases."},{id:5,type:"multiple-choice",question:"If $L(u) = 0$, we say $L$:",options:["Annihilates $u$","Integrates $u$","Differentiates $u$","Factors $u$"],correctIndex:0,difficulty:"easy",explanation:'The terminology is that $L$ "annihilates" $u$ when $L(u) = 0$, meaning $u$ is in the null space of $L$.'}],K=[{id:1,type:"multiple-choice",question:"If root $r$ has multiplicity $m$, the factor $(D-r)^m$ annihilates:",options:["$e^{rx}$ only","$e^{rx}, xe^{rx}, \\ldots, x^{m-1}e^{rx}$","$e^{rx}, e^{2rx}, \\ldots, e^{mrx}$","$1, x, x^2, \\ldots, x^{m-1}$"],correctIndex:1,difficulty:"medium",explanation:"A root of multiplicity $m$ contributes $m$ independent solutions: $e^{rx}, xe^{rx}, x^2 e^{rx}, \\ldots, x^{m-1}e^{rx}$."},{id:2,type:"multiple-choice",question:"For the equation $(D-2)^2(D+3)y = 0$, the general solution is:",options:["$y = c_1 e^{2x} + c_2 e^{-3x}$","$y = (c_1 + c_2 x + c_3 x^2)e^{2x}$","$y = c_1 e^{2x} + c_2 x e^{2x} + c_3 e^{-3x}$","$y = c_1 e^{2x} + c_2 e^{3x}$"],correctIndex:2,difficulty:"medium",explanation:"Root $2$ with multiplicity $2$ gives $e^{2x}, xe^{2x}$. Root $-3$ with multiplicity $1$ gives $e^{-3x}$."},{id:3,type:"multiple-choice",question:"The functions $1, x, x^2, \\ldots, x^{m-1}$ multiplied by $e^{rx}$ are:",options:["Linearly dependent","Equal","Orthogonal","Linearly independent"],correctIndex:3,difficulty:"easy",explanation:"Polynomials $1, x, \\ldots, x^{m-1}$ are independent, and multiplying by $e^{rx}$ preserves independence."},{id:4,type:"multiple-choice",question:"For $D^2 y = 0$ (root $0$ with multiplicity $2$), the solutions are:",options:["$1, x$","$e^x, e^{-x}$","$\\sin x, \\cos x$","$x, x^2$"],correctIndex:0,difficulty:"easy",explanation:"Root $r = 0$ with multiplicity $2$ gives $e^{0 \\cdot x} = 1$ and $xe^{0 \\cdot x} = x$."},{id:5,type:"numeric",question:"For $(D-1)^3(D+2)^2 y = 0$, how many independent solutions are there?",correctAnswer:5,numericRange:{min:1,max:10,precision:0},difficulty:"medium",explanation:"Root $1$ with multiplicity $3$ gives $3$ solutions; root $-2$ with multiplicity $2$ gives $2$ solutions. Total: $5$."}],ee=[{id:1,type:"multiple-choice",question:"Complex roots of a real characteristic polynomial occur in:",options:["Triples","Conjugate pairs","Single roots only","Quadruples"],correctIndex:1,difficulty:"easy",explanation:"Since coefficients are real, complex roots come in conjugate pairs: $\\alpha + i\\beta$ and $\\alpha - i\\beta$."},{id:2,type:"multiple-choice",question:"For complex roots $\\alpha \\pm i\\beta$, the real solutions are:",options:["$\\cos\\alpha x$ and $\\sin\\beta x$","$e^{\\alpha x}$ and $e^{\\beta x}$","$e^{\\alpha x}\\cos\\beta x$ and $e^{\\alpha x}\\sin\\beta x$","$e^{i\\beta x}$ and $e^{-i\\beta x}$"],correctIndex:2,difficulty:"medium",explanation:"Using Euler's formula, the real and imaginary parts of $e^{(\\alpha + i\\beta)x}$ give $e^{\\alpha x}\\cos\\beta x$ and $e^{\\alpha x}\\sin\\beta x$."},{id:3,type:"multiple-choice",question:"For $y'' + 4y = 0$ with roots $\\pm 2i$, the general solution is:",options:["$y = c_1 e^{2x} + c_2 e^{-2x}$","$y = c_1 e^{2ix} + c_2 e^{-2ix}$","$y = (c_1 + c_2 x)e^{2x}$","$y = c_1 \\cos 2x + c_2 \\sin 2x$"],correctIndex:3,difficulty:"easy",explanation:"Roots $\\pm 2i$ means $\\alpha = 0$, $\\beta = 2$. Solutions are $\\cos 2x$ and $\\sin 2x$."},{id:4,type:"multiple-choice",question:"If $\\alpha < 0$ for complex roots $\\alpha \\pm i\\beta$, the solutions:",options:["Decay while oscillating","Grow exponentially","Are constant","Are purely polynomial"],correctIndex:0,difficulty:"medium",explanation:"The factor $e^{\\alpha x}$ with $\\alpha < 0$ causes exponential decay, while $\\cos\\beta x, \\sin\\beta x$ provide oscillation."},{id:5,type:"multiple-choice",question:"For repeated complex roots $\\alpha \\pm i\\beta$ with multiplicity $m$, how many independent real solutions are there?",options:["$m$","$2m$","$m^2$","$2m - 1$"],correctIndex:1,difficulty:"hard",explanation:"Each pair gives $2$ solutions per multiplicity level: $x^{q-1}e^{\\alpha x}\\cos\\beta x$ and $x^{q-1}e^{\\alpha x}\\sin\\beta x$ for $q = 1, \\ldots, m$."}],te=[{id:1,type:"multiple-choice",question:"The general solution of a nonhomogeneous equation $L(y) = R$ has the form:",options:["Only a particular solution $y_1$","Only the homogeneous solutions $\\sum c_k u_k$","$y_1 + \\sum c_k u_k$ (particular + homogeneous)","The product $y_1 \\cdot u_1 \\cdots u_n$"],correctIndex:2,difficulty:"easy",explanation:"Every solution is a particular solution plus a linear combination of homogeneous solutions."},{id:2,type:"multiple-choice",question:"If $f$ solves $L(y) = R$ and $y_1$ is a particular solution, then $f - y_1$:",options:["Equals $R$","Solves $L(y) = 2R$","Equals zero","Solves $L(y) = 0$"],correctIndex:3,difficulty:"medium",explanation:"$L(f - y_1) = L(f) - L(y_1) = R - R = 0$, so $f - y_1$ is in the null space of $L$."},{id:3,type:"multiple-choice",question:"The superposition principle for linear equations states:",options:["Homogeneous solutions can be added to any particular solution","Solutions can only be multiplied","All solutions are equal","Nonlinear terms can be ignored"],correctIndex:0,difficulty:"easy",explanation:'Linearity allows adding homogeneous ("free") solutions to forced ("particular") solutions to get all solutions.'},{id:4,type:"multiple-choice",question:"The geometric analogy for solutions of $L(y) = R$ is:",options:["A line through the origin","A point plus a subspace (affine subspace)","A plane through the origin","The entire space"],correctIndex:1,difficulty:"medium",explanation:"Solutions form $y_1 + N(L)$: a particular point shifted by the subspace of homogeneous solutions (like a plane through a point, not through origin)."},{id:5,type:"multiple-choice",question:"To solve $L(y) = R$, we must:",options:["Find only the homogeneous solutions","Find only a particular solution","Find both homogeneous solutions and a particular solution","Factor the operator"],correctIndex:2,difficulty:"easy",explanation:"Both problems must be solved: (1) find a basis for $N(L)$, and (2) find one particular solution of $L(y) = R$."}],ie=[{id:1,type:"multiple-choice",question:"The method of variation of parameters seeks a particular solution of the form:",options:["$y_1 = c_1 u_1 + \\cdots + c_n u_n$ with constant $c_i$","$y_1 = x^n$","$y_1 = e^{rx}$","$y_1 = v_1(x) u_1 + \\cdots + v_n(x) u_n$ with varying $v_i$"],correctIndex:3,difficulty:"easy",explanation:"We replace the constants $c_i$ in the homogeneous solution by functions $v_i(x)$ to be determined."},{id:2,type:"multiple-choice",question:"In variation of parameters, the Wronskian matrix $W$ has rows consisting of:",options:["$u_i$ and their derivatives up to order $n-1$","The functions $u_1, \\ldots, u_n$ only","Only the highest derivatives","The coefficients of the equation"],correctIndex:0,difficulty:"medium",explanation:"The Wronskian matrix has $u_1, \\ldots, u_n$ in the first row, their first derivatives in the second, up to $(n-1)$th derivatives."},{id:3,type:"multiple-choice",question:"The system of equations for the functions $v_1, \\ldots, v_n$ can be written as:",options:["$W(x) v(x) = R(x)$","$W(x) v'(x) = R(x) \\cdot (0, \\ldots, 0, 1)^t$","$v(x) = W(x) R(x)$","$W'(x) = v(x)$"],correctIndex:1,difficulty:"hard",explanation:"The conditions lead to $W v' = R \\cdot e_n$ where $e_n = (0, \\ldots, 0, 1)^t$."},{id:4,type:"multiple-choice",question:"Variation of parameters works when:",options:["$R(x)$ is a polynomial only","$R(x)$ is an exponential only","We know the homogeneous solutions, regardless of $R(x)$","$R(x) = 0$"],correctIndex:2,difficulty:"medium",explanation:"The method works for any integrable $R(x)$, as long as we know $n$ independent homogeneous solutions."},{id:5,type:"multiple-choice",question:"The main computational steps in variation of parameters are:",options:["Factor the operator and find roots","Use the characteristic equation","Guess the form of the solution","Solve $W v' = R e_n$ for $v'$, then integrate"],correctIndex:3,difficulty:"medium",explanation:"We solve the linear system for $v'$, then integrate each component to find $v_1, \\ldots, v_n$."}],ne=[{id:1,type:"multiple-choice",question:"The Wronskian determinant of $n$ functions $u_1, \\ldots, u_n$ is:",options:["$\\det W$ where $W$ is the Wronskian matrix","$\\prod_{i=1}^n u_i$","$\\sum_{i=1}^n u_i$","$u_1 u_n' - u_n u_1'$"],correctIndex:0,difficulty:"easy",explanation:"The Wronskian determinant $w(x) = \\det W(x)$ is the determinant of the matrix with rows $u, u', \\ldots, u^{(n-1)}$."},{id:2,type:"multiple-choice",question:"Abel's formula states that the Wronskian satisfies:",options:["$w' = w$","$w' + P_1(x) w = 0$","$w'' = 0$","$w = \\text{constant}$"],correctIndex:1,difficulty:"medium",explanation:"The Wronskian satisfies the first-order ODE $w' + P_1(x) w = 0$, where $P_1$ is the coefficient of $y^{(n-1)}$."},{id:3,type:"multiple-choice",question:"According to Abel's formula, $w(x) = w(c) \\exp[-\\int_c^x P_1(t)\\,dt]$. This means the Wronskian:",options:["Is always zero","Changes sign","Is either identically zero or never zero","Equals $P_1(x)$"],correctIndex:2,difficulty:"hard",explanation:"Since an exponential is never zero, if $w(c) \\neq 0$ at any point, then $w(x) \\neq 0$ everywhere. Otherwise $w \\equiv 0$."},{id:4,type:"multiple-choice",question:"For second-order equations $y'' + P_1 y' + P_2 y = 0$, the Wronskian is:",options:["$w = u_1 + u_2$","$w = u_1' + u_2'$","$w = u_1 u_2$","$w = u_1 u_2' - u_1' u_2$"],correctIndex:3,difficulty:"easy",explanation:"For two functions, $w = \\det \\begin{bmatrix} u_1 & u_2 \\\\ u_1' & u_2' \\end{bmatrix} = u_1 u_2' - u_1' u_2$."},{id:5,type:"multiple-choice",question:"The Wronskian of independent solutions is always nonzero because:",options:["Zero Wronskian would contradict uniqueness of solutions","Exponentials are positive","The functions are continuous","The interval is bounded"],correctIndex:0,difficulty:"hard",explanation:"If $w(t_0) = 0$, a nontrivial linear combination vanishes at $t_0$ with all derivatives, contradicting uniqueness."}],ae=[{id:1,type:"multiple-choice",question:"The annihilator method converts $L(y) = R$ into:",options:["A first-order equation","A higher-order homogeneous equation $AL(y) = 0$","A system of equations","An integral equation"],correctIndex:1,difficulty:"easy",explanation:"If $A$ annihilates $R$, then applying $A$ to both sides gives $AL(y) = 0$, a homogeneous equation."},{id:2,type:"multiple-choice",question:"The polynomial $x^{m-1}$ is annihilated by:",options:["$D$","$D^{m-1}$","$D^m$","$(D - 1)^m$"],correctIndex:2,difficulty:"easy",explanation:"$D^m(x^{m-1}) = 0$ since differentiation $m$ times gives zero for a polynomial of degree $m-1$."},{id:3,type:"multiple-choice",question:"The function $e^{\\alpha x}$ is annihilated by:",options:["$D$","$D^2$","$(D + \\alpha)$","$(D - \\alpha)$"],correctIndex:3,difficulty:"easy",explanation:"$(D - \\alpha)(e^{\\alpha x}) = \\alpha e^{\\alpha x} - \\alpha e^{\\alpha x} = 0$."},{id:4,type:"multiple-choice",question:"To solve $y'' - 5y' + 6y = xe^x$, we need to find an operator that annihilates:",options:["$xe^x$, which is annihilated by $(D-1)^2$","$e^x$, which is annihilated by $(D-1)$","$x$, which is annihilated by $D$","$xe^x$, which is annihilated by $(D-1)$"],correctIndex:0,difficulty:"medium",explanation:"$xe^x$ requires $(D-1)^2$ because $x e^{\\alpha x}$ is annihilated by $(D - \\alpha)^2$."},{id:5,type:"multiple-choice",question:"The annihilator method does NOT work for:",options:["$R(x) = e^{2x}$","$R(x) = \\tan x$","$R(x) = x^2$","$R(x) = \\sin 3x$"],correctIndex:1,difficulty:"medium",explanation:"The method requires $R$ to be a combination of polynomials, exponentials, sines, and cosines. Functions like $\\tan x$, $\\log x$, or $e^{x^2}$ are not annihilated by constant-coefficient operators."}],oe=[{id:1,type:"multiple-choice",question:"A function $f$ is analytic on an interval if:",options:["It is continuous","It is differentiable","It has a convergent power series expansion","It is bounded"],correctIndex:2,difficulty:"easy",explanation:"Analytic means $f(x) = \\sum_{n=0}^\\infty a_n (x - x_0)^n$ converges on the interval."},{id:2,type:"multiple-choice",question:"For $y'' + P_1(x)y' + P_2(x)y = 0$ with analytic coefficients, Theorem 6.13 guarantees:",options:["No solutions exist","Polynomial solutions only","Only one solution","Two independent analytic solutions"],correctIndex:3,difficulty:"medium",explanation:"When $P_1$ and $P_2$ are analytic on an interval, there exist two independent solutions that are also analytic on that interval."},{id:3,type:"multiple-choice",question:"To find power series solutions, we substitute $y = \\sum a_n (x - x_0)^n$ and:",options:["Differentiate and equate coefficients to get a recursion","Solve for $y$ directly","Integrate the equation","Factor the operator"],correctIndex:0,difficulty:"medium",explanation:"Substituting the series and equating coefficients of like powers gives a recursion formula for the $a_n$."},{id:4,type:"multiple-choice",question:"The coefficients $a_0$ and $a_1$ in a power series solution represent:",options:["Random constants","$y(x_0)$ and $y'(x_0)$","The roots of the equation","The interval of convergence"],correctIndex:1,difficulty:"easy",explanation:"$a_0 = y(x_0)$ and $a_1 = y'(x_0)$ are the initial conditions that determine the specific solution."},{id:5,type:"multiple-choice",question:"Two independent power series solutions $u_1, u_2$ can be obtained by choosing:",options:["$a_0 = a_1 = 0$","$a_0 = a_1 = 1$","$(a_0, a_1) = (1, 0)$ and $(a_0, a_1) = (0, 1)$","Any values"],correctIndex:2,difficulty:"medium",explanation:"These choices give solutions with initial vectors $(1, 0)$ and $(0, 1)$, which are independent. Their Wronskian at $x_0$ is $1 \\neq 0$."}],se=[{id:1,type:"multiple-choice",question:"The Legendre equation is:",options:["$y'' + y = 0$","$x^2 y'' + xy' + y = 0$","$y'' + xy = 0$","$(1 - x^2)y'' - 2xy' + \\alpha(\\alpha + 1)y = 0$"],correctIndex:3,difficulty:"easy",explanation:"The Legendre equation has the specific form $(1 - x^2)y'' - 2xy' + \\alpha(\\alpha + 1)y = 0$."},{id:2,type:"multiple-choice",question:"The Legendre equation arises in physical problems involving:",options:["Spherical symmetry","Linear motion only","Exponential growth","Oscillations only"],correctIndex:0,difficulty:"easy",explanation:"The Legendre equation appears in problems with spherical symmetry, such as gravitational attraction and heat flow on spheres."},{id:3,type:"multiple-choice",question:"The recursion formula for the Legendre equation gives:",options:["$a_{n+1}$ in terms of $a_n$","$a_{n+2}$ in terms of $a_n$","$a_n$ in terms of $a_{n+3}$","$a_n = n!$"],correctIndex:1,difficulty:"medium",explanation:"The recursion $a_{n+2} = -\\frac{(\\alpha - n)(\\alpha + n + 1)}{(n+1)(n+2)} a_n$ connects every other coefficient."},{id:4,type:"multiple-choice",question:"The Legendre equation has polynomial solutions when:",options:["$\\alpha$ is any real number","$\\alpha < 0$","$\\alpha$ is a nonnegative integer","$\\alpha$ is irrational"],correctIndex:2,difficulty:"medium",explanation:"When $\\alpha$ is a nonnegative integer, the recursion terminates, giving polynomial solutions called Legendre polynomials."},{id:5,type:"multiple-choice",question:"For $\\alpha = 2$, the even solution $u_1(x)$ becomes:",options:["$1$","$x$","$x - \\frac{5}{3}x^3$","$1 - 3x^2$"],correctIndex:3,difficulty:"hard",explanation:"For $\\alpha = 2$ (even), the even power series terminates. The recursion gives $u_1(x) = 1 - 3x^2$."}],re=[{id:1,type:"multiple-choice",question:"The Legendre polynomials $P_n(x)$ are defined on which interval?",options:["$[-1, 1]$","$(-\\infty, \\infty)$","$[0, 1]$","$[0, \\infty)$"],correctIndex:0,difficulty:"easy",explanation:"Legendre polynomials are defined and orthogonal on the interval $[-1, 1]$."},{id:2,type:"multiple-choice",question:"The Rodrigues formula for Legendre polynomials is $P_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n}(x^2 - 1)^n$. What is $P_0(x)$?",options:["$0$","$1$","$x$","$x^2$"],correctIndex:1,difficulty:"easy",explanation:"For $n = 0$: $P_0(x) = \\frac{1}{2^0 \\cdot 0!}(x^2-1)^0 = 1$."},{id:3,type:"multiple-choice",question:"The Legendre polynomials satisfy which orthogonality relation?",options:["$\\int_{-\\infty}^{\\infty} P_m(x) P_n(x) e^{-x^2}\\, dx = 0$ for $m \\neq n$","$\\int_{0}^{\\infty} P_m(x) P_n(x) e^{-x}\\, dx = 0$ for $m \\neq n$","$\\int_{-1}^{1} P_m(x) P_n(x)\\, dx = 0$ for $m \\neq n$","$\\sum_{k=0}^{\\infty} P_m(k) P_n(k) = 0$ for $m \\neq n$"],correctIndex:2,difficulty:"medium",explanation:"Legendre polynomials are orthogonal with respect to the weight function $w(x) = 1$ on $[-1, 1]$."},{id:4,type:"multiple-choice",question:"What is the value of $\\int_{-1}^{1} [P_n(x)]^2\\, dx$?",options:["$1$","$\\frac{2}{n}$","$\\frac{1}{n+1}$","$\\frac{2}{2n+1}$"],correctIndex:3,difficulty:"medium",explanation:"The normalization integral for Legendre polynomials is $\\int_{-1}^{1} [P_n(x)]^2\\, dx = \\frac{2}{2n+1}$."},{id:5,type:"multiple-choice",question:"Using the Rodrigues formula, $P_1(x)$ equals:",options:["$x$","$1$","$\\frac{1}{2}(3x^2 - 1)$","$\\frac{1}{2}(5x^3 - 3x)$"],correctIndex:0,difficulty:"easy",explanation:"$P_1(x) = \\frac{1}{2^1 \\cdot 1!} \\frac{d}{dx}(x^2 - 1) = \\frac{1}{2} \\cdot 2x = x$."}],$e=[{id:1,type:"multiple-choice",question:"The method of Frobenius is used to find solutions near a point $x_0$ that is:",options:["An ordinary point","A regular singular point","An irregular singular point","Any point on the real line"],correctIndex:1,difficulty:"easy",explanation:"The method of Frobenius extends power series methods to regular singular points, where ordinary power series may fail."},{id:2,type:"multiple-choice",question:"For the equation $x^2 y'' + xp(x)y' + q(x)y = 0$ with $p$ and $q$ analytic at $x = 0$, the point $x = 0$ is:",options:["An ordinary point","An irregular singular point","A regular singular point","Not a singular point"],correctIndex:2,difficulty:"medium",explanation:"When $xp(x)$ and $x^2 q(x)$ are analytic at $x = 0$, the point is a regular singular point."},{id:3,type:"multiple-choice",question:"In the Frobenius method, the solution has the form $y = x^r \\sum_{n=0}^{\\infty} a_n x^n$ where $r$ is found from:",options:["The characteristic equation","The auxiliary equation","The recurrence relation","The indicial equation"],correctIndex:3,difficulty:"easy",explanation:"The exponent $r$ is determined by the indicial equation, obtained by substituting the Frobenius series into the differential equation."},{id:4,type:"multiple-choice",question:"If the indicial equation has roots $r_1$ and $r_2$ with $r_1 - r_2$ not an integer, then:",options:["Two linearly independent Frobenius solutions exist","Only one Frobenius solution exists","A logarithmic term must appear in the second solution","The equation has no series solution"],correctIndex:0,difficulty:"medium",explanation:"When the roots differ by a non-integer, two linearly independent Frobenius series solutions exist."},{id:5,type:"multiple-choice",question:"For the equation $2xy'' + (1-x)y' - y = 0$, what is the indicial equation at $x = 0$?",options:["$r(r-1) = 0$","$r(2r-1) = 0$","$2r(r-1) + r = 0$","$r^2 = 0$"],correctIndex:1,difficulty:"hard",explanation:"Rewriting as $y'' + \\frac{1-x}{2x}y' - \\frac{1}{2x}y = 0$, the indicial equation is $r(r-1) + \\frac{1}{2}r = r(2r-1)/2 = 0$, giving $r(2r-1) = 0$."}],le=[{id:1,type:"multiple-choice",question:"The Bessel equation of order $\\nu$ is:",options:["$y'' + y = 0$","$x^2 y'' + xy' + x^2 y = 0$","$x^2 y'' + xy' + (x^2 - \\nu^2)y = 0$","$y'' + \\frac{1}{x}y' + y = 0$"],correctIndex:2,difficulty:"easy",explanation:"The standard form of Bessel's equation of order $\\nu$ is $x^2 y'' + xy' + (x^2 - \\nu^2)y = 0$."},{id:2,type:"multiple-choice",question:"The Bessel function of the first kind $J_\\nu(x)$ is defined by a Frobenius series with leading term:",options:["$x^{-\\nu}$","$\\ln x$","$e^x$","$x^\\nu$"],correctIndex:3,difficulty:"medium",explanation:"For the Bessel equation, one root of the indicial equation is $r = \\nu$, giving $J_\\nu(x) = x^\\nu \\sum_{n=0}^{\\infty} a_n x^n$."},{id:3,type:"multiple-choice",question:"The Bessel function $J_0(0)$ equals:",options:["$1$","$0$","$\\infty$","Undefined"],correctIndex:0,difficulty:"easy",explanation:"The Bessel function $J_0(x)$ has the series expansion starting with $1 - \\frac{x^2}{4} + \\cdots$, so $J_0(0) = 1$."},{id:4,type:"multiple-choice",question:"For the Bessel equation of order $\\nu = 0$, the indicial equation has:",options:["Two distinct roots $r = 0$ and $r = 1$","A repeated root $r = 0$","Complex roots","No real roots"],correctIndex:1,difficulty:"medium",explanation:"When $\\nu = 0$, the indicial equation $r^2 - \\nu^2 = r^2 = 0$ has a double root at $r = 0$, requiring logarithmic terms for the second solution."},{id:5,type:"multiple-choice",question:"The recurrence relation for the coefficients in $J_\\nu(x)$ is:",options:["$a_{n+2} = a_n$","$a_{n+1} = \\frac{a_n}{n+1}$","$a_{n+2} = -\\frac{a_n}{(n+2)(n+2+2\\nu)}$","$a_{n+1} = -a_n$"],correctIndex:2,difficulty:"hard",explanation:"The Bessel equation yields a two-term recurrence where $a_{n+2}$ relates to $a_n$, with odd-indexed coefficients being zero."}],ce=[{id:1,type:"multiple-choice",question:"A first-order system of linear differential equations can be written in matrix form as:",options:["$Y' = Y^2$","$y'' + ay' + by = 0$","$\\frac{\\partial u}{\\partial t} = \\frac{\\partial^2 u}{\\partial x^2}$","$Y' = AY + F$ where $Y$ and $F$ are vectors and $A$ is a matrix"],correctIndex:3,difficulty:"easy",explanation:"A first-order linear system has the form $Y' = AY + F$ where $Y$ is a vector of unknowns, $A$ is the coefficient matrix, and $F$ is the forcing term."},{id:2,type:"multiple-choice",question:"A single $n$th-order linear ODE can be converted to a first-order system of how many equations?",options:["$n$","$n-1$","$1$","$2n$"],correctIndex:0,difficulty:"easy",explanation:"An $n$th-order ODE is equivalent to a system of $n$ first-order equations by introducing $y_1 = y, y_2 = y', \\ldots, y_n = y^{(n-1)}$."},{id:3,type:"multiple-choice",question:"For the homogeneous system $Y' = AY$, the solution space is:",options:["One-dimensional","A vector space of dimension equal to the size of $A$","Always infinite-dimensional","Not a vector space"],correctIndex:1,difficulty:"medium",explanation:"For an $n \\times n$ matrix $A$, the solution space of $Y' = AY$ is an $n$-dimensional vector space."},{id:4,type:"multiple-choice",question:"Which system is equivalent to the second-order equation $y'' + 3y' + 2y = 0$?",options:["$y_1' = -2y_1, \\quad y_2' = -3y_2$","$y_1' = y_2, \\quad y_2' = 2y_1 + 3y_2$","$y_1' = y_2, \\quad y_2' = -2y_1 - 3y_2$","$y_1' = y_1 + y_2, \\quad y_2' = y_1 - y_2$"],correctIndex:2,difficulty:"medium",explanation:"Setting $y_1 = y$ and $y_2 = y'$, we get $y_1' = y_2$ and $y_2' = y'' = -3y' - 2y = -3y_2 - 2y_1$."},{id:5,type:"multiple-choice",question:"The general solution of a homogeneous system $Y' = AY$ with $A$ an $n \\times n$ matrix requires:",options:["$1$ arbitrary constant","$n-1$ arbitrary constants","$n^2$ arbitrary constants","$n$ arbitrary constants"],correctIndex:3,difficulty:"easy",explanation:"The solution space has dimension $n$, so the general solution involves $n$ arbitrary constants (one for each basis solution)."}],de=[{id:1,type:"multiple-choice",question:"For a matrix function $A(t)$, the derivative $A'(t)$ is defined as:",options:["The matrix whose entries are the derivatives of the entries of $A(t)$","The determinant of $A(t)$","The inverse of $A(t)$","The transpose of $A(t)$"],correctIndex:0,difficulty:"easy",explanation:"The derivative of a matrix function is computed entry-by-entry: $(A'(t))_{ij} = \\frac{d}{dt}(A(t))_{ij}$."},{id:2,type:"multiple-choice",question:"If $A(t)$ and $B(t)$ are differentiable matrix functions, then $(AB)' =$",options:["$A'B'$","$A'B + AB'$","$BA' + B'A$","$A'B' + AB$"],correctIndex:1,difficulty:"medium",explanation:"The product rule for matrix functions is $(AB)' = A'B + AB'$. Note that order matters since matrix multiplication is not commutative."},{id:3,type:"multiple-choice",question:"The norm $\\|A\\|$ of a matrix $A$ used in convergence arguments for matrix series is typically:",options:["$\\|A\\| = \\det(A)$","$\\|A\\| = \\text{tr}(A)$","$\\|A\\| = \\max_{ij} |a_{ij}|$ or $\\sqrt{\\sum_{ij} |a_{ij}|^2}$","$\\|A\\| = \\sum_{i} a_{ii}$"],correctIndex:2,difficulty:"medium",explanation:"Common matrix norms include the max norm $\\max|a_{ij}|$ and the Frobenius norm $\\sqrt{\\sum|a_{ij}|^2}$, both useful for convergence analysis."},{id:4,type:"multiple-choice",question:"For the integral of a matrix function, $\\int_a^b A(t)\\,dt$ is:",options:["A scalar","The inverse of $A(t)$","Only defined for diagonal matrices","A matrix whose entries are integrals of the corresponding entries"],correctIndex:3,difficulty:"easy",explanation:"Matrix integration is performed entry-by-entry: $(\\int A(t)\\,dt)_{ij} = \\int (A(t))_{ij}\\,dt$."},{id:5,type:"multiple-choice",question:"If $Y(t)$ is a matrix solution of $Y' = AY$ and $Y(t_0) = I$, then for any initial vector $c$, the solution with $Y(t_0) = c$ is:",options:["$Y(t)c$","$Y(t) + c$","$cY(t)$","$Y(t)^{-1}c$"],correctIndex:0,difficulty:"hard",explanation:"The fundamental matrix $Y(t)$ with $Y(t_0) = I$ gives solutions as $Y(t)c$ for initial condition $c$."}],he=[{id:1,type:"multiple-choice",question:"The matrix exponential $e^A$ is defined by:",options:["$e^{a_{11}} + e^{a_{22}} + \\cdots$","$I + A + \\frac{A^2}{2!} + \\frac{A^3}{3!} + \\cdots$","A matrix whose entries are $e^{a_{ij}}$","$\\lim_{n \\to \\infty} (I + A/n)$"],correctIndex:1,difficulty:"easy",explanation:"The matrix exponential is defined by the power series $e^A = \\sum_{k=0}^{\\infty} \\frac{A^k}{k!}$."},{id:2,type:"multiple-choice",question:"For the zero matrix $O$, the exponential $e^O$ equals:",options:["$O$","Undefined","$I$ (identity matrix)","$e \\cdot I$"],correctIndex:2,difficulty:"easy",explanation:"$e^O = I + O + \\frac{O^2}{2!} + \\cdots = I$ since all powers of $O$ are $O$."},{id:3,type:"multiple-choice",question:"If $A$ is a diagonal matrix with entries $\\lambda_1, \\ldots, \\lambda_n$, then $e^A$ is:",options:["$\\lambda_1 e^{\\lambda_1} + \\cdots + \\lambda_n e^{\\lambda_n}$","The matrix $eI$","Not necessarily diagonal","A diagonal matrix with entries $e^{\\lambda_1}, \\ldots, e^{\\lambda_n}$"],correctIndex:3,difficulty:"medium",explanation:"For diagonal matrices, the exponential is computed entry-wise on the diagonal: $e^{\\text{diag}(\\lambda_i)} = \\text{diag}(e^{\\lambda_i})$."},{id:4,type:"multiple-choice",question:"The series $e^A = \\sum_{k=0}^{\\infty} \\frac{A^k}{k!}$ converges for:",options:["All square matrices $A$","Only symmetric matrices","Only nilpotent matrices","Only matrices with $\\|A\\| < 1$"],correctIndex:0,difficulty:"medium",explanation:"The exponential series converges absolutely for any square matrix $A$, regardless of its norm or properties."},{id:5,type:"multiple-choice",question:"If $N$ is nilpotent with $N^k = O$ for some $k$, then $e^N$ is:",options:["An infinite series","A finite sum: $I + N + \\frac{N^2}{2!} + \\cdots + \\frac{N^{k-1}}{(k-1)!}$","The zero matrix","Not defined"],correctIndex:1,difficulty:"medium",explanation:"For nilpotent $N$ with $N^k = O$, the series terminates after $k$ terms, giving a polynomial in $N$."}],fe=[{id:1,type:"multiple-choice",question:"The uniqueness theorem for $Y' = AY$ with initial condition $Y(t_0) = Y_0$ states that:",options:["There are infinitely many solutions","Solutions exist only for $t > t_0$","There is exactly one solution on any interval containing $t_0$","Solutions may not exist"],correctIndex:2,difficulty:"easy",explanation:"The uniqueness theorem guarantees exactly one solution passing through any given initial point."},{id:2,type:"multiple-choice",question:"For the matrix differential equation $Y' = AY$ with constant $A$, if $Y(0) = I$, then $Y(t) =$",options:["$tA$","$I + tA$","$A^t$","$e^{tA}$"],correctIndex:3,difficulty:"medium",explanation:"The unique solution to $Y' = AY$ with $Y(0) = I$ is the matrix exponential $Y(t) = e^{tA}$."},{id:3,type:"multiple-choice",question:"The uniqueness theorem implies that if two solutions agree at one point, they:",options:["Agree everywhere","May differ elsewhere","Must both be zero","Are linearly dependent"],correctIndex:0,difficulty:"easy",explanation:"By uniqueness, if $Y_1(t_0) = Y_2(t_0)$, then $Y_1(t) = Y_2(t)$ for all $t$."},{id:4,type:"multiple-choice",question:"The proof of uniqueness for $Y' = AY$ typically uses:",options:["Integration by parts","Gronwall's inequality or a contraction argument","The quadratic formula","Taylor's theorem only"],correctIndex:1,difficulty:"hard",explanation:"Uniqueness proofs often employ Gronwall's inequality or show that the difference of two solutions satisfies an inequality forcing it to zero."},{id:5,type:"multiple-choice",question:"If $\\Phi(t)$ is a fundamental matrix solution of $Y' = AY$, then every solution can be written as:",options:["$\\Phi(t) + c$ for some constant vector $c$","$c\\Phi(t)$ for some constant scalar $c$","$\\Phi(t)c$ for some constant vector $c$","$\\Phi(t)^{-1}$"],correctIndex:2,difficulty:"medium",explanation:"A fundamental matrix $\\Phi(t)$ generates all solutions via $Y(t) = \\Phi(t)c$ where $c$ is determined by initial conditions."}],ue=[{id:1,type:"multiple-choice",question:"The law of exponents $e^{A+B} = e^A e^B$ holds for matrices when:",options:["Always","When $A$ and $B$ are both diagonal","When $A$ and $B$ are both symmetric","When $AB = BA$ (commuting matrices)"],correctIndex:3,difficulty:"medium",explanation:"The law $e^{A+B} = e^A e^B$ holds if and only if $A$ and $B$ commute: $AB = BA$."},{id:2,type:"multiple-choice",question:"For the matrix exponential, $e^{tA} \\cdot e^{sA}$ equals:",options:["$e^{(t+s)A}$","$e^{tsA}$","$e^{tA + sA}$ only if $t = s$","$(e^A)^{t+s}$"],correctIndex:0,difficulty:"easy",explanation:"Since $tA$ and $sA$ commute (both are scalar multiples of $A$), we have $e^{tA}e^{sA} = e^{(t+s)A}$."},{id:3,type:"multiple-choice",question:"The inverse of $e^A$ is:",options:["$e^{1/A}$","$e^{-A}$","$(e^A)^T$","$I - A$"],correctIndex:1,difficulty:"easy",explanation:"Using the law of exponents: $e^A \\cdot e^{-A} = e^{A + (-A)} = e^O = I$, so $(e^A)^{-1} = e^{-A}$."},{id:4,type:"multiple-choice",question:"If $A$ and $B$ do not commute, then in general:",options:["$e^{A+B} = e^A e^B$","$e^{A+B} = e^B e^A$","$e^{A+B} \\neq e^A e^B$","$e^{A+B}$ does not exist"],correctIndex:2,difficulty:"medium",explanation:"When $AB \\neq BA$, the simple law of exponents fails. The correct formula involves the Baker-Campbell-Hausdorff series."},{id:5,type:"multiple-choice",question:"The derivative $\\frac{d}{dt}e^{tA}$ equals:",options:["$e^{tA}$","$Ae^{tA}$","$te^{tA}$","$e^{tA}A$ (which equals $Ae^{tA}$ since $A$ commutes with $e^{tA}$)"],correctIndex:3,difficulty:"medium",explanation:"$\\frac{d}{dt}e^{tA} = Ae^{tA} = e^{tA}A$ because $A$ and $e^{tA}$ commute (both are polynomials/series in $A$)."}],pe=[{id:1,type:"multiple-choice",question:"For the homogeneous system $Y' = AY$ with constant $A$, the general solution is:",options:["$Y(t) = e^{tA}c$ for any constant vector $c$","$Y(t) = e^{tA}$","$Y(t) = c_1 e^{\\lambda_1 t} + c_2 e^{\\lambda_2 t}$","$Y(t) = At + B$"],correctIndex:0,difficulty:"easy",explanation:"The general solution is $Y(t) = e^{tA}c$ where $c$ is an arbitrary constant vector (determined by initial conditions)."},{id:2,type:"multiple-choice",question:"If $\\lambda$ is an eigenvalue of $A$ with eigenvector $v$, then a solution of $Y' = AY$ is:",options:["$Y(t) = \\lambda t \\cdot v$","$Y(t) = e^{\\lambda t} v$","$Y(t) = v \\cos(\\lambda t)$","$Y(t) = \\lambda v$"],correctIndex:1,difficulty:"medium",explanation:"If $Av = \\lambda v$, then $Y(t) = e^{\\lambda t}v$ satisfies $Y' = \\lambda e^{\\lambda t}v = e^{\\lambda t}Av = AY$."},{id:3,type:"multiple-choice",question:"The existence theorem guarantees solutions to $Y' = AY$ with $Y(t_0) = Y_0$ exist for:",options:["Only $t > t_0$","Only $t < t_0$","All $t \\in \\mathbb{R}$ (when $A$ is constant)","Only in a neighborhood of $t_0$"],correctIndex:2,difficulty:"medium",explanation:"For constant coefficient systems, solutions exist globally for all time since $e^{tA}$ is defined for all $t$."},{id:4,type:"multiple-choice",question:"If $A$ is a $2 \\times 2$ matrix with distinct real eigenvalues $\\lambda_1, \\lambda_2$ and eigenvectors $v_1, v_2$, the general solution is:",options:["$c_1 \\cos(\\lambda_1 t) + c_2 \\sin(\\lambda_2 t)$","$e^{(\\lambda_1 + \\lambda_2)t}(c_1 v_1 + c_2 v_2)$","$(c_1 + c_2 t)e^{\\lambda_1 t}$","$c_1 e^{\\lambda_1 t} v_1 + c_2 e^{\\lambda_2 t} v_2$"],correctIndex:3,difficulty:"medium",explanation:"With distinct eigenvalues, the general solution is a linear combination of the exponential solutions for each eigenvalue-eigenvector pair."},{id:5,type:"multiple-choice",question:"The dimension of the solution space of $Y' = AY$ where $A$ is $n \\times n$ is:",options:["$n$","$1$","$n^2$","Infinite"],correctIndex:0,difficulty:"easy",explanation:"The solution space is $n$-dimensional, matching the number of initial conditions needed to uniquely determine a solution."}],me=[{id:1,type:"multiple-choice",question:"To compute $e^{tA}$ when $A$ is diagonalizable as $A = PDP^{-1}$, we use:",options:["$e^{tA} = e^{tP}e^{tD}e^{tP^{-1}}$","$e^{tA} = Pe^{tD}P^{-1}$","$e^{tA} = P^{-1}e^{tD}P$","$e^{tA} = e^{tP}De^{-tP}$"],correctIndex:1,difficulty:"medium",explanation:"If $A = PDP^{-1}$, then $A^k = PD^kP^{-1}$, so $e^{tA} = Pe^{tD}P^{-1}$ where $e^{tD}$ is diagonal with entries $e^{t\\lambda_i}$."},{id:2,type:"multiple-choice",question:"For a diagonal matrix $D = \\text{diag}(\\lambda_1, \\ldots, \\lambda_n)$, the exponential $e^{tD}$ is:",options:["$\\text{diag}(t\\lambda_1, \\ldots, t\\lambda_n)$","$e^t \\cdot D$","$\\text{diag}(e^{t\\lambda_1}, \\ldots, e^{t\\lambda_n})$","$D^t$"],correctIndex:2,difficulty:"easy",explanation:"The exponential of a diagonal matrix is diagonal with entries $e^{t\\lambda_i}$."},{id:3,type:"multiple-choice",question:"When $A$ has complex eigenvalues $\\alpha \\pm i\\beta$, the real solutions involve:",options:["Only exponentials","Only trigonometric functions","Logarithmic functions","$e^{\\alpha t}\\cos(\\beta t)$ and $e^{\\alpha t}\\sin(\\beta t)$ terms"],correctIndex:3,difficulty:"medium",explanation:"Complex eigenvalues $\\alpha \\pm i\\beta$ produce real solutions combining exponential decay/growth with oscillation."},{id:4,type:"multiple-choice",question:"If $A = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}$, then $e^{tA}$ equals:",options:["$\\begin{pmatrix} \\cos t & \\sin t \\\\ -\\sin t & \\cos t \\end{pmatrix}$","$\\begin{pmatrix} e^t & 0 \\\\ 0 & e^{-t} \\end{pmatrix}$","$\\begin{pmatrix} 1+t & t \\\\ -t & 1-t \\end{pmatrix}$","$\\begin{pmatrix} \\cosh t & \\sinh t \\\\ -\\sinh t & \\cosh t \\end{pmatrix}$"],correctIndex:0,difficulty:"hard",explanation:"This matrix has eigenvalues $\\pm i$, giving rotation: $e^{tA} = I\\cos t + A\\sin t$."},{id:5,type:"multiple-choice",question:"For a nilpotent matrix $N$ with $N^2 = O$, the exponential $e^{tN}$ is:",options:["$I$","$I + tN$","$I + tN + \\frac{t^2N^2}{2}$","An infinite series"],correctIndex:1,difficulty:"medium",explanation:"Since $N^2 = O$, all higher powers vanish, so $e^{tN} = I + tN$."}],ye=[{id:1,type:"multiple-choice",question:"The Cayley-Hamilton theorem states that every square matrix:",options:["Is diagonalizable","Has real eigenvalues","Satisfies its own characteristic equation","Commutes with its transpose"],correctIndex:2,difficulty:"easy",explanation:"If $p(\\lambda) = \\det(\\lambda I - A)$ is the characteristic polynomial of $A$, then $p(A) = O$ (the zero matrix)."},{id:2,type:"multiple-choice",question:"If $A$ is a $2 \\times 2$ matrix with characteristic polynomial $\\lambda^2 - 5\\lambda + 6$, then Cayley-Hamilton implies:",options:["$A^2 = 5A - 6I$","$A^2 + 5A + 6I = O$","$A = 5I$","$A^2 - 5A + 6I = O$"],correctIndex:3,difficulty:"medium",explanation:"By Cayley-Hamilton, substituting $A$ for $\\lambda$: $A^2 - 5A + 6I = O$."},{id:3,type:"multiple-choice",question:"Using Cayley-Hamilton, any power $A^n$ of an $n \\times n$ matrix can be expressed as:",options:["A polynomial in $A$ of degree at most $n-1$","A polynomial in $A$ of degree exactly $n$","An infinite series","A diagonal matrix"],correctIndex:0,difficulty:"medium",explanation:"Cayley-Hamilton lets us reduce $A^n$ to lower powers, so any $A^k$ is a polynomial in $A$ of degree at most $n-1$."},{id:4,type:"multiple-choice",question:"The Cayley-Hamilton theorem implies that $e^{tA}$ for an $n \\times n$ matrix is:",options:["Always a polynomial of degree $n$ in $t$","A polynomial in $A$ with coefficients depending on $t$","Equal to $I + tA$","Independent of $A$"],correctIndex:1,difficulty:"hard",explanation:"Since high powers of $A$ reduce to polynomials of degree $\\leq n-1$ in $A$, $e^{tA}$ can be written as $\\sum_{k=0}^{n-1} f_k(t)A^k$."},{id:5,type:"multiple-choice",question:"For a $3 \\times 3$ matrix with characteristic polynomial $\\lambda^3 - 6\\lambda^2 + 11\\lambda - 6$, Cayley-Hamilton gives:",options:["$A^3 = 6A^2 - 11A + 6I$","$A^3 + 6A^2 + 11A + 6I = O$","$A^3 - 6A^2 + 11A - 6I = O$","$A = 6I$"],correctIndex:2,difficulty:"medium",explanation:"Substituting $A$ for $\\lambda$ in the characteristic polynomial gives $A^3 - 6A^2 + 11A - 6I = O$."}],xe=[{id:1,type:"multiple-choice",question:"Putzer's method expresses $e^{tA}$ as a sum involving:",options:["The eigenvalues and eigenvectors of $A$","Trigonometric functions of the entries of $A$","Only the trace and determinant of $A$","The eigenvalues of $A$ and matrices $P_k$ defined recursively"],correctIndex:3,difficulty:"medium",explanation:"Putzer's method uses eigenvalues $\\lambda_1, \\ldots, \\lambda_n$ and recursively defined matrices $P_k$ to compute $e^{tA}$."},{id:2,type:"multiple-choice",question:"In Putzer's method, the matrices $P_k$ are defined by:",options:["$P_0 = I$, $P_k = (A - \\lambda_k I)P_{k-1}$ for $k \\geq 1$","$P_k = A^k$","$P_k = e^{\\lambda_k A}$","$P_k = \\lambda_k^k I$"],correctIndex:0,difficulty:"hard",explanation:"The matrices are built recursively: $P_0 = I$ and $P_k = (A - \\lambda_k I)P_{k-1}$, using the eigenvalues in sequence."},{id:3,type:"multiple-choice",question:"Putzer's formula $e^{tA} = \\sum_{k=0}^{n-1} r_{k+1}(t)P_k$ involves scalar functions $r_k(t)$ that satisfy:",options:["Algebraic equations","A triangular system of first-order ODEs","$r_k(t) = e^{\\lambda_k t}$ directly","The heat equation"],correctIndex:1,difficulty:"hard",explanation:"The functions $r_k(t)$ satisfy $r_1' = \\lambda_1 r_1$, $r_1(0) = 1$, and $r_k' = \\lambda_k r_k + r_{k-1}$, $r_k(0) = 0$."},{id:4,type:"multiple-choice",question:"An advantage of Putzer's method is that it:",options:["Only works for diagonalizable matrices","Requires computing eigenvectors","Works for any matrix using only eigenvalues (with multiplicities)","Avoids using eigenvalues entirely"],correctIndex:2,difficulty:"medium",explanation:"Putzer's method needs only the eigenvalues (including repeated ones), not the eigenvectors, making it practical for defective matrices."},{id:5,type:"multiple-choice",question:"For a $2 \\times 2$ matrix with repeated eigenvalue $\\lambda$, Putzer's method gives $P_0 = I$, $P_1 =$",options:["$A$","$A^2$","$\\lambda I$","$A - \\lambda I$"],correctIndex:3,difficulty:"medium",explanation:"By the recursion, $P_1 = (A - \\lambda_1 I)P_0 = A - \\lambda I$."}],be=[{id:1,type:"multiple-choice",question:"An alternative to computing $e^{tA}$ directly is to use the Laplace transform, giving:",options:["$e^{tA} = \\mathcal{L}^{-1}\\{(sI - A)^{-1}\\}$","$e^{tA} = \\mathcal{L}^{-1}\\{A\\}$","$e^{tA} = \\mathcal{L}\\{I + tA\\}$","$e^{tA} = sI - A$"],correctIndex:0,difficulty:"medium",explanation:"Taking Laplace transforms of $Y' = AY$, $Y(0) = I$ gives $\\mathcal{L}\\{e^{tA}\\} = (sI - A)^{-1}$."},{id:2,type:"multiple-choice",question:"The Jordan normal form approach computes $e^{tA}$ by writing $A = PJP^{-1}$ where $J$ is:",options:["Diagonal","Upper triangular with eigenvalues on diagonal and 1s or 0s above","Symmetric","Orthogonal"],correctIndex:1,difficulty:"medium",explanation:"The Jordan form $J$ has eigenvalues on the diagonal and 1s above the diagonal within each Jordan block."},{id:3,type:"multiple-choice",question:"For a Jordan block $J = \\lambda I + N$ where $N$ is nilpotent, $e^{tJ} =$",options:["$e^{\\lambda t}I$","$e^{\\lambda t} + e^{tN}$","$e^{\\lambda t}e^{tN}$","$\\lambda e^{tN}$"],correctIndex:2,difficulty:"medium",explanation:"Since $\\lambda I$ and $N$ commute, $e^{tJ} = e^{t\\lambda I}e^{tN} = e^{\\lambda t}e^{tN}$."},{id:4,type:"multiple-choice",question:"The resolvent method uses the integral $e^{tA} = \\frac{1}{2\\pi i}\\oint_C e^{\\lambda t}(\\lambda I - A)^{-1}d\\lambda$ where $C$:",options:["Is any closed curve","Is the unit circle","Passes through all eigenvalues","Encloses all eigenvalues of $A$"],correctIndex:3,difficulty:"hard",explanation:"The contour $C$ must enclose all eigenvalues of $A$ for the integral formula to yield $e^{tA}$."},{id:5,type:"multiple-choice",question:"The interpolation method for $e^{tA}$ uses the fact that $e^{tA}$ equals a polynomial of degree at most:",options:["$n - 1$ where $A$ is $n \\times n$","$n$ where $A$ is $n \\times n$","Equal to the number of distinct eigenvalues minus 1","Infinite"],correctIndex:0,difficulty:"medium",explanation:"By Cayley-Hamilton, $e^{tA}$ can be written as a polynomial in $A$ of degree at most $n-1$."}],ge=[{id:1,type:"multiple-choice",question:"The general solution of the nonhomogeneous system $Y' = AY + F(t)$ is:",options:["$e^{tA}F(t)$","$Y_h + Y_p$ where $Y_h$ solves $Y' = AY$ and $Y_p$ is a particular solution","Only the particular solution","$Y_h \\cdot Y_p$"],correctIndex:1,difficulty:"easy",explanation:"The general solution is the sum of the general homogeneous solution and any particular solution."},{id:2,type:"multiple-choice",question:"A particular solution of $Y' = AY + F(t)$ with $Y(0) = 0$ is given by:",options:["$\\int_0^t F(s)\\,ds$","$e^{tA}\\int_0^t F(s)\\,ds$","$\\int_0^t e^{(t-s)A}F(s)\\,ds$","$F(t) - F(0)$"],correctIndex:2,difficulty:"medium",explanation:"The variation of parameters formula gives $Y_p(t) = \\int_0^t e^{(t-s)A}F(s)\\,ds$."},{id:3,type:"multiple-choice",question:"For $Y' = AY + F(t)$ with initial condition $Y(0) = Y_0$, the solution is:",options:["$e^{tA}Y_0 + F(t)$","$e^{tA}(Y_0 + F(t))$","$Y_0 + \\int_0^t F(s)\\,ds$","$e^{tA}Y_0 + \\int_0^t e^{(t-s)A}F(s)\\,ds$"],correctIndex:3,difficulty:"medium",explanation:"The complete solution combines the homogeneous solution $e^{tA}Y_0$ with the particular solution integral."},{id:4,type:"multiple-choice",question:"If $F(t) = e^{\\alpha t}b$ is an exponential forcing, and $\\alpha$ is not an eigenvalue of $A$, a particular solution has the form:",options:["$e^{\\alpha t}(\\alpha I - A)^{-1}b$","$te^{\\alpha t}b$","$e^{\\alpha t}Ab$","$\\alpha^{-1}e^{\\alpha t}b$"],correctIndex:0,difficulty:"hard",explanation:"Trying $Y_p = e^{\\alpha t}c$ and substituting gives $(\\alpha I - A)c = b$, so $c = (\\alpha I - A)^{-1}b$ when $\\alpha$ is not an eigenvalue."},{id:5,type:"multiple-choice",question:"The method of undetermined coefficients for systems works when:",options:["$F(t)$ is any continuous function","$F(t)$ involves exponentials, polynomials, sines, and cosines","$A$ is diagonal","$F(t)$ is constant"],correctIndex:1,difficulty:"medium",explanation:"Undetermined coefficients applies when $F(t)$ is a combination of functions that reproduce themselves under differentiation."}],ve=[{id:1,type:"multiple-choice",question:"For the system $Y' = A(t)Y$ with variable coefficients, the matrix exponential $e^{tA}$:",options:["Still gives the solution","Equals $I + \\int_0^t A(s)\\,ds$","Does not generally solve the system when $A$ depends on $t$","Is undefined"],correctIndex:2,difficulty:"medium",explanation:"When $A = A(t)$ depends on $t$, the simple exponential formula fails because $A(t_1)$ and $A(t_2)$ may not commute."},{id:2,type:"multiple-choice",question:"A fundamental matrix $\\Phi(t)$ for $Y' = A(t)Y$ satisfies:",options:["$\\Phi' = A' \\Phi$","$\\Phi' = \\Phi A$ always","$\\Phi = e^{A(t)}$","$\\Phi' = A\\Phi$ and $\\det(\\Phi) \\neq 0$"],correctIndex:3,difficulty:"medium",explanation:"A fundamental matrix satisfies the matrix ODE and is invertible (nonzero determinant) for all $t$."},{id:3,type:"multiple-choice",question:"Abel's formula states that for $Y' = A(t)Y$, the determinant of a fundamental matrix satisfies:",options:["$\\det(\\Phi(t)) = \\det(\\Phi(0))\\exp\\left(\\int_0^t \\text{tr}(A(s))\\,ds\\right)$","$\\det(\\Phi(t)) = \\det(\\Phi(0))$","$\\det(\\Phi(t)) = 0$","$\\frac{d}{dt}\\det(\\Phi) = \\det(A)$"],correctIndex:0,difficulty:"hard",explanation:"Abel's formula: $\\det(\\Phi(t)) = \\det(\\Phi(t_0))\\exp(\\int_{t_0}^t \\text{tr}(A(s))\\,ds)$."},{id:4,type:"multiple-choice",question:"For variable coefficient systems, the general solution with initial condition $Y(t_0) = Y_0$ is:",options:["$Y(t) = \\Phi(t)Y_0$","$Y(t) = \\Phi(t)\\Phi(t_0)^{-1}Y_0$","$Y(t) = e^{\\int_{t_0}^t A(s)\\,ds}Y_0$","$Y(t) = Y_0 + \\int_{t_0}^t A(s)Y_0\\,ds$"],correctIndex:1,difficulty:"medium",explanation:"The solution is $Y(t) = \\Phi(t)\\Phi(t_0)^{-1}Y_0$ where $\\Phi$ is any fundamental matrix."},{id:5,type:"multiple-choice",question:"When does $Y' = A(t)Y$ have solution $e^{\\int_0^t A(s)\\,ds}$?",options:["Always","When $A(t)$ is constant","When $A(t_1)A(t_2) = A(t_2)A(t_1)$ for all $t_1, t_2$","Never"],correctIndex:2,difficulty:"hard",explanation:"The naive exponential works only when $A(t)$ at different times commutes, which includes constant $A$ as a special case."}],_e=[{id:1,type:"multiple-choice",question:"Power series methods for $Y' = A(t)Y$ assume solutions of the form:",options:["$Y(t) = t^r \\sum_{n=0}^{\\infty} c_n t^n$","$Y(t) = e^{\\lambda t}$","$Y(t) = \\sin(t) + \\cos(t)$","$Y(t) = \\sum_{n=0}^{\\infty} c_n t^n$ where $c_n$ are constant vectors"],correctIndex:3,difficulty:"easy",explanation:"Power series methods expand the solution as $Y(t) = \\sum c_n t^n$ with vector coefficients to be determined."},{id:2,type:"multiple-choice",question:"Substituting a power series into $Y' = A(t)Y$ yields:",options:["A recurrence relation for the coefficient vectors","An algebraic equation for the coefficients","The characteristic polynomial","No useful information"],correctIndex:0,difficulty:"medium",explanation:"Matching coefficients of like powers of $t$ gives recurrence relations determining $c_{n+1}$ from previous coefficients."},{id:3,type:"multiple-choice",question:"If $A$ is constant, the power series for $e^{tA}Y_0$ has coefficients:",options:["$c_n = Y_0$","$c_n = \\frac{A^n}{n!}Y_0$","$c_n = nA^{n-1}Y_0$","$c_n = A^n Y_0$"],correctIndex:1,difficulty:"medium",explanation:"$e^{tA}Y_0 = \\sum_{n=0}^{\\infty} \\frac{(tA)^n}{n!}Y_0 = \\sum_{n=0}^{\\infty} \\frac{A^n Y_0}{n!}t^n$."},{id:4,type:"multiple-choice",question:"The radius of convergence of the power series solution depends on:",options:["Only the initial condition","The dimension of the system","The analyticity of $A(t)$ and singularities of the equation","Whether $A$ is symmetric"],correctIndex:2,difficulty:"medium",explanation:"The series converges where $A(t)$ is analytic; singularities of $A(t)$ limit the radius of convergence."},{id:5,type:"multiple-choice",question:"For the system $Y' = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}Y$, the power series solution starting from $Y(0) = \\begin{pmatrix} a \\\\ b \\end{pmatrix}$ is:",options:["$\\begin{pmatrix} a \\\\ b \\end{pmatrix}$","$\\begin{pmatrix} a\\cos t \\\\ b\\sin t \\end{pmatrix}$","$\\begin{pmatrix} ae^t \\\\ be^t \\end{pmatrix}$","$\\begin{pmatrix} a + bt \\\\ b \\end{pmatrix}$"],correctIndex:3,difficulty:"medium",explanation:"The matrix is nilpotent ($A^2 = 0$), so $e^{tA} = I + tA$, giving $Y = (I + tA)\\begin{pmatrix} a \\\\ b \\end{pmatrix} = \\begin{pmatrix} a + bt \\\\ b \\end{pmatrix}$."}],Te=[{id:1,type:"multiple-choice",question:"The method of successive approximations (Picard iteration) for $Y' = AY$, $Y(0) = Y_0$ defines:",options:["$Y_{n+1}(t) = Y_0 + \\int_0^t AY_n(s)\\,ds$","$Y_{n+1}(t) = AY_n(t)$","$Y_{n+1}(t) = Y_n(t) + A$","$Y_{n+1}(t) = e^A Y_n(t)$"],correctIndex:0,difficulty:"medium",explanation:"Picard iteration: starting from $Y_0(t) = Y_0$, define $Y_{n+1}(t) = Y_0 + \\int_0^t AY_n(s)\\,ds$."},{id:2,type:"multiple-choice",question:"Starting with $Y_0(t) = Y_0$ (constant) and $A$ constant, the first iterate $Y_1(t)$ is:",options:["$Y_0$","$Y_0 + tAY_0$","$AY_0$","$e^{tA}Y_0$"],correctIndex:1,difficulty:"easy",explanation:"$Y_1(t) = Y_0 + \\int_0^t AY_0\\,ds = Y_0 + tAY_0 = (I + tA)Y_0$."},{id:3,type:"multiple-choice",question:"The successive approximations $Y_n(t)$ converge to the solution:",options:["Only for small $t$","Only for diagonalizable $A$","Uniformly on bounded intervals","In the limit $n \\to \\infty$ but may diverge"],correctIndex:2,difficulty:"medium",explanation:"Picard iteration converges uniformly on any bounded interval $[0, T]$, proving existence and uniqueness."},{id:4,type:"multiple-choice",question:"After $n$ iterations with constant $A$, the approximate solution is:",options:["$n!e^{tA}Y_0$","$(I + A)^n Y_0$","$A^n Y_0$","$\\sum_{k=0}^{n} \\frac{(tA)^k}{k!}Y_0$"],correctIndex:3,difficulty:"medium",explanation:"Each iteration adds one more term of the exponential series, giving the partial sum $\\sum_{k=0}^{n} \\frac{(tA)^k}{k!}Y_0$."},{id:5,type:"multiple-choice",question:"The proof of convergence of Picard iteration uses:",options:["A contraction mapping argument or comparison with geometric series","The ratio test","Integration by parts","The Fourier transform"],correctIndex:0,difficulty:"hard",explanation:"Convergence follows from showing $\\|Y_{n+1} - Y_n\\|$ decreases geometrically, using matrix norm estimates."}],Ae=[{id:1,type:"multiple-choice",question:"A scalar field is a function $f: \\mathbb{R}^n \\to$",options:["$\\mathbb{R}^n$","$\\mathbb{R}$","$\\mathbb{R}^m$ where $m > n$","$\\mathbb{C}$"],correctIndex:1,difficulty:"easy",explanation:"A scalar field assigns a real number to each point in $\\mathbb{R}^n$, so $f: \\mathbb{R}^n \\to \\mathbb{R}$."},{id:2,type:"multiple-choice",question:"A vector field on $\\mathbb{R}^n$ is a function $F: \\mathbb{R}^n \\to$",options:["$\\mathbb{R}$","$\\mathbb{R}^n$","$\\mathbb{R}^m$ (any dimension)","The set of all matrices"],correctIndex:2,difficulty:"medium",explanation:"A vector field assigns a vector to each point. In general, $F: \\mathbb{R}^n \\to \\mathbb{R}^m$ for some $m$."},{id:3,type:"multiple-choice",question:"The temperature distribution $T(x, y, z)$ in a room is an example of:",options:["A vector field","A tensor field","A matrix field","A scalar field"],correctIndex:3,difficulty:"easy",explanation:"Temperature assigns a single number (temperature value) to each point in space, making it a scalar field."},{id:4,type:"multiple-choice",question:"The velocity of a fluid at each point $(x, y, z)$ is an example of:",options:["A vector field","A scalar field","A constant","A differential equation"],correctIndex:0,difficulty:"easy",explanation:"Velocity has magnitude and direction at each point, making it a vector field $\\mathbf{v}(x,y,z)$."},{id:5,type:"multiple-choice",question:"If $f: \\mathbb{R}^3 \\to \\mathbb{R}$ and $\\mathbf{F}: \\mathbb{R}^3 \\to \\mathbb{R}^3$, then $f\\mathbf{F}$ is:",options:["A scalar field","A vector field from $\\mathbb{R}^3$ to $\\mathbb{R}^3$","Undefined","A matrix"],correctIndex:1,difficulty:"medium",explanation:"Multiplying a vector field by a scalar field gives a vector field: $(f\\mathbf{F})(\\mathbf{x}) = f(\\mathbf{x})\\mathbf{F}(\\mathbf{x})$."}],qe=[{id:1,type:"multiple-choice",question:"An open ball $B(\\mathbf{a}, r)$ in $\\mathbb{R}^n$ is the set of all points $\\mathbf{x}$ such that:",options:["$\\|\\mathbf{x} - \\mathbf{a}\\| = r$","$\\|\\mathbf{x} - \\mathbf{a}\\| \\leq r$","$\\|\\mathbf{x} - \\mathbf{a}\\| < r$","$\\|\\mathbf{x} - \\mathbf{a}\\| > r$"],correctIndex:2,difficulty:"easy",explanation:"An open ball consists of all points whose distance from the center is strictly less than the radius."},{id:2,type:"multiple-choice",question:"A set $S \\subseteq \\mathbb{R}^n$ is open if and only if:",options:["$S$ contains all its boundary points","$S$ is connected","$S$ is bounded","Every point of $S$ is an interior point"],correctIndex:3,difficulty:"medium",explanation:"A set is open if every point has a neighborhood entirely contained in the set (every point is interior)."},{id:3,type:"multiple-choice",question:"The intersection of two open sets is:",options:["Always open","Always closed","Neither open nor closed","Open only if the sets are disjoint"],correctIndex:0,difficulty:"easy",explanation:"The intersection of any finite collection of open sets is open (a fundamental topological property)."},{id:4,type:"multiple-choice",question:"In $\\mathbb{R}^2$, the set $\\{(x,y) : x^2 + y^2 < 1\\}$ is:",options:["Closed but not open","Open but not closed","Both open and closed","Neither open nor closed"],correctIndex:1,difficulty:"easy",explanation:"This is the open unit disk, which is open (strict inequality) but not closed (doesn't contain boundary circle)."},{id:5,type:"multiple-choice",question:"The union of infinitely many open sets is:",options:["Not necessarily open","Always closed","Always open","Never open"],correctIndex:2,difficulty:"medium",explanation:"Any union (finite or infinite) of open sets is open. This is another fundamental property of open sets."}],Ie=[{id:1,type:"multiple-choice",question:"The limit $\\lim_{\\mathbf{x} \\to \\mathbf{a}} f(\\mathbf{x}) = L$ means:",options:["$f(\\mathbf{a}) = L$","$f$ is differentiable at $\\mathbf{a}$","The function is continuous at $\\mathbf{a}$","For all $\\epsilon > 0$, there exists $\\delta > 0$ such that $\\|\\mathbf{x} - \\mathbf{a}\\| < \\delta$ implies $|f(\\mathbf{x}) - L| < \\epsilon$"],correctIndex:3,difficulty:"medium",explanation:"The $\\epsilon$-$\\delta$ definition: $f(\\mathbf{x})$ can be made arbitrarily close to $L$ by taking $\\mathbf{x}$ sufficiently close to $\\mathbf{a}$."},{id:2,type:"multiple-choice",question:"A function $f: \\mathbb{R}^n \\to \\mathbb{R}$ is continuous at $\\mathbf{a}$ if:",options:["$\\lim_{\\mathbf{x} \\to \\mathbf{a}} f(\\mathbf{x}) = f(\\mathbf{a})$","$\\lim_{\\mathbf{x} \\to \\mathbf{a}} f(\\mathbf{x})$ exists","$f$ is defined at $\\mathbf{a}$","$f$ is bounded near $\\mathbf{a}$"],correctIndex:0,difficulty:"easy",explanation:"Continuity requires three conditions: $f(\\mathbf{a})$ defined, limit exists, and limit equals function value."},{id:3,type:"multiple-choice",question:"For $f(x,y) = \\frac{xy}{x^2 + y^2}$ (with $f(0,0) = 0$), approaching $(0,0)$ along $y = mx$ gives:",options:["$0$ for all $m$","$\\frac{m}{1+m^2}$ (depends on $m$)","$1$ for all $m$","$m$ for all $m$"],correctIndex:1,difficulty:"hard",explanation:"Along $y = mx$: $f(x, mx) = \\frac{mx^2}{x^2 + m^2x^2} = \\frac{m}{1+m^2}$, which depends on the slope $m$."},{id:4,type:"multiple-choice",question:"If a limit depends on the path of approach, then:",options:["The limit exists and equals the average of path limits","The function is continuous","The limit does not exist","The function is differentiable"],correctIndex:2,difficulty:"medium",explanation:"If different paths give different limits, the overall limit does not exist (the limit must be unique if it exists)."},{id:5,type:"multiple-choice",question:"For $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ given by $f(\\mathbf{x}) = (f_1(\\mathbf{x}), \\ldots, f_m(\\mathbf{x}))$, continuity means:",options:["Only $f_1$ needs to be continuous","$f_1 \\cdot f_2 \\cdots f_m$ is continuous","$\\sum_i f_i$ is continuous","Each component $f_i$ is continuous"],correctIndex:3,difficulty:"medium",explanation:"A vector-valued function is continuous iff each component function is continuous."}],we=[{id:1,type:"multiple-choice",question:"The derivative of a scalar field $f$ at $\\mathbf{a}$ with respect to a vector $\\mathbf{y}$ is defined as:",options:["$\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{y}) - f(\\mathbf{a})}{h}$","$f(\\mathbf{a} + \\mathbf{y})$","$f(\\mathbf{a}) \\cdot \\mathbf{y}$","$\\nabla f \\times \\mathbf{y}$"],correctIndex:0,difficulty:"medium",explanation:"The derivative with respect to $\\mathbf{y}$ is $f'(\\mathbf{a}; \\mathbf{y}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{y}) - f(\\mathbf{a})}{h}$."},{id:2,type:"multiple-choice",question:"The derivative $f'(\\mathbf{a}; \\mathbf{y})$ is linear in:",options:["Only $\\mathbf{a}$","Only $\\mathbf{y}$","Both $\\mathbf{a}$ and $\\mathbf{y}$","Neither"],correctIndex:1,difficulty:"medium",explanation:"The derivative is linear in the direction $\\mathbf{y}$: $f'(\\mathbf{a}; c\\mathbf{y}) = cf'(\\mathbf{a}; \\mathbf{y})$."},{id:3,type:"multiple-choice",question:"For $f(x,y) = x^2 + y^2$, the derivative at $(1,1)$ with respect to $\\mathbf{y} = (1,0)$ is:",options:["$0$","$1$","$2$","$4$"],correctIndex:2,difficulty:"easy",explanation:"$f'((1,1); (1,0)) = \\lim_{h\\to 0}\\frac{(1+h)^2 + 1 - 2}{h} = \\lim_{h\\to 0}\\frac{2h + h^2}{h} = 2$."},{id:4,type:"multiple-choice",question:"The derivative $f'(\\mathbf{a}; \\mathbf{0})$ equals:",options:["$f(\\mathbf{a})$","$\\|\\nabla f(\\mathbf{a})\\|$","Undefined","$0$"],correctIndex:3,difficulty:"easy",explanation:"With $\\mathbf{y} = \\mathbf{0}$: $f'(\\mathbf{a}; \\mathbf{0}) = \\lim_{h\\to 0}\\frac{f(\\mathbf{a}) - f(\\mathbf{a})}{h} = 0$."},{id:5,type:"multiple-choice",question:"If $f'(\\mathbf{a}; \\mathbf{y})$ exists for all $\\mathbf{y}$, then $f$ is necessarily:",options:["Neither continuous nor differentiable in general","Differentiable at $\\mathbf{a}$","Continuous at $\\mathbf{a}$","Both continuous and differentiable"],correctIndex:0,difficulty:"hard",explanation:"Having all directional derivatives does not imply continuity or differentiability (counterexamples exist)."}],ke=[{id:1,type:"multiple-choice",question:"The directional derivative of $f$ at $\\mathbf{a}$ in the direction of unit vector $\\mathbf{u}$ is:",options:["$f(\\mathbf{a}) \\cdot \\mathbf{u}$","$f'(\\mathbf{a}; \\mathbf{u})$ where $\\|\\mathbf{u}\\| = 1$","$\\nabla f(\\mathbf{a})$","$f'(\\mathbf{a}; \\mathbf{u})/\\|\\mathbf{u}\\|$"],correctIndex:1,difficulty:"easy",explanation:"The directional derivative is $f'(\\mathbf{a}; \\mathbf{u})$ where $\\mathbf{u}$ is a unit vector in the direction of interest."},{id:2,type:"multiple-choice",question:"The partial derivative $\\frac{\\partial f}{\\partial x_i}$ at $\\mathbf{a}$ is the directional derivative in the direction:",options:["$\\mathbf{a}$","The gradient $\\nabla f(\\mathbf{a})$","The $i$th standard basis vector $\\mathbf{e}_i$","Any unit vector"],correctIndex:2,difficulty:"easy",explanation:"The partial derivative $\\frac{\\partial f}{\\partial x_i}(\\mathbf{a}) = f'(\\mathbf{a}; \\mathbf{e}_i)$ is the derivative along the $i$th coordinate axis."},{id:3,type:"multiple-choice",question:"For $f(x, y) = x^2y + y^3$, the partial derivative $\\frac{\\partial f}{\\partial x}$ is:",options:["$2xy + 3y^2$","$x^2 + 3y^2$","$2x + 3y^2$","$2xy$"],correctIndex:3,difficulty:"easy",explanation:"Treating $y$ as constant: $\\frac{\\partial}{\\partial x}(x^2y + y^3) = 2xy$."},{id:4,type:"multiple-choice",question:"For $f(x, y) = x^2y + y^3$, the partial derivative $\\frac{\\partial f}{\\partial y}$ is:",options:["$x^2 + 3y^2$","$2xy$","$2x + 3y^2$","$2xy + 3y^2$"],correctIndex:0,difficulty:"easy",explanation:"Treating $x$ as constant: $\\frac{\\partial}{\\partial y}(x^2y + y^3) = x^2 + 3y^2$."},{id:5,type:"multiple-choice",question:"If $f$ has continuous partial derivatives, the directional derivative in direction $\\mathbf{u}$ can be computed as:",options:["$\\mathbf{u} \\cdot \\mathbf{u}$","$\\nabla f(\\mathbf{a}) \\cdot \\mathbf{u}$","$\\|\\nabla f(\\mathbf{a})\\|$","$f(\\mathbf{a})\\mathbf{u}$"],correctIndex:1,difficulty:"medium",explanation:"When $f$ is differentiable, $D_{\\mathbf{u}}f(\\mathbf{a}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{u}$."}],Fe=[{id:1,type:"multiple-choice",question:"If all directional derivatives of $f$ exist at $\\mathbf{a}$, then $f$ is:",options:["Necessarily continuous at $\\mathbf{a}$","Necessarily differentiable at $\\mathbf{a}$","Not necessarily continuous at $\\mathbf{a}$","Necessarily constant near $\\mathbf{a}$"],correctIndex:2,difficulty:"hard",explanation:"Existence of all directional derivatives does not guarantee continuity. Classic example: $f(x,y) = \\frac{x^2y}{x^4+y^2}$ with $f(0,0)=0$."},{id:2,type:"multiple-choice",question:"For $f(x,y) = \\begin{cases} \\frac{xy^2}{x^2+y^4} & (x,y) \\neq (0,0) \\\\ 0 & (x,y) = (0,0) \\end{cases}$, the directional derivatives at origin:",options:["Do not exist in any direction","All equal zero","All equal 1","Exist but $f$ is not continuous at $(0,0)$"],correctIndex:3,difficulty:"hard",explanation:"Along any line through origin, the limit is 0, so all directional derivatives are 0. But along $x = y^2$, $f \\to 1/2$, so $f$ is discontinuous."},{id:3,type:"multiple-choice",question:"For $f$ to be continuous at $\\mathbf{a}$, having all partial derivatives exist at $\\mathbf{a}$ is:",options:["Neither necessary nor sufficient","Necessary","Sufficient","Both necessary and sufficient"],correctIndex:0,difficulty:"medium",explanation:"Partial derivatives can exist without continuity, and continuity can hold without partial derivatives existing."},{id:4,type:"multiple-choice",question:"If $f$ is differentiable at $\\mathbf{a}$, then all directional derivatives exist and:",options:["Are equal","Equal $\\nabla f(\\mathbf{a}) \\cdot \\mathbf{u}$ for direction $\\mathbf{u}$","Are zero","Are undefined"],correctIndex:1,difficulty:"medium",explanation:"Differentiability implies directional derivatives exist and can be computed via the gradient: $D_{\\mathbf{u}}f = \\nabla f \\cdot \\mathbf{u}$."},{id:5,type:"multiple-choice",question:"Differentiability of $f$ at $\\mathbf{a}$ implies:",options:["That $f$ is constant","Boundedness of $f$","Continuity at $\\mathbf{a}$","That all partial derivatives are zero"],correctIndex:2,difficulty:"easy",explanation:"Differentiability at a point implies continuity at that point (but the converse is false)."}],Pe=[{id:1,type:"multiple-choice",question:"A scalar field $f: \\mathbb{R}^n \\to \\mathbb{R}$ is differentiable at $\\mathbf{a}$ if there exists a linear map $T$ such that:",options:["$f(\\mathbf{a} + \\mathbf{h}) = f(\\mathbf{a}) + T(\\mathbf{h})$","$f'(\\mathbf{a}) = T$","$f(\\mathbf{a} + \\mathbf{h}) = T(\\mathbf{h})$","$f(\\mathbf{a} + \\mathbf{h}) = f(\\mathbf{a}) + T(\\mathbf{h}) + o(\\|\\mathbf{h}\\|)$"],correctIndex:3,difficulty:"medium",explanation:"Differentiability means $f(\\mathbf{a}+\\mathbf{h}) - f(\\mathbf{a}) - T(\\mathbf{h}) = o(\\|\\mathbf{h}\\|)$ as $\\mathbf{h} \\to \\mathbf{0}$."},{id:2,type:"multiple-choice",question:"The total derivative (or differential) $df_{\\mathbf{a}}$ is:",options:["A linear map from $\\mathbb{R}^n$ to $\\mathbb{R}$","A vector","A number","A matrix"],correctIndex:0,difficulty:"medium",explanation:"The total derivative at $\\mathbf{a}$ is the linear map $df_{\\mathbf{a}}: \\mathbb{R}^n \\to \\mathbb{R}$ that best approximates the change in $f$."},{id:3,type:"multiple-choice",question:"For $f: \\mathbb{R}^n \\to \\mathbb{R}$ differentiable at $\\mathbf{a}$, the total derivative can be represented by:",options:["The Hessian matrix","The gradient vector: $df_{\\mathbf{a}}(\\mathbf{h}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{h}$","The Laplacian","The Jacobian matrix"],correctIndex:1,difficulty:"medium",explanation:"For scalar fields, the total derivative is $df_{\\mathbf{a}}(\\mathbf{h}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{h}$, a linear functional."},{id:4,type:"multiple-choice",question:"The condition $\\lim_{\\mathbf{h} \\to \\mathbf{0}} \\frac{f(\\mathbf{a}+\\mathbf{h}) - f(\\mathbf{a}) - df_{\\mathbf{a}}(\\mathbf{h})}{\\|\\mathbf{h}\\|} = 0$ means:",options:["$f$ is continuous","$f$ has partial derivatives","$f$ is differentiable at $\\mathbf{a}$","$f$ is constant"],correctIndex:2,difficulty:"medium",explanation:"This limit condition is the definition of differentiability: the linear approximation error is $o(\\|\\mathbf{h}\\|)$."},{id:5,type:"multiple-choice",question:"If $f(x,y) = x^2 + 3xy$, the total derivative $df$ at any point is:",options:["$(2x + 3y, 3x)$","$2x + 3y + 3x$","$6xy$","The linear map $(h_1, h_2) \\mapsto (2x + 3y)h_1 + 3xh_2$"],correctIndex:3,difficulty:"hard",explanation:"$\\nabla f = (2x + 3y, 3x)$, so $df(h_1, h_2) = (2x+3y)h_1 + 3xh_2$."}],Se=[{id:1,type:"multiple-choice",question:"The gradient of $f: \\mathbb{R}^n \\to \\mathbb{R}$ is the vector:",options:["$\\left(\\frac{\\partial f}{\\partial x_1}, \\ldots, \\frac{\\partial f}{\\partial x_n}\\right)$","$(f, f, \\ldots, f)$","$\\sum_i \\frac{\\partial f}{\\partial x_i}$","$\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2}$"],correctIndex:0,difficulty:"easy",explanation:"The gradient $\\nabla f = \\left(\\frac{\\partial f}{\\partial x_1}, \\ldots, \\frac{\\partial f}{\\partial x_n}\\right)$ is the vector of partial derivatives."},{id:2,type:"multiple-choice",question:"The gradient $\\nabla f(\\mathbf{a})$ points in the direction of:",options:["Minimum rate of change","Maximum rate of increase of $f$","Zero change","Constant $f$"],correctIndex:1,difficulty:"easy",explanation:"The gradient points in the direction of steepest ascent (maximum rate of increase)."},{id:3,type:"multiple-choice",question:"The magnitude $\\|\\nabla f(\\mathbf{a})\\|$ equals:",options:["The value $f(\\mathbf{a})$","Zero always","The maximum directional derivative at $\\mathbf{a}$","The Laplacian"],correctIndex:2,difficulty:"medium",explanation:"Since $D_{\\mathbf{u}}f = \\nabla f \\cdot \\mathbf{u} \\leq \\|\\nabla f\\|\\|\\mathbf{u}\\| = \\|\\nabla f\\|$, the max is achieved when $\\mathbf{u} \\parallel \\nabla f$."},{id:4,type:"multiple-choice",question:"For $f(x, y, z) = x^2 + y^2 + z^2$, the gradient at $(1, 2, 3)$ is:",options:["$(1, 2, 3)$","$14$","$(1, 4, 9)$","$(2, 4, 6)$"],correctIndex:3,difficulty:"easy",explanation:"$\\nabla f = (2x, 2y, 2z)$, so at $(1,2,3)$: $\\nabla f = (2, 4, 6)$."},{id:5,type:"multiple-choice",question:"If $\\nabla f(\\mathbf{a}) = \\mathbf{0}$, then $\\mathbf{a}$ is:",options:["A critical point (stationary point)","Necessarily a minimum","Necessarily a maximum","Not in the domain of $f$"],correctIndex:0,difficulty:"medium",explanation:"When the gradient vanishes, $\\mathbf{a}$ is a critical point; it could be a max, min, or saddle point."}],ze=[{id:1,type:"multiple-choice",question:"A sufficient condition for differentiability of $f: \\mathbb{R}^n \\to \\mathbb{R}$ at $\\mathbf{a}$ is:",options:["Existence of partial derivatives at $\\mathbf{a}$","Existence and continuity of all partial derivatives in a neighborhood of $\\mathbf{a}$","Continuity of $f$ at $\\mathbf{a}$","Boundedness of $f$"],correctIndex:1,difficulty:"medium",explanation:"If all partial derivatives exist and are continuous near $\\mathbf{a}$, then $f$ is differentiable at $\\mathbf{a}$."},{id:2,type:"multiple-choice",question:"A function with continuous partial derivatives is said to be:",options:["Analytic","Harmonic","Of class $C^1$ (continuously differentiable)","Holomorphic"],correctIndex:2,difficulty:"easy",explanation:"A function is $C^1$ if it has continuous first-order partial derivatives."},{id:3,type:"multiple-choice",question:"Continuous differentiability ($C^1$) implies:",options:["Only existence of partial derivatives","That $f$ is unbounded","That $f$ is constant","Differentiability (in the total derivative sense)"],correctIndex:3,difficulty:"medium",explanation:"$C^1$ functions are differentiable because continuity of partials is sufficient for differentiability."},{id:4,type:"multiple-choice",question:'The converse "differentiable implies continuous partial derivatives" is:',options:["False","True","True only in dimension 2","True only for polynomial functions"],correctIndex:0,difficulty:"hard",explanation:"Differentiability implies existence of partial derivatives but not their continuity. Counterexamples exist."},{id:5,type:"multiple-choice",question:"For practical verification of differentiability, one typically checks:",options:["The limit definition directly","Whether partial derivatives exist and are continuous","Whether $f$ is bounded","Whether $f$ is a polynomial"],correctIndex:1,difficulty:"easy",explanation:"Checking continuity of partial derivatives is the standard practical method for verifying differentiability."}],Be=[{id:1,type:"multiple-choice",question:"For $f: \\mathbb{R}^n \\to \\mathbb{R}$ and $\\mathbf{g}: \\mathbb{R} \\to \\mathbb{R}^n$ with $h(t) = f(\\mathbf{g}(t))$, the chain rule gives:",options:["$h'(t) = f'(\\mathbf{g}(t))$","$h'(t) = f(\\mathbf{g}'(t))$","$h'(t) = \\nabla f(\\mathbf{g}(t)) \\cdot \\mathbf{g}'(t)$","$h'(t) = \\mathbf{g}'(t)$"],correctIndex:2,difficulty:"medium",explanation:"The chain rule: $h'(t) = \\nabla f(\\mathbf{g}(t)) \\cdot \\mathbf{g}'(t) = \\sum_i \\frac{\\partial f}{\\partial x_i} \\frac{dg_i}{dt}$."},{id:2,type:"multiple-choice",question:"If $z = f(x, y)$ where $x = g(t)$ and $y = h(t)$, then $\\frac{dz}{dt} =$",options:["$\\frac{\\partial f}{\\partial x} + \\frac{\\partial f}{\\partial y}$","$\\frac{dx}{dt}\\frac{dy}{dt}$","$\\frac{\\partial f}{\\partial t}$","$\\frac{\\partial f}{\\partial x}\\frac{dx}{dt} + \\frac{\\partial f}{\\partial y}\\frac{dy}{dt}$"],correctIndex:3,difficulty:"easy",explanation:"The chain rule for composite functions: $\\frac{dz}{dt} = \\frac{\\partial f}{\\partial x}\\frac{dx}{dt} + \\frac{\\partial f}{\\partial y}\\frac{dy}{dt}$."},{id:3,type:"multiple-choice",question:"For $f(x,y) = xy$ with $x = \\cos t$ and $y = \\sin t$, $\\frac{df}{dt}$ at $t = 0$ is:",options:["$1$","$0$","$-1$","$2$"],correctIndex:0,difficulty:"medium",explanation:"$\\frac{df}{dt} = y(-\\sin t) + x(\\cos t) = \\sin t(-\\sin t) + \\cos t(\\cos t) = \\cos^2 t - \\sin^2 t$. At $t=0$: $1 - 0 = 1$."},{id:4,type:"multiple-choice",question:"If $f(x,y)$ has continuous partials and $x = r\\cos\\theta$, $y = r\\sin\\theta$, then $\\frac{\\partial f}{\\partial r} =$",options:["$\\frac{\\partial f}{\\partial x}(-r\\sin\\theta) + \\frac{\\partial f}{\\partial y}(r\\cos\\theta)$","$\\frac{\\partial f}{\\partial x}\\cos\\theta + \\frac{\\partial f}{\\partial y}\\sin\\theta$","$\\frac{\\partial f}{\\partial x} + \\frac{\\partial f}{\\partial y}$","$r\\frac{\\partial f}{\\partial x}$"],correctIndex:1,difficulty:"hard",explanation:"Using chain rule: $\\frac{\\partial f}{\\partial r} = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial r} + \\frac{\\partial f}{\\partial y}\\frac{\\partial y}{\\partial r} = \\frac{\\partial f}{\\partial x}\\cos\\theta + \\frac{\\partial f}{\\partial y}\\sin\\theta$."},{id:5,type:"multiple-choice",question:"The chain rule requires the outer function to be:",options:["Continuous","Twice differentiable","Differentiable","Constant"],correctIndex:2,difficulty:"easy",explanation:"The chain rule applies when the outer function is differentiable at the relevant point."}],Qe=[{id:1,type:"multiple-choice",question:"A level set of $f: \\mathbb{R}^n \\to \\mathbb{R}$ at height $c$ is:",options:["$\\{\\mathbf{x} : f(\\mathbf{x}) > c\\}$","$\\{\\mathbf{x} : \\nabla f(\\mathbf{x}) = c\\}$","$\\{\\mathbf{x} : f(\\mathbf{x}) < c\\}$","$\\{\\mathbf{x} : f(\\mathbf{x}) = c\\}$"],correctIndex:3,difficulty:"easy",explanation:"A level set (or level curve/surface) is the set of points where $f$ takes a constant value $c$."},{id:2,type:"multiple-choice",question:"The gradient $\\nabla f$ at a point on a level set is:",options:["Normal (perpendicular) to the level set","Tangent to the level set","Zero","Parallel to the level set"],correctIndex:0,difficulty:"medium",explanation:"The gradient is perpendicular to level sets because directional derivatives along the level set are zero."},{id:3,type:"multiple-choice",question:"For the surface $f(x, y, z) = c$, the tangent plane at $(a, b, d)$ has normal vector:",options:["$(a, b, d)$","$\\nabla f(a, b, d)$","$(1, 1, 1)$","$f(a, b, d)$"],correctIndex:1,difficulty:"medium",explanation:"The gradient at a point is normal to the level surface, so it's the normal vector to the tangent plane."},{id:4,type:"multiple-choice",question:"The equation of the tangent plane to $f(x,y,z) = c$ at $(a,b,d)$ is:",options:["$f(x,y,z) = c$","$x + y + z = a + b + d$","$\\nabla f(a,b,d) \\cdot (x-a, y-b, z-d) = 0$","$(x-a)^2 + (y-b)^2 + (z-d)^2 = 0$"],correctIndex:2,difficulty:"medium",explanation:"The tangent plane consists of vectors perpendicular to $\\nabla f$: $\\nabla f \\cdot (\\mathbf{x} - \\mathbf{a}) = 0$."},{id:5,type:"multiple-choice",question:"For $f(x,y,z) = x^2 + y^2 + z^2$, the tangent plane to the sphere $x^2+y^2+z^2 = 1$ at $(1,0,0)$ is:",options:["$2x = 2$, i.e., $x = 1$","$x = 0$","$x + y + z = 1$","$x = 1$"],correctIndex:3,difficulty:"medium",explanation:"$\\nabla f = (2x, 2y, 2z)$, at $(1,0,0)$: $\\nabla f = (2,0,0)$. Tangent plane: $2(x-1) + 0 + 0 = 0$, i.e., $x = 1$."}],Ce=[{id:1,type:"multiple-choice",question:"For a vector field $\\mathbf{F}: \\mathbb{R}^n \\to \\mathbb{R}^m$, differentiability means there exists a linear map $L$ such that:",options:["$\\mathbf{F}(\\mathbf{a} + \\mathbf{h}) = \\mathbf{F}(\\mathbf{a}) + L(\\mathbf{h}) + o(\\|\\mathbf{h}\\|)$","$\\mathbf{F}(\\mathbf{a} + \\mathbf{h}) = \\mathbf{F}(\\mathbf{a}) + L$","$\\mathbf{F}(\\mathbf{a}) = L(\\mathbf{a})$","$\\mathbf{F}'(\\mathbf{a}) = 0$"],correctIndex:0,difficulty:"medium",explanation:"Differentiability of vector fields follows the same definition: linear approximation with error $o(\\|\\mathbf{h}\\|)$."},{id:2,type:"multiple-choice",question:"The derivative of a vector field $\\mathbf{F}: \\mathbb{R}^n \\to \\mathbb{R}^m$ at $\\mathbf{a}$ is represented by:",options:["A vector in $\\mathbb{R}^m$","An $m \\times n$ matrix (the Jacobian)","A scalar","An $n \\times n$ matrix"],correctIndex:1,difficulty:"medium",explanation:"The derivative of $\\mathbf{F}: \\mathbb{R}^n \\to \\mathbb{R}^m$ is an $m \\times n$ Jacobian matrix."},{id:3,type:"multiple-choice",question:"For $\\mathbf{F} = (F_1, \\ldots, F_m)$, the Jacobian matrix has $(i,j)$ entry:",options:["$F_i(\\mathbf{a})$","$\\frac{\\partial F_j}{\\partial x_i}$","$\\frac{\\partial F_i}{\\partial x_j}$","$F_i F_j$"],correctIndex:2,difficulty:"easy",explanation:"The Jacobian has entry $(i,j) = \\frac{\\partial F_i}{\\partial x_j}$: row $i$ is the gradient of $F_i$."},{id:4,type:"multiple-choice",question:"If $\\mathbf{F}: \\mathbb{R}^n \\to \\mathbb{R}^m$ is differentiable at $\\mathbf{a}$, then $\\mathbf{F}$ is:",options:["Not necessarily continuous","Linear","Constant","Continuous at $\\mathbf{a}$"],correctIndex:3,difficulty:"easy",explanation:"Differentiability implies continuity for vector fields, just as for scalar fields."},{id:5,type:"multiple-choice",question:"For $\\mathbf{F}(x,y) = (x^2 + y, xy)$, the Jacobian matrix at $(1,2)$ is:",options:["$\\begin{pmatrix} 2 & 1 \\\\ 2 & 1 \\end{pmatrix}$","$\\begin{pmatrix} 3 & 2 \\\\ 1 & 2 \\end{pmatrix}$","$\\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}$","$\\begin{pmatrix} 2 & 1 \\\\ 2 & 1 \\end{pmatrix}$"],correctIndex:0,difficulty:"hard",explanation:"$J = \\begin{pmatrix} \\partial_x(x^2+y) & \\partial_y(x^2+y) \\\\ \\partial_x(xy) & \\partial_y(xy) \\end{pmatrix} = \\begin{pmatrix} 2x & 1 \\\\ y & x \\end{pmatrix}$. At $(1,2)$: $\\begin{pmatrix} 2 & 1 \\\\ 2 & 1 \\end{pmatrix}$."}],je=[{id:1,type:"multiple-choice",question:"For vector fields $\\mathbf{F}: \\mathbb{R}^n \\to \\mathbb{R}^m$ and $\\mathbf{G}: \\mathbb{R}^m \\to \\mathbb{R}^p$, the chain rule states:",options:["$D(\\mathbf{G} \\circ \\mathbf{F})(\\mathbf{a}) = D\\mathbf{G}(\\mathbf{a}) + D\\mathbf{F}(\\mathbf{a})$","$D(\\mathbf{G} \\circ \\mathbf{F})(\\mathbf{a}) = D\\mathbf{G}(\\mathbf{F}(\\mathbf{a})) \\cdot D\\mathbf{F}(\\mathbf{a})$","$D(\\mathbf{G} \\circ \\mathbf{F})(\\mathbf{a}) = D\\mathbf{F}(\\mathbf{a}) \\cdot D\\mathbf{G}(\\mathbf{a})$","$D(\\mathbf{G} \\circ \\mathbf{F})(\\mathbf{a}) = D\\mathbf{G}(\\mathbf{a}) \\cdot D\\mathbf{F}(\\mathbf{F}(\\mathbf{a}))$"],correctIndex:1,difficulty:"medium",explanation:"The chain rule: the Jacobian of the composition is the product of Jacobians: $J_{\\mathbf{G}\\circ\\mathbf{F}} = J_{\\mathbf{G}}(\\mathbf{F}(\\mathbf{a})) \\cdot J_{\\mathbf{F}}(\\mathbf{a})$."},{id:2,type:"multiple-choice",question:"If $\\mathbf{F}: \\mathbb{R}^2 \\to \\mathbb{R}^2$ and $\\mathbf{G}: \\mathbb{R}^2 \\to \\mathbb{R}^3$, the Jacobian of $\\mathbf{G} \\circ \\mathbf{F}$ is:",options:["$2 \\times 2$","$2 \\times 3$","$3 \\times 2$","$3 \\times 3$"],correctIndex:2,difficulty:"medium",explanation:"$J_{\\mathbf{G}}$ is $3 \\times 2$ and $J_{\\mathbf{F}}$ is $2 \\times 2$. Product: $(3 \\times 2) \\cdot (2 \\times 2) = 3 \\times 2$."},{id:3,type:"multiple-choice",question:"In matrix form, the chain rule says that Jacobians:",options:["Add","Are inverses of each other","Commute","Multiply (in the correct order)"],correctIndex:3,difficulty:"easy",explanation:"The Jacobian of a composition is the matrix product of the individual Jacobians."},{id:4,type:"multiple-choice",question:"If $\\mathbf{F}(t) = (\\cos t, \\sin t)$ and $g(x,y) = x^2 + y^2$, then $(g \\circ \\mathbf{F})'(t) =$",options:["$2\\cos t \\cdot (-\\sin t) + 2\\sin t \\cdot \\cos t = 0$","$2$","$-2\\sin t \\cos t$","$1$"],correctIndex:0,difficulty:"medium",explanation:"$\\nabla g = (2x, 2y)$, $\\mathbf{F}'(t) = (-\\sin t, \\cos t)$. At $\\mathbf{F}(t)$: $(2\\cos t, 2\\sin t) \\cdot (-\\sin t, \\cos t) = 0$."},{id:5,type:"multiple-choice",question:"The result $(g \\circ \\mathbf{F})'(t) = 0$ for $\\mathbf{F}(t) = (\\cos t, \\sin t)$ and $g = x^2 + y^2$ means:",options:["$g$ is not differentiable","The image of $\\mathbf{F}$ lies on a level set of $g$","$\\mathbf{F}$ is constant","$g$ is constant everywhere"],correctIndex:1,difficulty:"medium",explanation:"Since $g(\\mathbf{F}(t)) = \\cos^2 t + \\sin^2 t = 1$ is constant, $\\mathbf{F}$ traces a level set of $g$ (the unit circle)."}],Xe=[{id:1,type:"multiple-choice",question:"Which of the following is the strongest condition for a function $f: \\mathbb{R}^n \\to \\mathbb{R}$ at a point $a$?",options:["All partial derivatives $D_1 f(a), \\ldots, D_n f(a)$ exist","All directional derivatives $f'(a; y)$ exist for all $y$","All partial derivatives are continuous at $a$","The function $f$ is differentiable at $a$"],correctIndex:2,difficulty:"medium",explanation:"Continuous differentiability (all partial derivatives continuous at $a$) is the strongest condition. It implies differentiability, which implies existence of all directional derivatives, which implies existence of partial derivatives. The implications do not reverse."},{id:2,type:"multiple-choice",question:"For a differentiable scalar field $f$, the gradient $\\nabla f(a)$ points in the direction of:",options:["The level set $f = f(a)$","Steepest decrease of $f$","The tangent plane to the surface $z = f(x, y)$","Steepest increase of $f$"],correctIndex:3,difficulty:"easy",explanation:"The gradient vector $\\nabla f(a)$ points in the direction of steepest increase of $f$ at the point $a$. Its magnitude $\\|\\nabla f(a)\\|$ gives the rate of steepest increase."},{id:3,type:"multiple-choice",question:"If $g(t) = f[r(t)]$ where $f$ is a scalar field and $r$ is a path, the chain rule gives:",options:["$g'(t) = \\nabla f(r(t)) \\cdot r'(t)$","$g'(t) = \\nabla f(r(t))$","$g'(t) = f'(r(t)) \\cdot r'(t)$","$g'(t) = Df(r(t)) \\cdot Dr(t)$"],correctIndex:0,difficulty:"medium",explanation:"By the chain rule for scalar fields composed with curves, $g'(t) = \\nabla f(r(t)) \\cdot r'(t)$, which is the dot product of the gradient evaluated along the path and the tangent vector to the path."},{id:4,type:"multiple-choice",question:"For a vector field $f: \\mathbb{R}^n \\to \\mathbb{R}^m$, the Jacobian determinant $|\\det Df|$ represents:",options:["The rate of change along a level set","The local volume magnification factor","The magnitude of the gradient","The trace of the Hessian matrix"],correctIndex:1,difficulty:"medium",explanation:"The absolute value of the Jacobian determinant $|\\det Df|$ represents the local volume magnification factor. It tells us how much the transformation $f$ magnifies or shrinks volumes near a point."},{id:5,type:"multiple-choice",question:"What is the relationship between the gradient $\\nabla f$ and level sets of a scalar field $f$?",options:["The gradient is tangent to the level sets","The gradient lies within the level sets","The gradient is perpendicular to the level sets","There is no relationship between them"],correctIndex:2,difficulty:"easy",explanation:"The gradient $\\nabla f$ is always perpendicular (normal) to the level sets $f = c$. This is because the directional derivative in any direction tangent to a level set is zero."}],Ye=[{id:1,type:"multiple-choice",question:"What is a partial differential equation (PDE)?",options:["An equation involving only ordinary derivatives","An equation that can only be solved numerically","An equation with no derivatives","An equation involving a scalar field and its partial derivatives"],correctIndex:3,difficulty:"easy",explanation:"A partial differential equation (PDE) is an equation involving a scalar field $f$ and one or more of its partial derivatives with respect to the independent variables."},{id:2,type:"multiple-choice",question:"For the PDE $\\frac{\\partial f(x, y)}{\\partial x} = 0$, the most general solution is:",options:["$f(x, y) = g(y)$ where $g$ is any function of $y$","$f(x, y) = C$ where $C$ is a constant","$f(x, y) = g(x)$ where $g$ is any function of $x$","$f(x, y) = xy$"],correctIndex:0,difficulty:"medium",explanation:"If $\\frac{\\partial f}{\\partial x} = 0$, then $f$ does not depend on $x$. The most general solution is $f(x, y) = g(y)$, where $g$ is an arbitrary function of $y$ alone. This makes the solution space infinite-dimensional."},{id:3,type:"multiple-choice",question:"For a homogeneous linear PDE of the form $L(f) = 0$, if $f$ and $g$ are solutions, then:",options:["Only $f + g$ is also a solution","$af + bg$ is also a solution for any constants $a$ and $b$","Only $cf$ is also a solution for constant $c$","No other linear combinations are solutions"],correctIndex:1,difficulty:"medium",explanation:"For homogeneous linear PDEs, the set of solutions forms a linear space. This means if $f$ and $g$ are solutions, then $af + bg$ is also a solution for any constants $a$ and $b$ (superposition principle)."},{id:4,type:"multiple-choice",question:"The key difference between solutions of ODEs and PDEs is that:",options:["ODE solutions depend on arbitrary functions, PDE solutions depend on constants","Both depend on the same number of arbitrary quantities","PDE solutions depend on arbitrary functions, ODE solutions depend on constants","Neither depends on arbitrary quantities"],correctIndex:2,difficulty:"medium",explanation:"ODE solutions typically depend on arbitrary constants, making the solution space finite-dimensional. PDE solutions depend on arbitrary functions, making the solution space infinite-dimensional. This is a fundamental difference between the two theories."},{id:5,type:"multiple-choice",question:"What role do auxiliary conditions (initial/boundary conditions) play in PDE problems?",options:["They make the problem harder to solve","They are optional and not mathematically significant","They always guarantee a unique solution exists","They select particular solutions from the infinite-dimensional solution space"],correctIndex:3,difficulty:"medium",explanation:"Auxiliary conditions (such as initial conditions or boundary conditions) are needed to select particular solutions from the wealth of solutions in the infinite-dimensional solution space of a PDE."}],De=[{id:1,type:"multiple-choice",question:"The first-order PDE $3\\frac{\\partial f}{\\partial x} + 2\\frac{\\partial f}{\\partial y} = 0$ can be written as:",options:["$(3\\mathbf{i} + 2\\mathbf{j}) \\cdot \\nabla f = 0$","$(3\\mathbf{i} + 2\\mathbf{j}) \\times \\nabla f = 0$","$\\nabla f = 3\\mathbf{i} + 2\\mathbf{j}$","$(3\\mathbf{i} - 2\\mathbf{j}) \\cdot \\nabla f = 0$"],correctIndex:0,difficulty:"easy",explanation:"The PDE $3\\frac{\\partial f}{\\partial x} + 2\\frac{\\partial f}{\\partial y} = 0$ can be written as the dot product $(3\\mathbf{i} + 2\\mathbf{j}) \\cdot \\nabla f = 0$, showing that the gradient is orthogonal to the vector $(3, 2)$."},{id:2,type:"multiple-choice",question:"For the PDE $a\\frac{\\partial f}{\\partial x} + b\\frac{\\partial f}{\\partial y} = 0$ (with $a, b$ constants), the level curves of any solution are:",options:["Circles centered at the origin","Straight lines parallel to $a\\mathbf{i} + b\\mathbf{j}$","Parabolas","Ellipses"],correctIndex:1,difficulty:"medium",explanation:"Since the gradient $\\nabla f$ is orthogonal to both level curves and to the vector $a\\mathbf{i} + b\\mathbf{j}$, the level curves must be parallel to $a\\mathbf{i} + b\\mathbf{j}$. These are straight lines of the form $bx - ay = c$."},{id:3,type:"multiple-choice",question:"The general solution to $a\\frac{\\partial f}{\\partial x} + b\\frac{\\partial f}{\\partial y} = 0$ is $f(x, y) = g(bx - ay)$ for some function $g$. This works because:",options:["The function $g$ must be a polynomial","$bx - ay$ equals the magnitude of the gradient","$bx - ay$ is constant along level curves","$g$ depends on both $x$ and $y$ independently"],correctIndex:2,difficulty:"medium",explanation:"The expression $bx - ay$ is constant along lines parallel to $a\\mathbf{i} + b\\mathbf{j}$, which are the level curves of any solution. Thus $f(x, y) = g(bx - ay)$ is constant along each level curve, as required."},{id:4,type:"multiple-choice",question:"To verify that $f(x, y) = g(2x - 3y)$ satisfies $3\\frac{\\partial f}{\\partial x} + 2\\frac{\\partial f}{\\partial y} = 0$, we compute the partial derivatives using:",options:["Integration by parts","The product rule","L'Hopital's rule","The chain rule"],correctIndex:3,difficulty:"easy",explanation:"Using the chain rule: $\\frac{\\partial f}{\\partial x} = 2g'(2x-3y)$ and $\\frac{\\partial f}{\\partial y} = -3g'(2x-3y)$. Then $3(2g') + 2(-3g') = 6g' - 6g' = 0$."},{id:5,type:"multiple-choice",question:"The technique of reducing a first-order PDE to a simpler form involves:",options:["A linear change of variables to make one partial derivative zero","Taking the Fourier transform","Multiplying by an integrating factor","Applying Green's theorem"],correctIndex:0,difficulty:"hard",explanation:"To solve first-order PDEs with constant coefficients, we introduce a linear change of variables $x = Au + Bv$, $y = Cu + Dv$ chosen so that the transformed equation has $\\frac{\\partial h}{\\partial u} = 0$, which is easily solved."}],Re=[{id:1,type:"multiple-choice",question:"The one-dimensional wave equation is:",options:["$\\frac{\\partial f}{\\partial t} = c^2 \\frac{\\partial f}{\\partial x}$","$\\frac{\\partial^2 f}{\\partial t^2} = c^2 \\frac{\\partial^2 f}{\\partial x^2}$","$\\frac{\\partial^2 f}{\\partial t^2} + c^2 \\frac{\\partial^2 f}{\\partial x^2} = 0$","$\\frac{\\partial f}{\\partial t} + c\\frac{\\partial f}{\\partial x} = 0$"],correctIndex:1,difficulty:"easy",explanation:"The one-dimensional wave equation is $\\frac{\\partial^2 f}{\\partial t^2} = c^2 \\frac{\\partial^2 f}{\\partial x^2}$, where $c$ is a positive constant representing the wave speed."},{id:2,type:"multiple-choice",question:"D'Alembert's solution to the wave equation with initial conditions $f(x, 0) = F(x)$ and $\\frac{\\partial f}{\\partial t}(x, 0) = G(x)$ is:",options:["$f(x, t) = F(x + ct) + F(x - ct)$","$f(x, t) = F(x)\\cos(ct) + G(x)\\sin(ct)$","$f(x, t) = \\frac{F(x + ct) + F(x - ct)}{2} + \\frac{1}{2c}\\int_{x-ct}^{x+ct} G(s) \\, ds$","$f(x, t) = e^{ct}F(x)$"],correctIndex:2,difficulty:"hard",explanation:"D'Alembert's solution combines traveling waves: $f(x, t) = \\frac{F(x + ct) + F(x - ct)}{2} + \\frac{1}{2c}\\int_{x-ct}^{x+ct} G(s) \\, ds$, satisfying both the wave equation and the initial conditions."},{id:3,type:"multiple-choice",question:"The wave equation can be factored as $L_1(L_2 f) = 0$ where:",options:["$L_1 = \\frac{\\partial}{\\partial t}$ and $L_2 = \\frac{\\partial}{\\partial x}$","$L_1 = \\frac{\\partial}{\\partial t} + \\frac{\\partial}{\\partial x}$ and $L_2 = \\frac{\\partial}{\\partial t} - \\frac{\\partial}{\\partial x}$","$L_1 = \\frac{\\partial^2}{\\partial t^2}$ and $L_2 = \\frac{\\partial^2}{\\partial x^2}$","$L_1 = \\frac{\\partial}{\\partial t} - c\\frac{\\partial}{\\partial x}$ and $L_2 = \\frac{\\partial}{\\partial t} + c\\frac{\\partial}{\\partial x}$"],correctIndex:3,difficulty:"medium",explanation:"The wave equation factors as $\\left(\\frac{\\partial}{\\partial t} - c\\frac{\\partial}{\\partial x}\\right)\\left(\\frac{\\partial}{\\partial t} + c\\frac{\\partial}{\\partial x}\\right)f = 0$. This factorization reduces the second-order equation to first-order equations."},{id:4,type:"multiple-choice",question:"The general solution to the wave equation has the form $f(x, t) = \\varphi_1(x + ct) + \\varphi_2(x - ct)$. This represents:",options:["Two waves traveling in opposite directions with speed $c$","Two waves traveling in the same direction","One standing wave","A wave that decays exponentially"],correctIndex:0,difficulty:"medium",explanation:"The solution consists of two traveling waves: $\\varphi_1(x + ct)$ travels to the left and $\\varphi_2(x - ct)$ travels to the right, both with speed $c$."},{id:5,type:"multiple-choice",question:"When the initial velocity $G(x) = 0$, D'Alembert's solution simplifies to:",options:["$f(x, t) = F(x)$","$f(x, t) = \\frac{F(x + ct) + F(x - ct)}{2}$","$f(x, t) = F(x + ct)$","$f(x, t) = F(x - ct)$"],correctIndex:1,difficulty:"easy",explanation:"When $G(x) = 0$, the integral term vanishes and $f(x, t) = \\frac{F(x + ct) + F(x - ct)}{2}$. This represents the initial profile splitting into two half-amplitude waves traveling in opposite directions."}],We=[{id:1,type:"multiple-choice",question:"If $F(x, y, z) = 0$ defines $z$ implicitly as a function of $x$ and $y$, and $\\frac{\\partial F}{\\partial z} \\neq 0$, then $\\frac{\\partial z}{\\partial x}$ equals:",options:["$\\frac{\\partial F / \\partial x}{\\partial F / \\partial z}$","$-\\frac{\\partial F / \\partial z}{\\partial F / \\partial x}$","$-\\frac{\\partial F / \\partial x}{\\partial F / \\partial z}$","$\\frac{\\partial F / \\partial z}{\\partial F / \\partial x}$"],correctIndex:2,difficulty:"medium",explanation:"Using implicit differentiation: if $F(x, y, z) = 0$ and $z = f(x, y)$, then differentiating with respect to $x$ gives $\\frac{\\partial F}{\\partial x} + \\frac{\\partial F}{\\partial z}\\frac{\\partial z}{\\partial x} = 0$, so $\\frac{\\partial z}{\\partial x} = -\\frac{\\partial F / \\partial x}{\\partial F / \\partial z}$."},{id:2,type:"multiple-choice",question:"For the unit sphere $x^2 + y^2 + z^2 = 1$, solving for $z$ in terms of $x$ and $y$ gives:",options:["One solution: $z = \\sqrt{1 - x^2 - y^2}$","Infinitely many solutions","No solution exists","Two solutions: $z = \\pm\\sqrt{1 - x^2 - y^2}$"],correctIndex:3,difficulty:"easy",explanation:"The equation $x^2 + y^2 + z^2 = 1$ has two solutions for $z$: $z = \\sqrt{1 - x^2 - y^2}$ (upper hemisphere) and $z = -\\sqrt{1 - x^2 - y^2}$ (lower hemisphere), valid for $x^2 + y^2 \\leq 1$."},{id:3,type:"multiple-choice",question:"The key condition for being able to solve $F(x, y, z) = 0$ for $z$ as a differentiable function of $x$ and $y$ near a point is:",options:["$\\frac{\\partial F}{\\partial z} \\neq 0$","$\\frac{\\partial F}{\\partial y} \\neq 0$","$\\frac{\\partial F}{\\partial x} \\neq 0$","$F = 0$"],correctIndex:0,difficulty:"medium",explanation:"The implicit function theorem requires that $\\frac{\\partial F}{\\partial z} \\neq 0$ at the point. This ensures we can solve for $z$ as a differentiable function of the other variables."},{id:4,type:"multiple-choice",question:"If $F(x_1, \\ldots, x_n) = 0$ defines $x_n$ implicitly as a differentiable function of $x_1, \\ldots, x_{n-1}$, then $D_k f = $ (for $k < n$):",options:["$D_k F$","$-\\frac{D_k F}{D_n F}$","$-D_k F$","$\\frac{D_k F}{D_n F}$"],correctIndex:1,difficulty:"medium",explanation:"By the general implicit function theorem, $D_k f = -\\frac{D_k F}{D_n F}$ at points where $D_n F \\neq 0$. This generalizes the two-variable formula to $n$ dimensions."},{id:5,type:"multiple-choice",question:"When two surfaces $F(x, y, z) = 0$ and $G(x, y, z) = 0$ intersect along a curve, the derivatives of functions along the curve involve:",options:["Only $F$ and its derivatives","Only $G$ and its derivatives","Jacobian determinants of $F$ and $G$","The Laplacian of $F + G$"],correctIndex:2,difficulty:"hard",explanation:"For two constraints defining a curve, solving for two variables in terms of the third involves Jacobian determinants. For example, $X'(z) = \\frac{\\partial(F, G)/\\partial(y, z)}{\\partial(F, G)/\\partial(x, y)}$."}],Le=[{id:1,type:"multiple-choice",question:"A point $(x_1, y_1)$ is called a stationary point (critical point) of $f$ if:",options:["$f(x_1, y_1) = 0$","The function $f$ is constant near $(x_1, y_1)$","$D_1 f(x_1, y_1) = D_2 f(x_1, y_1)$","$D_1 f(x_1, y_1) = 0$ and $D_2 f(x_1, y_1) = 0$"],correctIndex:3,difficulty:"easy",explanation:"A stationary point (critical point) is a point where all partial derivatives vanish: $D_1 f(x_1, y_1) = 0$ and $D_2 f(x_1, y_1) = 0$. This means $\\nabla f = 0$ at that point."},{id:2,type:"multiple-choice",question:"At a stationary point, the tangent plane to the surface $z = f(x, y)$ is:",options:["Horizontal","Vertical","Does not exist","Parallel to the $xz$-plane"],correctIndex:0,difficulty:"easy",explanation:"When $\\nabla f = 0$, the gradient vector of $F(x, y, z) = f(x, y) - z$ has the form $(0, 0, -1)$. This means the tangent plane is horizontal (parallel to the $xy$-plane)."},{id:3,type:"multiple-choice",question:"A saddle point of $f$ is a stationary point where:",options:["$f$ has a local maximum","Every neighborhood contains points where $f(x) < f(a)$ and points where $f(x) > f(a)$","$f$ has a local minimum","The gradient is undefined"],correctIndex:1,difficulty:"medium",explanation:"A saddle point is a stationary point that is neither a local max nor a local min. Every neighborhood contains points where $f$ is larger than $f(a)$ and points where $f$ is smaller than $f(a)$."},{id:4,type:"multiple-choice",question:"The function $f(x, y) = xy$ has at the origin:",options:["A relative maximum","A relative minimum","A saddle point","No stationary point"],correctIndex:2,difficulty:"medium",explanation:"For $f(x, y) = xy$, both partial derivatives are zero at the origin. But $f > 0$ in the first and third quadrants, and $f < 0$ in the second and fourth quadrants, so the origin is a saddle point."},{id:5,type:"multiple-choice",question:"The function $f(x, y) = 2 - x^2 - y^2$ has at the origin:",options:["A saddle point","A relative minimum","No stationary point","An absolute maximum"],correctIndex:3,difficulty:"easy",explanation:"Since $f(x, y) = 2 - (x^2 + y^2) \\leq 2 = f(0, 0)$ for all $(x, y)$, the origin is an absolute maximum. The level curves are circles, consistent with an extremum."}],Ee=[{id:1,type:"multiple-choice",question:"The Hessian matrix $H(x)$ of a scalar field $f$ at a point $x$ is:",options:["The matrix of second partial derivatives $[D_{ij}f(x)]$","The matrix of first partial derivatives","The gradient vector","The Jacobian matrix"],correctIndex:0,difficulty:"easy",explanation:"The Hessian matrix is the $n \\times n$ matrix of second-order partial derivatives: $H(x) = [D_{ij}f(x)]_{i,j=1}^n$. When the second partials are continuous, the Hessian is symmetric."},{id:2,type:"multiple-choice",question:"The second-order Taylor formula for a scalar field $f$ at a stationary point $a$ is:",options:["$f(a + y) - f(a) = \\nabla f(a) \\cdot y$","$f(a + y) - f(a) = \\frac{1}{2}yH(a)y^t + \\|y\\|^2 E_2(a, y)$","$f(a + y) - f(a) = yH(a)$","$f(a + y) - f(a) = 0$"],correctIndex:1,difficulty:"medium",explanation:"At a stationary point where $\\nabla f(a) = 0$, the second-order Taylor formula gives $f(a + y) - f(a) = \\frac{1}{2}yH(a)y^t + \\|y\\|^2 E_2(a, y)$, where $E_2 \\to 0$ as $y \\to 0$."},{id:3,type:"multiple-choice",question:"The quadratic form associated with the Hessian matrix is:",options:["$\\det H(a)$","$\\text{tr}(H(a))$","$yH(a)y^t = \\sum_{i,j} D_{ij}f(a)y_i y_j$","$\\|H(a)\\|$"],correctIndex:2,difficulty:"medium",explanation:"The quadratic form associated with the Hessian is $Q(y) = yH(a)y^t = \\sum_{i=1}^n \\sum_{j=1}^n D_{ij}f(a)y_i y_j$. Its sign determines the nature of stationary points."},{id:4,type:"multiple-choice",question:"For small $y$ near a stationary point, the sign of $f(a + y) - f(a)$ is determined by:",options:["The value of $f(a)$","The sign of the gradient","The trace of the Hessian","The sign of the quadratic form $yH(a)y^t$"],correctIndex:3,difficulty:"medium",explanation:"Since the error term $\\|y\\|^2 E_2(a, y)$ tends to zero faster than $\\|y\\|^2$, for small $y$ the sign of $f(a + y) - f(a)$ is determined by the sign of the quadratic form $yH(a)y^t$."},{id:5,type:"multiple-choice",question:"The proof of the second-order Taylor formula uses:",options:["The one-dimensional Taylor formula applied to $g(u) = f(a + uy)$","Green's theorem","The mean value theorem for integrals","Integration by parts"],correctIndex:0,difficulty:"hard",explanation:"The proof defines $g(u) = f(a + uy)$ and applies the one-dimensional second-order Taylor formula with Lagrange's remainder: $g(1) - g(0) = g'(0) + \\frac{1}{2!}g''(c)$. The chain rule gives the required formula."}],Ve=[{id:1,type:"multiple-choice",question:"A quadratic form $Q(y) = yAy^t$ is positive definite if and only if:",options:["All eigenvalues of $A$ are zero","All eigenvalues of $A$ are positive","All eigenvalues of $A$ are negative","The eigenvalues of $A$ have mixed signs"],correctIndex:1,difficulty:"medium",explanation:"A real symmetric matrix $A$ has $Q(y) > 0$ for all $y \\neq 0$ (positive definite) if and only if all its eigenvalues are positive."},{id:2,type:"multiple-choice",question:"If all eigenvalues of the Hessian $H(a)$ at a stationary point $a$ are positive, then $f$ has:",options:["A relative maximum at $a$","A saddle point at $a$","A relative minimum at $a$","No conclusion can be drawn"],correctIndex:2,difficulty:"medium",explanation:"If all eigenvalues are positive, the Hessian is positive definite. This means $f(a + y) - f(a) > 0$ for small $y \\neq 0$, so $f$ has a relative minimum at $a$."},{id:3,type:"multiple-choice",question:"If the Hessian $H(a)$ has both positive and negative eigenvalues at a stationary point, then:",options:["$f$ has a relative minimum at $a$","$f$ has a relative maximum at $a$","The function is not differentiable at $a$","$f$ has a saddle point at $a$"],correctIndex:3,difficulty:"medium",explanation:"If $H(a)$ has eigenvalues of opposite signs (indefinite), the quadratic form takes both positive and negative values. This means $f$ has a saddle point at $a$."},{id:4,type:"multiple-choice",question:"The diagonalization of a quadratic form $Q(y) = yAy^t$ using an orthogonal matrix $C$ gives:",options:["$Q(y) = \\sum_{i=1}^n \\lambda_i x_i^2$ where $x = yC$","$Q(y) = \\det(A)$","$Q(y) = \\text{tr}(A)$","$Q(y) = \\|y\\|^2$"],correctIndex:0,difficulty:"hard",explanation:"For a real symmetric matrix $A$, there exists an orthogonal matrix $C$ such that $Q(y) = \\sum_{i=1}^n \\lambda_i x_i^2$ where $x = yC$ and $\\lambda_1, \\ldots, \\lambda_n$ are the eigenvalues of $A$."},{id:5,type:"multiple-choice",question:"If all eigenvalues of the Hessian $H(a)$ are zero, then:",options:["$f$ definitely has a minimum at $a$","The eigenvalue test gives no information","$f$ definitely has a saddle point at $a$","$f$ definitely has a maximum at $a$"],correctIndex:1,difficulty:"medium",explanation:"If all eigenvalues are zero, the second-order test is inconclusive. Higher-order derivatives or direct analysis are needed to determine the nature of the stationary point."}],Ne=[{id:1,type:"multiple-choice",question:"For a function $f(x, y)$ with Hessian entries $A = D_{11}f$, $B = D_{12}f$, $C = D_{22}f$ at a stationary point, the discriminant is:",options:["$\\Delta = A + C$","$\\Delta = AC + B^2$","$\\Delta = AC - B^2$","$\\Delta = A - C$"],correctIndex:2,difficulty:"easy",explanation:"The Hessian determinant (discriminant) for two variables is $\\Delta = \\det H = AC - B^2$, where $A = D_{11}f$, $B = D_{12}f$, and $C = D_{22}f$."},{id:2,type:"multiple-choice",question:"If $\\Delta = AC - B^2 < 0$ at a stationary point, then $f$ has:",options:["A relative minimum","A relative maximum","Cannot be determined","A saddle point"],correctIndex:3,difficulty:"medium",explanation:"When $\\Delta < 0$, the eigenvalues of the Hessian have opposite signs (since $\\lambda_1 \\lambda_2 = \\Delta < 0$). This means $f$ has a saddle point."},{id:3,type:"multiple-choice",question:"If $\\Delta > 0$ and $A > 0$ at a stationary point, then $f$ has:",options:["A relative minimum","A relative maximum","A saddle point","Cannot be determined"],correctIndex:0,difficulty:"medium",explanation:"When $\\Delta > 0$, both eigenvalues have the same sign. Since $\\Delta = \\lambda_1 \\lambda_2 > 0$ and $A + C = \\lambda_1 + \\lambda_2$, if $A > 0$ then both eigenvalues are positive, giving a relative minimum."},{id:4,type:"multiple-choice",question:"If $\\Delta = 0$ at a stationary point, the second derivative test is:",options:["Conclusive for a minimum","Inconclusive","Conclusive for a saddle","Conclusive for a maximum"],correctIndex:1,difficulty:"easy",explanation:"When $\\Delta = 0$, at least one eigenvalue is zero, so the second derivative test is inconclusive. Other methods (such as examining higher-order derivatives or direct analysis) are needed."},{id:5,type:"multiple-choice",question:"For $f(x, y) = x^3 - 3xy^2$ at the origin, the Hessian test gives:",options:["$\\Delta > 0$, minimum","$\\Delta > 0$, maximum","$\\Delta = 0$, inconclusive","$\\Delta < 0$, saddle"],correctIndex:2,difficulty:"medium",explanation:`At the origin: $A = 6x|_{(0,0)} = 0$, $B = -6y|_{(0,0)} = 0$, $C = -6x|_{(0,0)} = 0$. So $\\Delta = 0 - 0 = 0$, making the test inconclusive. (Direct inspection shows it's a "monkey saddle".)`}],Oe=[{id:1,type:"multiple-choice",question:"In the method of Lagrange multipliers, if we want to extremize $f$ subject to $g(x) = 0$, the condition at an extremum is:",options:["$\\nabla f = 0$","$\\nabla g = 0$","$f = g$","$\\nabla f = \\lambda \\nabla g$ for some scalar $\\lambda$"],correctIndex:3,difficulty:"medium",explanation:"At a constrained extremum, the gradient of the objective function must be parallel to the gradient of the constraint: $\\nabla f = \\lambda \\nabla g$. The scalar $\\lambda$ is the Lagrange multiplier."},{id:2,type:"multiple-choice",question:"Geometrically, the condition $\\nabla f = \\lambda \\nabla g$ means:",options:["The level set of $f$ is tangent to the constraint surface","The level set of $f$ is perpendicular to the constraint surface","The gradients of $f$ and $g$ are perpendicular","$f$ and $g$ have the same level sets"],correctIndex:0,difficulty:"medium",explanation:"When $\\nabla f = \\lambda \\nabla g$, the gradients are parallel. Since each gradient is normal to its level set, this means the level set of $f$ is tangent to the constraint surface $g = 0$ at the extremum."},{id:3,type:"multiple-choice",question:"For $m$ constraints $g_1 = 0, \\ldots, g_m = 0$ in $n$ variables, the Lagrange condition is:",options:["$\\nabla f = 0$","$\\nabla f = \\lambda_1 \\nabla g_1 + \\cdots + \\lambda_m \\nabla g_m$","$\\nabla f = \\nabla g_1 \\cdot \\nabla g_m$","The constraints must be independent"],correctIndex:1,difficulty:"hard",explanation:"With $m$ constraints, the gradient of the objective must lie in the span of the constraint gradients: $\\nabla f = \\lambda_1 \\nabla g_1 + \\cdots + \\lambda_m \\nabla g_m$, giving $m$ Lagrange multipliers."},{id:4,type:"multiple-choice",question:"To find the closest point on a surface $g(x, y, z) = 0$ to the origin, we minimize:",options:["$f = x + y + z$ subject to $g = 0$","$f = g(x, y, z)$","$f = x^2 + y^2 + z^2$ subject to $g = 0$","$f = |g(x, y, z)|$"],correctIndex:2,difficulty:"easy",explanation:"To minimize distance to the origin, we minimize $r^2 = x^2 + y^2 + z^2$ (or equivalently $r$) subject to the constraint $g(x, y, z) = 0$."},{id:5,type:"multiple-choice",question:"The Lagrange multiplier method requires that the constraint gradients be:",options:["Zero at the extremum","Equal to each other","Perpendicular to the gradient of $f$","Linearly independent at the extremum"],correctIndex:3,difficulty:"medium",explanation:"For the method to be valid, the gradients $\\nabla g_1, \\ldots, \\nabla g_m$ must be linearly independent at the extremum. This is equivalent to requiring that not all relevant Jacobian determinants vanish."}],He=[{id:1,type:"multiple-choice",question:"A closed $n$-dimensional interval $[a, b]$ in $\\mathbb{R}^n$ is defined as:",options:["The Cartesian product $[a_1, b_1] \\times \\cdots \\times [a_n, b_n]$","A single point in $\\mathbb{R}^n$","An open ball of radius $1$","The set of all points with $\\|x\\| \\leq 1$"],correctIndex:0,difficulty:"easy",explanation:"A closed $n$-dimensional interval is the Cartesian product of $n$ closed intervals: $[a, b] = [a_1, b_1] \\times \\cdots \\times [a_n, b_n]$. For $n = 2$, this is a rectangle."},{id:2,type:"multiple-choice",question:"The Boundedness Theorem states that if $f$ is continuous on a closed interval $[a, b]$ in $\\mathbb{R}^n$, then:",options:["$f$ has infinitely many zeros","$f$ is bounded on $[a, b]$","$f$ is differentiable on $[a, b]$","$f$ is monotonic on $[a, b]$"],correctIndex:1,difficulty:"medium",explanation:"The Boundedness Theorem states that a continuous scalar field on a closed bounded interval is bounded: there exists $C > 0$ such that $|f(x)| \\leq C$ for all $x$ in $[a, b]$."},{id:3,type:"multiple-choice",question:"The Extreme-Value Theorem in $\\mathbb{R}^n$ states that if $f$ is continuous on a closed interval $[a, b]$, then:",options:["$f$ is constant on $[a, b]$","$f$ has no critical points","$f$ attains its supremum and infimum on $[a, b]$","$f$ is zero somewhere in $[a, b]$"],correctIndex:2,difficulty:"medium",explanation:"The Extreme-Value Theorem guarantees that a continuous function on a closed bounded interval attains its maximum and minimum: there exist points $c, d \\in [a, b]$ with $f(c) = \\sup f$ and $f(d) = \\inf f$."},{id:4,type:"multiple-choice",question:"The proof of the Boundedness Theorem uses:",options:["The Mean Value Theorem","The Implicit Function Theorem","Green's Theorem","Successive bisection and nested intervals"],correctIndex:3,difficulty:"hard",explanation:"The proof uses successive bisection: if $f$ were unbounded on $[a, b]$, bisecting creates nested intervals on which $f$ is unbounded. These nest to a point where continuity gives a contradiction."},{id:5,type:"multiple-choice",question:"The Uniform Continuity Theorem (small-span theorem) states that for continuous $f$ on a closed $[a, b]$, for every $\\varepsilon > 0$:",options:["There is a partition where the span of $f$ on each subinterval is less than $\\varepsilon$","$f$ can be made constant by changing finitely many values","$f$ has at most finitely many discontinuities","The derivative of $f$ exists and is bounded by $\\varepsilon$"],correctIndex:0,difficulty:"hard",explanation:"The Uniform Continuity Theorem says we can partition $[a, b]$ into finitely many subintervals so that the span (max minus min) of $f$ on each subinterval is less than $\\varepsilon$. This is the essence of uniform continuity."}],Ge=[{id:1,type:"multiple-choice",question:"A line integral is denoted by $\\int f \\cdot d\\alpha$ where:",options:["$f$ is a scalar field and $\\alpha$ is a constant","$f$ is a vector field and $\\alpha$ is a path","$f$ and $\\alpha$ are both scalar fields","$f$ is a constant and $\\alpha$ is a vector field"],correctIndex:1,difficulty:"easy",explanation:"A line integral $\\int f \\cdot d\\alpha$ involves a vector field $f$ defined on a curve described by a path $\\alpha$. The dot suggests an inner product of vectors."},{id:2,type:"multiple-choice",question:"A path $\\alpha: [a, b] \\to \\mathbb{R}^n$ is called smooth if:",options:["$\\alpha$ is constant","$\\alpha$ is continuous but not differentiable","$\\alpha'$ exists and is continuous on $(a, b)$","$\\alpha$ is a polynomial function"],correctIndex:2,difficulty:"medium",explanation:"A path is smooth if its derivative $\\alpha'$ exists and is continuous on the open interval $(a, b)$. This ensures the curve has a continuously turning tangent line."},{id:3,type:"multiple-choice",question:"A piecewise smooth path has:",options:["No tangent lines anywhere","Discontinuities at every point","A tangent line everywhere","A tangent line at all but finitely many points"],correctIndex:3,difficulty:"medium",explanation:'A piecewise smooth path can be partitioned into finitely many subintervals on each of which it is smooth. The path has a tangent line at all but finitely many "corner" points.'},{id:4,type:"multiple-choice",question:"Line integrals are fundamental in physics for computing:",options:["Work, potential energy, heat flow, and circulation","Mass only","Temperature only","Electric charge only"],correctIndex:0,difficulty:"easy",explanation:"Line integrals occur in many physical applications including work done by a force, potential energy, heat flow, change in entropy, and circulation of a fluid."},{id:5,type:"multiple-choice",question:"The difference between a curve and a path is that:",options:["Curves are in 2D, paths are in 3D","A curve is just the set of points; a path includes how the curve is traced","Curves are smooth, paths are not","There is no difference"],correctIndex:1,difficulty:"medium",explanation:"A curve is the graph (set of points) of a continuous function. A path is the function itself, which specifies how the curve is traceddirection, speed, and parametrization. Line integrals depend on the path, not just the curve."}],Ue=[{id:1,type:"multiple-choice",question:"The line integral of a vector field $f$ along a path $\\alpha$ on $[a, b]$ is defined as:",options:["$\\int_a^b f(\\alpha(t)) \\, dt$","$\\int_a^b \\|f(\\alpha(t))\\| \\, dt$","$\\int_a^b f[\\alpha(t)] \\cdot \\alpha'(t) \\, dt$","$\\int_a^b f(t) \\cdot \\alpha(t) \\, dt$"],correctIndex:2,difficulty:"medium",explanation:"The line integral is $\\int f \\cdot d\\alpha = \\int_a^b f[\\alpha(t)] \\cdot \\alpha'(t) \\, dt$, the integral of the dot product of the field evaluated along the path with the path's tangent vector."},{id:2,type:"multiple-choice",question:"In component form with $f = (f_1, \\ldots, f_n)$ and $\\alpha = (\\alpha_1, \\ldots, \\alpha_n)$, the line integral equals:",options:["$\\sum_{k=1}^n f_k[\\alpha(t)]$","$\\int_a^b (f_1 + \\cdots + f_n) \\, dt$","$\\prod_{k=1}^n \\int_a^b f_k[\\alpha(t)] \\, dt$","$\\sum_{k=1}^n \\int_a^b f_k[\\alpha(t)] \\alpha_k'(t) \\, dt$"],correctIndex:3,difficulty:"medium",explanation:"In components: $\\int f \\cdot d\\alpha = \\sum_{k=1}^n \\int_a^b f_k[\\alpha(t)] \\alpha_k'(t) \\, dt$, which is also written as $\\int f_1 \\, d\\alpha_1 + \\cdots + f_n \\, d\\alpha_n$."},{id:3,type:"multiple-choice",question:"If $\\alpha(a) = \\alpha(b)$ (closed path), the line integral is often denoted:",options:["$\\oint$","$\\iint$","$\\int$","$\\partial$"],correctIndex:0,difficulty:"easy",explanation:"The symbol $\\oint$ is used to indicate integration along a closed path, where the starting and ending points coincide."},{id:4,type:"multiple-choice",question:"For $f(x, y) = \\sqrt{y}\\mathbf{i} + (x^3 + y)\\mathbf{j}$, integrating from $(0, 0)$ to $(1, 1)$ along different paths:",options:["Always gives the same value","May give different values depending on the path","Is always zero","Is undefined"],correctIndex:1,difficulty:"medium",explanation:"In general, line integrals depend on the path, not just the endpoints. The example in the section shows two different paths give values $17/12$ and $59/42$."},{id:5,type:"multiple-choice",question:"In two dimensions, the line integral notation $\\int_C f_1 \\, dx + f_2 \\, dy$ means:",options:["$\\int_C (f_1 + f_2)(dx + dy)$","$f_1 \\cdot f_2 \\cdot \\text{length of } C$","$\\int_a^b [f_1(\\alpha(t))\\alpha_1'(t) + f_2(\\alpha(t))\\alpha_2'(t)] \\, dt$","$\\int_a^b f_1 \\, dt + \\int_a^b f_2 \\, dt$"],correctIndex:2,difficulty:"medium",explanation:"The notation $\\int_C f_1 \\, dx + f_2 \\, dy$ is shorthand for $\\int_a^b [f_1(\\alpha(t))\\alpha_1'(t) + f_2(\\alpha(t))\\alpha_2'(t)] \\, dt$ where $\\alpha = (\\alpha_1, \\alpha_2)$ parametrizes $C$."}],Je=[{id:1,type:"multiple-choice",question:"The linearity property of line integrals states that:",options:["$\\int f \\cdot d(a\\alpha) = a \\int f \\cdot d\\alpha$","$\\int f \\cdot d\\alpha = \\int g \\cdot d\\alpha$","$\\int (f + g) \\cdot d\\alpha = \\int f \\cdot d\\alpha \\cdot \\int g \\cdot d\\alpha$","$\\int (af + bg) \\cdot d\\alpha = a \\int f \\cdot d\\alpha + b \\int g \\cdot d\\alpha$"],correctIndex:3,difficulty:"easy",explanation:"Linearity: $\\int (af + bg) \\cdot d\\alpha = a \\int f \\cdot d\\alpha + b \\int g \\cdot d\\alpha$ for scalar constants $a, b$ and vector fields $f, g$."},{id:2,type:"multiple-choice",question:"If a curve $C$ is split into $C_1$ and $C_2$, the additive property gives:",options:["$\\int_C f = \\int_{C_1} f + \\int_{C_2} f$","$\\int_C f = \\int_{C_1} f \\cdot \\int_{C_2} f$","$\\int_C f = \\int_{C_1} f - \\int_{C_2} f$","$\\int_C f = \\max(\\int_{C_1} f, \\int_{C_2} f)$"],correctIndex:0,difficulty:"easy",explanation:"The additive property: if $C$ is divided into $C_1$ and $C_2$, then $\\int_C f \\cdot d\\alpha = \\int_{C_1} f \\cdot d\\alpha + \\int_{C_2} f \\cdot d\\alpha$."},{id:3,type:"multiple-choice",question:"Two paths $\\alpha$ and $\\beta$ with the same graph are called equivalent. If they trace the curve in the same direction:",options:["$\\int f \\cdot d\\alpha = -\\int f \\cdot d\\beta$","$\\int f \\cdot d\\alpha = \\int f \\cdot d\\beta$","$\\int f \\cdot d\\alpha = 0$","$\\int f \\cdot d\\beta = 0$"],correctIndex:1,difficulty:"medium",explanation:"If equivalent paths $\\alpha$ and $\\beta$ trace the same curve in the same direction (orientation-preserving), then $\\int f \\cdot d\\alpha = \\int f \\cdot d\\beta$."},{id:4,type:"multiple-choice",question:"If paths $\\alpha$ and $\\beta$ trace the same curve in opposite directions:",options:["$\\int f \\cdot d\\alpha = \\int f \\cdot d\\beta$","$\\int f \\cdot d\\alpha + \\int f \\cdot d\\beta = 1$","$\\int f \\cdot d\\alpha = -\\int f \\cdot d\\beta$","Both integrals are zero"],correctIndex:2,difficulty:"medium",explanation:"If $\\alpha$ and $\\beta$ trace the same curve in opposite directions, then $\\int f \\cdot d\\alpha = -\\int f \\cdot d\\beta$. Reversing direction negates the integral."},{id:5,type:"multiple-choice",question:"The change of parameter formula uses the chain rule because if $\\beta(t) = \\alpha[u(t)]$, then:",options:["$\\beta'(t) = \\alpha[u(t)]$","$\\beta'(t) = \\alpha'(t)$","$\\beta'(t) = u'(t)$","$\\beta'(t) = \\alpha'[u(t)] u'(t)$"],correctIndex:3,difficulty:"medium",explanation:"By the chain rule, $\\beta'(t) = \\alpha'[u(t)] u'(t)$. The sign of $u'(t)$ determines whether the reparametrization preserves or reverses orientation."}],Me=[{id:1,type:"multiple-choice",question:"The work done by a force field $f$ along a path $\\alpha$ is defined as:",options:["$W = \\int f \\cdot d\\alpha$","$W = \\|f\\| \\cdot \\text{length of path}$","$W = f(\\alpha(b)) - f(\\alpha(a))$","$W = \\int \\|f\\| \\, ds$"],correctIndex:0,difficulty:"easy",explanation:"Work done by a force field $f$ moving a particle along a path $\\alpha$ is the line integral $W = \\int f \\cdot d\\alpha$."},{id:2,type:"multiple-choice",question:"For a constant force $f = \\mathbf{c}$, the work done moving from $\\mathbf{a}$ to $\\mathbf{b}$ along any path is:",options:["$\\mathbf{c} \\cdot \\mathbf{a}$","$\\mathbf{c} \\cdot (\\mathbf{b} - \\mathbf{a})$","$\\mathbf{c} \\cdot \\mathbf{b}$","$\\|\\mathbf{c}\\| \\cdot \\|\\mathbf{b} - \\mathbf{a}\\|$"],correctIndex:1,difficulty:"medium",explanation:"For a constant force, $W = \\mathbf{c} \\cdot (\\mathbf{b} - \\mathbf{a})$, the dot product of the force and the displacement vector. This is independent of the path."},{id:3,type:"multiple-choice",question:"A force field is called conservative if:",options:["The field is always zero","The work is always positive","The work depends only on the endpoints, not the path","The field has no curl"],correctIndex:2,difficulty:"medium",explanation:"A conservative force field is one for which the work done depends only on the initial and final positions, not on the path taken between them."},{id:4,type:"multiple-choice",question:"The work-energy principle states that the work done by $f$ equals:",options:["The change in potential energy","Zero","The total energy","The change in kinetic energy"],correctIndex:3,difficulty:"medium",explanation:"The work-energy principle: $\\int f \\cdot dr = \\frac{1}{2}mv^2(b) - \\frac{1}{2}mv^2(a)$. Work equals the change in kinetic energy."},{id:5,type:"multiple-choice",question:"From Newton's second law $f = mr''$, the work integral $\\int f \\cdot r' \\, dt$ equals:",options:["$\\frac{1}{2}m[v^2(b) - v^2(a)]$","$m \\cdot r'(b)$","$m[r(b) - r(a)]$","$\\frac{1}{2}m v(b)$"],correctIndex:0,difficulty:"hard",explanation:"Using $f = mr''$ and $v = r'$: $f \\cdot r' = mr'' \\cdot r' = m v' \\cdot v = \\frac{1}{2}m \\frac{d}{dt}(v \\cdot v) = \\frac{1}{2}m \\frac{d}{dt}(v^2)$. Integrating gives the change in kinetic energy."}],Ze=[{id:1,type:"multiple-choice",question:"The arc-length function $s(t)$ for a path $\\alpha$ on $[a, t]$ is:",options:["$s(t) = \\int_a^t \\alpha(u) \\, du$","$s(t) = \\int_a^t \\|\\alpha'(u)\\| \\, du$","$s(t) = \\|\\alpha(t) - \\alpha(a)\\|$","$s(t) = t - a$"],correctIndex:1,difficulty:"medium",explanation:"The arc-length function is $s(t) = \\int_a^t \\|\\alpha'(u)\\| \\, du$, which gives the length of the curve from $\\alpha(a)$ to $\\alpha(t)$."},{id:2,type:"multiple-choice",question:"The derivative of arc length satisfies $s'(t) = $:",options:["$\\alpha(t)$","$\\alpha'(t)$","$\\|\\alpha'(t)\\|$","$1$"],correctIndex:2,difficulty:"easy",explanation:"By the fundamental theorem of calculus, $s'(t) = \\|\\alpha'(t)\\|$, which is the speed along the curve."},{id:3,type:"multiple-choice",question:"The line integral with respect to arc length $\\int_C \\varphi \\, ds$ is defined as:",options:["$\\int_a^b \\varphi[\\alpha(t)] \\, dt$","$\\int_a^b s(t) \\, dt$","$\\int_a^b \\varphi[\\alpha(t)] \\alpha'(t) \\, dt$","$\\int_a^b \\varphi[\\alpha(t)] s'(t) \\, dt$"],correctIndex:3,difficulty:"medium",explanation:"The line integral with respect to arc length is $\\int_C \\varphi \\, ds = \\int_a^b \\varphi[\\alpha(t)] s'(t) \\, dt = \\int_a^b \\varphi[\\alpha(t)] \\|\\alpha'(t)\\| \\, dt$."},{id:4,type:"multiple-choice",question:"The flow integral of a velocity field $f$ along a curve $C$ is:",options:["$\\int_C f \\cdot T \\, ds$ where $T$ is the unit tangent","$\\int_C \\|f\\| \\, ds$","$\\int_C f \\cdot N \\, ds$ where $N$ is the normal","$\\int_C f \\times T \\, ds$"],correctIndex:0,difficulty:"medium",explanation:"The flow integral is $\\int_C f \\cdot T \\, ds$, where $T$ is the unit tangent vector. This measures the tangential component of velocity integrated along the curve."},{id:5,type:"multiple-choice",question:"For a wire with density $\\mu(x, y, z)$ along a curve $C$, the total mass is:",options:["$\\int_C \\mu(x, y, z) \\, dt$","$\\int_C \\mu(x, y, z) \\, ds$","$\\mu \\cdot \\text{length}(C)$","$\\int_C \\frac{1}{\\mu} \\, ds$"],correctIndex:1,difficulty:"easy",explanation:"The total mass of a wire with variable density $\\mu$ is $M = \\int_C \\mu(x, y, z) \\, ds$, the integral of density with respect to arc length."}],Ke=[{id:1,type:"multiple-choice",question:"An open set $S$ in $\\mathbb{R}^n$ is called connected if:",options:["It contains only one point","It is bounded","Every pair of points can be joined by a piecewise smooth path in $S$","It is closed"],correctIndex:2,difficulty:"medium",explanation:"An open set $S$ is connected if every pair of points in $S$ can be joined by a piecewise smooth path whose graph lies entirely in $S$."},{id:2,type:"multiple-choice",question:"A set is disconnected if:",options:["It is empty","It is unbounded","It contains only isolated points","It is the union of two or more disjoint nonempty open sets"],correctIndex:3,difficulty:"medium",explanation:"An open set $S$ is disconnected if it can be written as the union of two or more disjoint nonempty open sets. Connected sets are precisely those that are not disconnected."},{id:3,type:"multiple-choice",question:"The line integral of $f$ is independent of the path in $S$ means:",options:["The integral has the same value for all paths joining any two points in $S$","The integral is zero along every path","The integral depends only on the length of the path","The field $f$ is constant"],correctIndex:0,difficulty:"medium",explanation:"Path independence means the line integral from $\\mathbf{a}$ to $\\mathbf{b}$ has the same value for all piecewise smooth paths in $S$ joining $\\mathbf{a}$ to $\\mathbf{b}$, for every pair of points."},{id:4,type:"multiple-choice",question:"Which of the following is an example of an open connected set in the plane?",options:["The set of all points with $x > 0$ or $x < -1$ (two separate regions)","The interior of an ellipse","A single point","The empty set"],correctIndex:1,difficulty:"easy",explanation:"The interior of an ellipse is open (no boundary points) and connected (any two interior points can be joined by a path inside). Two separate regions like $x > 0$ or $x < -1$ would be disconnected."},{id:5,type:"multiple-choice",question:"The main result relating path independence to gradients is that path independence holds if and only if:",options:["$f$ is constant","$f$ is continuous","$f$ is the gradient of some potential function","$f$ is bounded"],correctIndex:2,difficulty:"medium",explanation:"For a continuous vector field on an open connected set, the line integral is path-independent if and only if $f$ is the gradient of some potential function. This is a fundamental characterization."}],et=[{id:1,type:"multiple-choice",question:"The second fundamental theorem for line integrals states that:",options:["$\\int_{\\mathbf{a}}^{\\mathbf{b}} \\nabla\\varphi \\cdot d\\alpha = 0$","$\\int_{\\mathbf{a}}^{\\mathbf{b}} \\nabla\\varphi \\cdot d\\alpha = \\nabla\\varphi(\\mathbf{b})$","$\\int_{\\mathbf{a}}^{\\mathbf{b}} \\nabla\\varphi \\cdot d\\alpha = \\varphi(\\mathbf{a})$","$\\int_{\\mathbf{a}}^{\\mathbf{b}} \\nabla\\varphi \\cdot d\\alpha = \\varphi(\\mathbf{b}) - \\varphi(\\mathbf{a})$"],correctIndex:3,difficulty:"medium",explanation:"The second fundamental theorem: $\\int_{\\mathbf{a}}^{\\mathbf{b}} \\nabla\\varphi \\cdot d\\alpha = \\varphi(\\mathbf{b}) - \\varphi(\\mathbf{a})$. The line integral of a gradient equals the change in the potential."},{id:2,type:"multiple-choice",question:"This theorem is proved using the chain rule applied to $g(t) = \\varphi[\\alpha(t)]$, which gives:",options:["$g'(t) = \\nabla\\varphi[\\alpha(t)] \\cdot \\alpha'(t)$","$g'(t) = \\varphi[\\alpha(t)]$","$g'(t) = \\alpha'(t)$","$g'(t) = 0$"],correctIndex:0,difficulty:"medium",explanation:"By the chain rule, $g'(t) = \\nabla\\varphi[\\alpha(t)] \\cdot \\alpha'(t)$. Integrating from $a$ to $b$ gives $g(b) - g(a) = \\varphi(\\mathbf{b}) - \\varphi(\\mathbf{a})$."},{id:3,type:"multiple-choice",question:"A corollary of the second fundamental theorem is that for a closed path (where $\\mathbf{b} = \\mathbf{a}$):",options:["$\\oint \\nabla\\varphi \\cdot d\\alpha = \\varphi(\\mathbf{a})$","$\\oint \\nabla\\varphi \\cdot d\\alpha = 0$","$\\oint \\nabla\\varphi \\cdot d\\alpha = 1$","$\\oint \\nabla\\varphi \\cdot d\\alpha = 2\\pi$"],correctIndex:1,difficulty:"easy",explanation:"For a closed path, $\\oint \\nabla\\varphi \\cdot d\\alpha = \\varphi(\\mathbf{a}) - \\varphi(\\mathbf{a}) = 0$. The line integral of a gradient around any closed path is zero."},{id:4,type:"multiple-choice",question:"If $f = \\nabla\\varphi$ represents a force field, the work done moving from $\\mathbf{a}$ to $\\mathbf{b}$:",options:["Depends on the path taken","Is always positive","Depends only on the values of $\\varphi$ at the endpoints","Is always zero"],correctIndex:2,difficulty:"medium",explanation:"For a gradient field, work $= \\varphi(\\mathbf{b}) - \\varphi(\\mathbf{a})$, depending only on the potential values at the endpoints, not on the path taken."},{id:5,type:"multiple-choice",question:"The theorem implies that line integrals of gradients are:",options:["Always zero","Path-dependent","Undefined","Independent of the path"],correctIndex:3,difficulty:"easy",explanation:"Since $\\int \\nabla\\varphi \\cdot d\\alpha = \\varphi(\\mathbf{b}) - \\varphi(\\mathbf{a})$ depends only on endpoints, the line integral of a gradient is independent of the path."}],tt=[{id:1,type:"multiple-choice",question:"If $f = \\nabla\\varphi$, the function $\\varphi$ is called:",options:["A potential function for $f$","The divergence of $f$","The gradient of $f$","The curl of $f$"],correctIndex:0,difficulty:"easy",explanation:"If $f = \\nabla\\varphi$, then $\\varphi$ is called a potential function for $f$. The level sets of $\\varphi$ are called equipotential surfaces."},{id:2,type:"multiple-choice",question:"The Newtonian gravitational potential is:",options:["$\\varphi = GmMr$","$\\varphi = GmM/r$","$\\varphi = -GmMr^2$","$\\varphi = GmM/r^2$"],correctIndex:1,difficulty:"medium",explanation:"The Newtonian potential is $\\varphi(x, y, z) = GmM/r$ where $r = \\sqrt{x^2 + y^2 + z^2}$. Its gradient gives the gravitational force $f = -GmMr^{-3}\\mathbf{r}$."},{id:3,type:"multiple-choice",question:"For the potential $\\varphi = r^n$, we have $\\nabla(r^n) = $:",options:["$nr^n$","$nr^{n-1}$","$nr^{n-2}\\mathbf{r}$","$r^{n-1}\\mathbf{r}$"],correctIndex:2,difficulty:"medium",explanation:"For $\\varphi = r^n$ where $r = \\|\\mathbf{r}\\|$, the gradient is $\\nabla(r^n) = nr^{n-2}\\mathbf{r}$ where $\\mathbf{r} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k}$."},{id:4,type:"multiple-choice",question:"The principle of conservation of mechanical energy states that for a gradient force field:",options:["Kinetic energy is constant","Potential energy is constant","Work done is always zero","Kinetic energy plus potential energy is constant"],correctIndex:3,difficulty:"medium",explanation:"For a conservative (gradient) force field, kinetic energy $k$ plus potential energy $-\\varphi$ is constant: $k(\\mathbf{x}) - \\varphi(\\mathbf{x}) = \\text{constant}$."},{id:5,type:"multiple-choice",question:"A force field will NOT be conservative if:",options:["Friction or viscosity exists in the system","It is continuous","It acts in three dimensions","It is bounded"],correctIndex:0,difficulty:"easy",explanation:"Force fields with friction or viscosity are not conservative because they convert mechanical energy into heat. Such forces cannot be written as gradients of a potential."}],it=[{id:1,type:"multiple-choice",question:"The first fundamental theorem for line integrals states that if line integrals of $f$ are path-independent, then:",options:["$f$ is constant","$\\nabla\\varphi = f$ where $\\varphi(\\mathbf{x}) = \\int_{\\mathbf{a}}^{\\mathbf{x}} f \\cdot d\\alpha$","$f = 0$","The integral is always zero"],correctIndex:1,difficulty:"medium",explanation:"If line integrals are path-independent, define $\\varphi(\\mathbf{x}) = \\int_{\\mathbf{a}}^{\\mathbf{x}} f \\cdot d\\alpha$. The first fundamental theorem shows $\\nabla\\varphi = f$, so $f$ is a gradient."},{id:2,type:"multiple-choice",question:"To prove that $D_k\\varphi(\\mathbf{x}) = f_k(\\mathbf{x})$, we integrate from $\\mathbf{x}$ to $\\mathbf{x} + h\\mathbf{e}_k$ along:",options:["Any path","A circular arc","A line segment parallel to the $k$th axis","A spiral"],correctIndex:2,difficulty:"hard",explanation:"We use a line segment from $\\mathbf{x}$ to $\\mathbf{x} + h\\mathbf{e}_k$ (parallel to the $k$th coordinate axis), then take the limit as $h \\to 0$ to get the partial derivative."},{id:3,type:"multiple-choice",question:"The first fundamental theorem is the converse of the second in the sense that:",options:["The first is stronger than the second","They are unrelated","Both prove the same thing","Second says gradients have path-independent integrals; first says path-independent integrals come from gradients"],correctIndex:3,difficulty:"medium",explanation:"The second fundamental theorem shows gradients have path-independent line integrals. The first shows the converse: if integrals are path-independent, the field must be a gradient."},{id:4,type:"multiple-choice",question:"For the indefinite line integral $\\varphi(\\mathbf{x}) = \\int_{\\mathbf{a}}^{\\mathbf{x}} f \\cdot d\\alpha$ to be well-defined:",options:["The integral must be path-independent","$f$ must be constant","The starting point $\\mathbf{a}$ must be the origin","$f$ must be zero"],correctIndex:0,difficulty:"medium",explanation:"For $\\varphi(\\mathbf{x})$ to be uniquely defined, the integral must give the same value regardless of the path from $\\mathbf{a}$ to $\\mathbf{x}$, i.e., the integral must be path-independent."},{id:5,type:"multiple-choice",question:"The proof uses the additive property to write $\\varphi(\\mathbf{x} + h\\mathbf{y}) - \\varphi(\\mathbf{x})$ as:",options:["A product of integrals","An integral from $\\mathbf{x}$ to $\\mathbf{x} + h\\mathbf{y}$","Zero","The gradient at $\\mathbf{x}$"],correctIndex:1,difficulty:"medium",explanation:"By additivity, $\\varphi(\\mathbf{x} + h\\mathbf{y}) - \\varphi(\\mathbf{x}) = \\int_{\\mathbf{x}}^{\\mathbf{x} + h\\mathbf{y}} f \\cdot d\\alpha$, an integral over a short path from $\\mathbf{x}$ to $\\mathbf{x} + h\\mathbf{y}$."}],nt=[{id:1,type:"multiple-choice",question:"According to Theorem 10.5, which three conditions are equivalent for a continuous vector field on an open connected set?",options:["Being bounded, continuous, and differentiable","Being constant, linear, and polynomial","Being a gradient, having path-independent integrals, and having zero circulation around closed paths","Having continuous partials, being integrable, and being bounded"],correctIndex:2,difficulty:"medium",explanation:"The three equivalent conditions are: (a) $f$ is the gradient of a potential, (b) line integrals are path-independent, (c) line integrals are zero around every closed path."},{id:2,type:"multiple-choice",question:"If $\\oint_C f \\neq 0$ for some closed curve $C$, then:",options:["$f$ is definitely a gradient","$f$ is constant","No conclusion can be drawn","$f$ is definitely NOT a gradient"],correctIndex:3,difficulty:"medium",explanation:"If the line integral around any closed curve is nonzero, then $f$ cannot be a gradient. A gradient field has zero circulation around every closed path."},{id:3,type:"multiple-choice",question:"If $\\oint_C f = 0$ for a particular closed curve $C$, then:",options:["$f$ might or might not be a gradient","$f$ must be a gradient","$f$ cannot be a gradient","$f$ is constant"],correctIndex:0,difficulty:"medium",explanation:"Zero circulation around one particular curve (or even infinitely many) does not guarantee $f$ is a gradient. The condition must hold for ALL closed curves."},{id:4,type:"multiple-choice",question:"The component test (necessary condition for a gradient) in 2D states that if $f = P\\mathbf{i} + Q\\mathbf{j}$ is a gradient, then:",options:["$P = Q$","$\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$","$\\frac{\\partial P}{\\partial x} = \\frac{\\partial Q}{\\partial y}$","$P + Q = 0$"],correctIndex:1,difficulty:"medium",explanation:"If $f = \\nabla\\varphi$, then $P = \\frac{\\partial\\varphi}{\\partial x}$ and $Q = \\frac{\\partial\\varphi}{\\partial y}$. By equality of mixed partials, $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$."},{id:5,type:"multiple-choice",question:"In general, the component test $D_i f_j = D_j f_i$ is:",options:["Both necessary and sufficient for being a gradient","Sufficient but not necessary for being a gradient","Necessary but not always sufficient for being a gradient","Neither necessary nor sufficient"],correctIndex:2,difficulty:"hard",explanation:"The component test is necessary (gradients must satisfy it) but not always sufficient. The topology of the domain matters---on simply connected domains it is also sufficient, but not on domains with holes."}],at=[{id:1,type:"multiple-choice",question:"To construct a potential function by integrating along coordinate axes in 2D, one formula is:",options:["$\\varphi(x, y) = \\int_a^x f_1(t, y) \\, dt$","$\\varphi(x, y) = \\int_a^x \\int_b^y f_1 f_2 \\, dt \\, ds$","$\\varphi(x, y) = f_1(x, y) + f_2(x, y)$","$\\varphi(x, y) = \\int_a^x f_1(t, b) \\, dt + \\int_b^y f_2(x, t) \\, dt$"],correctIndex:3,difficulty:"medium",explanation:"One method: integrate $f_1$ horizontally from $(a, b)$ to $(x, b)$, then integrate $f_2$ vertically from $(x, b)$ to $(x, y)$: $\\varphi(x, y) = \\int_a^x f_1(t, b) \\, dt + \\int_b^y f_2(x, t) \\, dt$."},{id:2,type:"multiple-choice",question:"The method of indefinite integrals works by integrating $\\frac{\\partial\\varphi}{\\partial x} = f_1$ to get:",options:["$\\varphi(x, y, z) = \\int f_1(x, y, z) \\, dx + A(y, z)$","$\\varphi(x, y, z) = f_1(x, y, z)$","$\\varphi(x, y, z) = \\int f_1 \\, dy$","$\\varphi(x, y, z) = x \\cdot f_1$"],correctIndex:0,difficulty:"medium",explanation:'Integrating $\\frac{\\partial\\varphi}{\\partial x} = f_1$ with respect to $x$ gives $\\varphi = \\int f_1 \\, dx + A(y, z)$, where $A(y, z)$ is a "constant" depending on the other variables.'},{id:3,type:"multiple-choice",question:"When constructing a potential by indefinite integrals, the arbitrary functions $A(y, z)$, $B(x, z)$, $C(x, y)$ must be chosen so that:",options:["Each is constant","All three expressions for $\\varphi$ agree","They sum to zero","They are all polynomials"],correctIndex:1,difficulty:"medium",explanation:"Each partial integration gives $\\varphi$ plus an arbitrary function of the other variables. These must be chosen so all three expressions for $\\varphi$ are consistent (agree everywhere)."},{id:4,type:"multiple-choice",question:"A set $S$ in $\\mathbb{R}^n$ is called convex if:",options:["It is bounded","It is open","Every pair of points can be joined by a line segment lying entirely in $S$","It contains the origin"],correctIndex:2,difficulty:"easy",explanation:"A set is convex if for any two points in the set, the entire line segment joining them also lies in the set. Every open convex set is connected."},{id:5,type:"multiple-choice",question:"On an open convex set containing the origin, a potential can be found using:",options:["$\\varphi(\\mathbf{x}) = \\mathbf{x} \\cdot \\mathbf{x}$","$\\varphi(\\mathbf{x}) = f(\\mathbf{x})$","$\\varphi(\\mathbf{x}) = \\|\\mathbf{x}\\|$","$\\varphi(\\mathbf{x}) = \\int_0^1 f(t\\mathbf{x}) \\cdot \\mathbf{x} \\, dt$"],correctIndex:3,difficulty:"hard",explanation:"On a convex set containing the origin, integrate along the line segment from $\\mathbf{0}$ to $\\mathbf{x}$: $\\varphi(\\mathbf{x}) = \\int_0^1 f(t\\mathbf{x}) \\cdot \\mathbf{x} \\, dt$."}],ot=[{id:1,type:"multiple-choice",question:"A first-order differential equation $P(x, y) \\, dx + Q(x, y) \\, dy = 0$ is called exact if:",options:["The vector field $V = P\\mathbf{i} + Q\\mathbf{j}$ is a gradient","$P + Q = 0$","$P = Q$","$P$ and $Q$ are both constants"],correctIndex:0,difficulty:"medium",explanation:"The equation is exact if $V(x, y) = P\\mathbf{i} + Q\\mathbf{j} = \\nabla\\varphi$ for some scalar field $\\varphi$. This means $P = \\frac{\\partial\\varphi}{\\partial x}$ and $Q = \\frac{\\partial\\varphi}{\\partial y}$."},{id:2,type:"multiple-choice",question:"For an exact equation with potential $\\varphi$, every solution $y = Y(x)$ satisfies:",options:["$\\varphi(x, Y(x)) = 0$","$\\varphi(x, Y(x)) = C$ for some constant $C$","$\\frac{d\\varphi}{dx} = Y(x)$","$\\varphi = x + Y(x)$"],correctIndex:1,difficulty:"medium",explanation:"If the equation is exact with potential $\\varphi$, then every solution satisfies $\\varphi(x, Y(x)) = C$ for some constant $C$. The level curves of $\\varphi$ are solution curves."},{id:3,type:"multiple-choice",question:"To check if $P \\, dx + Q \\, dy = 0$ is exact, we verify:",options:["$P = Q$","$\\frac{\\partial P}{\\partial x} = \\frac{\\partial Q}{\\partial y}$","$\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$","$PQ = 1$"],correctIndex:2,difficulty:"medium",explanation:"The necessary condition for exactness is $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ (the component test for $V = P\\mathbf{i} + Q\\mathbf{j}$ to be a gradient)."},{id:4,type:"multiple-choice",question:"An integrating factor $\\mu(x, y)$ is a function such that multiplying by $\\mu$:",options:["Makes $P$ and $Q$ equal","Makes the solution unique","Makes the equation linear","Makes the equation exact"],correctIndex:3,difficulty:"medium",explanation:"An integrating factor $\\mu$ transforms a non-exact equation into an exact one: if $P \\, dx + Q \\, dy = 0$ is not exact, then $\\mu P \\, dx + \\mu Q \\, dy = 0$ may be exact."},{id:5,type:"multiple-choice",question:"For the equation $y \\, dx + 2x \\, dy = 0$, multiplying by $y$ gives $y^2 \\, dx + 2xy \\, dy = 0$. The potential is:",options:["$\\varphi = xy^2$","$\\varphi = y^2 + 2xy$","$\\varphi = x^2y$","$\\varphi = xy$"],correctIndex:0,difficulty:"medium",explanation:"After multiplying by $y$: $P = y^2$ and $Q = 2xy$. Integrating $P$ with respect to $x$ gives $xy^2 + A(y)$. Checking with $Q$: $\\frac{\\partial}{\\partial y}(xy^2) = 2xy = Q$, so $\\varphi = xy^2$."}],st=[{id:1,type:"multiple-choice",question:"A double integral extends one-dimensional integration by replacing the interval $[a, b]$ with:",options:["A single point","A two-dimensional region $Q$","A line in space","A three-dimensional volume"],correctIndex:1,difficulty:"easy",explanation:"The double integral generalizes the one-dimensional integral by replacing the interval $[a, b]$ with a two-dimensional region of integration $Q$ (typically starting with rectangles)."},{id:2,type:"multiple-choice",question:"The notation $\\iint_Q f(x, y) \\, dx \\, dy$ represents:",options:["A line integral","The gradient of $f$","A double integral over the region $Q$","A surface integral"],correctIndex:2,difficulty:"easy",explanation:"The notation $\\iint_Q f(x, y) \\, dx \\, dy$ denotes a double integral of the scalar field $f$ over the two-dimensional region $Q$."},{id:3,type:"multiple-choice",question:"A rectangle in the plane is defined as:",options:["Any four-sided polygon","An infinite strip","A region with curved boundaries","The Cartesian product $[a, b] \\times [c, d]$"],correctIndex:3,difficulty:"easy",explanation:"A rectangle $Q$ is the Cartesian product of two closed intervals: $Q = [a, b] \\times [c, d] = \\{(x, y) : a \\leq x \\leq b, c \\leq y \\leq d\\}$."},{id:4,type:"multiple-choice",question:"The definition of the double integral follows the pattern:",options:["First for step functions, then for more general bounded functions","First for polynomials, then for continuous functions","First for smooth functions, then for discontinuous functions","Only for continuous functions"],correctIndex:0,difficulty:"medium",explanation:"Like one-dimensional integration, the double integral is first defined for step functions (where it is a simple sum), then extended to general bounded functions using approximation by step functions."},{id:5,type:"multiple-choice",question:"Most double integrals in practice are computed by:",options:["Direct summation","Iterated integration (repeated one-dimensional integration)","Monte Carlo methods","Graphical methods"],correctIndex:1,difficulty:"easy",explanation:"The main computational tool is iterated integration: the double integral is evaluated by performing two successive one-dimensional integrals, integrating first with respect to one variable, then the other."}],rt=[{id:1,type:"multiple-choice",question:"A partition $P$ of a rectangle $Q = [a, b] \\times [c, d]$ is:",options:["A single point in $Q$","A curve dividing $Q$ in half","The Cartesian product $P_1 \\times P_2$ of partitions of $[a, b]$ and $[c, d]$","The boundary of $Q$"],correctIndex:2,difficulty:"medium",explanation:"A partition of the rectangle $Q$ is $P = P_1 \\times P_2$, where $P_1$ partitions $[a, b]$ and $P_2$ partitions $[c, d]$. This decomposes $Q$ into subrectangles."},{id:2,type:"multiple-choice",question:"If $P_1$ has $n$ subintervals and $P_2$ has $m$ subintervals, then the partition $P$ decomposes $Q$ into:",options:["$n + m$ subrectangles","$n^m$ subrectangles","$\\max(n, m)$ subrectangles","$n \\cdot m$ subrectangles"],correctIndex:3,difficulty:"easy",explanation:"The partition $P = P_1 \\times P_2$ creates $n \\cdot m$ subrectangles (each subinterval of $P_1$ paired with each subinterval of $P_2$)."},{id:3,type:"multiple-choice",question:"A function $f$ on a rectangle $Q$ is a step function if:",options:["There exists a partition $P$ such that $f$ is constant on each open subrectangle of $P$","$f$ is constant on all of $Q$","$f$ is continuous","$f$ takes only integer values"],correctIndex:0,difficulty:"medium",explanation:"A step function on $Q$ is constant on the open subrectangles of some partition $P$. The values on the boundaries of subrectangles do not affect the integral."},{id:4,type:"multiple-choice",question:"A partition $P'$ is finer than $P$ if:",options:["$P' = P$","$P \\subseteq P'$ (every point of $P$ is also in $P'$)","$P' \\subseteq P$","$P'$ has fewer points than $P$"],correctIndex:1,difficulty:"medium",explanation:"A partition $P'$ is finer than $P$ if $P \\subseteq P'$, meaning $P'$ includes all points of $P$ and possibly more. A finer partition creates more (and smaller) subrectangles."},{id:5,type:"multiple-choice",question:"The set of step functions on a rectangle $Q$ forms:",options:["An empty set","A single function","A linear space","A bounded set"],correctIndex:2,difficulty:"medium",explanation:"Step functions form a linear space: if $f$ and $g$ are step functions, so is $c_1 f + c_2 g$. The common refinement of their partitions works for the linear combination."}],$t=[{id:1,type:"multiple-choice",question:"For a step function $f$ constant on open subrectangles with value $c_{ij}$ on subrectangle $Q_{ij}$, the double integral is:",options:["$\\sum_{i,j} c_{ij}$","$\\sum_{i,j} c_{ij}^2$","$\\max_{i,j} c_{ij}$","$\\sum_{i,j} c_{ij} (x_i - x_{i-1})(y_j - y_{j-1})$"],correctIndex:3,difficulty:"medium",explanation:"The double integral of a step function is $\\iint_Q f = \\sum_{i,j} c_{ij} (x_i - x_{i-1})(y_j - y_{j-1})$, summing each constant value times the area of its subrectangle."},{id:2,type:"multiple-choice",question:"If $f$ is a positive step function, the term $c_{ij} \\cdot (x_i - x_{i-1})(y_j - y_{j-1})$ represents:",options:["The volume of a rectangular box with base $Q_{ij}$ and height $c_{ij}$","The height of a box","The area of the subrectangle","The perimeter of the subrectangle"],correctIndex:0,difficulty:"easy",explanation:"For positive $f$, each term $c_{ij} (x_i - x_{i-1})(y_j - y_{j-1})$ is the volume of a box with base area $(x_i - x_{i-1})(y_j - y_{j-1})$ and height $c_{ij}$."},{id:3,type:"multiple-choice",question:"If $f(x, y) = k$ is constant on the interior of $Q = [a, b] \\times [c, d]$, then $\\iint_Q f = $:",options:["$k$","$k(b - a)(d - c)$","$k(d - c)$","$k(b - a)$"],correctIndex:1,difficulty:"easy",explanation:"For a constant function $f = k$, the double integral equals the constant times the area: $\\iint_Q k = k(b - a)(d - c)$."},{id:4,type:"multiple-choice",question:"The notation $\\Delta x_i$ and $\\Delta y_j$ in the double integral sum stands for:",options:["Derivatives","Variables of integration","Differences: $x_i - x_{i-1}$ and $y_j - y_{j-1}$","Error terms"],correctIndex:2,difficulty:"easy",explanation:"The notation $\\Delta x_i = x_i - x_{i-1}$ and $\\Delta y_j = y_j - y_{j-1}$ represents the widths of the subrectangles in each direction."},{id:5,type:"multiple-choice",question:"The value of the integral of a step function is independent of:",options:["The function values","The region $Q$","The dimension","The choice of partition (as long as $f$ is constant on its open subrectangles)"],correctIndex:3,difficulty:"medium",explanation:"As in 1D, refining the partition does not change the integral value. Any partition for which $f$ is constant on open subrectangles gives the same integral."}],lt=[{id:1,type:"multiple-choice",question:"For step functions on a rectangle, the iterated integration formula states:",options:["$\\iint_Q f = \\int_c^d \\left[ \\int_a^b f(x, y) \\, dx \\right] dy$","$\\iint_Q f = \\int_a^b f \\, dx \\cdot \\int_c^d f \\, dy$","$\\iint_Q f = \\int_a^b f + \\int_c^d f$","$\\iint_Q f = f(b, d) - f(a, c)$"],correctIndex:0,difficulty:"medium",explanation:"For step functions, the double integral can be computed by iterated integration: $\\iint_Q f = \\int_c^d [\\int_a^b f(x, y) \\, dx] \\, dy = \\int_a^b [\\int_c^d f(x, y) \\, dy] \\, dx$."},{id:2,type:"multiple-choice",question:"The linearity property of double integrals states that $\\iint_Q [c_1 s + c_2 t] = $:",options:["$c_1 c_2 \\iint_Q s \\cdot \\iint_Q t$","$c_1 \\iint_Q s + c_2 \\iint_Q t$","$(c_1 + c_2) \\iint_Q (s + t)$","$\\iint_Q s + \\iint_Q t$"],correctIndex:1,difficulty:"easy",explanation:"The linearity property: $\\iint_Q [c_1 s + c_2 t] = c_1 \\iint_Q s + c_2 \\iint_Q t$ for constants $c_1, c_2$ and step functions $s, t$."},{id:3,type:"multiple-choice",question:"The additive property states that if $Q$ is subdivided into $Q_1$ and $Q_2$, then:",options:["$\\iint_Q s = \\iint_{Q_1} s - \\iint_{Q_2} s$","$\\iint_Q s = \\iint_{Q_1} s \\cdot \\iint_{Q_2} s$","$\\iint_Q s = \\iint_{Q_1} s + \\iint_{Q_2} s$","$\\iint_Q s = \\max(\\iint_{Q_1} s, \\iint_{Q_2} s)$"],correctIndex:2,difficulty:"easy",explanation:"The additive property: if $Q = Q_1 \\cup Q_2$ (with $Q_1, Q_2$ sharing only boundary), then $\\iint_Q s = \\iint_{Q_1} s + \\iint_{Q_2} s$."},{id:4,type:"multiple-choice",question:"The comparison theorem states that if $s(x, y) \\leq t(x, y)$ everywhere on $Q$, then:",options:["$\\iint_Q s = \\iint_Q t$","$\\iint_Q s \\geq \\iint_Q t$","$\\iint_Q s \\cdot \\iint_Q t \\geq 0$","$\\iint_Q s \\leq \\iint_Q t$"],correctIndex:3,difficulty:"easy",explanation:"The comparison theorem: if $s \\leq t$ on $Q$, then $\\iint_Q s \\leq \\iint_Q t$. In particular, if $t \\geq 0$, then $\\iint_Q t \\geq 0$."},{id:5,type:"multiple-choice",question:"These properties for step functions are proved by:",options:["Direct computation from the definition or using the iterated formula and 1D theorems","Advanced measure theory","Fourier analysis","Complex integration"],correctIndex:0,difficulty:"medium",explanation:"The properties can be proved either directly from the sum definition or by using the iterated integration formula and the corresponding theorems for one-dimensional integrals."}],ct=[{id:1,type:"multiple-choice",question:"A bounded function $f$ on a rectangle $Q$ is integrable if:",options:["$f$ is continuous","There exists a unique number $I$ with $\\iint_Q s \\leq I \\leq \\iint_Q t$ for all step functions $s \\leq f \\leq t$","$f$ is differentiable","$f$ is a polynomial"],correctIndex:1,difficulty:"medium",explanation:"A bounded function is integrable if there is exactly one number $I$ satisfying $\\iint_Q s \\leq I \\leq \\iint_Q t$ for all step functions $s \\leq f \\leq t$. This $I$ is the double integral."},{id:2,type:"multiple-choice",question:"The lower integral $\\underline{I}(f)$ is defined as:",options:["The infimum of all double integrals of step functions above $f$","The average of the upper and lower bounds","The supremum of all double integrals of step functions below $f$","Zero"],correctIndex:2,difficulty:"medium",explanation:"The lower integral is $\\underline{I}(f) = \\sup\\{\\iint_Q s : s \\text{ is a step function with } s \\leq f\\}$, the least upper bound of integrals of step functions below $f$."},{id:3,type:"multiple-choice",question:"The upper integral $\\overline{I}(f)$ is defined as:",options:["The supremum of integrals of step functions below $f$","$+\\infty$","The maximum value of $f$","The infimum of integrals of step functions above $f$"],correctIndex:3,difficulty:"medium",explanation:"The upper integral is $\\overline{I}(f) = \\inf\\{\\iint_Q t : t \\text{ is a step function with } t \\geq f\\}$, the greatest lower bound of integrals of step functions above $f$."},{id:4,type:"multiple-choice",question:"A bounded function $f$ is integrable on $Q$ if and only if:",options:["$\\underline{I}(f) = \\overline{I}(f)$","$\\underline{I}(f) < \\overline{I}(f)$","$f$ is continuous","$\\overline{I}(f) = 0$"],correctIndex:0,difficulty:"medium",explanation:"A function is integrable iff its lower and upper integrals are equal: $\\underline{I}(f) = \\overline{I}(f)$. When equal, this common value is the double integral."},{id:5,type:"multiple-choice",question:"This definition of the double integral is analogous to:",options:["The Riemann sum definition in 1D","The Darboux definition in 1D using upper and lower sums","The Lebesgue integral","The Newton-Leibniz formula"],correctIndex:1,difficulty:"hard",explanation:"The definition using upper and lower integrals (via step functions) parallels the Darboux approach to the one-dimensional Riemann integral. Integrability means the upper and lower integrals coincide."}],dt=[{id:1,type:"multiple-choice",question:"Theorem 11.5 states that for an integrable function $f$ on $Q = [a, b] \\times [c, d]$:",options:["$\\iint_Q f = \\int_a^b f \\, dx + \\int_c^d f \\, dy$","$\\iint_Q f = f(b, d)$","$\\iint_Q f = \\int_c^d [\\int_a^b f(x, y) \\, dx] \\, dy$ (under appropriate conditions)","$\\iint_Q f = 0$"],correctIndex:2,difficulty:"medium",explanation:"Theorem 11.5: If $f$ is integrable on $Q$ and $\\int_a^b f(x, y) \\, dx$ exists for each $y$ and the resulting function of $y$ is integrable, then $\\iint_Q f = \\int_c^d [\\int_a^b f(x, y) \\, dx] \\, dy$."},{id:2,type:"multiple-choice",question:"The function $A(y) = \\int_a^b f(x, y) \\, dx$ represents:",options:["The area under the surface","The maximum of $f$","The gradient of $f$","The integral of $f$ with $y$ held fixed (a function of $y$)"],correctIndex:3,difficulty:"easy",explanation:"$A(y) = \\int_a^b f(x, y) \\, dx$ is the result of integrating $f$ with respect to $x$ while treating $y$ as a constant. This produces a function of $y$ alone."},{id:3,type:"multiple-choice",question:"Iterated integration means:",options:["First integrating with respect to one variable, then integrating the result with respect to the other","Integrating infinitely many times","Using numerical approximation","Integrating over a curve"],correctIndex:0,difficulty:"easy",explanation:"Iterated integration (repeated integration) means first integrating with respect to $x$ (holding $y$ fixed) to get a function of $y$, then integrating that function with respect to $y$."},{id:4,type:"multiple-choice",question:"The order of integration can be changed (Fubini's theorem condition):",options:["Never","When both iterated integrals exist (under appropriate hypotheses)","Always without any conditions","Only for constant functions"],correctIndex:1,difficulty:"medium",explanation:"Under appropriate conditions (when both iterated integrals exist), we can interchange the order: $\\int_c^d [\\int_a^b f \\, dx] \\, dy = \\int_a^b [\\int_c^d f \\, dy] \\, dx$."},{id:5,type:"multiple-choice",question:"Theorem 11.5 is the two-dimensional analog of:",options:["The mean value theorem","L'Hopital's rule","The second fundamental theorem of calculus","Taylor's theorem"],correctIndex:2,difficulty:"medium",explanation:"Theorem 11.5 is the 2D analog of the second fundamental theorem of calculus. Just as the 1D integral can be computed via antiderivatives, the 2D integral can be computed via iterated 1D integrals."}],ht=[{id:1,type:"multiple-choice",question:"The ordinate set of a nonnegative function $f$ over a rectangle $Q$ is:",options:["The set of points $(x, y)$ in $Q$","The level sets of $f$","The graph of $f$","The set of points $(x, y, z)$ with $(x, y) \\in Q$ and $0 \\leq z \\leq f(x, y)$"],correctIndex:3,difficulty:"medium",explanation:"The ordinate set is the 3D region between $Q$ (in the $xy$-plane) and the surface $z = f(x, y)$: all points $(x, y, z)$ with $(x, y) \\in Q$ and $0 \\leq z \\leq f(x, y)$."},{id:2,type:"multiple-choice",question:"For a nonnegative function $f$, the double integral $\\iint_Q f$ equals:",options:["The volume of the ordinate set","The surface area of the graph","The area of $Q$","The perimeter of $Q$"],correctIndex:0,difficulty:"easy",explanation:"When $f \\geq 0$, the double integral $\\iint_Q f(x, y) \\, dx \\, dy$ equals the volume of the region under the surface $z = f(x, y)$ and above $Q$."},{id:3,type:"multiple-choice",question:"The cross-sectional area $A(y) = \\int_a^b f(x, y) \\, dx$ represents:",options:["The total volume","The area of the slice of the ordinate set cut by a plane parallel to the $xz$-plane at height $y$","The boundary of the region","The centroid"],correctIndex:1,difficulty:"medium",explanation:"For fixed $y$, $A(y) = \\int_a^b f(x, y) \\, dx$ is the area of the vertical cross-section of the ordinate set cut by a plane perpendicular to the $y$-axis at that value of $y$."},{id:4,type:"multiple-choice",question:"The volume formula $v(S) = \\int_c^d A(y) \\, dy$ is reminiscent of:",options:["The disk method in single-variable calculus","The chain rule","Cavalieri's principle (volume by cross-sections)","Integration by parts"],correctIndex:2,difficulty:"medium",explanation:"This is Cavalieri's principle: volume equals the integral of cross-sectional areas. Slicing the solid and integrating the areas of the slices gives the total volume."},{id:5,type:"multiple-choice",question:"In the example $\\iint_Q (x\\sin y - ye^x) \\, dx \\, dy$ over $Q = [-1, 1] \\times [0, \\pi/2]$, integrating first with respect to $x$ gives $A(y) = $:",options:["$2\\sin y$","$x\\sin y$","$ye^x$","$-ey + y/e$"],correctIndex:3,difficulty:"hard",explanation:"$A(y) = \\int_{-1}^1 (x\\sin y - ye^x) \\, dx = [\\frac{x^2}{2}\\sin y - ye^x]_{-1}^1 = (\\frac{1}{2}\\sin y - ye) - (\\frac{1}{2}\\sin y - ye^{-1}) = -ey + y/e$."}],ft=[{id:1,type:"multiple-choice",question:"If $f$ is continuous on a rectangle $Q = [a, b] \\times [c, d]$, then according to Theorem 11.6, which statement is true?",options:["$f$ is integrable on $Q$ and the integral can be computed by iterated integration","$f$ is integrable only if it is bounded","$f$ may not be integrable even though it is continuous","The order of iterated integration cannot be changed"],correctIndex:0,difficulty:"easy",explanation:"Theorem 11.6 states that continuous functions on rectangles are integrable, and the value can be obtained by iterated integration in either order: $\\iint_Q f = \\int_c^d [\\int_a^b f(x,y)\\,dx]dy = \\int_a^b [\\int_c^d f(x,y)\\,dy]dx$."},{id:2,type:"multiple-choice",question:"In the proof of Theorem 11.6 (integrability of continuous functions), the small-span theorem is used to show that:",options:["$f$ is bounded on $Q$","There exists a partition such that the span of $f$ in every subrectangle is arbitrarily small","$f$ has finitely many discontinuities","The upper and lower integrals are both zero"],correctIndex:1,difficulty:"medium",explanation:"The small-span theorem (Theorem 9.10) guarantees that for any $\\epsilon > 0$, there is a partition of $Q$ into subrectangles such that the span (difference between max and min) of $f$ in every subrectangle is less than $\\epsilon$."},{id:3,type:"multiple-choice",question:"In proving integrability, step functions $s$ and $t$ are constructed satisfying $s \\leq f \\leq t$. The key step shows that:",options:["$\\iint_Q s = \\iint_Q t$","$s$ and $t$ are continuous functions","$\\iint_Q t - \\iint_Q s < \\epsilon \\cdot a(Q)$ for arbitrarily small $\\epsilon$","$s = t$ everywhere on $Q$"],correctIndex:2,difficulty:"medium",explanation:"The proof shows that $\\iint_Q t - \\iint_Q s < \\epsilon \\cdot a(Q)$ where $a(Q)$ is the area of the rectangle. Since $\\epsilon$ can be made arbitrarily small, this forces $\\underline{I}(f) = \\overline{I}(f)$, proving integrability."},{id:4,type:"multiple-choice",question:"If $A(y) = \\int_a^b f(x, y)\\,dx$ where $f$ is continuous on $Q = [a,b] \\times [c,d]$, what property does $A$ have?",options:["$A$ is discontinuous at finitely many points","$A$ may be undefined for some values of $y$","$A$ is constant","$A$ is continuous on $[c, d]$"],correctIndex:3,difficulty:"medium",explanation:"When $f$ is continuous on $Q$, the partial integral $A(y) = \\int_a^b f(x,y)\\,dx$ exists for all $y \\in [c,d]$ and defines a continuous function on $[c,d]$. This allows $\\int_c^d A(y)\\,dy$ to exist and equal $\\iint_Q f$."},{id:5,type:"multiple-choice",question:"The two-dimensional integrability theorem for continuous functions is analogous to which one-dimensional result?",options:["Continuous functions on closed intervals are Riemann integrable","The fundamental theorem of calculus","The mean value theorem","Every differentiable function is continuous"],correctIndex:0,difficulty:"easy",explanation:"Theorem 11.6 is the two-dimensional analogue of the fact that continuous functions on closed intervals $[a,b]$ are Riemann integrable. Both results rely on uniform continuity to approximate the function by step functions."}],ut=[{id:1,type:"multiple-choice",question:"A bounded subset $A$ of the plane has content zero if:",options:["The area of $A$ is exactly zero","For every $\\epsilon > 0$, there is a finite set of rectangles whose union contains $A$ with total area $\\leq \\epsilon$","$A$ contains no interior points","$A$ is contained in a single rectangle"],correctIndex:1,difficulty:"easy",explanation:"By definition, a bounded plane set has content zero if it can be enclosed in a union of finitely many rectangles whose total area is arbitrarily small."},{id:2,type:"multiple-choice",question:"Which of the following sets does NOT have content zero?",options:["A finite set of points","A line segment","An open disk","The graph of a continuous function on $[a, b]$"],correctIndex:2,difficulty:"easy",explanation:"An open disk has positive area, so it cannot be covered by rectangles with arbitrarily small total area. Finite point sets, line segments, and graphs of continuous functions all have content zero."},{id:3,type:"multiple-choice",question:"According to Theorem 11.7, if $f$ is bounded on rectangle $Q$ and its set of discontinuities has content zero, then:",options:["$f$ is continuous on $Q$","The integral of $f$ is zero","$f$ has no discontinuities","$f$ is integrable on $Q$"],correctIndex:3,difficulty:"medium",explanation:"Theorem 11.7 states that a bounded function on a rectangle is integrable if the set of its discontinuities has content zero. This extends integrability beyond just continuous functions."},{id:4,type:"multiple-choice",question:"In the proof of Theorem 11.7, subrectangles containing points of discontinuity contribute to the difference $\\iint_Q t - \\iint_Q s$ by at most:",options:["$2M\\delta$ where $M$ bounds $|f|$ and $\\delta$ is the total area of subrectangles containing discontinuities","$\\epsilon \\cdot a(Q)$","$M \\cdot a(Q)$","Zero"],correctIndex:0,difficulty:"hard",explanation:"On subrectangles containing discontinuities, the step functions $s$ and $t$ are set to $-M$ and $M$ respectively. The contribution is bounded by $2M$ times the total area $\\delta$ of these subrectangles, which can be made arbitrarily small."},{id:5,type:"multiple-choice",question:"Which property of sets of content zero is used in extending integrability beyond continuous functions?",options:["Every set of content zero is empty","Subsets of sets of content zero also have content zero","Sets of content zero are always bounded","The union of infinitely many sets of content zero has content zero"],correctIndex:1,difficulty:"medium",explanation:"A key property is that every subset of a set of content zero also has content zero. Additionally, the finite union of bounded sets of content zero has content zero."}],pt=[{id:1,type:"multiple-choice",question:"To define the double integral of $f$ over a bounded region $S$ (not necessarily rectangular), we define $\\tilde{f}$ on an enclosing rectangle $Q$ by:",options:["$\\tilde{f}(x,y) = f(x,y)$ for all $(x,y) \\in Q$","$\\tilde{f}(x,y) = 0$ for all $(x,y) \\in Q$","$\\tilde{f}(x,y) = f(x,y)$ if $(x,y) \\in S$ and $\\tilde{f}(x,y) = 0$ if $(x,y) \\in Q - S$","$\\tilde{f}(x,y) = 1$ if $(x,y) \\in S$ and $\\tilde{f}(x,y) = f(x,y)$ if $(x,y) \\in Q - S$"],correctIndex:2,difficulty:"easy",explanation:"The extended function $\\tilde{f}$ equals $f$ inside $S$ and is set to zero outside $S$ (but within the enclosing rectangle $Q$). If $\\tilde{f}$ is integrable on $Q$, we define $\\iint_S f = \\iint_Q \\tilde{f}$."},{id:2,type:"multiple-choice",question:"A region of Type I is described by:",options:["$\\{(x,y) \\mid c \\leq y \\leq d$ and $\\psi_1(y) \\leq x \\leq \\psi_2(y)\\}$","$\\{(x,y) \\mid x^2 + y^2 \\leq r^2\\}$","$\\{(x,y) \\mid a \\leq x \\leq b$ and $c \\leq y \\leq d\\}$","$\\{(x,y) \\mid a \\leq x \\leq b$ and $\\varphi_1(x) \\leq y \\leq \\varphi_2(x)\\}$"],correctIndex:3,difficulty:"easy",explanation:"A Type I region is bounded between two curves $y = \\varphi_1(x)$ and $y = \\varphi_2(x)$ over an interval $a \\leq x \\leq b$. Vertical lines intersect the region in segments."},{id:3,type:"multiple-choice",question:"For a Type I region $S$ with $\\varphi_1(x) \\leq y \\leq \\varphi_2(x)$ for $a \\leq x \\leq b$, the double integral is computed by:",options:["$\\int_a^b [\\int_{\\varphi_1(x)}^{\\varphi_2(x)} f(x,y)\\,dy]\\,dx$","$\\int_c^d [\\int_a^b f(x,y)\\,dx]\\,dy$","$\\int_a^b \\int_c^d f(x,y)\\,dy\\,dx$","$\\int_a^b [\\int_a^b f(x,y)\\,dx]\\,dy$"],correctIndex:0,difficulty:"medium",explanation:"For a Type I region, we integrate first with respect to $y$ from $\\varphi_1(x)$ to $\\varphi_2(x)$, then with respect to $x$ from $a$ to $b$. The inner limits depend on $x$."},{id:4,type:"multiple-choice",question:"According to Theorem 11.8, the graph of a continuous function $\\varphi$ on $[a,b]$ has:",options:["Positive area","Content zero","Infinite length","Non-measurable area"],correctIndex:1,difficulty:"medium",explanation:"Theorem 11.8 states that the graph of a continuous function on a closed interval has content zero. This is key to proving integrability on Type I regions."},{id:5,type:"multiple-choice",question:"A region of Type II differs from Type I in that:",options:["It is bounded by horizontal lines instead of vertical lines","It must be a rectangle","Horizontal lines intersect it in segments (x varies between functions of y)","It cannot be integrated over"],correctIndex:2,difficulty:"medium",explanation:"In a Type II region, $\\psi_1(y) \\leq x \\leq \\psi_2(y)$ for $c \\leq y \\leq d$. Horizontal lines intersect the region in segments, and we integrate first with respect to $x$."}],mt=[{id:1,type:"multiple-choice",question:"The area of a plane region $S$ can be computed using the double integral:",options:["$\\iint_S f(x,y)\\,dx\\,dy$","$\\iint_S (x + y)\\,dx\\,dy$","$\\iint_S xy\\,dx\\,dy$","$\\iint_S dx\\,dy$"],correctIndex:3,difficulty:"easy",explanation:"The area of a region $S$ is given by $a(S) = \\iint_S dx\\,dy$. This is equivalent to integrating the constant function $f(x,y) = 1$ over the region."},{id:2,type:"multiple-choice",question:"If $f(x,y) \\geq 0$ is continuous on a region $S$, the double integral $\\iint_S f(x,y)\\,dx\\,dy$ represents:",options:["The volume under the surface $z = f(x,y)$ over $S$","The area of $S$","The surface area of $z = f(x,y)$","The perimeter of $S$"],correctIndex:0,difficulty:"easy",explanation:"When $f \\geq 0$, the double integral represents the volume of the solid (ordinate set) lying between the region $S$ in the xy-plane and the surface $z = f(x,y)$ above it."},{id:3,type:"multiple-choice",question:"The volume of an ellipsoid $\\frac{x^2}{a^2} + \\frac{y^2}{b^2} + \\frac{z^2}{c^2} = 1$ is:",options:["$\\pi abc$","$\\frac{4}{3}\\pi abc$","$4\\pi abc$","$\\frac{4}{3}\\pi a^2bc$"],correctIndex:1,difficulty:"medium",explanation:"The volume of an ellipsoid with semi-axes $a$, $b$, $c$ is $V = \\frac{4}{3}\\pi abc$. When $a = b = c$, this reduces to the familiar formula $\\frac{4}{3}\\pi r^3$ for a sphere."},{id:4,type:"multiple-choice",question:"If $f \\leq g$ are both continuous on region $S$, the double integral $\\iint_S (g - f)\\,dx\\,dy$ represents:",options:["The area between the graphs of $f$ and $g$","The average value of $g - f$","The volume between the surfaces $z = f(x,y)$ and $z = g(x,y)$ over $S$","The surface area between $f$ and $g$"],correctIndex:2,difficulty:"medium",explanation:"The double integral $\\iint_S (g - f)\\,dx\\,dy$ gives the volume of the solid lying between the lower surface $z = f(x,y)$ and upper surface $z = g(x,y)$ over the region $S$."},{id:5,type:"multiple-choice",question:"For a Type I region $S$ bounded by $y = \\varphi_1(x)$ and $y = \\varphi_2(x)$ over $[a,b]$, the area formula reduces to:",options:["$\\int_a^b [\\varphi_2(x) + \\varphi_1(x)]\\,dx$","$\\int_a^b [\\varphi_2(x)]^2 - [\\varphi_1(x)]^2\\,dx$","$\\int_a^b \\varphi_1(x)\\varphi_2(x)\\,dx$","$\\int_a^b [\\varphi_2(x) - \\varphi_1(x)]\\,dx$"],correctIndex:3,difficulty:"easy",explanation:"With $f(x,y) = 1$, the inner integral gives $\\int_{\\varphi_1(x)}^{\\varphi_2(x)} 1\\,dy = \\varphi_2(x) - \\varphi_1(x)$, so the area is $\\int_a^b [\\varphi_2(x) - \\varphi_1(x)]\\,dx$."}],yt=[{id:1,type:"multiple-choice",question:"The total mass $m(S)$ of a thin plate with shape $S$ and density function $f(x,y)$ is:",options:["$\\iint_S f(x,y)\\,dx\\,dy$","$\\iint_S dx\\,dy$","$\\iint_S [f(x,y)]^2\\,dx\\,dy$","$\\iint_S \\sqrt{f(x,y)}\\,dx\\,dy$"],correctIndex:0,difficulty:"easy",explanation:"If $f(x,y)$ represents mass per unit area (density), then the total mass is obtained by integrating the density over the region: $m(S) = \\iint_S f(x,y)\\,dx\\,dy$."},{id:2,type:"multiple-choice",question:"The x-coordinate $\\bar{x}$ of the center of mass of a plate with density $f$ over region $S$ satisfies:",options:["$\\bar{x} = \\iint_S x\\,dx\\,dy$","$\\bar{x} \\cdot m(S) = \\iint_S x f(x,y)\\,dx\\,dy$","$\\bar{x} = \\iint_S f(x,y)\\,dx\\,dy$","$\\bar{x} \\cdot a(S) = \\iint_S x f(x,y)\\,dx\\,dy$"],correctIndex:1,difficulty:"medium",explanation:"The center of mass is a weighted average: $\\bar{x} \\cdot m(S) = \\iint_S x f(x,y)\\,dx\\,dy$. The integral $\\iint_S x f(x,y)\\,dx\\,dy$ is called the moment about the y-axis."},{id:3,type:"multiple-choice",question:"When the density is constant, the center of mass is called the:",options:["Moment of inertia","Radius of gyration","Centroid","Principal axis"],correctIndex:2,difficulty:"easy",explanation:"When density is constant, the center of mass depends only on the geometry of the region and is called the centroid. The constant density factor cancels in the formula."},{id:4,type:"multiple-choice",question:"The moment of inertia $I_y$ of a plate about the y-axis is given by:",options:["$\\iint_S y f(x,y)\\,dx\\,dy$","$\\iint_S y^2 f(x,y)\\,dx\\,dy$","$\\iint_S x f(x,y)\\,dx\\,dy$","$\\iint_S x^2 f(x,y)\\,dx\\,dy$"],correctIndex:3,difficulty:"medium",explanation:"The moment of inertia about the y-axis is $I_y = \\iint_S x^2 f(x,y)\\,dx\\,dy$, where $x^2$ is the square of the distance from each point to the y-axis."},{id:5,type:"multiple-choice",question:"The polar moment of inertia $I_0$ about the origin is related to $I_x$ and $I_y$ by:",options:["$I_0 = I_x + I_y$","$I_0 = I_x \\cdot I_y$","$I_0 = I_x - I_y$","$I_0 = \\sqrt{I_x^2 + I_y^2}$"],correctIndex:0,difficulty:"medium",explanation:"The polar moment of inertia is $I_0 = \\iint_S (x^2 + y^2)f\\,dx\\,dy = I_y + I_x$, since the squared distance from the origin is $x^2 + y^2$."}],xt=[{id:1,type:"multiple-choice",question:"Pappus's first theorem states that the volume of a solid of revolution equals:",options:["$\\pi r^2 h$","The area of the generating region times the distance traveled by its centroid","The surface area times the thickness","The integral of the cross-sectional area"],correctIndex:1,difficulty:"easy",explanation:"Pappus's first theorem: $v(S) = 2\\pi \\bar{y} \\cdot a(Q)$, where $\\bar{y}$ is the distance from the centroid to the axis. The centroid travels a circle of circumference $2\\pi\\bar{y}$."},{id:2,type:"multiple-choice",question:"A torus is generated by rotating a disk of radius $R$ about an axis at distance $b > R$ from its center. Its volume is:",options:["$\\frac{4}{3}\\pi R^3$","$\\pi R^2 b$","$2\\pi^2 R^2 b$","$4\\pi R^2 b$"],correctIndex:2,difficulty:"medium",explanation:"Using Pappus: $\\bar{y} = b$ (distance to axis) and $a(Q) = \\pi R^2$ (disk area). So $v = 2\\pi b \\cdot \\pi R^2 = 2\\pi^2 R^2 b$."},{id:3,type:"multiple-choice",question:"To find the centroid of a semicircular disk of radius $R$, we can use Pappus's theorem by noting that rotating it about the diameter generates a:",options:["Hemisphere","Cone","Cylinder","Sphere"],correctIndex:3,difficulty:"medium",explanation:"Rotating a semicircular disk about its diameter generates a full sphere. Using the known sphere volume $\\frac{4}{3}\\pi R^3$ and Pappus's theorem, we can solve for $\\bar{y} = \\frac{4R}{3\\pi}$."},{id:4,type:"multiple-choice",question:"Pappus's second theorem states that the center of mass of the union of two plates is:",options:["A convex combination of their individual centers of mass, weighted by mass","The midpoint of the line joining their centers of mass","The geometric center of the combined region","Always equidistant from both original centers of mass"],correctIndex:0,difficulty:"medium",explanation:"The combined center of mass is $C = \\frac{m(A)C_A + m(B)C_B}{m(A) + m(B)}$, a weighted average (convex combination) of the individual centers of mass."},{id:5,type:"numeric",question:"A semicircular disk of radius $R = 3$ has centroid at distance $\\bar{y} = \\frac{4R}{3\\pi}$ from its diameter. What is $\\bar{y}$ rounded to two decimal places?",correctAnswer:1.27,numericRange:{min:0,max:5,precision:2},difficulty:"medium",explanation:"With $R = 3$: $\\bar{y} = \\frac{4 \\cdot 3}{3\\pi} = \\frac{4}{\\pi} \\approx 1.27$."}],bt=[{id:1,type:"multiple-choice",question:"Green's theorem relates:",options:["A triple integral to a surface integral","A double integral over a region to a line integral around its boundary","A line integral to the gradient of a function","Two double integrals over different regions"],correctIndex:1,difficulty:"easy",explanation:"Green's theorem states $\\iint_R (\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y})\\,dx\\,dy = \\oint_C P\\,dx + Q\\,dy$, relating a double integral to a line integral."},{id:2,type:"multiple-choice",question:"In Green's theorem, the line integral is taken around the boundary curve $C$ in the:",options:["Clockwise direction","Direction of increasing arc length","Counterclockwise (positive) direction","Either direction with appropriate sign"],correctIndex:2,difficulty:"easy",explanation:"The standard form of Green's theorem requires the line integral to be taken in the counterclockwise (positive) direction, keeping the region on the left."},{id:3,type:"multiple-choice",question:"A Jordan curve is:",options:["Any closed curve","A piecewise linear curve","A curve that encloses zero area","A simple closed curve (no self-intersections)"],correctIndex:3,difficulty:"medium",explanation:"A Jordan curve (simple closed curve) is a closed curve with no self-intersectionsdistinct parameter values give distinct points, except at the endpoints."},{id:4,type:"multiple-choice",question:"Green's theorem for a Type I region is proved by showing that $-\\iint_R \\frac{\\partial P}{\\partial y}\\,dx\\,dy$ equals:",options:["$\\oint_C P\\,dx$","$\\oint_C Q\\,dy$","$\\oint_C P\\,dy$","$\\iint_R P\\,dx\\,dy$"],correctIndex:0,difficulty:"hard",explanation:"For Type I regions, one proves $-\\iint_R \\frac{\\partial P}{\\partial y}\\,dx\\,dy = \\oint_C P\\,dx$ by iterated integration and comparing with the line integral."},{id:5,type:"multiple-choice",question:"The expression $\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y}$ appearing in Green's theorem is related to:",options:["The divergence of the vector field $(P, Q)$","The curl (z-component) of the vector field $(P, Q, 0)$","The gradient of a potential function","The Laplacian of a scalar field"],correctIndex:1,difficulty:"medium",explanation:"For $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j}$, the expression $\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y}$ is the z-component of $\\nabla \\times \\mathbf{F}$ (the curl), making Green's theorem a 2D version of Stokes' theorem."}],gt=[{id:1,type:"multiple-choice",question:"Using Green's theorem, the area of a region $R$ enclosed by curve $C$ can be expressed as:",options:["$\\oint_C x\\,dx + y\\,dy$","$\\oint_C y\\,dx + x\\,dy$","$\\frac{1}{2}\\oint_C -y\\,dx + x\\,dy$","$\\oint_C x\\,dx - y\\,dy$"],correctIndex:2,difficulty:"medium",explanation:"With $P = -y/2$ and $Q = x/2$, we have $\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} = 1$. So $a(R) = \\iint_R 1\\,dA = \\frac{1}{2}\\oint_C -y\\,dx + x\\,dy$."},{id:2,type:"multiple-choice",question:"If $\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} = -2$ everywhere on region $R$ with area $A$, then $\\oint_C P\\,dx + Q\\,dy$ equals:",options:["$2A$","$-A/2$","$A$","$-2A$"],correctIndex:3,difficulty:"medium",explanation:"By Green's theorem: $\\oint_C P\\,dx + Q\\,dy = \\iint_R (-2)\\,dA = -2 \\cdot a(R) = -2A$."},{id:3,type:"multiple-choice",question:"The area formula using a parametric curve $x = X(t)$, $y = Y(t)$ for $a \\leq t \\leq b$ involves:",options:["$\\frac{1}{2}\\int_a^b [X(t)Y'(t) - Y(t)X'(t)]\\,dt$","$\\int_a^b X(t)Y(t)\\,dt$","$\\int_a^b [X'(t)]^2 + [Y'(t)]^2\\,dt$","$\\int_a^b X'(t)Y'(t)\\,dt$"],correctIndex:0,difficulty:"hard",explanation:"The area is $\\frac{1}{2}\\int_a^b [X(t)Y'(t) - Y(t)X'(t)]\\,dt = \\frac{1}{2}\\int_a^b \\begin{vmatrix} X(t) & Y(t) \\\\ X'(t) & Y'(t) \\end{vmatrix}dt$."},{id:4,type:"multiple-choice",question:"The device that measures area by tracing boundaries (based on the area-as-line-integral formula) is called a:",options:["Integrator","Planimeter","Goniometer","Theodolite"],correctIndex:1,difficulty:"easy",explanation:"A planimeter is a mechanical device that computes area by tracing the boundary of a region, using the principle that area equals a line integral around the boundary."},{id:5,type:"numeric",question:"The ellipse $4x^2 + y^2 = 4$ has semi-axes $a = 1$ and $b = 2$. Using Green's theorem, compute the work done by $\\mathbf{F} = (y + 3x)\\mathbf{i} + (2y - x)\\mathbf{j}$ around this ellipse.",correctAnswer:-12.57,numericRange:{min:-20,max:0,precision:2},difficulty:"hard",explanation:"$\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} = -1 - 1 = -2$. Area of ellipse = $\\pi ab = 2\\pi$. Work = $-2 \\cdot 2\\pi = -4\\pi \\approx -12.57$."}],vt=[{id:1,type:"multiple-choice",question:"An open connected set $S$ in the plane is simply connected if:",options:["It has finite area","It is bounded","For every Jordan curve in $S$, the interior of the curve is also in $S$","It contains no isolated points"],correctIndex:2,difficulty:"medium",explanation:'A set is simply connected if it has no "holes"every Jordan curve lying in the set has its interior also contained in the set.'},{id:2,type:"multiple-choice",question:"An annulus (region between two concentric circles) is:",options:["Simply connected","Convex","Not connected","Multiply connected (not simply connected)"],correctIndex:3,difficulty:"easy",explanation:"An annulus is multiply connected because a circle centered at the common center with intermediate radius lies in the annulus, but its interior (containing the inner disk) is not in the annulus."},{id:3,type:"multiple-choice",question:"On a simply connected domain, the condition $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ is:",options:["Both necessary and sufficient","Sufficient but not necessary","Necessary but not sufficient for $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j}$ to be a gradient","Neither necessary nor sufficient"],correctIndex:0,difficulty:"medium",explanation:"Theorem 11.11: On a simply connected domain, $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ is both necessary and sufficient for $\\mathbf{F}$ to be a gradient."},{id:4,type:"multiple-choice",question:"The vector field $\\mathbf{F} = \\frac{-y}{x^2+y^2}\\mathbf{i} + \\frac{x}{x^2+y^2}\\mathbf{j}$ satisfies $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ on $\\mathbb{R}^2 - \\{(0,0)\\}$, but is NOT a gradient there because:",options:["The field is not continuous",'The domain is not simply connected (it has a "hole" at the origin)',"The partial derivatives are not continuous","The field is unbounded"],correctIndex:1,difficulty:"hard",explanation:"The punctured plane $\\mathbb{R}^2 - \\{(0,0)\\}$ is multiply connected (has a hole at the origin). The equality of partials is necessary but not sufficient on such domains."},{id:5,type:"multiple-choice",question:"The proof that the condition $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ implies path independence on simply connected domains uses:",options:["The implicit function theorem","The inverse function theorem","Green's theorem applied to regions bounded by different paths","Integration by parts"],correctIndex:2,difficulty:"hard",explanation:"The proof uses Green's theorem: if two paths join the same points, they form a closed curve bounding a region in $S$. By Green's theorem, the integral around this curve is zero, proving path independence."}],_t=[{id:1,type:"multiple-choice",question:"For Green's theorem on a multiply connected region with outer boundary $C_1$ and inner boundary $C_2$, the formula includes:",options:["$\\oint_{C_1} + \\oint_{C_2}$ (both counterclockwise)","Only $\\oint_{C_1}$","$\\oint_{C_1} \\cdot \\oint_{C_2}$","$\\oint_{C_1} - \\oint_{C_2}$ (both taken counterclockwise when viewed separately)"],correctIndex:3,difficulty:"medium",explanation:"For a region with a hole, $\\iint_R (\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y})\\,dA = \\oint_{C_1} - \\oint_{C_2}$, where the minus sign accounts for the inner boundary being traversed clockwise relative to the region."},{id:2,type:"multiple-choice",question:"The proof of Green's theorem for multiply connected regions uses:",options:["Crosscuts that connect the boundary components, reducing to simply connected pieces","Limiting arguments from simply connected regions","Approximation by rectangles","The implicit function theorem"],correctIndex:0,difficulty:"medium",explanation:"By introducing crosscuts connecting the boundary components, the multiply connected region is transformed into simply connected pieces. Line integrals along crosscuts cancel (traversed twice in opposite directions)."},{id:3,type:"multiple-choice",question:"The Invariance Under Deformation theorem (11.13) states that if $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ in region $S$, and $C_2$ lies inside $C_1$ with the annular region in $S$, then:",options:["$\\oint_{C_1} = 0$","$\\oint_{C_1} = \\oint_{C_2}$ (same orientation)","$\\oint_{C_1} = -\\oint_{C_2}$","$\\oint_{C_1} + \\oint_{C_2} = \\iint_R$"],correctIndex:1,difficulty:"hard",explanation:"When the curl is zero, the line integral over the annular region vanishes, so $\\oint_{C_1} - \\oint_{C_2} = 0$, i.e., $\\oint_{C_1} = \\oint_{C_2}$ when both are traversed in the same direction."},{id:4,type:"multiple-choice",question:"The Invariance Under Deformation theorem implies that the value of a line integral depends only on:",options:["The exact shape of the curve","The length of the curve",'Which "holes" are enclosed by the curve',"The parametrization of the curve"],correctIndex:2,difficulty:"medium",explanation:"When $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$, a curve can be deformed without changing the line integral, as long as it doesn't cross any holes. The integral only depends on which holes are enclosed."},{id:5,type:"multiple-choice",question:"Continuous deformation of a curve in a region $S$ means that:",options:["The curve can be stretched to any length","The curve's endpoints must remain fixed","The curve must pass through every point of $S$","The curve can be smoothly transformed while staying within $S$"],correctIndex:3,difficulty:"easy",explanation:'Continuous deformation means smoothly transforming one curve into another while all intermediate curves remain within the region $S$. This is the intuitive meaning of "no holes" for simply connected regions.'}],Tt=[{id:1,type:"multiple-choice",question:"The winding number $W(\\alpha; P_0)$ of a closed curve $\\alpha$ with respect to a point $P_0$ not on the curve is:",options:["Always an integer (positive, negative, or zero)","Always a positive integer","Any real number","Always zero or one"],correctIndex:0,difficulty:"easy",explanation:"The winding number is always an integer. It counts how many times the curve winds around the point, with positive values for counterclockwise and negative for clockwise."},{id:2,type:"multiple-choice",question:"For a simple closed curve (Jordan curve) $C$ and a point $P_0$, the winding number is:",options:["Always 1","0 if $P_0$ is outside $C$, and $\\pm 1$ if $P_0$ is inside $C$","The area enclosed by $C$","0 if $P_0$ is inside $C$, and 1 if $P_0$ is outside $C$"],correctIndex:1,difficulty:"medium",explanation:"For a Jordan curve, the winding number is 0 for exterior points and $+1$ or $-1$ for interior points, depending on the orientation (counterclockwise or clockwise)."},{id:3,type:"multiple-choice",question:"A curve traces a circle counterclockwise if the winding number with respect to interior points is:",options:["$-1$","$0$","$+1$","Undefined"],correctIndex:2,difficulty:"easy",explanation:"A curve traced counterclockwise (positive direction) has winding number $+1$ for all points inside. Clockwise traversal gives $-1$."},{id:4,type:"multiple-choice",question:"The winding number formula involves the line integral $\\frac{1}{2\\pi}\\oint_C \\frac{-(y-y_0)\\,dx + (x-x_0)\\,dy}{(x-x_0)^2 + (y-y_0)^2}$. This integrand satisfies $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$ everywhere except:",options:["On the curve $C$","At the origin","On the x-axis","At the point $P_0 = (x_0, y_0)$"],correctIndex:3,difficulty:"hard",explanation:"The integrand has a singularity at $P_0 = (x_0, y_0)$ where the denominator vanishes. Away from $P_0$, the equality of partials holds, explaining why deformations not crossing $P_0$ preserve the winding number."},{id:5,type:"numeric",question:"For a circle of radius $a$ centered at $(x_0, y_0)$ traced once counterclockwise, what is the winding number with respect to the center?",correctAnswer:1,numericRange:{min:-5,max:5,precision:0},difficulty:"easy",explanation:"Using $\\alpha(t) = (a\\cos t + x_0, a\\sin t + y_0)$ for $0 \\leq t \\leq 2\\pi$, the winding number integral simplifies to $\\frac{1}{2\\pi}\\int_0^{2\\pi} 1\\,dt = 1$."}],At=[{id:1,type:"multiple-choice",question:"The change of variables formula for double integrals transforms $\\iint_S f(x,y)\\,dx\\,dy$ into:",options:["$\\iint_T f[X(u,v), Y(u,v)] |J(u,v)|\\,du\\,dv$","$\\iint_T f[X(u,v), Y(u,v)]\\,du\\,dv$","$\\iint_T f[X(u,v), Y(u,v)] J(u,v)\\,du\\,dv$","$\\iint_T f(u,v)\\,du\\,dv$"],correctIndex:0,difficulty:"easy",explanation:"The transformation formula is $\\iint_S f(x,y)\\,dx\\,dy = \\iint_T f[X(u,v), Y(u,v)] |J(u,v)|\\,du\\,dv$, where $|J|$ is the absolute value of the Jacobian determinant."},{id:2,type:"multiple-choice",question:"The Jacobian determinant $J(u,v)$ for the mapping $x = X(u,v)$, $y = Y(u,v)$ is:",options:["$\\frac{\\partial X}{\\partial u} + \\frac{\\partial Y}{\\partial v}$","$\\frac{\\partial X}{\\partial u}\\frac{\\partial Y}{\\partial v} - \\frac{\\partial X}{\\partial v}\\frac{\\partial Y}{\\partial u}$","$\\frac{\\partial X}{\\partial u} \\cdot \\frac{\\partial Y}{\\partial v}$","$\\frac{\\partial X}{\\partial u}\\frac{\\partial Y}{\\partial u} + \\frac{\\partial X}{\\partial v}\\frac{\\partial Y}{\\partial v}$"],correctIndex:1,difficulty:"medium",explanation:"The Jacobian is the determinant $J = \\begin{vmatrix} \\frac{\\partial X}{\\partial u} & \\frac{\\partial Y}{\\partial u} \\\\ \\frac{\\partial X}{\\partial v} & \\frac{\\partial Y}{\\partial v} \\end{vmatrix} = \\frac{\\partial X}{\\partial u}\\frac{\\partial Y}{\\partial v} - \\frac{\\partial X}{\\partial v}\\frac{\\partial Y}{\\partial u}$."},{id:3,type:"multiple-choice",question:"The geometric interpretation of $|J(u,v)|$ is:",options:["The angle between coordinate curves","The length magnification factor","The area magnification factor","The volume of the image region"],correctIndex:2,difficulty:"medium",explanation:"The absolute value of the Jacobian $|J|$ represents the local magnification factor for areas. A small rectangle in the uv-plane with area $\\Delta u \\cdot \\Delta v$ maps to a parallelogram with area approximately $|J| \\Delta u \\cdot \\Delta v$."},{id:4,type:"multiple-choice",question:"The vectors $\\mathbf{V}_1 = \\frac{\\partial \\mathbf{r}}{\\partial u}$ and $\\mathbf{V}_2 = \\frac{\\partial \\mathbf{r}}{\\partial v}$ are:",options:["Normal to the coordinate curves","Always of unit length","Always perpendicular to each other","Tangent to the u-curves and v-curves, respectively"],correctIndex:3,difficulty:"medium",explanation:"$\\mathbf{V}_1 = \\frac{\\partial \\mathbf{r}}{\\partial u}$ is tangent to u-curves (where v is constant), and $\\mathbf{V}_2 = \\frac{\\partial \\mathbf{r}}{\\partial v}$ is tangent to v-curves. Their cross product relates to $J$."},{id:5,type:"multiple-choice",question:"If $J(u,v) = 1$ for all $(u,v)$ in the parameter domain, then the mapping:",options:["Preserves areas","Is not invertible","Preserves angles","Is a rotation"],correctIndex:0,difficulty:"easy",explanation:"When $|J| = 1$, there is no magnification or reduction of areasthe mapping is area-preserving. This doesn't necessarily mean it preserves shapes or angles."}],qt=[{id:1,type:"multiple-choice",question:"The polar coordinate transformation is $x = r\\cos\\theta$, $y = r\\sin\\theta$. The Jacobian determinant is:",options:["$1$","$r$","$r^2$","$\\cos\\theta \\sin\\theta$"],correctIndex:1,difficulty:"easy",explanation:"$J = \\begin{vmatrix} \\cos\\theta & \\sin\\theta \\\\ -r\\sin\\theta & r\\cos\\theta \\end{vmatrix} = r\\cos^2\\theta + r\\sin^2\\theta = r$."},{id:2,type:"multiple-choice",question:"The transformation formula in polar coordinates is:",options:["$\\iint_S f(x,y)\\,dx\\,dy = \\iint_T f(r\\cos\\theta, r\\sin\\theta)\\,dr\\,d\\theta$","$\\iint_S f(x,y)\\,dx\\,dy = \\iint_T f(r\\cos\\theta, r\\sin\\theta)\\,r^2\\,dr\\,d\\theta$","$\\iint_S f(x,y)\\,dx\\,dy = \\iint_T f(r\\cos\\theta, r\\sin\\theta)\\,r\\,dr\\,d\\theta$","$\\iint_S f(x,y)\\,dx\\,dy = \\iint_T f(r, \\theta)\\,dr\\,d\\theta$"],correctIndex:2,difficulty:"easy",explanation:"The area element in polar coordinates is $dx\\,dy = r\\,dr\\,d\\theta$, giving $\\iint_S f(x,y)\\,dx\\,dy = \\iint_T f(r\\cos\\theta, r\\sin\\theta)\\,r\\,dr\\,d\\theta$."},{id:3,type:"multiple-choice",question:"In polar coordinates, the r-curves (constant $\\theta$) are:",options:["Circles centered at the origin","Ellipses","Spirals","Straight lines through the origin"],correctIndex:3,difficulty:"easy",explanation:"When $\\theta$ is constant, varying $r$ traces a ray from the origin at angle $\\theta$ to the positive x-axis."},{id:4,type:"multiple-choice",question:"To compute $\\iint_S \\sqrt{a^2 - x^2 - y^2}\\,dx\\,dy$ over the first quadrant of the disk $x^2 + y^2 \\leq a^2$, polar coordinates transform this to:",options:["$\\int_0^{\\pi/2}\\int_0^a \\sqrt{a^2 - r^2}\\,r\\,dr\\,d\\theta$","$\\int_0^{2\\pi}\\int_0^a \\sqrt{a^2 - r^2}\\,r\\,dr\\,d\\theta$","$\\int_0^{\\pi/2}\\int_0^a \\sqrt{a^2 - r^2}\\,dr\\,d\\theta$","$\\int_0^a\\int_0^{\\pi/2} \\sqrt{a^2 - r^2}\\,dr\\,d\\theta$"],correctIndex:0,difficulty:"medium",explanation:"First quadrant means $0 \\leq \\theta \\leq \\pi/2$. The disk $x^2 + y^2 \\leq a^2$ becomes $0 \\leq r \\leq a$. Include the factor $r$ from the Jacobian."},{id:5,type:"numeric",question:"The volume of one octant of a sphere of radius $a = 6$ is $\\frac{\\pi a^3}{6}$. What is this volume?",correctAnswer:113.1,numericRange:{min:100,max:130,precision:1},difficulty:"medium",explanation:"Volume = $\\frac{\\pi \\cdot 6^3}{6} = \\frac{216\\pi}{6} = 36\\pi \\approx 113.1$."}],It=[{id:1,type:"multiple-choice",question:"For a linear transformation $x = Au + Bv$, $y = Cu + Dv$, the Jacobian determinant is:",options:["$A + B + C + D$","$AD - BC$","$AC - BD$","$AB + CD$"],correctIndex:1,difficulty:"easy",explanation:"The Jacobian is $J = \\begin{vmatrix} A & C \\\\ B & D \\end{vmatrix} = AD - BC$, the same as the determinant of the transformation matrix."},{id:2,type:"multiple-choice",question:"A linear transformation has an inverse if and only if:",options:["$A = D$ and $B = C$","$A + D = 0$","$AD - BC \\neq 0$","$AB = CD$"],correctIndex:2,difficulty:"easy",explanation:"The linear system can be solved for $u$ and $v$ if and only if the determinant $AD - BC \\neq 0$, which is the condition for the matrix to be invertible."},{id:3,type:"multiple-choice",question:"Linear transformations map parallel lines to:",options:["Circles","Parabolas","Perpendicular lines","Parallel lines"],correctIndex:3,difficulty:"easy",explanation:"Linear transformations preserve parallelismparallel lines map to parallel lines. Consequently, rectangles map to parallelograms."},{id:4,type:"multiple-choice",question:"For the change of variables $u = y - x$, $v = y + x$, the Jacobian $\\frac{\\partial(x,y)}{\\partial(u,v)}$ is:",options:["$-1/2$","$-1$","$1/2$","$1$"],correctIndex:0,difficulty:"hard",explanation:"Solving: $x = (v-u)/2$, $y = (v+u)/2$. Then $J = \\begin{vmatrix} -1/2 & 1/2 \\\\ 1/2 & 1/2 \\end{vmatrix} = -1/4 - 1/4 = -1/2$."},{id:5,type:"multiple-choice",question:"When is a linear transformation useful for computing double integrals?",options:["When the region is circular","When the integrand or region involves linear combinations like $y - x$ and $y + x$","When the function is discontinuous","When the Jacobian equals 1"],correctIndex:1,difficulty:"medium",explanation:"Linear transformations are useful when the integrand contains expressions like $y - x$ and $y + x$, or when the region is bounded by non-axis-parallel lines."}],wt=[{id:1,type:"multiple-choice",question:"An n-fold integral over an n-dimensional region $S$ is denoted:",options:["$\\int_S f$","$\\sum_{i=1}^n \\int f_i$","$\\int \\cdots \\int_S f(x_1, \\ldots, x_n)\\,dx_1 \\cdots dx_n$","$\\prod_{i=1}^n \\int f\\,dx_i$"],correctIndex:2,difficulty:"easy",explanation:"The n-fold integral is written with n integral signs: $\\int \\cdots \\int_S f(x_1, \\ldots, x_n)\\,dx_1 \\cdots dx_n$."},{id:2,type:"multiple-choice",question:"For a solid $S$ described by $(x,y) \\in Q$ and $\\varphi_1(x,y) \\leq z \\leq \\varphi_2(x,y)$, the triple integral is computed by:",options:["$\\iiint_S f = \\int_{\\varphi_1}^{\\varphi_2} \\iint_Q f\\,dx\\,dy\\,dz$","$\\iiint_S f = \\iint_Q f \\cdot \\int dz$","$\\iiint_S f = \\int_a^b \\int_c^d \\int_e^f f\\,dx\\,dy\\,dz$","$\\iiint_S f = \\iint_Q [\\int_{\\varphi_1(x,y)}^{\\varphi_2(x,y)} f(x,y,z)\\,dz]\\,dx\\,dy$"],correctIndex:3,difficulty:"medium",explanation:"We first integrate with respect to $z$ from $\\varphi_1(x,y)$ to $\\varphi_2(x,y)$, then integrate the result over the projection $Q$ in the xy-plane."},{id:3,type:"multiple-choice",question:"The volume of an n-dimensional sphere of radius $a$ involves which special function?",options:["The gamma function $\\Gamma$","The Bessel function","The error function","The zeta function"],correctIndex:0,difficulty:"medium",explanation:"The volume is $V_n(a) = \\frac{\\pi^{n/2}}{\\Gamma(n/2 + 1)}a^n$. The gamma function generalizes the factorial to non-integer arguments."},{id:4,type:"multiple-choice",question:"For $n = 2$, the formula $V_n(a) = \\frac{\\pi^{n/2}}{\\Gamma(n/2 + 1)}a^n$ gives:",options:["$2a$","$\\pi a^2$","$\\frac{4}{3}\\pi a^3$","$\\frac{\\pi^2 a^4}{2}$"],correctIndex:1,difficulty:"easy",explanation:"For $n = 2$: $V_2(a) = \\frac{\\pi^1}{\\Gamma(2)}a^2 = \\frac{\\pi}{1!}a^2 = \\pi a^2$, the area of a circle."},{id:5,type:"multiple-choice",question:"A function $f$ is integrable on an n-dimensional interval if it is:",options:["Bounded","Differentiable everywhere","Bounded and has discontinuities on a set of n-dimensional content zero","Continuous at least at one point"],correctIndex:2,difficulty:"medium",explanation:"The integrability condition extends to n dimensions: $f$ must be bounded, and its set of discontinuities must have n-dimensional content zero."}],kt=[{id:1,type:"multiple-choice",question:"Cylindrical coordinates $(r, \\theta, z)$ are related to Cartesian coordinates by:",options:["$x = r\\sin\\theta\\cos\\varphi$, $y = r\\sin\\theta\\sin\\varphi$, $z = r\\cos\\theta$","$x = r\\cos z$, $y = r\\sin z$, $z = \\theta$","$x = r$, $y = \\theta$, $z = z$","$x = r\\cos\\theta$, $y = r\\sin\\theta$, $z = z$"],correctIndex:3,difficulty:"easy",explanation:"Cylindrical coordinates use polar coordinates in the xy-plane ($x = r\\cos\\theta$, $y = r\\sin\\theta$) while leaving $z$ unchanged."},{id:2,type:"multiple-choice",question:"The Jacobian determinant for cylindrical coordinates is:",options:["$r$","$1$","$r^2$","$r^2\\sin\\theta$"],correctIndex:0,difficulty:"easy",explanation:"The Jacobian for cylindrical coordinates is $r$, the same as for polar coordinates. The volume element is $dV = r\\,dr\\,d\\theta\\,dz$."},{id:3,type:"multiple-choice",question:"In cylindrical coordinates, the surface $r = $ constant represents:",options:["A plane","A vertical cylinder centered on the z-axis","A sphere","A cone"],correctIndex:1,difficulty:"easy",explanation:"$r = c$ describes all points at distance $c$ from the z-axis, forming a vertical cylinder of radius $c$ centered on the z-axis."},{id:4,type:"multiple-choice",question:"The paraboloid $x^2 + y^2 = 2z$ in cylindrical coordinates becomes:",options:["$r = 2z$","$r = z^2$","$r^2 = 2z$","$r\\theta = 2z$"],correctIndex:2,difficulty:"medium",explanation:"Since $x^2 + y^2 = r^2$ in cylindrical coordinates, the paraboloid $x^2 + y^2 = 2z$ becomes $r^2 = 2z$ or $z = r^2/2$."},{id:5,type:"multiple-choice",question:"Cylindrical coordinates are particularly useful for regions with:",options:["Spherical symmetry","No particular symmetry","Planar symmetry","Cylindrical symmetry (about the z-axis)"],correctIndex:3,difficulty:"easy",explanation:"Cylindrical coordinates are ideal for regions bounded by cylinders, cones, or surfaces of revolution about the z-axis, where the symmetry simplifies the integration limits."}],Ft=[{id:1,type:"multiple-choice",question:"Spherical coordinates $(\\rho, \\theta, \\varphi)$ are related to Cartesian coordinates by:",options:["$x = \\rho\\cos\\theta\\sin\\varphi$, $y = \\rho\\sin\\theta\\sin\\varphi$, $z = \\rho\\cos\\varphi$","$x = \\rho\\cos\\theta$, $y = \\rho\\sin\\theta$, $z = \\rho$","$x = \\rho\\sin\\varphi$, $y = \\rho\\cos\\varphi$, $z = \\rho\\theta$","$x = \\rho$, $y = \\theta$, $z = \\varphi$"],correctIndex:0,difficulty:"medium",explanation:"In spherical coordinates: $x = \\rho\\cos\\theta\\sin\\varphi$, $y = \\rho\\sin\\theta\\sin\\varphi$, $z = \\rho\\cos\\varphi$, where $\\rho$ is the distance from origin, $\\theta$ is the azimuthal angle, and $\\varphi$ is the polar angle."},{id:2,type:"multiple-choice",question:"The Jacobian determinant for spherical coordinates is:",options:["$\\rho$","$\\rho^2\\sin\\varphi$","$\\rho^2$","$\\rho\\sin\\varphi$"],correctIndex:1,difficulty:"medium",explanation:"The Jacobian for spherical coordinates is $|J| = \\rho^2\\sin\\varphi$. The volume element is $dV = \\rho^2\\sin\\varphi\\,d\\rho\\,d\\theta\\,d\\varphi$."},{id:3,type:"multiple-choice",question:"In spherical coordinates, the surface $\\varphi = $ constant represents:",options:["A sphere","A half-plane through the z-axis","A circular cone with axis along the z-axis","A cylinder"],correctIndex:2,difficulty:"medium",explanation:"$\\varphi = c$ describes all points making angle $c$ with the positive z-axis, forming a cone with vertex at the origin and axis along the z-axis."},{id:4,type:"numeric",question:"The volume of a sphere of radius $a = 3$ using spherical coordinates is $\\frac{4\\pi a^3}{3}$. Calculate this volume.",correctAnswer:113.1,numericRange:{min:100,max:130,precision:1},difficulty:"easy",explanation:"Volume = $\\frac{4\\pi \\cdot 27}{3} = \\frac{108\\pi}{3} = 36\\pi \\approx 113.1$."},{id:5,type:"multiple-choice",question:"The factor $\\sin\\varphi$ in the Jacobian $\\rho^2\\sin\\varphi$ accounts for:",options:["The radial scaling","The coordinate singularity at $\\theta = 0$","The curvature of the sphere","The varying circumference of latitude circles as $\\varphi$ changes"],correctIndex:3,difficulty:"hard",explanation:"The factor $\\sin\\varphi$ reflects that circles of constant $\\varphi$ have circumference $2\\pi\\rho\\sin\\varphi$, which varies from 0 at the poles to maximum at the equator."}],Pt=[{id:1,type:"multiple-choice",question:"A parametric surface is described by:",options:["Three equations $x = X(u, v)$, $y = Y(u, v)$, $z = Z(u, v)$ where $(u, v)$ varies over a region","One equation $F(x, y, z) = 0$","One equation $z = f(x, y)$","Two equations relating $x$, $y$, and $z$"],correctIndex:0,difficulty:"easy",explanation:"A parametric surface uses two parameters $(u, v)$ to generate points in 3-space via three coordinate functions: $x = X(u, v)$, $y = Y(u, v)$, $z = Z(u, v)$."},{id:2,type:"multiple-choice",question:"The vector equation of a parametric surface is:",options:["$\\mathbf{r}(t) = X(t)\\mathbf{i} + Y(t)\\mathbf{j} + Z(t)\\mathbf{k}$","$\\mathbf{r}(u, v) = X(u, v)\\mathbf{i} + Y(u, v)\\mathbf{j} + Z(u, v)\\mathbf{k}$","$\\mathbf{r} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k}$","$\\mathbf{r}(u, v) = u\\mathbf{i} + v\\mathbf{j}$"],correctIndex:1,difficulty:"easy",explanation:"The vector equation $\\mathbf{r}(u, v) = X(u, v)\\mathbf{i} + Y(u, v)\\mathbf{j} + Z(u, v)\\mathbf{k}$ compactly represents the surface as the image of the parameter domain."},{id:3,type:"multiple-choice",question:"A simple parametric surface is one where:",options:["The parameter domain is a rectangle","The surface has no boundary","The mapping $\\mathbf{r}$ is one-to-one","The parametric equations are linear"],correctIndex:2,difficulty:"medium",explanation:"A simple parametric surface has a one-to-one mapping $\\mathbf{r}$ from the parameter domain to the surfacedistinct parameter values give distinct surface points."},{id:4,type:"multiple-choice",question:"For a sphere of radius $a$ parametrized by $x = a\\cos u\\cos v$, $y = a\\sin u\\cos v$, $z = a\\sin v$, the parameter $u$ represents:",options:["The polar angle from the z-axis","The distance from the origin","The elevation above the xy-plane","The azimuthal angle (related to longitude)"],correctIndex:3,difficulty:"medium",explanation:"In this parametrization, $u$ is the azimuthal angle (like longitude) and $v$ is related to latitude. Varying $u$ from $0$ to $2\\pi$ traces circles of constant $v$."},{id:5,type:"multiple-choice",question:"The advantage of parametric representation over explicit ($z = f(x, y)$) representation is:",options:["Parametric representation can describe surfaces that are not graphs (like spheres)","Parametric surfaces are always simpler","Explicit representation requires more equations","Parametric surfaces are always smooth"],correctIndex:0,difficulty:"medium",explanation:"Parametric representation is more flexibleit can describe closed surfaces like spheres that cannot be written as single-valued functions $z = f(x, y)$."}],St=[{id:1,type:"multiple-choice",question:"The fundamental vector product of a parametric surface $\\mathbf{r}(u, v)$ is:",options:["$\\frac{\\partial \\mathbf{r}}{\\partial u} + \\frac{\\partial \\mathbf{r}}{\\partial v}$","$\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}$","$\\frac{\\partial \\mathbf{r}}{\\partial u} \\cdot \\frac{\\partial \\mathbf{r}}{\\partial v}$","$\\frac{\\partial^2 \\mathbf{r}}{\\partial u \\partial v}$"],correctIndex:1,difficulty:"easy",explanation:"The fundamental vector product is the cross product $\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}$, which is normal to the surface at each point."},{id:2,type:"multiple-choice",question:"A point on a parametric surface is called a regular point if:",options:["The surface passes through the origin at that point","Both partial derivatives equal zero","The fundamental vector product is nonzero there","The parametrization is linear near that point"],correctIndex:2,difficulty:"medium",explanation:"A regular point is one where the fundamental vector product $\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v} \\neq \\mathbf{0}$. This means the surface has a well-defined tangent plane there."},{id:3,type:"multiple-choice",question:"The fundamental vector product serves as:",options:["A tangent vector to the surface","The curvature of the surface","The velocity of a curve on the surface","A normal vector to the surface"],correctIndex:3,difficulty:"easy",explanation:"Since $\\frac{\\partial \\mathbf{r}}{\\partial u}$ and $\\frac{\\partial \\mathbf{r}}{\\partial v}$ are tangent to the surface, their cross product is perpendicular to both, hence normal to the surface."},{id:4,type:"multiple-choice",question:"For the explicit surface $z = f(x, y)$ with $\\mathbf{r}(x, y) = x\\mathbf{i} + y\\mathbf{j} + f(x, y)\\mathbf{k}$, the fundamental vector product is:",options:["$-f_x\\mathbf{i} - f_y\\mathbf{j} + \\mathbf{k}$","$f_x\\mathbf{i} + f_y\\mathbf{j} + \\mathbf{k}$","$\\mathbf{i} + \\mathbf{j} + f_x f_y\\mathbf{k}$","$-\\mathbf{i} - \\mathbf{j} + \\mathbf{k}$"],correctIndex:0,difficulty:"hard",explanation:"$\\frac{\\partial \\mathbf{r}}{\\partial x} = \\mathbf{i} + f_x\\mathbf{k}$, $\\frac{\\partial \\mathbf{r}}{\\partial y} = \\mathbf{j} + f_y\\mathbf{k}$. Their cross product is $-f_x\\mathbf{i} - f_y\\mathbf{j} + \\mathbf{k}$."},{id:5,type:"multiple-choice",question:"The magnitude of the fundamental vector product represents:",options:["The angle between coordinate curves","The local area magnification factor","The curvature of the surface","The volume element"],correctIndex:1,difficulty:"medium",explanation:"The magnitude $\\|\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}\\|$ gives the area magnificationa small rectangle $\\Delta u \\times \\Delta v$ in the parameter domain maps to a region with area approximately this magnitude times $\\Delta u \\Delta v$."}],zt=[{id:1,type:"multiple-choice",question:"The surface area of a parametric surface $S = \\mathbf{r}(T)$ is given by:",options:["$\\iint_T du\\,dv$","$\\iint_T \\frac{\\partial \\mathbf{r}}{\\partial u} \\cdot \\frac{\\partial \\mathbf{r}}{\\partial v}\\,du\\,dv$","$\\iint_T \\|\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}\\|\\,du\\,dv$","$\\iint_T (\\frac{\\partial \\mathbf{r}}{\\partial u} + \\frac{\\partial \\mathbf{r}}{\\partial v})\\,du\\,dv$"],correctIndex:2,difficulty:"easy",explanation:"The surface area is $a(S) = \\iint_T \\|\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}\\|\\,du\\,dv$, integrating the magnitude of the fundamental vector product."},{id:2,type:"multiple-choice",question:"For a surface given explicitly as $z = f(x, y)$ over region $T$, the surface area formula is:",options:["$\\iint_T dx\\,dy$","$\\iint_T |f(x, y)|\\,dx\\,dy$","$\\iint_T (f_x + f_y)\\,dx\\,dy$","$\\iint_T \\sqrt{1 + f_x^2 + f_y^2}\\,dx\\,dy$"],correctIndex:3,difficulty:"medium",explanation:"For $z = f(x, y)$, the magnitude of the fundamental vector product is $\\sqrt{1 + f_x^2 + f_y^2}$, giving $a(S) = \\iint_T \\sqrt{1 + f_x^2 + f_y^2}\\,dx\\,dy$."},{id:3,type:"multiple-choice",question:"The Area Cosine Principle states that if region $S$ is projected onto region $T$ in a plane at angle $\\gamma$, then:",options:["$a(T) = a(S) \\cos\\gamma$","$a(T) = a(S) \\sin\\gamma$","$a(T) = a(S) \\tan\\gamma$","$a(T) = a(S)/\\cos\\gamma$"],correctIndex:0,difficulty:"medium",explanation:"The projection shrinks areas by a factor of $\\cos\\gamma$, where $\\gamma$ is the angle between the planes: $a(T) = a(S)\\cos\\gamma$."},{id:4,type:"numeric",question:"The surface area of a hemisphere of radius $a = 4$ is $2\\pi a^2$. Calculate this area.",correctAnswer:100.53,numericRange:{min:95,max:110,precision:2},difficulty:"easy",explanation:"Surface area = $2\\pi(4)^2 = 2\\pi \\cdot 16 = 32\\pi \\approx 100.53$."},{id:5,type:"multiple-choice",question:"Pappus's theorem for surface area states that a surface of revolution generated by rotating a curve of length $L$ about an axis has area:",options:["$\\pi L^2$","$2\\pi L \\bar{h}$ where $\\bar{h}$ is the distance from the centroid of the curve to the axis","$\\pi L \\bar{h}$","$4\\pi L \\bar{h}$"],correctIndex:1,difficulty:"medium",explanation:"The surface area equals the length of the curve times the circumference traced by its centroid: $A = L \\cdot 2\\pi\\bar{h} = 2\\pi L \\bar{h}$."}],Bt=[{id:1,type:"multiple-choice",question:"The surface integral of a scalar field $f$ over a parametric surface $S = \\mathbf{r}(T)$ is:",options:["$\\iint_T f[\\mathbf{r}(u, v)]\\,du\\,dv$","$\\iint_T f[\\mathbf{r}(u, v)] (\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v})\\,du\\,dv$","$\\iint_T f[\\mathbf{r}(u, v)] \\|\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}\\|\\,du\\,dv$","$\\iint_S f\\,dx\\,dy$"],correctIndex:2,difficulty:"easy",explanation:"The surface integral $\\iint_S f\\,dS = \\iint_T f[\\mathbf{r}(u, v)] \\|\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v}\\|\\,du\\,dv$, where $dS$ is the element of surface area."},{id:2,type:"multiple-choice",question:"When $f = 1$, the surface integral $\\iint_S dS$ equals:",options:["The volume under the surface","The perimeter of $S$","Zero","The surface area of $S$"],correctIndex:3,difficulty:"easy",explanation:"With $f = 1$, $\\iint_S dS = \\iint_S 1\\,dS = a(S)$, the surface area."},{id:3,type:"multiple-choice",question:"If $f(x, y, z)$ represents mass density on a surface $S$, then $\\iint_S f\\,dS$ gives:",options:["The total mass","The center of mass","The moment of inertia","The average density"],correctIndex:0,difficulty:"easy",explanation:"When $f$ is mass per unit area (surface density), integrating over the surface gives total mass: $m = \\iint_S f\\,dS$."},{id:4,type:"multiple-choice",question:"The z-coordinate of the center of mass of a surface $S$ with uniform density is:",options:["$\\bar{z} = \\iint_S z\\,dS$","$\\bar{z} = \\frac{\\iint_S z\\,dS}{\\iint_S dS}$","$\\bar{z} = \\iint_S z^2\\,dS$","$\\bar{z} = \\frac{1}{2}\\iint_S z\\,dS$"],correctIndex:1,difficulty:"medium",explanation:"With uniform density, the centroid coordinates are $\\bar{x} = \\frac{\\iint_S x\\,dS}{a(S)}$, $\\bar{y} = \\frac{\\iint_S y\\,dS}{a(S)}$, $\\bar{z} = \\frac{\\iint_S z\\,dS}{a(S)}$."},{id:5,type:"multiple-choice",question:"The rate of fluid flow through surface $S$ in the direction of normal $\\mathbf{n}$ is given by the integral:",options:["$\\iint_S \\mathbf{F}\\,dS$","$\\iint_S \\mathbf{F} \\times \\mathbf{n}\\,dS$","$\\iint_S \\mathbf{F} \\cdot \\mathbf{n}\\,dS$","$\\iint_S |\\mathbf{F}|\\,dS$"],correctIndex:2,difficulty:"medium",explanation:"The flux of $\\mathbf{F}$ through $S$ is $\\iint_S \\mathbf{F} \\cdot \\mathbf{n}\\,dS$, measuring how much of $\\mathbf{F}$ passes through the surface in the direction of the normal."}],Qt=[{id:1,type:"multiple-choice",question:"The flux integral of a vector field $\\mathbf{F}$ over surface $S$ is written as:",options:["$\\iint_S \\mathbf{F}\\,dS$","$\\iint_S \\nabla \\cdot \\mathbf{F}\\,dS$","$\\iint_S \\|\\mathbf{F}\\|\\,dS$","$\\iint_S \\mathbf{F} \\cdot d\\mathbf{S}$"],correctIndex:3,difficulty:"easy",explanation:"The flux integral is $\\iint_S \\mathbf{F} \\cdot d\\mathbf{S} = \\iint_S \\mathbf{F} \\cdot \\mathbf{n}\\,dS$, where $d\\mathbf{S} = \\mathbf{n}\\,dS$ combines the normal and area element."},{id:2,type:"multiple-choice",question:"In the parametric computation of a flux integral, we use:",options:["The fundamental vector product itself (not just its magnitude)","The magnitude of the fundamental vector product","The sum of partial derivatives","The determinant of the Jacobian matrix"],correctIndex:0,difficulty:"medium",explanation:"$\\iint_S \\mathbf{F} \\cdot d\\mathbf{S} = \\iint_T \\mathbf{F} \\cdot (\\frac{\\partial \\mathbf{r}}{\\partial u} \\times \\frac{\\partial \\mathbf{r}}{\\partial v})\\,du\\,dv$. The vector product preserves direction, not just magnitude."},{id:3,type:"multiple-choice",question:"Reversing the orientation of a surface (flipping the normal) changes the flux integral by:",options:["A factor of 2","A sign change","No change","Multiplying by the surface area"],correctIndex:1,difficulty:"easy",explanation:"$\\iint_{-S} \\mathbf{F} \\cdot d\\mathbf{S} = -\\iint_S \\mathbf{F} \\cdot d\\mathbf{S}$. Reversing orientation negates the normal, hence the sign change."},{id:4,type:"multiple-choice",question:"For a surface $z = f(x, y)$ over region $T$, the flux integral becomes:",options:["$\\iint_T (P + Q + R)\\,dx\\,dy$","$\\iint_T (Pf_x + Qf_y + R)\\,dx\\,dy$","$\\iint_T (-Pf_x - Qf_y + R)\\,dx\\,dy$","$\\iint_T \\sqrt{P^2 + Q^2 + R^2}\\,dx\\,dy$"],correctIndex:2,difficulty:"hard",explanation:"With $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j} + R\\mathbf{k}$ and fundamental vector product $-f_x\\mathbf{i} - f_y\\mathbf{j} + \\mathbf{k}$, the flux is $\\iint_T (-Pf_x - Qf_y + R)\\,dx\\,dy$."},{id:5,type:"multiple-choice",question:"If $\\mathbf{F}$ represents fluid velocity, the flux $\\iint_S \\mathbf{F} \\cdot d\\mathbf{S}$ measures:",options:["The total kinetic energy of the fluid","The total mass of fluid","The pressure on the surface","The rate of fluid volume crossing the surface per unit time"],correctIndex:3,difficulty:"medium",explanation:"Flux of a velocity field gives the volumetric flow rate through the surfacehow much volume of fluid crosses per unit time in the direction of the normal."}],Ct=[{id:1,type:"multiple-choice",question:"Stokes' theorem relates:",options:["A surface integral to a line integral around the boundary of the surface","A line integral to a double integral over a plane region","A triple integral to a surface integral","Two different line integrals"],correctIndex:0,difficulty:"easy",explanation:"Stokes' theorem: $\\oint_C \\mathbf{F} \\cdot d\\mathbf{r} = \\iint_S (\\nabla \\times \\mathbf{F}) \\cdot d\\mathbf{S}$, relating a line integral around boundary $C$ to a surface integral over $S$."},{id:2,type:"multiple-choice",question:"In Stokes' theorem, the orientation of the boundary curve $C$ and the normal to $S$ are related by:",options:["The left-hand rule","The right-hand rule","They must be perpendicular","They are independent"],correctIndex:1,difficulty:"medium",explanation:"The right-hand rule relates the orientations: if fingers curl in the direction of $C$, the thumb points in the direction of the surface normal."},{id:3,type:"multiple-choice",question:"The curl of $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j} + R\\mathbf{k}$ is:",options:["$(\\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} + \\frac{\\partial R}{\\partial z})$","$(\\frac{\\partial P}{\\partial y} - \\frac{\\partial Q}{\\partial x})\\mathbf{k}$","$(\\frac{\\partial R}{\\partial y} - \\frac{\\partial Q}{\\partial z})\\mathbf{i} + (\\frac{\\partial P}{\\partial z} - \\frac{\\partial R}{\\partial x})\\mathbf{j} + (\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y})\\mathbf{k}$","$P\\mathbf{i} \\times Q\\mathbf{j} \\times R\\mathbf{k}$"],correctIndex:2,difficulty:"medium",explanation:"The curl is $\\nabla \\times \\mathbf{F} = (\\frac{\\partial R}{\\partial y} - \\frac{\\partial Q}{\\partial z})\\mathbf{i} + (\\frac{\\partial P}{\\partial z} - \\frac{\\partial R}{\\partial x})\\mathbf{j} + (\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y})\\mathbf{k}$."},{id:4,type:"multiple-choice",question:"When $S$ is a region in the xy-plane and $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j}$, Stokes' theorem reduces to:",options:["The fundamental theorem of calculus","The divergence theorem","The chain rule","Green's theorem"],correctIndex:3,difficulty:"easy",explanation:"For a planar region with $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j}$, Stokes' theorem gives $\\oint_C P\\,dx + Q\\,dy = \\iint_S (\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y})\\,dA$, which is Green's theorem."},{id:5,type:"multiple-choice",question:"The curl of $\\mathbf{F} = y\\mathbf{i} + z\\mathbf{j} + x\\mathbf{k}$ is:",options:["$-\\mathbf{i} - \\mathbf{j} - \\mathbf{k}$","$\\mathbf{i} + \\mathbf{j} + \\mathbf{k}$","$\\mathbf{0}$","$x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k}$"],correctIndex:0,difficulty:"hard",explanation:"$\\nabla \\times \\mathbf{F} = (\\frac{\\partial x}{\\partial y} - \\frac{\\partial z}{\\partial z})\\mathbf{i} + (\\frac{\\partial y}{\\partial z} - \\frac{\\partial x}{\\partial x})\\mathbf{j} + (\\frac{\\partial z}{\\partial x} - \\frac{\\partial y}{\\partial y})\\mathbf{k} = (0-1)\\mathbf{i} + (0-1)\\mathbf{j} + (0-1)\\mathbf{k} = -\\mathbf{i} - \\mathbf{j} - \\mathbf{k}$."}],jt=[{id:1,type:"multiple-choice",question:"The divergence of $\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j} + R\\mathbf{k}$ is:",options:["$\\frac{\\partial P}{\\partial x} \\cdot \\frac{\\partial Q}{\\partial y} \\cdot \\frac{\\partial R}{\\partial z}$","$\\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} + \\frac{\\partial R}{\\partial z}$","$P + Q + R$","$\\frac{\\partial P}{\\partial y} + \\frac{\\partial Q}{\\partial z} + \\frac{\\partial R}{\\partial x}$"],correctIndex:1,difficulty:"easy",explanation:"The divergence is $\\nabla \\cdot \\mathbf{F} = \\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} + \\frac{\\partial R}{\\partial z}$, the sum of the partial derivatives."},{id:2,type:"multiple-choice",question:"The curl can be written symbolically as:",options:["$\\nabla \\cdot \\mathbf{F}$","$\\nabla^2 \\mathbf{F}$","$\\nabla \\times \\mathbf{F}$","$\\mathbf{F} \\cdot \\nabla$"],correctIndex:2,difficulty:"easy",explanation:'The curl is $\\nabla \\times \\mathbf{F}$, the "cross product" of the nabla operator with $\\mathbf{F}$.'},{id:3,type:"multiple-choice",question:"A vector field $\\mathbf{F}$ is irrotational if:",options:["$\\text{div } \\mathbf{F} = 0$","$\\mathbf{F}$ is constant","$\\mathbf{F} = \\mathbf{0}$","$\\text{curl } \\mathbf{F} = \\mathbf{0}$"],correctIndex:3,difficulty:"medium",explanation:"Irrotational means $\\nabla \\times \\mathbf{F} = \\mathbf{0}$ (zero curl). On simply connected domains, this is equivalent to $\\mathbf{F}$ being a gradient."},{id:4,type:"multiple-choice",question:"On an open convex set, $\\mathbf{F}$ is a gradient if and only if:",options:["$\\text{curl } \\mathbf{F} = \\mathbf{0}$","$\\text{div } \\mathbf{F} = 0$","$\\mathbf{F}$ is bounded","$\\mathbf{F}$ has continuous derivatives"],correctIndex:0,difficulty:"medium",explanation:"On convex (hence simply connected) sets, $\\mathbf{F}$ is a gradient iff $\\nabla \\times \\mathbf{F} = \\mathbf{0}$."},{id:5,type:"multiple-choice",question:"For $\\mathbf{F} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k}$, the divergence and curl are:",options:["$\\text{div } \\mathbf{F} = 0$, $\\text{curl } \\mathbf{F} = \\mathbf{i} + \\mathbf{j} + \\mathbf{k}$","$\\text{div } \\mathbf{F} = 3$, $\\text{curl } \\mathbf{F} = \\mathbf{0}$","$\\text{div } \\mathbf{F} = 1$, $\\text{curl } \\mathbf{F} = \\mathbf{0}$","$\\text{div } \\mathbf{F} = 3$, $\\text{curl } \\mathbf{F} = \\mathbf{i} + \\mathbf{j} + \\mathbf{k}$"],correctIndex:1,difficulty:"medium",explanation:"$\\text{div } \\mathbf{F} = 1 + 1 + 1 = 3$. For curl: all cross-partials vanish (e.g., $\\frac{\\partial z}{\\partial y} - \\frac{\\partial y}{\\partial z} = 0$), so $\\text{curl } \\mathbf{F} = \\mathbf{0}$."}],Xt=[{id:1,type:"multiple-choice",question:"The Laplacian of a scalar field $\\varphi$ is:",options:["$\\nabla \\varphi$","$\\nabla \\times \\nabla \\varphi$","$\\nabla^2 \\varphi = \\frac{\\partial^2 \\varphi}{\\partial x^2} + \\frac{\\partial^2 \\varphi}{\\partial y^2} + \\frac{\\partial^2 \\varphi}{\\partial z^2}$","$\\nabla \\cdot \\varphi$"],correctIndex:2,difficulty:"easy",explanation:"The Laplacian $\\nabla^2 \\varphi = \\text{div}(\\nabla \\varphi) = \\frac{\\partial^2 \\varphi}{\\partial x^2} + \\frac{\\partial^2 \\varphi}{\\partial y^2} + \\frac{\\partial^2 \\varphi}{\\partial z^2}$."},{id:2,type:"multiple-choice",question:"A function $\\varphi$ with $\\nabla^2 \\varphi = 0$ is called:",options:["Irrotational","Solenoidal","Conservative","Harmonic"],correctIndex:3,difficulty:"easy",explanation:"A harmonic function satisfies Laplace's equation $\\nabla^2 \\varphi = 0$. Such functions arise in potential theory, heat conduction, and electrostatics."},{id:3,type:"multiple-choice",question:"The identity $\\text{curl}(\\text{grad } \\varphi) = $ is:",options:["$\\mathbf{0}$ (the zero vector)","$\\text{grad}(\\text{div } \\varphi)$","$\\nabla^2 \\varphi$","$\\varphi$"],correctIndex:0,difficulty:"medium",explanation:"$\\nabla \\times (\\nabla \\varphi) = \\mathbf{0}$ always (assuming continuous second partials). The curl of a gradient is always zero."},{id:4,type:"multiple-choice",question:"The identity $\\text{div}(\\text{curl } \\mathbf{F}) = $ is:",options:["$\\nabla^2 \\mathbf{F}$","$0$ (scalar zero)","$\\text{curl}(\\text{div } \\mathbf{F})$","$\\mathbf{F}$"],correctIndex:1,difficulty:"medium",explanation:"$\\nabla \\cdot (\\nabla \\times \\mathbf{F}) = 0$ always. The divergence of a curl is always zero."},{id:5,type:"multiple-choice",question:"The identity $\\text{curl}(\\text{curl } \\mathbf{F})$ equals:",options:["$\\nabla^2 \\mathbf{F}$","$\\text{grad}(\\text{div } \\mathbf{F}) + \\nabla^2 \\mathbf{F}$","$\\text{grad}(\\text{div } \\mathbf{F}) - \\nabla^2 \\mathbf{F}$","$\\text{div}(\\text{grad } \\mathbf{F})$"],correctIndex:2,difficulty:"hard",explanation:"The vector identity: $\\nabla \\times (\\nabla \\times \\mathbf{F}) = \\nabla(\\nabla \\cdot \\mathbf{F}) - \\nabla^2 \\mathbf{F}$, where $\\nabla^2 \\mathbf{F}$ is the component-wise Laplacian."}],Yt=[{id:1,type:"multiple-choice",question:"A vector field $\\mathbf{F}$ with $\\text{div } \\mathbf{F} = 0$ is called:",options:["Irrotational","Conservative","Harmonic","Solenoidal"],correctIndex:3,difficulty:"easy",explanation:"A solenoidal (or divergence-free) field has $\\nabla \\cdot \\mathbf{F} = 0$. Examples include magnetic fields and incompressible fluid velocity fields."},{id:2,type:"multiple-choice",question:"For $\\mathbf{F}$ to be expressible as $\\text{curl } \\mathbf{G}$ for some $\\mathbf{G}$, a necessary condition is:",options:["$\\text{div } \\mathbf{F} = 0$","$\\text{curl } \\mathbf{F} = \\mathbf{0}$","$\\mathbf{F}$ is bounded","$\\mathbf{F}$ is continuous"],correctIndex:0,difficulty:"medium",explanation:"Since $\\text{div}(\\text{curl } \\mathbf{G}) = 0$ always, we need $\\text{div } \\mathbf{F} = 0$ for $\\mathbf{F}$ to be a curl."},{id:3,type:"multiple-choice",question:"On an open interval (rectangular box) in 3-space, $\\mathbf{F}$ is the curl of some $\\mathbf{G}$ if and only if:",options:["$\\text{curl } \\mathbf{F} = \\mathbf{0}$","$\\text{div } \\mathbf{F} = 0$","$\\mathbf{F}$ is a gradient","$\\mathbf{F}$ is harmonic"],correctIndex:1,difficulty:"medium",explanation:"On intervals (simply connected regions), $\\text{div } \\mathbf{F} = 0$ is both necessary and sufficient for $\\mathbf{F} = \\text{curl } \\mathbf{G}$."},{id:4,type:"multiple-choice",question:"If $\\text{curl } \\mathbf{G} = \\mathbf{F}$, then $\\text{curl}(\\mathbf{G} + \\nabla \\varphi)$ equals:",options:["$\\mathbf{F} + \\nabla \\varphi$","$\\nabla \\varphi$","$\\mathbf{F}$","$\\mathbf{0}$"],correctIndex:2,difficulty:"medium",explanation:"$\\text{curl}(\\mathbf{G} + \\nabla \\varphi) = \\text{curl } \\mathbf{G} + \\text{curl}(\\nabla \\varphi) = \\mathbf{F} + \\mathbf{0} = \\mathbf{F}$. Adding a gradient doesn't change the curl."},{id:5,type:"multiple-choice",question:"The field $\\mathbf{V} = \\frac{\\mathbf{r}}{r^3}$ (where $\\mathbf{r} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k}$) on the region between two spheres:",options:["Is a curl because $\\text{div } \\mathbf{V} = 0$","Is a gradient","Has nonzero divergence","Is solenoidal but NOT a curl on this region"],correctIndex:3,difficulty:"hard",explanation:`$\\mathbf{V}$ has $\\text{div } \\mathbf{V} = 0$ away from the origin, but it's not a curl on the spherical shell because the topology has a "hole." The flux through any sphere centered at the origin is $4\\pi \\neq 0$.`}],Dt=[{id:1,type:"multiple-choice",question:"Stokes' theorem can be extended to surfaces with holes by:",options:["Using Green's theorem for multiply connected regions","Ignoring the inner boundaries","Restricting to simply connected parameter domains","Requiring the surface to be closed"],correctIndex:0,difficulty:"medium",explanation:"For surfaces with holes, we extend Stokes' theorem using the same technique as Green's theorem for multiply connected regions, with line integrals over all boundary components."},{id:2,type:"multiple-choice",question:"A surface is orientable if:",options:["It is bounded","A continuous unit normal can be defined over the entire surface","It has no boundary","It is simply connected"],correctIndex:1,difficulty:"medium",explanation:'Orientability means we can consistently choose a normal direction over the entire surface without discontinuitiesthe surface has two distinct "sides."'},{id:3,type:"multiple-choice",question:"A Mobius band is:",options:["Orientable and simply connected","A closed surface","Non-orientable (has only one side)","A surface without boundary"],correctIndex:2,difficulty:"easy",explanation:"A Mobius band is the classic example of a non-orientable surfaceit has only one side, and you cannot consistently define a continuous normal over it."},{id:4,type:"multiple-choice",question:"Stokes' theorem cannot be extended to:",options:["Surfaces with holes","Multiply connected parameter domains","Surfaces given explicitly as $z = f(x, y)$","Non-orientable surfaces like the Mobius band"],correctIndex:3,difficulty:"medium",explanation:"Stokes' theorem requires orientability. On non-orientable surfaces, we cannot consistently define the normal, so the theorem fails."},{id:5,type:"multiple-choice",question:"For any closed orientable surface $S$ (no boundary):",options:["$\\iint_S (\\text{curl } \\mathbf{F}) \\cdot d\\mathbf{S} = 0$","$\\iint_S \\mathbf{F} \\cdot d\\mathbf{S} = 0$ for all $\\mathbf{F}$","$\\iint_S d\\mathbf{S} = 0$","$\\iint_S (\\text{div } \\mathbf{F}) d\\mathbf{S} = 0$"],correctIndex:0,difficulty:"hard",explanation:"A closed surface has no boundary, so by Stokes' theorem the line integral (over empty boundary) is zero: $\\iint_S (\\text{curl } \\mathbf{F}) \\cdot d\\mathbf{S} = \\oint_\\emptyset \\mathbf{F} \\cdot d\\mathbf{r} = 0$."}],Rt=[{id:1,type:"multiple-choice",question:"The Divergence Theorem (Gauss' Theorem) relates:",options:["A line integral to a surface integral","A triple integral over a solid to a surface integral over its boundary","A double integral to a line integral","Two surface integrals"],correctIndex:1,difficulty:"easy",explanation:"The Divergence Theorem: $\\iiint_V (\\text{div } \\mathbf{F})\\,dV = \\iint_S \\mathbf{F} \\cdot \\mathbf{n}\\,dS$, relating a volume integral to a surface integral over the boundary."},{id:2,type:"multiple-choice",question:"In the Divergence Theorem, $\\mathbf{n}$ is:",options:["Any normal to the surface","The tangent vector to the boundary","The unit outer (outward-pointing) normal","The gradient of the surface"],correctIndex:2,difficulty:"easy",explanation:"The surface integral uses the unit outward normal $\\mathbf{n}$, pointing away from the interior of the solid $V$."},{id:3,type:"multiple-choice",question:"For $\\mathbf{F} = x^2\\mathbf{i} + y^2\\mathbf{j} + z^2\\mathbf{k}$, the divergence is:",options:["$x^2 + y^2 + z^2$","$2(x + y + z)$","$6$","$2x + 2y + 2z$"],correctIndex:3,difficulty:"easy",explanation:"$\\text{div } \\mathbf{F} = \\frac{\\partial(x^2)}{\\partial x} + \\frac{\\partial(y^2)}{\\partial y} + \\frac{\\partial(z^2)}{\\partial z} = 2x + 2y + 2z$."},{id:4,type:"multiple-choice",question:"The Divergence Theorem is proved first for solids that are:",options:["Projectable onto all three coordinate planes (like xy-projectable)","Cubes only","Spheres only","Convex and bounded"],correctIndex:0,difficulty:"hard",explanation:"The proof works for xy-projectable (and similarly yz- and xz-projectable) solids. General solids are handled by decomposition."},{id:5,type:"numeric",question:"Using the Divergence Theorem, find $\\iiint_V (2x + 2y + 2z)\\,dV$ over the unit cube $[0,1]^3$.",correctAnswer:3,numericRange:{min:0,max:10,precision:0},difficulty:"medium",explanation:"$\\iiint_{[0,1]^3} (2x + 2y + 2z)\\,dV = 2\\int_0^1 x\\,dx + 2\\int_0^1 y\\,dy + 2\\int_0^1 z\\,dz = 2(\\frac{1}{2}) + 2(\\frac{1}{2}) + 2(\\frac{1}{2}) = 3$."}],Wt=[{id:1,type:"multiple-choice",question:"The coordinate-free definition of divergence is:",options:["$\\text{div } \\mathbf{F}(\\mathbf{a}) = \\lim_{t \\to 0} \\frac{1}{|S(t)|} \\oint_{C(t)} \\mathbf{F} \\cdot d\\mathbf{r}$","$\\text{div } \\mathbf{F}(\\mathbf{a}) = \\lim_{t \\to 0} \\frac{1}{|V(t)|} \\iint_{S(t)} \\mathbf{F} \\cdot \\mathbf{n}\\,dS$","$\\text{div } \\mathbf{F}(\\mathbf{a}) = \\nabla \\cdot \\mathbf{F}$","$\\text{div } \\mathbf{F}(\\mathbf{a}) = \\lim_{t \\to 0} \\iint_{S(t)} \\mathbf{F} \\cdot \\mathbf{n}\\,dS$"],correctIndex:1,difficulty:"hard",explanation:"The divergence is the limit of the flux per unit volume through a shrinking sphere: $\\text{div } \\mathbf{F}(\\mathbf{a}) = \\lim_{t \\to 0} \\frac{1}{|V(t)|} \\iint_{S(t)} \\mathbf{F} \\cdot \\mathbf{n}\\,dS$."},{id:2,type:"multiple-choice",question:"The physical interpretation of divergence for a velocity field is:",options:["The angular velocity","The kinetic energy density","The rate of expansion or compression per unit volume","The pressure"],correctIndex:2,difficulty:"medium",explanation:'Divergence measures the rate at which fluid expands (positive divergence) or compresses (negative divergence) at a pointthe local "source strength."'},{id:3,type:"multiple-choice",question:"The physical interpretation of $\\mathbf{n} \\cdot \\text{curl } \\mathbf{F}$ for a velocity field is:",options:["The rate of volume expansion","The acceleration","The pressure gradient","The circulation density (rotation rate) about axis $\\mathbf{n}$"],correctIndex:3,difficulty:"medium",explanation:"$\\mathbf{n} \\cdot \\text{curl } \\mathbf{F}$ is the circulation per unit area through a disk perpendicular to $\\mathbf{n}$, measuring the local rotation rate about that axis."},{id:4,type:"multiple-choice",question:"Green's first identity states:",options:["$\\iint_S f \\frac{\\partial g}{\\partial n}\\,dS = \\iiint_V (f\\nabla^2 g + \\nabla f \\cdot \\nabla g)\\,dV$","$\\iint_S f g\\,dS = \\iiint_V (f + g)\\,dV$","$\\iint_S \\nabla f \\cdot \\nabla g\\,dS = \\iiint_V f g\\,dV$","$\\iint_S f\\,dS = \\iiint_V \\nabla f\\,dV$"],correctIndex:0,difficulty:"hard",explanation:"Green's first identity: $\\iint_S f \\frac{\\partial g}{\\partial n}\\,dS = \\iiint_V (f\\nabla^2 g + \\nabla f \\cdot \\nabla g)\\,dV$, derived from the divergence theorem applied to $f \\nabla g$."},{id:5,type:"multiple-choice",question:"If $f$ is harmonic ($\\nabla^2 f = 0$) in a solid $V$ with boundary $S$, then:",options:["$\\iint_S f\\,dS = 0$","$\\iint_S \\frac{\\partial f}{\\partial n}\\,dS = 0$","$\\iiint_V f\\,dV = 0$","$\\iint_S f^2\\,dS = 0$"],correctIndex:1,difficulty:"hard",explanation:"By Green's first identity with $f = g$: if $\\nabla^2 f = 0$, then $\\iint_S \\frac{\\partial f}{\\partial n}\\,dS = \\iiint_V |\\nabla f|^2\\,dV$. Taking $f = 1$ and $g$ harmonic shows $\\iint_S \\frac{\\partial g}{\\partial n}\\,dS = 0$."}],Lt=[{id:1,type:"multiple-choice",question:"The mathematical theory of probability began with correspondence between which two mathematicians?",options:["Newton and Leibniz","Gauss and Euler","Pascal and Fermat","Laplace and Lagrange"],correctIndex:2,difficulty:"easy",explanation:"Probability theory originated in the 17th century correspondence between Blaise Pascal and Pierre de Fermat, prompted by gambling questions from the Chevalier de Mr."},{id:2,type:"multiple-choice",question:"The modern axiomatic foundation of probability theory was established by:",options:["Pascal in the 17th century","Laplace in the 18th century","Gauss in the 19th century","Kolmogorov in the 1930s"],correctIndex:3,difficulty:"medium",explanation:"Andrey Kolmogorov established the rigorous measure-theoretic foundation of probability in 1933, unifying discrete and continuous probability in a single framework."},{id:3,type:"multiple-choice",question:"The three fundamental ingredients of the mathematical theory of probability are:",options:["Sample space, Boolean algebra of events, and probability measure","Mean, variance, and standard deviation","Random variables, expectations, and distributions","Independence, conditional probability, and Bayes' theorem"],correctIndex:0,difficulty:"medium",explanation:"The axiomatic approach requires: a sample space $S$ of outcomes, a Boolean algebra $\\mathscr{B}$ of events (subsets of $S$), and a probability measure $P$ assigning probabilities to events."},{id:4,type:"multiple-choice",question:"A probability measure is a special type of:",options:["Random variable","Set function","Distribution function","Density function"],correctIndex:1,difficulty:"easy",explanation:"A probability measure is a set functionit assigns real numbers (probabilities) to sets (events). It satisfies additional axioms: non-negativity, normalization ($P(S) = 1$), and additivity."},{id:5,type:"multiple-choice",question:"The historical problem that sparked probability theory asked about betting on:",options:["The sum of two dice being seven","The probability of drawing an ace from a deck",'At least one "double six" in 24 throws of a pair of dice',"The outcome of coin flips"],correctIndex:2,difficulty:"medium",explanation:"The Chevalier de Mr asked Pascal whether it was profitable to bet even money on getting at least one double six in 24 throws of two dice."}],Et=[{id:1,type:"multiple-choice",question:"A set function $f$ is called finitely additive if for every pair of disjoint sets $A$ and $B$:",options:["$f(A \\cup B) = \\max(f(A), f(B))$","$f(A \\cap B) = f(A) \\cdot f(B)$","$f(A \\cup B) = f(A) \\cdot f(B)$","$f(A \\cup B) = f(A) + f(B)$"],correctIndex:3,difficulty:"easy",explanation:"Finite additivity means that for disjoint sets, the set function of the union equals the sum of the set functions of the individual sets: $f(A \\cup B) = f(A) + f(B)$."},{id:2,type:"multiple-choice",question:"If $f$ is a finitely additive set function and $\\varnothing$ is in the Boolean algebra, what is $f(\\varnothing)$?",options:["$0$","$-1$","$1$","Undefined"],correctIndex:0,difficulty:"easy",explanation:"Since $A = A \\cup \\varnothing$ with $A$ and $\\varnothing$ disjoint, we have $f(A) = f(A) + f(\\varnothing)$, which implies $f(\\varnothing) = 0$."},{id:3,type:"multiple-choice",question:"For any two sets $A$ and $B$ in a Boolean algebra (not necessarily disjoint), the inclusion-exclusion principle states:",options:["$f(A \\cup B) = f(A) + f(B)$","$f(A \\cup B) = f(A) + f(B) - f(A \\cap B)$","$f(A \\cup B) = f(A) + f(B) + f(A \\cap B)$","$f(A \\cup B) = f(A) \\cdot f(B) - f(A \\cap B)$"],correctIndex:1,difficulty:"medium",explanation:"The inclusion-exclusion principle accounts for the overlap: $f(A \\cup B) = f(A) + f(B) - f(A \\cap B)$. We subtract the intersection to avoid counting it twice."},{id:4,type:"multiple-choice",question:"A Boolean algebra $\\mathscr{B}$ of subsets of $S$ must be closed under which operations?",options:["Union only","Complementation only","Complementation and union","Intersection only"],correctIndex:2,difficulty:"medium",explanation:"A Boolean algebra is defined as a nonempty collection closed under complementation and union. Closure under intersection and set difference then follows from these properties."},{id:5,type:"multiple-choice",question:"If $f$ is finitely additive and $A \\subseteq B$, then:",options:["$f(B - A) = f(B) + f(A)$","$f(B - A) = f(B) / f(A)$","$f(B - A) = f(A) - f(B)$","$f(B - A) = f(B) - f(A)$"],correctIndex:3,difficulty:"medium",explanation:"Since $B = A \\cup (B - A)$ with $A$ and $B - A$ disjoint, we have $f(B) = f(A) + f(B - A)$, so $f(B - A) = f(B) - f(A)$."}],Vt=[{id:1,type:"multiple-choice",question:"A finitely additive set function $f$ is called a measure if it additionally satisfies:",options:["$f(A) \\geq 0$ for all $A$","$f(A) = 1$ for all $A$","$f(A) < 0$ for all $A$","$f(S) = 0$"],correctIndex:0,difficulty:"easy",explanation:"A measure is a finitely additive set function that is nonnegative: $f(A) \\geq 0$ for all sets $A$ in the Boolean algebra."},{id:2,type:"multiple-choice",question:"The counting measure $\\nu(A)$ on a finite set $S$ assigns to each subset $A$:",options:["The sum of elements in $A$","The number of elements in $A$","The product of elements in $A$","The maximum element in $A$"],correctIndex:1,difficulty:"easy",explanation:"The counting measure assigns to each subset $A$ its cardinality, i.e., the number of elements in $A$."},{id:3,type:"multiple-choice",question:"The Dirac measure (point mass) $\\delta_p(A)$ at a point $p$ is defined as:",options:["$\\delta_p(A) = |A|$","$\\delta_p(A) = p$ for all $A$","$\\delta_p(A) = 1$ if $p \\in A$, and $0$ otherwise","$\\delta_p(A) = 0$ if $p \\in A$, and $1$ otherwise"],correctIndex:2,difficulty:"medium",explanation:"The Dirac measure at $p$ assigns measure 1 to any set containing $p$ and measure 0 to any set not containing $p$."},{id:4,type:"multiple-choice",question:"If $f$ is a measure and $A \\subseteq B$, then:",options:["$f(A) \\geq f(B)$","$f(A) = f(B)$","No relationship can be determined","$f(A) \\leq f(B)$"],correctIndex:3,difficulty:"medium",explanation:"Monotonicity: since $f(B) = f(A) + f(B - A)$ and $f(B - A) \\geq 0$ (nonnegativity), we have $f(A) \\leq f(B)$."},{id:5,type:"multiple-choice",question:"A measure $f$ is called normalized if:",options:["$f(S) = 1$","$f(S) = 0$","$f(\\varnothing) = 1$","$f(A) \\leq 1$ for all $A$"],correctIndex:0,difficulty:"easy",explanation:"A normalized measure assigns the value 1 to the entire sample space $S$. This is the defining property of a probability measure."}],Nt=[{id:1,type:"multiple-choice",question:"A probability measure $P$ on a Boolean algebra $\\mathscr{B}$ must satisfy all of the following EXCEPT:",options:["$P$ is finitely additive","$P(A) = P(B)$ for all $A, B$","$P(S) = 1$","$P(A) \\geq 0$ for all $A$"],correctIndex:1,difficulty:"easy",explanation:"A probability measure must be finitely additive, nonnegative, and assign total probability 1 to the sample space. It does NOT require all sets to have equal probability."},{id:2,type:"multiple-choice",question:"For a finite sample space $S = \\{a_1, a_2, \\ldots, a_n\\}$ with equally likely outcomes, the probability of a subset $A$ with $k$ elements is:",options:["$k$","$n/k$","$k/n$","$1/k$"],correctIndex:2,difficulty:"easy",explanation:"With equally likely outcomes, each point has probability $1/n$. A subset $A$ with $k$ elements has probability $P(A) = k/n = |A|/|S|$."},{id:3,type:"multiple-choice",question:"The triple $(S, \\mathscr{B}, P)$ consisting of sample space, Boolean algebra, and probability measure is called:",options:["A random variable","A distribution function","An expectation","A probability space"],correctIndex:3,difficulty:"easy",explanation:"The complete description of a probabilistic model is the probability space $(S, \\mathscr{B}, P)$."},{id:4,type:"multiple-choice",question:"For an unbiased coin toss with sample space $S = \\{h, t\\}$, if $H = \\{h\\}$ and $T = \\{t\\}$, then:",options:["$P(H) = P(T) = 1/2$","$P(H) = 1$ and $P(T) = 0$","$P(H) = P(T) = 1$","$P(H) + P(T) = 1/2$"],correctIndex:0,difficulty:"easy",explanation:"For an unbiased coin, both outcomes are equally likely. Since $P(S) = P(H) + P(T) = 1$, we have $P(H) = P(T) = 1/2$."},{id:5,type:"multiple-choice",question:"If $P(a_i)$ denotes the probability of outcome $a_i$ in a finite sample space, which condition must the point probabilities satisfy?",options:["$\\sum_i P(a_i) = 0$","$\\sum_i P(a_i) = 1$ and $P(a_i) \\geq 0$","$\\prod_i P(a_i) = 1$","$P(a_i) < 0$ for some $i$"],correctIndex:1,difficulty:"medium",explanation:"Point probabilities must be nonnegative and sum to 1: $\\sum_i P(a_i) = 1$ with $P(a_i) \\geq 0$ for all $i$."}],Ot=[{id:1,type:"multiple-choice",question:"In probability terminology, an event $A$ is said to have occurred if:",options:["$P(A) = 1$","$P(A) > 0$","The outcome $x$ satisfies $x \\in A$","$A = S$"],correctIndex:2,difficulty:"easy",explanation:"If an experiment produces outcome $x$, and $x \\in A$, then we say event $A$ has occurred."},{id:2,type:"multiple-choice",question:"The impossible event is represented by:",options:["The sample space $S$","The complement of $S$","Any set with $P(A) < 1$","The empty set $\\varnothing$"],correctIndex:3,difficulty:"easy",explanation:"The empty set $\\varnothing$ is the impossible event because no outcome can belong to it, so it never occurs."},{id:3,type:"multiple-choice",question:'The statement "At least one of $A$ or $B$ occurs" corresponds to which set?',options:["$A \\cup B$","$A \\cap B$","$A' \\cap B'$","$A - B$"],correctIndex:0,difficulty:"medium",explanation:'"At least one of $A$ or $B$ occurs" means the outcome is in $A$ or $B$ (or both), which is the union $A \\cup B$.'},{id:4,type:"multiple-choice",question:"Two events $A$ and $B$ are called mutually exclusive if:",options:["$A \\cup B = S$","$A \\cap B = \\varnothing$","$P(A) = P(B)$","$A \\subseteq B$"],correctIndex:1,difficulty:"medium",explanation:"Events are mutually exclusive (or disjoint) if they cannot both occur, i.e., $A \\cap B = \\varnothing$."},{id:5,type:"multiple-choice",question:"Which statement is TRUE about events with probability zero?",options:["An event with probability zero must be the empty set","An event with probability zero is always impossible","An event with probability zero may be nonempty","Probability zero is not possible for any event"],correctIndex:2,difficulty:"hard",explanation:"An event with probability zero is not necessarily impossible (empty). Some nonempty subsets may be assigned probability zero, especially in infinite sample spaces."}],Ht=[{id:1,type:"multiple-choice",question:"When tossing a coin twice with equally likely outcomes, the probability of getting at least one head is:",options:["$1/4$","$1/2$","$1$","$3/4$"],correctIndex:3,difficulty:"easy",explanation:'The sample space is $\\{hh, ht, th, tt\\}$. The event "at least one head" is $\\{hh, ht, th\\}$, which has 3 elements out of 4. So $P = 3/4$.'},{id:2,type:"multiple-choice",question:"Three fair dice are rolled. What is the number of outcomes in the sample space?",options:["$216$","$36$","$18$","$6$"],correctIndex:0,difficulty:"easy",explanation:"Each die has 6 outcomes, so the sample space for three dice has $6^3 = 216$ elements."},{id:3,type:"multiple-choice",question:"A die is thrown once. Using inclusion-exclusion, $P(\\text{even or multiple of 3})$ equals:",options:["$P(\\text{even}) + P(\\text{mult. of 3})$","$P(\\text{even}) + P(\\text{mult. of 3}) - P(\\text{even and mult. of 3})$","$P(\\text{even}) \\cdot P(\\text{mult. of 3})$","$P(\\text{even}) - P(\\text{mult. of 3})$"],correctIndex:1,difficulty:"medium",explanation:"By inclusion-exclusion: $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$. Here $A = \\{2,4,6\\}$, $B = \\{3,6\\}$, $A \\cap B = \\{6\\}$."},{id:4,type:"numeric",question:"A die is thrown once. What is the probability (as a fraction with denominator 6) that the number is even or a multiple of 3? Enter the numerator.",correctAnswer:4,numericRange:{min:0,max:6,precision:0},difficulty:"medium",explanation:"Even numbers: $\\{2, 4, 6\\}$. Multiples of 3: $\\{3, 6\\}$. Union: $\\{2, 3, 4, 6\\}$. Probability = $4/6$."},{id:5,type:"multiple-choice",question:'When solving probability problems, "at random" typically means:',options:["The outcome is predetermined","The probability is unknown","All outcomes are equally likely","The sample space is infinite"],correctIndex:2,difficulty:"easy",explanation:'When objects are chosen "at random," this means equally likely outcomes. This is the classical interpretation of randomness.'}],Gt=[{id:1,type:"multiple-choice",question:"When sampling $k$ items from a set of $n$ elements WITH replacement, the number of ordered $k$-tuples is:",options:["$n!/(n-k)!$","$k^n$","$\\binom{n}{k}$","$n^k$"],correctIndex:3,difficulty:"easy",explanation:"With replacement, each of the $k$ positions can be filled by any of the $n$ elements, giving $n^k$ possibilities."},{id:2,type:"multiple-choice",question:"The number of permutations (ordered arrangements without replacement) of $k$ items from $n$ distinct items is:",options:["$n!/(n-k)!$","$\\binom{n}{k}$","$n^k$","$k!$"],correctIndex:0,difficulty:"medium",explanation:"Without replacement: first position has $n$ choices, second has $n-1$, etc. This gives $n(n-1)\\cdots(n-k+1) = n!/(n-k)!$."},{id:3,type:"multiple-choice",question:"The binomial coefficient $\\binom{n}{k}$ counts:",options:["Ordered $k$-tuples from $n$ elements","Unordered subsets of size $k$ from $n$ elements","Arrangements with replacement","The number of ways to arrange $n$ items"],correctIndex:1,difficulty:"easy",explanation:"$\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ counts combinations: unordered selections of $k$ elements from $n$ elements."},{id:4,type:"numeric",question:"How many distinct 5-card hands can be dealt from a standard 52-card deck? Express as $\\binom{52}{5}$. What is $\\binom{52}{5}$?",correctAnswer:2598960,numericRange:{min:0,max:1e7,precision:0},difficulty:"hard",explanation:"$\\binom{52}{5} = \\frac{52!}{5! \\cdot 47!} = \\frac{52 \\times 51 \\times 50 \\times 49 \\times 48}{120} = 2,598,960$."},{id:5,type:"multiple-choice",question:"The total number of subsets of a set with $n$ elements is:",options:["$n!$","$2n$","$2^n$","$n^2$"],correctIndex:2,difficulty:"easy",explanation:"Each element is either in or out of a subset, giving $2^n$ total subsets. This also follows from $\\sum_{k=0}^n \\binom{n}{k} = 2^n$."}],Ut=[{id:1,type:"multiple-choice",question:"The conditional probability of $A$ given $B$ is defined as:",options:["$P(A \\mid B) = P(A) + P(B)$","$P(A \\mid B) = P(A) / P(B)$","$P(A \\mid B) = P(A \\cup B) / P(B)$","$P(A \\mid B) = P(A \\cap B) / P(B)$"],correctIndex:3,difficulty:"easy",explanation:"Conditional probability is defined as $P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}$, provided $P(B) \\neq 0$."},{id:2,type:"multiple-choice",question:"The multiplication rule states that $P(A \\cap B)$ equals:",options:["$P(B) \\cdot P(A \\mid B)$","$P(A) \\cdot P(B)$ always","$P(A) + P(B)$","$P(A) - P(B)$"],correctIndex:0,difficulty:"medium",explanation:"The multiplication rule: $P(A \\cap B) = P(B) \\cdot P(A \\mid B) = P(A) \\cdot P(B \\mid A)$."},{id:3,type:"multiple-choice",question:"A die shows an even number. What is $P(\\text{divisible by 3} \\mid \\text{even})$?",options:["$1/6$","$1/3$","$1/2$","$2/3$"],correctIndex:1,difficulty:"medium",explanation:"Even = $\\{2, 4, 6\\}$, divisible by 3 = $\\{3, 6\\}$. Intersection = $\\{6\\}$. $P(\\text{div. 3} \\mid \\text{even}) = (1/6)/(3/6) = 1/3$."},{id:4,type:"multiple-choice",question:"If $P(B) > 0$, then $P(\\cdot \\mid B)$ as a function of events:",options:["Is not a probability measure","Always equals $P(\\cdot)$","Is itself a probability measure","Is undefined for all events"],correctIndex:2,difficulty:"medium",explanation:"For fixed $B$ with $P(B) > 0$, the function $P(\\cdot \\mid B)$ satisfies all axioms of a probability measure: nonnegativity, $P(B \\mid B) = 1$, and additivity."},{id:5,type:"multiple-choice",question:"Conditioning on event $B$ is equivalent to:",options:["Multiplying all probabilities by $P(B)$","Ignoring event $B$ entirely","Setting $P(B) = 0$","Changing the sample space to $B$ and rescaling probabilities by $1/P(B)$"],correctIndex:3,difficulty:"hard",explanation:"Conditioning restricts attention to $B$ as the new sample space and rescales probabilities by dividing by $P(B)$ so that $B$ has probability 1."}],Jt=[{id:1,type:"multiple-choice",question:"Two events $A$ and $B$ are independent if and only if:",options:["$P(A \\cap B) = P(A) \\cdot P(B)$","$P(A \\cup B) = P(A) + P(B)$","$A \\cap B = \\varnothing$","$P(A) = P(B)$"],correctIndex:0,difficulty:"easy",explanation:"Independence is defined by the factorization $P(A \\cap B) = P(A) \\cdot P(B)$. This means knowing one event occurred does not change the probability of the other."},{id:2,type:"multiple-choice",question:"If $A$ and $B$ are independent and $P(B) \\neq 0$, then $P(A \\mid B)$ equals:",options:["$P(B)$","$P(A)$","$P(A) + P(B)$","$0$"],correctIndex:1,difficulty:"medium",explanation:"If independent: $P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A) \\cdot P(B)}{P(B)} = P(A)$. Knowing $B$ does not change $P(A)$."},{id:3,type:"multiple-choice",question:"If $A$ and $B$ are disjoint with $P(A), P(B) > 0$, are they independent?",options:["Yes, disjoint events are always independent","Only if $P(A) = P(B)$","No, disjoint events with positive probability cannot be independent","Only if $P(A \\cup B) = 1$"],correctIndex:2,difficulty:"hard",explanation:"Disjoint means $A \\cap B = \\varnothing$, so $P(A \\cap B) = 0$. But $P(A) \\cdot P(B) > 0$. Since $0 \\neq P(A) \\cdot P(B)$, they cannot be independent."},{id:4,type:"multiple-choice",question:"For three events to be mutually independent, how many equations must hold?",options:["1","3","7","4"],correctIndex:3,difficulty:"medium",explanation:"For $A, B, C$: three pairwise conditions $P(A \\cap B) = P(A)P(B)$, etc., plus $P(A \\cap B \\cap C) = P(A)P(B)P(C)$. Total: 4 equations."},{id:5,type:"multiple-choice",question:"If $A$ and $B$ are independent, then $A$ and $B'$ are:",options:["Independent","Never independent","Always disjoint","Equal in probability"],correctIndex:0,difficulty:"medium",explanation:"If $A$ and $B$ are independent, then $A$ and $B'$, $A'$ and $B$, and $A'$ and $B'$ are all independent pairs."}],Mt=[{id:1,type:"multiple-choice",question:"For a compound experiment of two independent experiments with sample spaces $S_1$ and $S_2$, the combined sample space is:",options:["$S_1 \\cup S_2$","$S_1 \\times S_2$","$S_1 \\cap S_2$","$S_1 + S_2$"],correctIndex:1,difficulty:"easy",explanation:"The compound experiment has sample space $S_1 \\times S_2$, the Cartesian product of the individual sample spaces."},{id:2,type:"multiple-choice",question:"In de Mere's problem, the probability of at least one double six in $n$ throws of two dice is:",options:["$(1/36)^n$","$(35/36)^n$","$1 - (35/36)^n$","$n/36$"],correctIndex:2,difficulty:"medium",explanation:"The probability of no double six in one throw is $35/36$. For $n$ independent throws, no double six has probability $(35/36)^n$. So at least one has probability $1 - (35/36)^n$."},{id:3,type:"numeric",question:"What is the minimum number of throws needed so that $P(\\text{at least one double six}) \\geq 1/2$?",correctAnswer:25,numericRange:{min:1,max:100,precision:0},difficulty:"hard",explanation:"Need $(35/36)^n \\leq 1/2$, so $n \\geq \\log(1/2)/\\log(35/36) \\approx 24.6$. Thus $n = 25$ throws are needed."},{id:4,type:"multiple-choice",question:"For independent experiments, if $U \\subseteq S_1$ and $V \\subseteq S_2$, then $P(U \\times V)$ equals:",options:["$P_1(U) + P_2(V)$","$\\max(P_1(U), P_2(V))$","$P_1(U) / P_2(V)$","$P_1(U) \\cdot P_2(V)$"],correctIndex:3,difficulty:"medium",explanation:"For independent experiments, probabilities multiply: $P(U \\times V) = P_1(U) \\cdot P_2(V)$."},{id:5,type:"multiple-choice",question:"An event $A = C_1 \\times S_2$ in a compound experiment is called:",options:["An event determined by the first experiment","A random variable","The impossible event","A conditional probability"],correctIndex:0,difficulty:"medium",explanation:"An event of the form $C_1 \\times S_2$ depends only on the outcome of the first experiment, so it is determined by the first experiment."}],Zt=[{id:1,type:"multiple-choice",question:"In Bernoulli trials, each trial has:",options:["Multiple possible outcomes","Exactly two outcomes: success with probability $p$ and failure with probability $q = 1-p$","Outcomes that depend on previous trials","Equally likely outcomes only"],correctIndex:1,difficulty:"easy",explanation:"Bernoulli trials are repeated independent trials with two outcomes: success (probability $p$) and failure (probability $q = 1-p$)."},{id:2,type:"multiple-choice",question:"The probability of exactly $k$ successes in $n$ Bernoulli trials is given by:",options:["$p^k q^{n-k}$","$\\binom{n}{k} p^n$","$\\binom{n}{k} p^k q^{n-k}$","$n p^k$"],correctIndex:2,difficulty:"easy",explanation:"Bernoulli's formula: $P(\\text{exactly } k \\text{ successes}) = \\binom{n}{k} p^k q^{n-k}$, where $\\binom{n}{k}$ counts the arrangements."},{id:3,type:"multiple-choice",question:"The binomial distribution satisfies $\\sum_{k=0}^{n} \\binom{n}{k} p^k q^{n-k} =$",options:["$0$","$n$","$pq$","$1$"],correctIndex:3,difficulty:"medium",explanation:"The sum equals $(p + q)^n = 1^n = 1$ by the binomial theorem. This confirms the probabilities sum to 1 as required."},{id:4,type:"numeric",question:"An unbiased coin is tossed 4 times. What is the probability of exactly 2 heads? Express as a fraction with denominator 16. Enter the numerator.",correctAnswer:6,numericRange:{min:0,max:16,precision:0},difficulty:"medium",explanation:"$P(\\text{2 heads}) = \\binom{4}{2} (1/2)^2 (1/2)^2 = 6 \\cdot 1/16 = 6/16$."},{id:5,type:"multiple-choice",question:"The probability of at least $r$ successes in $n$ Bernoulli trials equals:",options:["$\\sum_{k=r}^{n} \\binom{n}{k} p^k q^{n-k}$","$\\sum_{k=0}^{r-1} \\binom{n}{k} p^k q^{n-k}$","$\\binom{n}{r} p^r q^{n-r}$","$1 - p^r$"],correctIndex:0,difficulty:"medium",explanation:'"At least $r$" means $k = r, r+1, \\ldots, n$, so we sum: $\\sum_{k=r}^{n} \\binom{n}{k} p^k q^{n-k}$.'}],Kt=[{id:1,type:"multiple-choice",question:"In $n$ Bernoulli trials with success probability $p$, if $(n+1)p$ is NOT an integer, the most probable number of successes is:",options:["$np$","$\\lfloor (n+1)p \\rfloor$","$(n+1)p$","$n$"],correctIndex:1,difficulty:"medium",explanation:"When $(n+1)p$ is not an integer, the unique maximum of the binomial distribution occurs at $k = \\lfloor (n+1)p \\rfloor$."},{id:2,type:"multiple-choice",question:"If $(n+1)p$ IS an integer, then the maximum of the binomial distribution occurs at:",options:["A unique value $k = (n+1)p$","All values of $k$","Two values: $k = (n+1)p$ and $k = (n+1)p - 1$","Only $k = 0$"],correctIndex:2,difficulty:"hard",explanation:"When $(n+1)p$ is an integer, the maximum occurs at two consecutive values: $k = (n+1)p$ and $k = (n+1)p - 1$."},{id:3,type:"numeric",question:"A pair of dice is rolled 28 times. What is the most probable number of sevens? (Probability of rolling 7 is $1/6$)",correctAnswer:4,numericRange:{min:0,max:28,precision:0},difficulty:"medium",explanation:"$(n+1)p = 29 \\cdot (1/6) = 29/6 \\approx 4.83$. Since this is not an integer, the mode is $\\lfloor 29/6 \\rfloor = 4$."},{id:4,type:"multiple-choice",question:"The ratio $r(k) = f(k)/f(k+1)$ for the binomial distribution is:",options:["Constant for all $k$","Strictly decreasing in $k$","Alternating","Strictly increasing in $k$"],correctIndex:3,difficulty:"hard",explanation:"The ratio $r(k) = \\frac{k+1}{n-k} \\cdot \\frac{1-p}{p}$ is strictly increasing in $k$. This monotonicity is key to finding the mode."},{id:5,type:"multiple-choice",question:"The most probable number of successes $k^*$ satisfies approximately:",options:["$k^* \\approx np$","$k^* \\approx p$","$k^* \\approx n$","$k^* \\approx n/p$"],correctIndex:0,difficulty:"easy",explanation:"The mode is close to the expected value $np$. More precisely, $np - q \\leq k^* \\leq np + p$."}],ei=[{id:1,type:"multiple-choice",question:"A set $S$ is countably infinite if it is in one-to-one correspondence with:",options:["The real numbers","The positive integers $\\{1, 2, 3, \\ldots\\}$","The interval $[0, 1]$","Any finite set"],correctIndex:1,difficulty:"easy",explanation:"A set is countably infinite if there exists a bijection between it and the positive integers $\\{1, 2, 3, \\ldots\\}$."},{id:2,type:"multiple-choice",question:"Which of the following sets is countable?",options:["The real numbers $\\mathbb{R}$","All subsets of $\\mathbb{N}$","The rational numbers $\\mathbb{Q}$","The interval $(0, 1)$"],correctIndex:2,difficulty:"medium",explanation:"The rationals $\\mathbb{Q}$ are countable: they can be written as a countable union of countable sets $\\{x/n : x \\in \\mathbb{Z}\\}$ for each $n \\geq 1$."},{id:3,type:"multiple-choice",question:"A countable union of countable sets is:",options:["Always uncountable","Always finite","Neither countable nor uncountable","Countable"],correctIndex:3,difficulty:"medium",explanation:"One of the key properties of countable sets: a countable union of countable sets remains countable."},{id:4,type:"multiple-choice",question:"Cantor's diagonal argument shows that:",options:["The real numbers in $(0, 1)$ are uncountable","The rationals are uncountable","The integers are uncountable","All infinite sets are countable"],correctIndex:0,difficulty:"medium",explanation:"Cantor's diagonalization constructs a real number in $(0, 1)$ that differs from every number in any supposed list, proving the reals are uncountable."},{id:5,type:"multiple-choice",question:"The power set (set of all subsets) of a countably infinite set is:",options:["Finite","Uncountable","Countably infinite","Empty"],correctIndex:1,difficulty:"hard",explanation:"The power set of a countably infinite set is uncountable. This is proved by a diagonal argument: assuming a bijection leads to the paradoxical set $B = \\{a \\in A : a \\notin f(a)\\}$."}],ti=[{id:1,type:"multiple-choice",question:"A set function is countably additive (-additive) if for pairwise disjoint sets $A_1, A_2, \\ldots$:",options:["$P(\\bigcup_{k=1}^{\\infty} A_k) = \\prod_{k=1}^{\\infty} P(A_k)$","$P(\\bigcup_{k=1}^{\\infty} A_k) = \\max_k P(A_k)$","$P(\\bigcup_{k=1}^{\\infty} A_k) = \\sum_{k=1}^{\\infty} P(A_k)$","$P(\\bigcup_{k=1}^{\\infty} A_k) = P(A_1)$"],correctIndex:2,difficulty:"easy",explanation:"Countable additivity extends finite additivity to infinite unions: $P(\\bigcup_{k=1}^{\\infty} A_k) = \\sum_{k=1}^{\\infty} P(A_k)$ for pairwise disjoint sets."},{id:2,type:"multiple-choice",question:"For the geometric distribution, $P(X = k) = (1-p)^{k-1}p$ for $k = 1, 2, 3, \\ldots$. What does $\\sum_{k=1}^{\\infty} P(X = k)$ equal?",options:["$0$","$p$","$\\infty$","$1$"],correctIndex:3,difficulty:"medium",explanation:"$\\sum_{k=1}^{\\infty} (1-p)^{k-1}p = p \\sum_{j=0}^{\\infty} (1-p)^j = p \\cdot \\frac{1}{1-(1-p)} = p \\cdot \\frac{1}{p} = 1$."},{id:3,type:"multiple-choice",question:"The Poisson distribution with parameter $\\lambda$ assigns probability:",options:["$P(k) = \\lambda^k e^{-\\lambda} / k!$","$P(k) = \\lambda^k / k!$","$P(k) = e^{-\\lambda k}$","$P(k) = \\lambda / k$"],correctIndex:0,difficulty:"easy",explanation:"The Poisson distribution is $P(k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$ for $k = 0, 1, 2, \\ldots$"},{id:4,type:"multiple-choice",question:"The Poisson probabilities sum to 1 because:",options:["$\\sum_{k=0}^{\\infty} \\lambda^k = e^{\\lambda}$","$\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} = e^{\\lambda}$","$e^{-\\lambda} = 0$","$\\lambda = 1$ always"],correctIndex:1,difficulty:"medium",explanation:"$\\sum_{k=0}^{\\infty} \\frac{\\lambda^k e^{-\\lambda}}{k!} = e^{-\\lambda} \\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} = e^{-\\lambda} \\cdot e^{\\lambda} = 1$."},{id:5,type:"multiple-choice",question:"For uncountable sample spaces like $\\mathbb{R}$, which statement is true?",options:["All subsets can be assigned probabilities consistently","Probability theory does not apply","We must restrict to a -algebra of measurable sets","Every point has positive probability"],correctIndex:2,difficulty:"hard",explanation:'For uncountable spaces, not all subsets can be assigned probabilities consistently. We restrict to a -algebra of "measurable" sets, leading to measure theory.'}],ii=[{id:1,type:"multiple-choice",question:"The calculus of probabilities connects probability theory with:",options:["Algebra only","Geometry only","Number theory only","Analysis (integration, differentiation, limits)"],correctIndex:3,difficulty:"easy",explanation:"The calculus of probabilities uses integration for computing probabilities, differentiation for density functions, and limits for convergence theorems."},{id:2,type:"multiple-choice",question:"For continuous random variables, probability is computed by:",options:["Integration","Summation","Multiplication","Counting"],correctIndex:0,difficulty:"easy",explanation:"For continuous distributions, $P(a < X \\leq b) = \\int_a^b f(x)\\,dx$ where $f$ is the density function."},{id:3,type:"multiple-choice",question:"When the distribution function $F$ is differentiable, the density function is:",options:["$f(x) = F(x)$","$f(x) = F'(x)$","$f(x) = \\int F(x)\\,dx$","$f(x) = 1/F(x)$"],correctIndex:1,difficulty:"medium",explanation:"When $F$ is differentiable, the density is the derivative: $f(x) = F'(x)$."},{id:4,type:"multiple-choice",question:"The expectation of a continuous random variable with density $f$ is:",options:["$E(X) = \\int_{-\\infty}^{\\infty} f(x)\\,dx$","$E(X) = \\max_x f(x)$","$E(X) = \\int_{-\\infty}^{\\infty} x f(x)\\,dx$","$E(X) = f(0)$"],correctIndex:2,difficulty:"medium",explanation:"The expectation is the weighted average: $E(X) = \\int_{-\\infty}^{\\infty} x f(x)\\,dx$."},{id:5,type:"multiple-choice",question:"Which mathematician provided the rigorous axiomatic foundations of probability?",options:["Newton","Euler","Fermat","Kolmogorov"],correctIndex:3,difficulty:"easy",explanation:"Kolmogorov (1903-1987) established the measure-theoretic foundations of probability in his 1933 work."}],ni=[{id:1,type:"multiple-choice",question:"A random variable $X$ on a sample space $S$ is:",options:["A real-valued function defined on $S$","A probability measure","A subset of $S$","A constant"],correctIndex:0,difficulty:"easy",explanation:"A random variable is a real-valued function that assigns a numerical value $X(\\omega)$ to each outcome $\\omega \\in S$."},{id:2,type:"multiple-choice",question:"For two dice, if $X$ is the sum of the faces, then $X(3, 4) =$",options:["$3$","$7$","$4$","$12$"],correctIndex:1,difficulty:"easy",explanation:"$X(i, j) = i + j$, so $X(3, 4) = 3 + 4 = 7$."},{id:3,type:"multiple-choice",question:"A two-dimensional random variable $(X, Y)$ is:",options:["A single function","The product $X \\cdot Y$","A pair of random variables on the same sample space","Always independent"],correctIndex:2,difficulty:"medium",explanation:"A two-dimensional random variable is a pair $(X, Y)$ of one-dimensional random variables defined on the same sample space."},{id:4,type:"multiple-choice",question:"If $X$ is a random variable and $\\varphi$ is a function, then $Y = \\varphi(X)$ is:",options:["Not a random variable","The inverse of $X$","Always equal to $X$","A random variable defined by $Y(\\omega) = \\varphi(X(\\omega))$"],correctIndex:3,difficulty:"medium",explanation:"Functions of random variables are also random variables: $Y(\\omega) = \\varphi(X(\\omega))$."},{id:5,type:"multiple-choice",question:"The notation $P(X \\leq t)$ means:",options:["$P(\\{\\omega : X(\\omega) \\leq t\\})$","$P(\\{t\\})$","$X \\cdot P(t)$","$P(S) \\cdot t$"],correctIndex:0,difficulty:"medium",explanation:"$P(X \\leq t)$ is shorthand for the probability of the event $\\{\\omega \\in S : X(\\omega) \\leq t\\}$."}],ai=[{id:1,type:"multiple-choice",question:"The distribution function (CDF) of a random variable $X$ is defined as:",options:["$F(t) = P(X = t)$","$F(t) = P(X \\leq t)$","$F(t) = P(X > t)$","$F(t) = P(X < t)$"],correctIndex:1,difficulty:"easy",explanation:"The cumulative distribution function is $F(t) = P(X \\leq t)$, the probability that $X$ takes a value at most $t$."},{id:2,type:"multiple-choice",question:"Which property must every distribution function satisfy?",options:["$\\lim_{t \\to -\\infty} F(t) = 1$","$\\lim_{t \\to +\\infty} F(t) = 0$","$F$ is monotonically increasing","$F$ is always differentiable"],correctIndex:2,difficulty:"medium",explanation:"A distribution function is monotonically increasing: if $a < b$, then $F(a) \\leq F(b)$. Also $\\lim_{t \\to -\\infty} F(t) = 0$ and $\\lim_{t \\to +\\infty} F(t) = 1$."},{id:3,type:"multiple-choice",question:"Using the distribution function, $P(a < X \\leq b)$ equals:",options:["$F(a) - F(b)$","$F(a) + F(b)$","$F(a) \\cdot F(b)$","$F(b) - F(a)$"],correctIndex:3,difficulty:"easy",explanation:"$P(a < X \\leq b) = P(X \\leq b) - P(X \\leq a) = F(b) - F(a)$."},{id:4,type:"multiple-choice",question:"For a discrete distribution, the distribution function $F$ is:",options:["A step function with jumps at the mass points","A smooth curve","Always linear","Undefined"],correctIndex:0,difficulty:"medium",explanation:"For discrete distributions, $F$ is a step function that jumps at each mass point. The size of the jump at $x$ equals $P(X = x)$."},{id:5,type:"multiple-choice",question:"If $F$ is continuous everywhere, then for any single value $t$:",options:["$P(X = t) > 0$","$P(X = t) = 0$","$P(X = t) = 1$","$P(X = t) = F(t)$"],correctIndex:1,difficulty:"medium",explanation:"When $F$ is continuous, $P(X = t) = F(t) - \\lim_{s \\to t^-} F(s) = 0$. No single point has positive probability."}],oi=[{id:1,type:"multiple-choice",question:"A probability mass function (pmf) must satisfy:",options:["$\\sum_k p(x_k) = 0$","$p(x_k) < 0$ for some $k$","$p(x_k) \\geq 0$ and $\\sum_k p(x_k) = 1$","$\\prod_k p(x_k) = 1$"],correctIndex:2,difficulty:"easy",explanation:"A pmf is nonnegative and sums to 1: $p(x_k) \\geq 0$ for all $k$ and $\\sum_k p(x_k) = 1$."},{id:2,type:"multiple-choice",question:"The binomial distribution with parameters $n$ and $p$ models:",options:["Waiting time until first success","Uniform distribution on $[0, 1]$","Number of rare events in continuous time","Number of successes in $n$ independent Bernoulli trials"],correctIndex:3,difficulty:"easy",explanation:"The binomial distribution gives the probability of $k$ successes in $n$ independent trials, each with success probability $p$."},{id:3,type:"multiple-choice",question:"The geometric distribution $P(X = k) = (1-p)^{k-1}p$ models:",options:["Number of trials until the first success","Number of successes in $n$ trials","Total number of outcomes","Continuous waiting time"],correctIndex:0,difficulty:"medium",explanation:"The geometric distribution models the number of Bernoulli trials needed to get the first success."},{id:4,type:"multiple-choice",question:"The Poisson distribution arises as a limit of the binomial when:",options:["$n \\to \\infty$ and $p \\to 1$","$n \\to \\infty$, $p \\to 0$, with $np \\to \\lambda$","$n \\to 0$ and $p \\to 0$","$n$ and $p$ are both fixed"],correctIndex:1,difficulty:"hard",explanation:"The Poisson is a limit of the binomial as $n \\to \\infty$ and $p \\to 0$ such that $np \\to \\lambda$. It models rare events."},{id:5,type:"multiple-choice",question:"For the Poisson distribution, $P(X \\geq 2)$ equals:",options:["$1 - e^{-\\lambda}$","$\\lambda e^{-\\lambda}$","$1 - e^{-\\lambda} - \\lambda e^{-\\lambda}$","$e^{-\\lambda}$"],correctIndex:2,difficulty:"medium",explanation:"$P(X \\geq 2) = 1 - P(X = 0) - P(X = 1) = 1 - e^{-\\lambda} - \\lambda e^{-\\lambda}$."}],si=[{id:1,type:"multiple-choice",question:"A random variable $X$ is continuous if:",options:["$P(X = t) > 0$ for all $t$","$F(t)$ is a step function","$X$ takes only integer values","$P(X = t) = 0$ for every real number $t$"],correctIndex:3,difficulty:"easy",explanation:"A continuous random variable has $P(X = t) = 0$ for every $t$. Probability is spread continuously, not concentrated at points."},{id:2,type:"multiple-choice",question:"If $f$ is a probability density function, then:",options:["$\\int_{-\\infty}^{\\infty} f(u)\\,du = 1$","$\\int_{-\\infty}^{\\infty} f(u)\\,du = 0$","$f(t) = P(X = t)$","$f(t) < 0$ for some $t$"],correctIndex:0,difficulty:"easy",explanation:"A pdf integrates to 1 over the entire real line: $\\int_{-\\infty}^{\\infty} f(u)\\,du = 1$."},{id:3,type:"multiple-choice",question:"For a continuous distribution, $P(a < X \\leq b)$ equals:",options:["$f(b) - f(a)$","$\\int_a^b f(u)\\,du$","$f(a) + f(b)$","$F(a) \\cdot F(b)$"],correctIndex:1,difficulty:"medium",explanation:"Probability is the area under the density curve: $P(a < X \\leq b) = \\int_a^b f(u)\\,du$."},{id:4,type:"multiple-choice",question:"The density $f(t)$ represents:",options:["The probability that $X = t$","The cumulative probability up to $t$","The rate of probability accumulation at $t$","The variance at $t$"],correctIndex:2,difficulty:"medium",explanation:"The density is NOT the probability at $t$ (that is 0). It represents the rate at which probability accumulates: $f(t) = F'(t)$ when differentiable."},{id:5,type:"multiple-choice",question:"For a continuous distribution, $P(a < X < b)$ compared to $P(a \\leq X \\leq b)$ is:",options:["Strictly less","Strictly greater","Cannot be determined","Equal"],correctIndex:3,difficulty:"medium",explanation:"Since $P(X = a) = P(X = b) = 0$ for continuous distributions, including or excluding the endpoints makes no difference."}],ri=[{id:1,type:"multiple-choice",question:"The uniform distribution on $[a, b]$ has density:",options:["$f(t) = 1/(b-a)$ for $a < t < b$","$f(t) = 1$ for all $t$","$f(t) = (b-a)$ for $a < t < b$","$f(t) = t/(b-a)$"],correctIndex:0,difficulty:"easy",explanation:"The uniform density is constant: $f(t) = 1/(b-a)$ for $t \\in (a, b)$ and 0 elsewhere."},{id:2,type:"multiple-choice",question:"For the uniform distribution on $[a, b]$, $P(X \\leq t)$ for $a < t < b$ equals:",options:["$t$","$(t-a)/(b-a)$","$t/(b-a)$","$(b-t)/(b-a)$"],correctIndex:1,difficulty:"medium",explanation:"The CDF is $F(t) = (t-a)/(b-a)$ for $a < t < b$, representing the fraction of the interval to the left of $t$."},{id:3,type:"multiple-choice",question:"The characteristic property of the uniform distribution is that:",options:["All intervals have the same probability","Longer intervals have smaller probability","Intervals of equal length have equal probability","Only the endpoints have positive probability"],correctIndex:2,difficulty:"medium",explanation:"For uniform distributions, $P(X \\in I)$ depends only on the length of $I$, not its location. Equal-length intervals have equal probability."},{id:4,type:"multiple-choice",question:"A stick is broken at a uniformly random point. The probability the left piece is at least twice the right piece is:",options:["$1/2$","$1/4$","$2/3$","$1/3$"],correctIndex:3,difficulty:"hard",explanation:"Let $Y$ be uniform on $[0,1]$. Left $\\geq$ 2(Right) means $Y \\geq 2(1-Y)$, so $3Y \\geq 2$, thus $Y \\geq 2/3$. Probability = $1 - 2/3 = 1/3$."},{id:5,type:"multiple-choice",question:"The uniform distribution represents:",options:["Maximum ignorance within an interval","Maximum knowledge about $X$","Discrete outcomes only","Heavy-tailed behavior"],correctIndex:0,difficulty:"easy",explanation:'The uniform distribution represents "maximum ignorance"when we have no reason to prefer any part of the interval over another.'}],$i=[{id:1,type:"multiple-choice",question:"The Cauchy distribution has density:",options:["$f(t) = e^{-t}$","$f(t) = 1/(\\pi(1 + t^2))$","$f(t) = t^2/\\pi$","$f(t) = 1/\\sqrt{2\\pi} e^{-t^2/2}$"],correctIndex:1,difficulty:"easy",explanation:"The Cauchy density is $f(t) = \\frac{1}{\\pi(1 + t^2)}$."},{id:2,type:"multiple-choice",question:"The Cauchy distribution function is:",options:["$F(t) = t$","$F(t) = 1 - e^{-t}$","$F(t) = 1/2 + (1/\\pi)\\arctan t$","$F(t) = t^2$"],correctIndex:2,difficulty:"medium",explanation:"The Cauchy CDF is $F(t) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan t$."},{id:3,type:"multiple-choice",question:"If $\\theta$ is uniformly distributed on $[-\\pi/2, \\pi/2]$, then $Y = \\tan\\theta$ has:",options:["Uniform distribution","Normal distribution","Exponential distribution","Cauchy distribution"],correctIndex:3,difficulty:"hard",explanation:'The tangent of a uniformly distributed angle produces the Cauchy distribution. This is the "spinning pointer" construction.'},{id:4,type:"multiple-choice",question:"A remarkable property of the Cauchy distribution is:",options:["It has no finite expectation or variance","It has the smallest variance","It is always positive","It equals the normal distribution"],correctIndex:0,difficulty:"medium",explanation:"The Cauchy distribution has such heavy tails that $\\int_{-\\infty}^{\\infty} |t| f(t)\\,dt$ diverges. It has no finite mean or variance."},{id:5,type:"multiple-choice",question:'The Cauchy distribution has "heavy tails," meaning:',options:["The density goes to zero quickly","The density decays slowly like $1/t^2$","All probability is near the origin","The distribution is bounded"],correctIndex:1,difficulty:"medium",explanation:"Heavy tails: $f(t) \\sim 1/(\\pi t^2)$ as $|t| \\to \\infty$. This slow decay causes the integrals for expectation to diverge."}],li=[{id:1,type:"multiple-choice",question:"The exponential distribution with parameter $\\lambda > 0$ has density:",options:["$f(t) = e^{-t}$ for $t \\geq 0$","$f(t) = t e^{-t}$ for $t \\geq 0$","$f(t) = \\lambda e^{-\\lambda t}$ for $t \\geq 0$","$f(t) = 1/\\lambda$ for $t \\geq 0$"],correctIndex:2,difficulty:"easy",explanation:"The exponential density is $f(t) = \\lambda e^{-\\lambda t}$ for $t \\geq 0$ and 0 otherwise."},{id:2,type:"multiple-choice",question:"The distribution function of the exponential distribution is:",options:["$F(t) = e^{-\\lambda t}$ for $t \\geq 0$","$F(t) = t/\\lambda$ for $t \\geq 0$","$F(t) = \\lambda t$ for $t \\geq 0$","$F(t) = 1 - e^{-\\lambda t}$ for $t \\geq 0$"],correctIndex:3,difficulty:"medium",explanation:"The CDF is $F(t) = 1 - e^{-\\lambda t}$ for $t \\geq 0$."},{id:3,type:"multiple-choice",question:"The memoryless property states that $P(X > t+s \\mid X > t)$ equals:",options:["$P(X > s)$","$P(X > t)$","$P(X > t) \\cdot P(X > s)$","$P(X > t + s)$"],correctIndex:0,difficulty:"medium",explanation:"Memoryless: $P(X > t+s \\mid X > t) = P(X > s)$. The probability of surviving additional time $s$ doesn't depend on current age $t$."},{id:4,type:"multiple-choice",question:"The exponential distribution is the unique continuous distribution with:",options:["Finite variance","The memoryless property","Mean equal to variance","Bounded support"],correctIndex:1,difficulty:"hard",explanation:'The exponential is the unique continuous distribution satisfying the memoryless (or "lack of memory") property.'},{id:5,type:"multiple-choice",question:"If $\\lambda = 0.001$ and we want $P(X > T) = 0.95$, the half-life concept relates $\\lambda$ to $t_{1/2}$ by:",options:["$\\lambda = t_{1/2}$","$\\lambda = t_{1/2} / 2$","$\\lambda = \\log 2 / t_{1/2}$","$\\lambda = e^{t_{1/2}}$"],correctIndex:2,difficulty:"hard",explanation:"At the half-life $t_{1/2}$, $P(X > t_{1/2}) = 1/2$, so $e^{-\\lambda t_{1/2}} = 1/2$, giving $\\lambda = \\log 2 / t_{1/2}$."}],ci=[{id:1,type:"multiple-choice",question:"The standard normal distribution has parameters:",options:["Mean $m = 0$ and variance $\\sigma^2 = 0$","Mean $m = 1$ and variance $\\sigma^2 = 1$","Mean $m = 0$ and variance $\\sigma^2 = 2\\pi$","Mean $m = 0$ and variance $\\sigma^2 = 1$"],correctIndex:3,difficulty:"easy",explanation:"The standard normal distribution has mean $m = 0$ and variance $\\sigma^2 = 1$."},{id:2,type:"multiple-choice",question:"The density of the standard normal distribution is:",options:["$\\phi(t) = \\frac{1}{\\sqrt{2\\pi}} e^{-t^2/2}$","$\\phi(t) = e^{-t^2}$","$\\phi(t) = \\frac{1}{2} e^{-|t|}$","$\\phi(t) = \\frac{1}{\\pi(1+t^2)}$"],correctIndex:0,difficulty:"medium",explanation:"The standard normal density is $\\phi(t) = \\frac{1}{\\sqrt{2\\pi}} e^{-t^2/2}$."},{id:3,type:"multiple-choice",question:"The famous Gaussian integral $\\int_{-\\infty}^{\\infty} e^{-x^2}dx$ equals:",options:["$1$","$\\sqrt{\\pi}$","$2$","$\\pi$"],correctIndex:1,difficulty:"medium",explanation:"The Gaussian integral evaluates to $\\sqrt{\\pi}$. This ensures the standard normal density integrates to 1."},{id:4,type:"multiple-choice",question:"For a normal distribution with mean $m$ and standard deviation $\\sigma$, approximately what percentage lies within one standard deviation of the mean?",options:["About 50%","About 95%","About 68%","About 99.7%"],correctIndex:2,difficulty:"easy",explanation:"About 68% of a normal distribution lies within one standard deviation of the mean ($m \\pm \\sigma$)."},{id:5,type:"multiple-choice",question:"The symmetry property $\\Phi(-t) = 1 - \\Phi(t)$ follows from:",options:["The density being always positive","The mean being 0","The variance being 1","The density being symmetric about 0"],correctIndex:3,difficulty:"medium",explanation:"The standard normal density $\\phi(t)$ is symmetric about 0: $\\phi(-t) = \\phi(t)$. This symmetry implies $\\Phi(-t) = 1 - \\Phi(t)$."}],di=[{id:1,type:"multiple-choice",question:"The joint distribution function of $(X, Y)$ is defined as:",options:["$F(a, b) = P(X \\leq a, Y \\leq b)$","$F(a, b) = P(X = a, Y = b)$","$F(a, b) = P(X \\leq a) + P(Y \\leq b)$","$F(a, b) = P(X \\leq a) \\cdot P(Y \\leq b)$ always"],correctIndex:0,difficulty:"easy",explanation:"The joint CDF is $F(a, b) = P(X \\leq a, Y \\leq b)$, the probability that $X \\leq a$ AND $Y \\leq b$."},{id:2,type:"multiple-choice",question:"The probability $P(a < X \\leq b, c < Y \\leq d)$ in terms of the joint distribution $F$ is:",options:["$F(b, d) - F(a, c)$","$F(b, d) - F(a, d) - F(b, c) + F(a, c)$","$F(b, d) + F(a, c)$","$F(b, d) \\cdot F(a, c)$"],correctIndex:1,difficulty:"hard",explanation:"The inclusion-exclusion formula: $P(a < X \\leq b, c < Y \\leq d) = F(b,d) - F(a,d) - F(b,c) + F(a,c)$."},{id:3,type:"multiple-choice",question:"The marginal distribution $F_X(t)$ is obtained from the joint distribution by:",options:["$F_X(t) = F(t, 0)$","$F_X(t) = F(t, t)$","$F_X(t) = \\lim_{b \\to \\infty} F(t, b)$","$F_X(t) = F(0, t)$"],correctIndex:2,difficulty:"medium",explanation:"The marginal $F_X(t) = P(X \\leq t) = \\lim_{b \\to \\infty} P(X \\leq t, Y \\leq b) = \\lim_{b \\to \\infty} F(t, b)$."},{id:4,type:"multiple-choice",question:"Random variables $X$ and $Y$ are independent if and only if:",options:["$F(a, b) = F_X(a) + F_Y(b)$ for all $a, b$","$F_X(a) = F_Y(b)$ for all $a, b$","$F(a, b) = 0$ for all $a, b$","$F(a, b) = F_X(a) \\cdot F_Y(b)$ for all $a, b$"],correctIndex:3,difficulty:"medium",explanation:"Independence means the joint CDF factors: $F(a, b) = F_X(a) \\cdot F_Y(b)$ for all $a, b$."},{id:5,type:"multiple-choice",question:"Knowing only the marginal distributions $F_X$ and $F_Y$:",options:["Is not sufficient to determine the joint distribution","Determines independence","Completely determines the joint distribution","Means $X$ and $Y$ are independent"],correctIndex:0,difficulty:"hard",explanation:"Marginals alone do not determine the joint distribution. Many different joint distributions can have the same marginals."}],hi=[{id:1,type:"multiple-choice",question:"For discrete $(X, Y)$, the joint pmf is $p(x, y) =$",options:["$P(X \\leq x, Y \\leq y)$","$P(X = x, Y = y)$","$P(X = x) + P(Y = y)$","$P(X = x) \\cdot P(Y = y)$ always"],correctIndex:1,difficulty:"easy",explanation:"The joint pmf gives the probability of both $X = x$ AND $Y = y$: $p(x, y) = P(X = x, Y = y)$."},{id:2,type:"multiple-choice",question:"The marginal pmf $p_X(x_i)$ is obtained from the joint pmf by:",options:["$p_X(x_i) = p(x_i, 0)$","$p_X(x_i) = \\prod_j p(x_i, y_j)$","$p_X(x_i) = \\sum_j p(x_i, y_j)$","$p_X(x_i) = p(x_i, x_i)$"],correctIndex:2,difficulty:"medium",explanation:"Sum over all values of $Y$: $p_X(x_i) = P(X = x_i) = \\sum_j p(x_i, y_j)$."},{id:3,type:"multiple-choice",question:"The conditional pmf of $X$ given $Y = y_j$ is:",options:["$p(x_i, y_j)$","$p(x_i, y_j) / p_X(x_i)$","$p_X(x_i) \\cdot p_Y(y_j)$","$p(x_i, y_j) / p_Y(y_j)$"],correctIndex:3,difficulty:"medium",explanation:"Conditional probability: $P(X = x_i \\mid Y = y_j) = \\frac{p(x_i, y_j)}{p_Y(y_j)}$."},{id:4,type:"multiple-choice",question:"For two fair dice rolls $X$ and $Y$, the joint pmf $p(i, j) =$",options:["$1/36$","$1/6$","$1/12$","$(i + j)/36$"],correctIndex:0,difficulty:"easy",explanation:"Each of the 36 pairs $(i, j)$ with $i, j \\in \\{1, \\ldots, 6\\}$ has equal probability $1/36$."},{id:5,type:"multiple-choice",question:"For discrete random variables, $X$ and $Y$ are independent iff:",options:["$p(x_i, y_j) = p_X(x_i) + p_Y(y_j)$ for all $i, j$","$p(x_i, y_j) = p_X(x_i) \\cdot p_Y(y_j)$ for all $i, j$","$p(x_i, y_j) = 0$ for all $i, j$","$p_X(x_i) = p_Y(y_j)$ for all $i, j$"],correctIndex:1,difficulty:"medium",explanation:"Independence: the joint pmf factors into the product of marginals for ALL pairs $(x_i, y_j)$."}],fi=[{id:1,type:"multiple-choice",question:"For continuous $(X, Y)$ with joint density $f$, $P[(X, Y) \\in Q]$ equals:",options:["$\\int_Q f(x, y)\\,dx$","$f(Q)$","$\\iint_Q f(x, y)\\,dx\\,dy$","$\\int_Q f(x)\\,dx \\cdot \\int_Q f(y)\\,dy$"],correctIndex:2,difficulty:"easy",explanation:"Probability is the double integral of the joint density over the region $Q$."},{id:2,type:"multiple-choice",question:"The joint density must satisfy:",options:["$\\iint f(x, y)\\,dx\\,dy = 0$","$\\iint f(x, y)\\,dx\\,dy = \\infty$","$f(x, y) < 0$ for some $(x, y)$","$\\iint f(x, y)\\,dx\\,dy = 1$"],correctIndex:3,difficulty:"easy",explanation:"A joint density integrates to 1 over the entire plane: $\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x, y)\\,dx\\,dy = 1$."},{id:3,type:"multiple-choice",question:"The marginal density $f_X(x)$ is obtained by:",options:["$f_X(x) = \\int_{-\\infty}^{\\infty} f(x, y)\\,dy$","$f_X(x) = f(x, 0)$","$f_X(x) = \\int_{-\\infty}^{\\infty} f(x, y)\\,dx$","$f_X(x) = f(x, x)$"],correctIndex:0,difficulty:"medium",explanation:"Integrate out the other variable: $f_X(x) = \\int_{-\\infty}^{\\infty} f(x, y)\\,dy$."},{id:4,type:"multiple-choice",question:"For continuous random variables, independence means:",options:["$f(x, y) = f_X(x) + f_Y(y)$","$f(x, y) = f_X(x) \\cdot f_Y(y)$ for all $(x, y)$","$F(a, b) = F_X(a) + F_Y(b)$","$f_X(x) = f_Y(y)$ for all $x, y$"],correctIndex:1,difficulty:"medium",explanation:"Independence: the joint density factors as $f(x, y) = f_X(x) \\cdot f_Y(y)$ for all $(x, y)$."},{id:5,type:"multiple-choice",question:"For uniform distribution on the unit square $[0,1] \\times [0,1]$, are $X$ and $Y$ independent?",options:["No, because $f(x, y) = 1$","Only if $x = y$","Yes, because $f(x, y) = f_X(x) \\cdot f_Y(y) = 1 \\cdot 1 = 1$","Cannot be determined"],correctIndex:2,difficulty:"hard",explanation:"The marginals are $f_X(x) = f_Y(y) = 1$ on $[0,1]$. Since $f(x, y) = 1 = f_X(x) f_Y(y)$, $X$ and $Y$ are independent."}],ui=[{id:1,type:"multiple-choice",question:"When transforming $(X, Y)$ to $(U, V)$ via a one-to-one mapping, the new density involves:",options:["Only the old density","The square of the old density","The old density divided by the Jacobian","The old density times the absolute value of the Jacobian"],correctIndex:3,difficulty:"medium",explanation:"The change of variables formula: $g(u, v) = f[Q(u,v), R(u,v)] \\cdot |\\partial(Q, R)/\\partial(u, v)|$."},{id:2,type:"multiple-choice",question:"For the transformation $U = X + Y$, $V = X - Y$, the Jacobian of the inverse transformation is:",options:["$1/2$","$2$","$1$","$-1/2$"],correctIndex:0,difficulty:"hard",explanation:"The inverse is $x = (u+v)/2$, $y = (u-v)/2$. The Jacobian determinant is $|\\partial(x,y)/\\partial(u,v)| = 1/2$."},{id:3,type:"multiple-choice",question:"The density of $U = X + Y$ for general $(X, Y)$ is:",options:["$f_X(u) + f_Y(u)$","$\\int_{-\\infty}^{\\infty} f(x, u-x)\\,dx$","$f(u, u)$","$f_X(u) \\cdot f_Y(u)$"],correctIndex:1,difficulty:"hard",explanation:"The density of the sum is $f_{X+Y}(u) = \\int_{-\\infty}^{\\infty} f(x, u-x)\\,dx$."},{id:4,type:"multiple-choice",question:"When $X$ and $Y$ are independent, the density of $X + Y$ is the:",options:["Sum of $f_X$ and $f_Y$","Product of $f_X$ and $f_Y$","Convolution of $f_X$ and $f_Y$","Maximum of $f_X$ and $f_Y$"],correctIndex:2,difficulty:"medium",explanation:"For independent variables, $f_{X+Y}(u) = \\int f_X(x) f_Y(u-x)\\,dx = (f_X * f_Y)(u)$, the convolution."},{id:5,type:"multiple-choice",question:"For independent $X, Y$ with CDFs $F_X, F_Y$, the CDF of $\\max(X, Y)$ is:",options:["$F_X(t) + F_Y(t)$","$1 - F_X(t) F_Y(t)$","$\\max(F_X(t), F_Y(t))$","$F_X(t) \\cdot F_Y(t)$"],correctIndex:3,difficulty:"hard",explanation:"$P(\\max(X,Y) \\leq t) = P(X \\leq t, Y \\leq t) = P(X \\leq t) P(Y \\leq t) = F_X(t) F_Y(t)$ by independence."}],pi=[{id:1,type:"multiple-choice",question:"The expectation of a continuous random variable with density $f$ is:",options:["$E(X) = \\int_{-\\infty}^{\\infty} t\\,f(t)\\,dt$","$E(X) = \\int_{-\\infty}^{\\infty} f(t)\\,dt$","$E(X) = \\max_t f(t)$","$E(X) = f(0)$"],correctIndex:0,difficulty:"easy",explanation:"Expectation is the weighted average: $E(X) = \\int_{-\\infty}^{\\infty} t f(t)\\,dt$."},{id:2,type:"multiple-choice",question:"For constants $a, b$ and random variables $X, Y$, $E(aX + bY)$ equals:",options:["$E(X) + E(Y)$","$aE(X) + bE(Y)$","$abE(XY)$","$(a+b)E(X+Y)$"],correctIndex:1,difficulty:"easy",explanation:"Expectation is linear: $E(aX + bY) = aE(X) + bE(Y)$."},{id:3,type:"multiple-choice",question:"The expectation of the uniform distribution on $[a, b]$ is:",options:["$a$","$b$","$(a + b)/2$","$b - a$"],correctIndex:2,difficulty:"medium",explanation:"$E(X) = \\int_a^b \\frac{t}{b-a}\\,dt = \\frac{(a+b)}{2}$, the midpoint of the interval."},{id:4,type:"multiple-choice",question:"For the binomial distribution with parameters $n$ and $p$, $E(X)$ equals:",options:["$n$","$p$","$n/p$","$np$"],correctIndex:3,difficulty:"easy",explanation:"The expected number of successes in $n$ Bernoulli trials with success probability $p$ is $E(X) = np$."},{id:5,type:"multiple-choice",question:"If $X$ and $Y$ are independent, then $E(XY)$ equals:",options:["$E(X) \\cdot E(Y)$","$E(X) + E(Y)$","$E(X + Y)$","$E(X)/E(Y)$"],correctIndex:0,difficulty:"medium",explanation:"For independent random variables, $E(XY) = E(X) \\cdot E(Y)$. This does NOT hold in general."}],mi=[{id:1,type:"multiple-choice",question:"The variance of a random variable $X$ is defined as:",options:["$\\text{Var}(X) = E(X)$","$\\text{Var}(X) = E[(X - E(X))^2]$","$\\text{Var}(X) = E(X^2)$","$\\text{Var}(X) = [E(X)]^2$"],correctIndex:1,difficulty:"easy",explanation:"Variance is the expected squared deviation from the mean: $\\text{Var}(X) = E[(X - E(X))^2]$."},{id:2,type:"multiple-choice",question:"The computational formula for variance is:",options:["$\\text{Var}(X) = E(X^2) + [E(X)]^2$","$\\text{Var}(X) = [E(X)]^2 - E(X^2)$","$\\text{Var}(X) = E(X^2) - [E(X)]^2$","$\\text{Var}(X) = E(X^2) \\cdot [E(X)]^2$"],correctIndex:2,difficulty:"medium",explanation:"The shortcut formula: $\\text{Var}(X) = E(X^2) - [E(X)]^2$."},{id:3,type:"multiple-choice",question:"For a constant $a$, $\\text{Var}(aX)$ equals:",options:["$a\\text{Var}(X)$","$\\text{Var}(X)/a$","$\\text{Var}(X)$","$a^2\\text{Var}(X)$"],correctIndex:3,difficulty:"medium",explanation:"Variance scales by the square of the constant: $\\text{Var}(aX) = a^2 \\text{Var}(X)$."},{id:4,type:"multiple-choice",question:"For the uniform distribution on $[a, b]$, the variance is:",options:["$(b - a)^2/12$","$(b - a)/12$","$(b - a)^2$","$(a + b)^2/12$"],correctIndex:0,difficulty:"hard",explanation:"The variance of a uniform distribution on $[a, b]$ is $\\text{Var}(X) = (b - a)^2/12$."},{id:5,type:"multiple-choice",question:"If $X$ and $Y$ are independent, then $\\text{Var}(X + Y)$ equals:",options:["$\\text{Var}(X) \\cdot \\text{Var}(Y)$","$\\text{Var}(X) + \\text{Var}(Y)$","$\\text{Var}(X) - \\text{Var}(Y)$","$[\\text{Var}(X) + \\text{Var}(Y)]^2$"],correctIndex:1,difficulty:"medium",explanation:"For independent variables, variances add: $\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)$."}],yi=[{id:1,type:"multiple-choice",question:"Chebyshev's inequality states that for any $c > 0$:",options:["$P(|X - E(X)| > c) \\geq \\text{Var}(X)/c^2$","$P(|X - E(X)| > c) = \\text{Var}(X)/c^2$","$P(|X - E(X)| > c) \\leq \\text{Var}(X)/c^2$","$P(|X - E(X)| > c) \\leq c^2/\\text{Var}(X)$"],correctIndex:2,difficulty:"easy",explanation:"Chebyshev's inequality: $P(|X - E(X)| > c) \\leq \\frac{\\text{Var}(X)}{c^2}$."},{id:2,type:"multiple-choice",question:"Using Chebyshev's inequality with $c = k\\sigma$, the probability of deviating more than $k$ standard deviations is at most:",options:["$k^2$","$1/k$","$k/\\sigma$","$1/k^2$"],correctIndex:3,difficulty:"medium",explanation:"$P(|X - E(X)| > k\\sigma) \\leq \\frac{\\sigma^2}{(k\\sigma)^2} = \\frac{1}{k^2}$."},{id:3,type:"multiple-choice",question:"By Chebyshev's inequality, at most what fraction of probability lies more than 2 standard deviations from the mean?",options:["$1/4$","$1/2$","$1/8$","$1/16$"],correctIndex:0,difficulty:"medium",explanation:"With $k = 2$: $P(|X - \\mu| > 2\\sigma) \\leq 1/4 = 25\\%$."},{id:4,type:"multiple-choice",question:"Chebyshev's inequality is remarkable because:",options:["It gives exact probabilities","It applies to ANY distribution with finite variance","It applies only to normal distributions","It requires the distribution to be continuous"],correctIndex:1,difficulty:"hard",explanation:"Chebyshev's inequality is universal: it holds for any distribution with finite variance, regardless of shape."},{id:5,type:"multiple-choice",question:"Compared to Chebyshev's bound, the normal distribution has:",options:["The same tail probabilities","Much larger tail probabilities","Much smaller tail probabilities","No tail probabilities"],correctIndex:2,difficulty:"medium",explanation:"Chebyshev bounds are loose. For normal distributions, $P(|X-\\mu| > 2\\sigma) \\approx 4.6\\%$, much less than Chebyshev's 25%."}],xi=[{id:1,type:"multiple-choice",question:"The Weak Law of Large Numbers states that for i.i.d. random variables with mean $m$:",options:["$\\bar{X} \\to m$ with probability 0","$P(\\bar{X} = m) = 1$ for all $n$","$\\bar{X} = m$ always","$\\lim_{n \\to \\infty} P(|\\bar{X} - m| > \\epsilon) = 0$ for every $\\epsilon > 0$"],correctIndex:3,difficulty:"medium",explanation:"The Weak Law: sample averages converge to the population mean in probability. For any $\\epsilon > 0$, $P(|\\bar{X} - m| > \\epsilon) \\to 0$ as $n \\to \\infty$."},{id:2,type:"multiple-choice",question:"The sample mean $\\bar{X} = \\frac{1}{n}\\sum_{k=1}^n X_k$ has variance:",options:["$\\sigma^2/n$","$n\\sigma^2$","$\\sigma^2$","$\\sigma/n$"],correctIndex:0,difficulty:"easy",explanation:"For i.i.d. variables with variance $\\sigma^2$: $\\text{Var}(\\bar{X}) = \\sigma^2/n$. Variance decreases as $n$ increases."},{id:3,type:"multiple-choice",question:"The proof of the Weak Law of Large Numbers uses:",options:["Integration by parts","Chebyshev's inequality","The Chain Rule","L'Hopital's Rule"],correctIndex:1,difficulty:"medium",explanation:"The proof applies Chebyshev's inequality to $\\bar{X}$: $P(|\\bar{X} - m| > \\epsilon) \\leq \\sigma^2/(n\\epsilon^2) \\to 0$."},{id:4,type:"multiple-choice",question:"The Law of Large Numbers justifies:",options:["Using single observations as estimates","Ignoring sample size","Using sample averages to estimate population means","Assuming all distributions are normal"],correctIndex:2,difficulty:"easy",explanation:"The Law of Large Numbers shows that sample averages converge to population means, justifying their use as estimators."},{id:5,type:"multiple-choice",question:"In Bernoulli trials with success probability $p$, the Law of Large Numbers says that $X/n$ (relative frequency) converges to:",options:["$0$","$1$","$1 - p$","$p$"],correctIndex:3,difficulty:"easy",explanation:"The relative frequency of successes $X/n$ converges in probability to $p$, the true success probability. This connects probability to long-run frequency."}],bi=[{id:1,type:"multiple-choice",question:"The Central Limit Theorem states that the standardized sum $Z_n = \\frac{S_n - nm}{\\sigma\\sqrt{n}}$ converges in distribution to which distribution as $n \\to \\infty$?",options:["Standard normal distribution","Exponential distribution","Uniform distribution","Poisson distribution"],correctIndex:0,difficulty:"easy",explanation:"The Central Limit Theorem states that the standardized sum converges to the standard normal distribution $\\Phi(t) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^t e^{-u^2/2}\\,du$."},{id:2,type:"multiple-choice",question:"For the CLT to apply, which conditions must the random variables $X_1, X_2, \\ldots, X_n$ satisfy?",options:["They must be normally distributed","They must be independent with the same distribution and finite variance","They must have variance equal to 1","They must be discrete random variables"],correctIndex:1,difficulty:"medium",explanation:"The CLT requires independence, identical distribution, and finite variance $\\sigma^2 > 0$. Remarkably, the individual distribution can be any distribution meeting these criteria."},{id:3,type:"multiple-choice",question:"For a large $n$, the sum $S_n = X_1 + X_2 + \\cdots + X_n$ is approximately normal with mean $nm$ and variance:",options:["$\\sigma^2$","$\\sigma^2/n$","$n\\sigma^2$","$n^2\\sigma^2$"],correctIndex:2,difficulty:"medium",explanation:"When $X_i$ are i.i.d. with mean $m$ and variance $\\sigma^2$, the sum $S_n$ has variance $n\\sigma^2$ (variances add for independent variables)."},{id:4,type:"multiple-choice",question:"In the normal approximation to the binomial distribution, the continuity correction involves adding or subtracting:",options:["$\\pm 1$","$\\pm \\sigma$","$\\pm 1/n$","$\\pm 1/2$"],correctIndex:3,difficulty:"medium",explanation:"The continuity correction of $\\pm 1/2$ improves accuracy when approximating a discrete distribution (binomial) by a continuous one (normal)."},{id:5,type:"numeric",question:"A fair coin is tossed 100 times. Using the CLT, what is the standard deviation of the number of heads?",correctAnswer:5,numericRange:{min:0,max:50,precision:0},difficulty:"easy",explanation:"For a binomial with $n = 100$ and $p = 1/2$, $\\sigma = \\sqrt{npq} = \\sqrt{100 \\cdot 0.5 \\cdot 0.5} = \\sqrt{25} = 5$."}],gi=[{id:1,type:"multiple-choice",question:"What is the central problem that numerical analysis addresses?",options:["Obtaining approximate numerical solutions when exact computation is impossible or impractical","Finding exact solutions to all mathematical problems","Proving mathematical theorems rigorously","Classifying different types of functions"],correctIndex:0,difficulty:"easy",explanation:"Numerical analysis provides approximate solutions to problems where exact solutions cannot be computed directly, such as roots of high-degree polynomials or integrals without elementary antiderivatives."},{id:2,type:"multiple-choice",question:"Why does the polynomial $x^5 - x + 1 = 0$ illustrate a key problem in numerical analysis?",options:["It has no roots","There is no general formula for roots of polynomials of degree five or higher","It cannot be graphed","Its coefficients are irrational"],correctIndex:1,difficulty:"medium",explanation:"By the Abel-Ruffini theorem, there is no general algebraic formula for roots of polynomials of degree 5 or higher, necessitating numerical methods."},{id:3,type:"multiple-choice",question:"Which integral is mentioned as having no elementary antiderivative?",options:["$\\int x^2\\,dx$","$\\int \\sin(x)\\,dx$","$\\int e^{-x^2}\\,dx$","$\\int \\frac{1}{x}\\,dx$"],correctIndex:2,difficulty:"easy",explanation:"The Gaussian integral $\\int e^{-x^2}\\,dx$ cannot be expressed in terms of elementary functions, yet it is essential in probability and statistics."},{id:4,type:"multiple-choice",question:"Why are polynomials the natural choice for function approximation?",options:["They are the only continuous functions","They can only be evaluated using addition","They always pass through the origin","They can be evaluated using only addition and multiplication, and their derivatives/integrals are again polynomials"],correctIndex:3,difficulty:"medium",explanation:"Polynomials require only addition and multiplication for evaluation, their calculus operations yield polynomials, and the Weierstrass theorem guarantees any continuous function can be uniformly approximated by polynomials."},{id:5,type:"numeric",question:"A polynomial of degree $n$ has how many coefficients (degrees of freedom)?",correctAnswer:0,numericRange:{min:0,max:100,precision:0},difficulty:"easy",explanation:"A polynomial $p(x) = a_0 + a_1 x + \\cdots + a_n x^n$ of degree $n$ has $n + 1$ coefficients. If we enter $n$, the answer is $n + 1$. For this question, if $n = 0$ (constant), the answer is 1 coefficient."}],vi=[{id:1,type:"multiple-choice",question:"The Taylor polynomial of degree $n$ for $f$ centered at $a$ is given by:",options:["$T_n(x) = \\sum_{k=0}^{n} \\frac{f^{(k)}(a)}{k!}(x - a)^k$","$T_n(x) = \\sum_{k=0}^{n} f(a) \\cdot x^k$","$T_n(x) = \\sum_{k=0}^{n} \\frac{f(a)}{k}(x - a)^k$","$T_n(x) = f(a) + f'(a)(x-a)$"],correctIndex:0,difficulty:"easy",explanation:"The Taylor polynomial uses the derivatives of $f$ at the point $a$, divided by $k!$, multiplied by $(x-a)^k$."},{id:2,type:"multiple-choice",question:"The error in Taylor approximation $f(x) - T_n(x)$ is given by the Lagrange remainder formula:",options:["$\\frac{f^{(n)}(\\xi)}{n!}(x - a)^n$","$\\frac{f^{(n+1)}(\\xi)}{(n+1)!}(x - a)^{n+1}$","$\\frac{f'(\\xi)}{2}(x - a)^2$","$f^{(n+1)}(a)(x - a)^{n+1}$"],correctIndex:1,difficulty:"medium",explanation:"The Lagrange remainder involves the $(n+1)$-th derivative evaluated at some $\\xi$ between $a$ and $x$, divided by $(n+1)!$."},{id:3,type:"multiple-choice",question:"What is the determinant of a Vandermonde matrix with distinct points $x_0, x_1, \\ldots, x_n$?",options:["$0$","$1$","$\\prod_{0 \\leq i < j \\leq n} (x_j - x_i)$","$\\sum_{k=0}^{n} x_k$"],correctIndex:2,difficulty:"hard",explanation:"The Vandermonde determinant is $\\prod_{0 \\leq i < j \\leq n} (x_j - x_i)$, which is nonzero when all $x_k$ are distinct, guaranteeing a unique interpolating polynomial."},{id:4,type:"multiple-choice",question:"Given $n + 1$ distinct interpolation points, the unique interpolating polynomial has degree at most:",options:["$n - 1$","$2n$","$n + 1$","$n$"],correctIndex:3,difficulty:"easy",explanation:"With $n + 1$ points, we can determine $n + 1$ coefficients, giving a polynomial of degree at most $n$."},{id:5,type:"multiple-choice",question:"Which is a limitation of Taylor polynomials for practical approximation?",options:["They require knowledge of derivatives, which may be unavailable","They always have degree exactly $n$","They cannot approximate continuous functions","They require complex numbers"],correctIndex:0,difficulty:"medium",explanation:"Taylor polynomials need derivatives at the expansion point, accuracy degrades away from that point, and they may perform poorly for global approximation on an interval."}],_i=[{id:1,type:"multiple-choice",question:"The Lagrange basis polynomial $L_k(x)$ satisfies $L_k(x_j) = \\delta_{kj}$. What does this mean?",options:["$L_k(x_j) = 1$ for all $j$","$L_k(x_j) = 1$ if $j = k$, and $0$ if $j \\neq k$","$L_k(x_j) = 0$ for all $j$","$L_k(x_j) = k$ for all $j$"],correctIndex:1,difficulty:"easy",explanation:'The Kronecker delta $\\delta_{kj}$ equals 1 when $k = j$ and 0 otherwise. This property allows each $L_k$ to "pick out" exactly one data value.'},{id:2,type:"multiple-choice",question:"The Lagrange interpolation formula is:",options:["$p(x) = \\sum_{k=0}^{n} x_k L_k(y)$","$p(x) = \\prod_{k=0}^{n} y_k L_k(x)$","$p(x) = \\sum_{k=0}^{n} y_k L_k(x)$","$p(x) = \\sum_{k=0}^{n} y_k x^k$"],correctIndex:2,difficulty:"easy",explanation:"The Lagrange formula writes the interpolating polynomial as a linear combination of basis polynomials $L_k(x)$, weighted by the data values $y_k$."},{id:3,type:"multiple-choice",question:"For linear interpolation through two points $(x_0, y_0)$ and $(x_1, y_1)$, what is $L_0(x)$?",options:["$\\frac{x - x_0}{x_1 - x_0}$","$\\frac{x_1 - x}{x_1 + x_0}$","$\\frac{x_0 - x_1}{x - x_1}$","$\\frac{x - x_1}{x_0 - x_1}$"],correctIndex:3,difficulty:"medium",explanation:"$L_0(x) = \\frac{x - x_1}{x_0 - x_1}$ equals 1 at $x_0$ and 0 at $x_1$, as required by the Lagrange basis property."},{id:4,type:"multiple-choice",question:"What is a practical drawback of the Lagrange formula?",options:["Adding a new point requires recomputing all basis polynomials","It only works for linear functions","It cannot handle negative function values","It requires the points to be equally spaced"],correctIndex:0,difficulty:"medium",explanation:"When a new point is added, every Lagrange basis polynomial $L_k(x)$ must be recalculated since each depends on all interpolation points."},{id:5,type:"multiple-choice",question:"If $\\omega(x) = (x - x_0)(x - x_1)\\cdots(x - x_n)$, then $\\omega'(x_k)$ equals:",options:["$\\sum_{j \\neq k}(x_k - x_j)$","$\\prod_{j \\neq k}(x_k - x_j)$","$(x_k)^n$","$n \\cdot \\omega(x_k)$"],correctIndex:1,difficulty:"hard",explanation:"By the product rule, $\\omega'(x_k) = \\prod_{j \\neq k}(x_k - x_j)$ since all other factors vanish at $x = x_k$."}],Ti=[{id:1,type:"multiple-choice",question:"The interpolation error formula states that $f(x) - p(x) = \\frac{f^{(n+1)}(\\xi)}{(n+1)!} \\omega(x)$. What is $\\omega(x)$?",options:["$(x - a)^{n+1}$","$x^{n+1}$","$(x - x_0)(x - x_1)\\cdots(x - x_n)$","$\\sum_{k=0}^{n}(x - x_k)$"],correctIndex:2,difficulty:"easy",explanation:"$\\omega(x) = (x - x_0)(x - x_1)\\cdots(x - x_n)$ is the product of factors involving all interpolation points."},{id:2,type:"multiple-choice",question:"The interpolation error formula involves the $(n+1)$-th derivative of $f$ evaluated at some point $\\xi$. Where is $\\xi$ located?",options:["At $x_0$","At $x_n$","Outside the interval $[x_0, x_n]$","In the smallest interval containing $x, x_0, x_1, \\ldots, x_n$"],correctIndex:3,difficulty:"medium",explanation:"The point $\\xi$ lies somewhere in the smallest interval containing all the interpolation points and the evaluation point $x$."},{id:3,type:"multiple-choice",question:"The proof of the interpolation error formula uses which classical theorem?",options:["Rolle's Theorem","Mean Value Theorem","Fundamental Theorem of Calculus","L'Hopital's Rule"],correctIndex:0,difficulty:"medium",explanation:"The proof repeatedly applies Rolle's theorem to show that $g^{(n+1)}$ has at least one zero, which gives the error formula."},{id:4,type:"multiple-choice",question:"What phenomenon can occur when using equally spaced interpolation points for some functions?",options:["The interpolation becomes exact","Runge's phenomenon: error can grow as $n$ increases","The error decreases exponentially","The polynomial becomes constant"],correctIndex:1,difficulty:"medium",explanation:"Runge's phenomenon shows that for some functions, equally spaced points can cause the interpolation error to grow unboundedly as the number of points increases."},{id:5,type:"multiple-choice",question:"Comparing interpolation error to Taylor remainder, which term replaces $(x-a)^{n+1}$?",options:["$n!$","$f^{(n+1)}(\\xi)$","$\\omega(x)$","$(x - x_0)^{n+1}$"],correctIndex:2,difficulty:"easy",explanation:"In interpolation, $\\omega(x) = (x - x_0)\\cdots(x - x_n)$ replaces $(x-a)^{n+1}$. Taylor expansion can be viewed as interpolation at $a$ with multiplicity $n+1$."}],Ai=[{id:1,type:"multiple-choice",question:"The first-order divided difference $f[x_k, x_{k+1}]$ is defined as:",options:["$f(x_{k+1}) - f(x_k)$","$f(x_k) \\cdot f(x_{k+1})$","$\\frac{f(x_k) + f(x_{k+1})}{2}$","$\\frac{f(x_{k+1}) - f(x_k)}{x_{k+1} - x_k}$"],correctIndex:3,difficulty:"easy",explanation:"The first divided difference is the slope of the secant line through the two points, generalizing the difference quotient."},{id:2,type:"multiple-choice",question:"What is an advantage of Newton's interpolation formula over Lagrange's?",options:["Adding a new point only adds one term","It requires fewer data points","It works only for polynomials","It requires no arithmetic operations"],correctIndex:0,difficulty:"easy",explanation:"Newton's formula is incremental: adding a new point $x_{n+1}$ only requires computing one new divided difference and adding one term."},{id:3,type:"multiple-choice",question:"The forward difference operator $\\Delta$ is defined as $\\Delta f_k = $",options:["$f_k - f_{k-1}$","$f_{k+1} - f_k$","$f_{k+1} + f_k$","$\\frac{f_{k+1} - f_k}{h}$"],correctIndex:1,difficulty:"easy",explanation:"The forward difference $\\Delta f_k = f_{k+1} - f_k$ measures the change in $f$ at consecutive points."},{id:4,type:"multiple-choice",question:"For equally spaced points with spacing $h$, the divided difference $f[x_0, x_1, \\ldots, x_n]$ equals:",options:["$\\Delta^n f_0$","$n! \\, h^n \\Delta^n f_0$","$\\frac{\\Delta^n f_0}{n! \\, h^n}$","$\\frac{\\Delta^n f_0}{h}$"],correctIndex:2,difficulty:"medium",explanation:"The divided difference is related to the forward difference by $f[x_0, \\ldots, x_n] = \\frac{\\Delta^n f_0}{n! \\, h^n}$."},{id:5,type:"multiple-choice",question:"In Newton's forward difference formula, $p(x_0 + sh) = \\sum_{k=0}^{n} \\binom{s}{k} \\Delta^k f_0$, what is $\\binom{s}{k}$?",options:["The ordinary binomial coefficient $\\frac{n!}{k!(n-k)!}$","$s^k$","The Stirling number of the first kind","The generalized binomial coefficient $\\frac{s(s-1)(s-2)\\cdots(s-k+1)}{k!}$"],correctIndex:3,difficulty:"medium",explanation:"The generalized binomial coefficient extends to non-integer $s$: $\\binom{s}{k} = \\frac{s(s-1)\\cdots(s-k+1)}{k!}$."}],qi=[{id:1,type:"multiple-choice",question:"The falling factorial $x^{(n)}$ is defined as:",options:["$x(x-1)(x-2)\\cdots(x-n+1)$","$x(x+1)(x+2)\\cdots(x+n-1)$","$x^n$","$\\frac{x!}{(x-n)!}$ only"],correctIndex:0,difficulty:"easy",explanation:"The falling factorial $x^{(n)} = x(x-1)(x-2)\\cdots(x-n+1)$ is a product of $n$ consecutive descending integers starting from $x$."},{id:2,type:"multiple-choice",question:"The key property of factorial polynomials is that $\\Delta x^{(n)} = $",options:["$x^{(n-1)}$","$n \\cdot x^{(n-1)}$","$n! \\cdot x^{(n-1)}$","$(n-1) \\cdot x^{(n)}$"],correctIndex:1,difficulty:"easy",explanation:"Just as $\\frac{d}{dx}x^n = nx^{n-1}$, we have $\\Delta x^{(n)} = n \\cdot x^{(n-1)}$. This makes factorial polynomials natural for discrete calculus."},{id:3,type:"multiple-choice",question:"What is $x^{(2)}$ when $x = 5$?",options:["$25$","$10$","$20$","$30$"],correctIndex:2,difficulty:"easy",explanation:"$x^{(2)} = x(x-1)$, so $5^{(2)} = 5 \\cdot 4 = 20$."},{id:4,type:"multiple-choice",question:"The Stirling numbers connect ordinary powers and factorial polynomials. If $x^{(n)} = \\sum_{k=0}^{n} s(n, k) x^k$, what are the $s(n,k)$ called?",options:["Stirling numbers of the second kind","Euler numbers","Bernoulli numbers","Stirling numbers of the first kind"],correctIndex:3,difficulty:"medium",explanation:"Stirling numbers of the first kind $s(n,k)$ expand falling factorials in terms of ordinary powers. Stirling numbers of the second kind do the reverse."},{id:5,type:"multiple-choice",question:"To find $\\sum_{k=0}^{n-1} k^2$ using factorial polynomials, we first express $k^2$ as:",options:["$k^{(2)} + k^{(1)}$","$k^{(2)}$","$k^{(2)} - k^{(1)}$","$2k^{(2)}$"],correctIndex:0,difficulty:"medium",explanation:"Since $k^{(2)} = k(k-1) = k^2 - k$, we have $k^2 = k^{(2)} + k = k^{(2)} + k^{(1)}$. This allows summation using the anti-difference formula."}],Ii=[{id:1,type:"multiple-choice",question:"The Chebyshev polynomial $T_n(x)$ is defined on $[-1, 1]$ by:",options:["$T_n(x) = \\sin(n \\arcsin x)$","$T_n(x) = \\cos(n \\arccos x)$","$T_n(x) = \\tan(n \\arctan x)$","$T_n(x) = e^{n \\ln x}$"],correctIndex:1,difficulty:"easy",explanation:"The Chebyshev polynomials are defined by $T_n(x) = \\cos(n \\arccos x)$, connecting polynomial algebra to trigonometry."},{id:2,type:"multiple-choice",question:"The Chebyshev polynomials satisfy the recurrence relation:",options:["$T_{n+1}(x) = xT_n(x) - T_{n-1}(x)$","$T_{n+1}(x) = 2xT_n(x) + T_{n-1}(x)$","$T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x)$","$T_{n+1}(x) = T_n(x) + T_{n-1}(x)$"],correctIndex:2,difficulty:"medium",explanation:"The recurrence $T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x)$ follows from the cosine addition formula, with $T_0(x) = 1$ and $T_1(x) = x$."},{id:3,type:"multiple-choice",question:"What is $T_2(x)$?",options:["$x^2$","$2x^2 + 1$","$x^2 - 1$","$2x^2 - 1$"],correctIndex:3,difficulty:"easy",explanation:"Using the recurrence: $T_2(x) = 2x \\cdot T_1(x) - T_0(x) = 2x \\cdot x - 1 = 2x^2 - 1$."},{id:4,type:"multiple-choice",question:"The zeros of $T_n(x)$ on $[-1, 1]$ are called Chebyshev nodes. Where are they located?",options:["Clustered near the endpoints of the interval","Clustered near the center of the interval","Equally spaced throughout the interval","At the integers from $-1$ to $1$"],correctIndex:0,difficulty:"medium",explanation:"The Chebyshev nodes $x_k = \\cos\\left(\\frac{(2k+1)\\pi}{2n}\\right)$ are clustered near the endpoints, which counteracts polynomial oscillation near boundaries."},{id:5,type:"multiple-choice",question:"Why are Chebyshev nodes optimal for polynomial interpolation?",options:["They make the interpolating polynomial unique","They minimize the maximum value of $|\\omega(x)|$ over the interval","They make all divided differences equal","They ensure the polynomial has integer coefficients"],correctIndex:1,difficulty:"medium",explanation:"Using Chebyshev nodes makes $\\omega(x)$ a multiple of $T_{n+1}(x)$, minimizing $\\max|\\omega(x)|$ and thus the interpolation error bound."}],wi=[{id:1,type:"multiple-choice",question:"The trapezoidal rule approximates $\\int_a^b f(x)\\,dx$ by:",options:["$(b - a) \\cdot f(a)$","$(b - a) \\cdot f\\left(\\frac{a+b}{2}\\right)$","$\\frac{b - a}{2}[f(a) + f(b)]$","$\\frac{b - a}{3}[f(a) + f(b)]$"],correctIndex:2,difficulty:"easy",explanation:"The trapezoidal rule uses linear interpolation between endpoints, giving the area of a trapezoid: $\\frac{b - a}{2}[f(a) + f(b)]$."},{id:2,type:"multiple-choice",question:"The error in the single-interval trapezoidal rule is:",options:["$O(b-a)$","$O((b-a)^2)$","$O((b-a)^4)$","$O((b-a)^3)$"],correctIndex:3,difficulty:"medium",explanation:"The error is $-\\frac{(b-a)^3}{12}f''(\\xi)$, which is $O((b-a)^3)$. This means the rule is exact for linear functions."},{id:3,type:"multiple-choice",question:"In the composite trapezoidal rule with $n$ subintervals, the weights for interior points are:",options:["$2$","$1$","$4$","$h$"],correctIndex:0,difficulty:"easy",explanation:"The composite rule is $\\frac{h}{2}[f(x_0) + 2f(x_1) + 2f(x_2) + \\cdots + 2f(x_{n-1}) + f(x_n)]$. Interior points get weight 2."},{id:4,type:"multiple-choice",question:"For the composite trapezoidal rule, the global error is:",options:["$O(h)$","$O(h^2)$","$O(h^3)$","$O(h^4)$"],correctIndex:1,difficulty:"medium",explanation:"The composite error is $-\\frac{(b-a)h^2}{12}f''(\\xi) = O(h^2)$. Halving $h$ reduces error by a factor of 4."},{id:5,type:"numeric",question:"Using the trapezoidal rule with $a = 0$, $b = 2$, $f(0) = 1$, and $f(2) = 5$, what is the approximate integral?",correctAnswer:6,numericRange:{min:0,max:20,precision:0},difficulty:"easy",explanation:"$\\frac{b - a}{2}[f(a) + f(b)] = \\frac{2 - 0}{2}[1 + 5] = 1 \\cdot 6 = 6$."}],ki=[{id:1,type:"multiple-choice",question:"Simpson's rule on $[a, b]$ with midpoint $m = (a+b)/2$ is:",options:["$\\frac{b - a}{2}[f(a) + f(b)]$","$\\frac{b - a}{4}[f(a) + 2f(m) + f(b)]$","$\\frac{b - a}{6}[f(a) + 4f(m) + f(b)]$","$\\frac{b - a}{3}[f(a) + f(m) + f(b)]$"],correctIndex:2,difficulty:"easy",explanation:"Simpson's rule uses quadratic interpolation through three points, yielding $\\frac{b - a}{6}[f(a) + 4f(m) + f(b)]$."},{id:2,type:"multiple-choice",question:"The error term in Simpson's rule involves which derivative?",options:["$f''(\\xi)$","$f'''(\\xi)$","$f^{(5)}(\\xi)$","$f^{(4)}(\\xi)$"],correctIndex:3,difficulty:"medium",explanation:"Remarkably, Simpson's rulebased on quadratic interpolationis exact for cubics. The error involves $f^{(4)}(\\xi)$, not $f'''$."},{id:3,type:"multiple-choice",question:"For the composite Simpson's rule with $n$ subintervals, $n$ must be:",options:["An even number","An odd number","Any positive integer","A power of 2"],correctIndex:0,difficulty:"easy",explanation:"Simpson's rule uses pairs of subintervals (three points each), so $n$ must be even."},{id:4,type:"multiple-choice",question:"The pattern of coefficients in composite Simpson's rule is:",options:["$1, 2, 2, 2, \\ldots, 2, 1$","$1, 4, 2, 4, 2, \\ldots, 4, 1$","$1, 1, 1, \\ldots, 1, 1$","$1, 3, 3, 1, 3, 3, \\ldots$"],correctIndex:1,difficulty:"medium",explanation:"The coefficients alternate: $1, 4, 2, 4, 2, \\ldots, 2, 4, 1$, with 4 at odd-indexed interior points and 2 at even-indexed interior points."},{id:5,type:"multiple-choice",question:"The composite Simpson's rule has error of order:",options:["$O(h^2)$","$O(h^3)$","$O(h^4)$","$O(h^5)$"],correctIndex:2,difficulty:"medium",explanation:"Simpson's rule has $O(h^4)$ error. Halving the step size reduces the error by a factor of 16, making it much more accurate than the trapezoidal rule."}],Fi=[{id:1,type:"multiple-choice",question:"The Euler summation formula connects:",options:["Derivatives and integrals","Polynomials and rational functions","Complex and real numbers","Finite sums and integrals"],correctIndex:3,difficulty:"easy",explanation:"The Euler summation formula expresses a finite sum $\\sum_{k=1}^{n} f(k)$ in terms of an integral $\\int_1^n f(x)\\,dx$ plus correction terms."},{id:2,type:"multiple-choice",question:"Which special numbers appear in the Euler summation formula?",options:["Bernoulli numbers","Prime numbers","Fibonacci numbers","Catalan numbers"],correctIndex:0,difficulty:"easy",explanation:"The correction terms in the Euler summation formula involve the Bernoulli numbers $B_{2k}$."},{id:3,type:"multiple-choice",question:"What is the value of $B_2$, the second Bernoulli number?",options:["$-\\frac{1}{2}$","$\\frac{1}{6}$","$-\\frac{1}{30}$","$\\frac{1}{42}$"],correctIndex:1,difficulty:"medium",explanation:"The Bernoulli numbers are $B_0 = 1$, $B_1 = -\\frac{1}{2}$, $B_2 = \\frac{1}{6}$, $B_4 = -\\frac{1}{30}$, etc."},{id:4,type:"multiple-choice",question:"Stirling's formula gives the asymptotic approximation:",options:["$n! \\sim n^n$","$n! \\sim e^n$","$n! \\sim \\sqrt{2\\pi n}\\left(\\frac{n}{e}\\right)^n$","$n! \\sim 2^n$"],correctIndex:2,difficulty:"medium",explanation:"Stirling's formula $n! \\sim \\sqrt{2\\pi n}(n/e)^n$ is derived by applying the Euler summation formula to $\\ln(n!) = \\sum_{k=1}^{n} \\ln k$."},{id:5,type:"multiple-choice",question:"In the asymptotic expansion for the harmonic sum $\\sum_{k=1}^{n} \\frac{1}{k}$, what constant appears?",options:["$\\pi$","$e$","The golden ratio $\\phi$","The Euler-Mascheroni constant $\\gamma \\approx 0.5772$"],correctIndex:3,difficulty:"medium",explanation:"The harmonic sum satisfies $\\sum_{k=1}^{n} \\frac{1}{k} = \\ln n + \\gamma + O(1/n)$, where $\\gamma \\approx 0.5772$ is the Euler-Mascheroni constant."}],Pi={0:t,1:i,2:n,3:a,4:o,5:s,6:r,7:$,8:l,9:c,10:d,11:h,12:f,13:u,14:p,15:m,16:y,17:x,18:b,19:g,20:v,21:_,22:T,23:A,24:q,25:I,26:w,27:k,28:F,29:P,30:S,31:z,32:B,33:Q,34:C,35:j,36:X,37:Y,38:D,39:R,40:W,41:L,42:E,43:V,44:N,45:O,46:H,47:G,48:U,49:J,50:M,51:Z,52:K,53:ee,54:te,55:ie,56:ne,57:ae,58:oe,59:se,60:re,61:$e,62:le,63:ce,64:de,65:he,66:fe,67:ue,68:pe,69:me,70:ye,71:xe,72:be,73:ge,74:ve,75:_e,76:Te,77:Ae,78:qe,79:Ie,80:we,81:ke,82:Fe,83:Pe,84:Se,85:ze,86:Be,87:Qe,88:Ce,89:je,90:Xe,91:Ye,92:De,93:Re,94:We,95:Le,96:Ee,97:Ve,98:Ne,99:Oe,100:He,101:Ge,102:Ue,103:Je,104:Me,105:Ze,106:Ke,107:et,108:tt,109:it,110:nt,111:at,112:ot,113:st,114:rt,115:$t,116:lt,117:ct,118:dt,119:ht,120:ft,121:ut,122:pt,123:mt,124:yt,125:xt,126:bt,127:gt,128:vt,129:_t,130:Tt,131:At,132:qt,133:It,134:wt,135:kt,136:Ft,137:Pt,138:St,139:zt,140:Bt,141:Qt,142:Ct,143:jt,144:Xt,145:Yt,146:Dt,147:Rt,148:Wt,149:Lt,150:Et,151:Vt,152:Nt,153:Ot,154:Ht,155:Gt,156:Ut,157:Jt,158:Mt,159:Zt,160:Kt,161:ei,162:ti,163:ii,164:ni,165:ai,166:oi,167:si,168:ri,169:$i,170:li,171:ci,172:di,173:hi,174:fi,175:ui,176:pi,177:mi,178:yi,179:xi,180:bi,181:gi,182:vi,183:_i,184:Ti,185:Ai,186:qi,187:Ii,188:wi,189:ki,190:Fi};function Si(e){return Pi[e]??null}export{Si as g};
