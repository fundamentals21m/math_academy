import{j as e}from"./vendor-animation-0o8UKZ_1.js";import{L as Y,C as _,S as X}from"./Callout-B_HVXLUb.js";import{D as x,T as C,E as A,R as M}from"./ContentBlocks-BGX5GcBB.js";import{I as s,M as i}from"./MathBlock-_bBfq7Jh.js";import{r as u}from"./vendor-react-Drj8qL0h.js";import"./index-Df8Jh5wn.js";import"./vendor-math-p018AHG0.js";import"./vendor-firebase-core-BXWtuYvb.js";const L=[{id:"s06-e01",type:"multiple-choice",question:"In simple linear regression $Y = \\beta_0 + \\beta_1 X + \\epsilon$, what does $\\beta_0$ represent?",options:["The slope","The error","The prediction","The intercept"],correctIndex:3,difficulty:"easy",explanation:"$\\beta_0$ is the intercept - the expected value of $Y$ when $X = 0$."},{id:"s06-e02",type:"multiple-choice",question:"The least squares method minimizes:",options:["The sum of squared residuals (RSS)","The sum of residuals","The variance of predictions","The sum of absolute residuals"],correctIndex:0,difficulty:"easy",explanation:"Least squares finds coefficients that minimize RSS = $\\sum(y_i - \\hat{y}_i)^2$."},{id:"s06-e03",type:"multiple-choice",question:"What does $R^2$ measure?",options:["The number of predictors","The proportion of variance explained by the model","The slope of the regression line","The intercept of the regression line"],correctIndex:1,difficulty:"easy",explanation:"$R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}}$ measures how much of the total variance in $Y$ is explained by the model."},{id:"s06-e04",type:"text",question:"What do we call the difference between the observed value and the predicted value? (one word)",correctAnswer:"residual",difficulty:"easy",explanation:"The residual is $e_i = y_i - \\hat{y}_i$, the difference between observed and predicted values."},{id:"s06-e05",type:"multiple-choice",question:"A slope coefficient $\\beta_1 = 0.05$ means:",options:["Y is 5% of X","The correlation is 0.05","A one-unit increase in X is associated with a 0.05 increase in Y","The model explains 5% of variance"],correctIndex:2,difficulty:"easy",explanation:"The slope tells us: for each one-unit increase in $X$, we expect $Y$ to increase by $\\beta_1 = 0.05$ units."},{id:"s06-m01",type:"multiple-choice",question:"The null hypothesis $H_0: \\beta_1 = 0$ tests whether:",options:["The intercept is zero","The R-squared is zero","The residuals are zero","There is no relationship between X and Y"],correctIndex:3,difficulty:"medium",explanation:"If $\\beta_1 = 0$, then $X$ has no linear effect on $Y$ - there is no relationship."},{id:"s06-m02",type:"multiple-choice",question:"A 95% confidence interval for $\\beta_1$ is approximately:",options:["$\\hat{\\beta}_1 \\pm 2 \\cdot \\text{SE}(\\hat{\\beta}_1)$","$\\hat{\\beta}_1 \\pm \\text{SE}(\\hat{\\beta}_1)$","$\\hat{\\beta}_1 \\pm \\text{RSS}$","$\\hat{\\beta}_1 \\pm 3 \\cdot \\text{SE}(\\hat{\\beta}_1)$"],correctIndex:0,difficulty:"medium",explanation:"A 95% CI is approximately the estimate $\\pm$ 2 standard errors (more precisely, $\\pm$ 1.96 SE)."},{id:"s06-m03",type:"numeric",question:"If $R^2 = 0.64$, what percentage of the variance in Y is explained by X?",correctAnswer:64,numericRange:{min:0,max:100,precision:0},difficulty:"medium",explanation:"$R^2 = 0.64$ means 64% of the variance in $Y$ is explained by the linear relationship with $X$."},{id:"s06-m04",type:"multiple-choice",question:"The t-statistic for testing $\\beta_1 = 0$ is calculated as:",options:["$\\hat{\\beta}_1 \\times \\text{SE}(\\hat{\\beta}_1)$","$\\hat{\\beta}_1 / \\text{SE}(\\hat{\\beta}_1)$","$\\text{SE}(\\hat{\\beta}_1) / \\hat{\\beta}_1$","$\\hat{\\beta}_1 - \\text{SE}(\\hat{\\beta}_1)$"],correctIndex:1,difficulty:"medium",explanation:"$t = \\frac{\\hat{\\beta}_1 - 0}{\\text{SE}(\\hat{\\beta}_1)} = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}$"},{id:"s06-m05",type:"multiple-choice",question:"RSE (Residual Standard Error) estimates:",options:["The standard deviation of $\\beta_1$","The standard deviation of X","The standard deviation of the error term $\\epsilon$","The standard deviation of Y"],correctIndex:2,difficulty:"medium",explanation:"RSE = $\\sqrt{\\frac{\\text{RSS}}{n-2}}$ estimates $\\sigma$, the standard deviation of the error term."},{id:"s06-h01",type:"multiple-choice",question:"In simple linear regression, $R^2 = r^2$ where $r$ is:",options:["The regression coefficient","The residual","The standard error","The correlation between X and Y"],correctIndex:3,difficulty:"hard",explanation:"In simple linear regression (one predictor), $R^2$ equals the square of the correlation coefficient between $X$ and $Y$."},{id:"s06-h02",type:"multiple-choice",question:"A p-value of 0.001 for $\\beta_1$ means:",options:["The probability of seeing such extreme results if $\\beta_1 = 0$ is 0.001","The probability that $\\beta_1 = 0$ is 0.001","We are 0.1% confident in our result","The effect size is 0.001"],correctIndex:0,difficulty:"hard",explanation:"The p-value is the probability of observing a t-statistic this extreme (or more) if the null hypothesis ($\\beta_1 = 0$) were true."},{id:"s06-h03",type:"multiple-choice",question:"The formula $\\hat{\\beta}_1 = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum(x_i - \\bar{x})^2}$ shows that $\\hat{\\beta}_1$:",options:["Depends only on $Y$ values","Is a weighted sum of the $y_i$ values","Depends only on $X$ values","Always equals the correlation"],correctIndex:1,difficulty:"hard",explanation:"The numerator involves products of deviations. This can be rewritten to show $\\hat{\\beta}_1$ is a linear combination of the $y_i$."},{id:"s06-h04",type:"numeric",question:"If TSS = 1000 and RSS = 200, what is $R^2$? (Enter as a decimal)",correctAnswer:.8,numericRange:{min:0,max:1,precision:2},difficulty:"hard",explanation:"$R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}} = 1 - \\frac{200}{1000} = 1 - 0.2 = 0.8$"}];function z(){const[n,y]=u.useState([{x:50,y:180},{x:100,y:150},{x:150,y:140},{x:200,y:100},{x:250,y:80}]),[f,v]=u.useState(null),h=320,j=240,a=20,c=u.useMemo(()=>{if(n.length<2)return null;const t=n.length,l=n.reduce((o,r)=>o+r.x,0),d=n.reduce((o,r)=>o+r.y,0),m=n.reduce((o,r)=>o+r.x*r.y,0),p=n.reduce((o,r)=>o+r.x*r.x,0),b=(t*m-l*d)/(t*p-l*l),g=(d-b*l)/t,q=d/t,S=n.reduce((o,r)=>o+Math.pow(r.y-q,2),0),w=n.reduce((o,r)=>{const I=b*r.x+g;return o+Math.pow(r.y-I,2)},0),E=S>0?1-w/S:0;return{slope:b,intercept:g,rss:w,rSquared:E}},[n]),T=u.useCallback(t=>{if(f!==null)return;const d=t.currentTarget.getBoundingClientRect(),m=t.clientX-d.left,p=t.clientY-d.top;m>a&&m<h-a&&p>a&&p<j-a&&y([...n,{x:m,y:p}])},[n,f]),R=u.useCallback(t=>l=>{l.stopPropagation(),v(t)},[]),N=u.useCallback(t=>{if(f===null)return;const d=t.currentTarget.getBoundingClientRect(),m=Math.max(a,Math.min(h-a,t.clientX-d.left)),p=Math.max(a,Math.min(j-a,t.clientY-d.top));y(n.map((b,g)=>g===f?{x:m,y:p}:b))},[f,n]),$=u.useCallback(()=>{v(null)},[]),k=()=>y([]);return e.jsxs("div",{className:"p-6 bg-dark-800/50 rounded-xl",children:[e.jsx("h3",{className:"text-lg font-semibold text-dark-100 mb-4",children:"Linear Regression Fitter"}),e.jsxs("div",{className:"flex gap-4",children:[e.jsxs("svg",{width:h,height:j,className:"bg-dark-900 rounded-lg cursor-crosshair",onClick:T,onMouseMove:N,onMouseUp:$,onMouseLeave:$,children:[[.25,.5,.75].map(t=>e.jsxs("g",{children:[e.jsx("line",{x1:a,y1:j*t,x2:h-a,y2:j*t,stroke:"#374151",strokeDasharray:"4,4"}),e.jsx("line",{x1:h*t,y1:a,x2:h*t,y2:j-a,stroke:"#374151",strokeDasharray:"4,4"})]},t)),c&&e.jsx("line",{x1:a,y1:c.slope*a+c.intercept,x2:h-a,y2:c.slope*(h-a)+c.intercept,stroke:"#10b981",strokeWidth:2}),n.map((t,l)=>e.jsx("circle",{cx:t.x,cy:t.y,r:8,fill:f===l?"#60a5fa":"#3b82f6",stroke:"#1e3a8a",strokeWidth:2,className:"cursor-move",onMouseDown:R(l)},l))]}),e.jsxs("div",{className:"flex-1 space-y-3",children:[e.jsxs("div",{className:"text-sm",children:[e.jsx("span",{className:"text-dark-400",children:"Points:"}),e.jsx("span",{className:"text-dark-200 ml-2",children:n.length})]}),c&&e.jsxs(e.Fragment,{children:[e.jsxs("div",{className:"text-sm",children:[e.jsx("span",{className:"text-dark-400",children:"Slope (β₁):"}),e.jsx("span",{className:"text-emerald-400 ml-2 font-mono",children:c.slope.toFixed(3)})]}),e.jsxs("div",{className:"text-sm",children:[e.jsx("span",{className:"text-dark-400",children:"Intercept (β₀):"}),e.jsx("span",{className:"text-emerald-400 ml-2 font-mono",children:c.intercept.toFixed(1)})]}),e.jsxs("div",{className:"text-sm",children:[e.jsx("span",{className:"text-dark-400",children:"RSS:"}),e.jsx("span",{className:"text-amber-400 ml-2 font-mono",children:c.rss.toFixed(1)})]}),e.jsxs("div",{className:"text-sm",children:[e.jsx("span",{className:"text-dark-400",children:"R²:"}),e.jsx("span",{className:"text-blue-400 ml-2 font-mono",children:c.rSquared.toFixed(3)})]})]}),e.jsx("button",{onClick:k,className:"mt-4 px-3 py-1.5 text-xs bg-dark-700 hover:bg-dark-600 text-dark-300 rounded-lg transition-colors",children:"Clear Points"})]})]}),e.jsx("p",{className:"mt-4 text-xs text-dark-500",children:"Click to add points. Drag points to adjust. The green line shows the least squares fit."})]})}function Q(){return e.jsxs(Y,{sectionId:6,children:[e.jsx("h2",{children:"Simple Linear Regression"}),e.jsxs("p",{children:["Simple linear regression is a very straightforward approach for predicting a quantitative response ",e.jsx(s,{children:"Y"})," on the basis of a single predictor variable ",e.jsx(s,{children:"X"}),". It assumes that there is approximately a linear relationship between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"}),"."]}),e.jsxs(x,{title:"Simple Linear Regression Model",children:[e.jsx("p",{children:"We can write this relationship as:"}),e.jsx(i,{children:"Y \\approx \\beta_0 + \\beta_1 X"}),e.jsxs("p",{className:"mt-2",children:["Here ",e.jsx(s,{children:"\\beta_0"})," and ",e.jsx(s,{children:"\\beta_1"})," are two unknown constants that represent the ",e.jsx("em",{children:"intercept"})," and ",e.jsx("em",{children:"slope"})," terms in the linear model."]}),e.jsxs("p",{className:"mt-2",children:["Together, ",e.jsx(s,{children:"\\beta_0"})," and ",e.jsx(s,{children:"\\beta_1"})," are known as the model",e.jsx("strong",{children:" coefficients"})," or ",e.jsx("strong",{children:"parameters"}),"."]})]}),e.jsxs("p",{children:["Once we have used our training data to produce estimates ",e.jsx(s,{children:"\\hat{\\beta}_0"})," and ",e.jsx(s,{children:"\\hat{\\beta}_1"})," for the model coefficients, we can predict future values using:"]}),e.jsx(i,{children:"\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x"}),e.jsxs("p",{children:["where ",e.jsx(s,{children:"\\hat{y}"})," indicates a prediction of ",e.jsx(s,{children:"Y"})," on the basis of ",e.jsx(s,{children:"X = x"}),". The hat symbol denotes the estimated value."]}),e.jsx("h2",{children:"Estimating the Coefficients"}),e.jsxs("p",{children:["Let ",e.jsx(s,{children:"(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)"})," represent ",e.jsx(s,{children:"n"})," observation pairs. We want to find coefficient estimates ",e.jsx(s,{children:"\\hat{\\beta}_0"})," and ",e.jsx(s,{children:"\\hat{\\beta}_1"})," such that the resulting line is as close as possible to the ",e.jsx(s,{children:"n"})," data points."]}),e.jsxs(x,{title:"Residual Sum of Squares (RSS)",children:[e.jsxs("p",{children:["The most common approach is to minimize the ",e.jsx("em",{children:"residual sum of squares"}),":"]}),e.jsx(i,{children:"\\text{RSS} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)^2"}),e.jsxs("p",{className:"mt-2",children:["The RSS measures the total squared deviation between the observed values ",e.jsx(s,{children:"y_i"})," and the values predicted by the linear model."]})]}),e.jsx("h3",{children:"Interactive Visualization"}),e.jsx("p",{children:"Try adding and moving points in the visualization below to see how the least squares regression line changes in real-time:"}),e.jsx("div",{className:"my-6",children:e.jsx(z,{})}),e.jsxs(C,{title:"Least Squares Coefficient Estimates",children:[e.jsx("p",{children:"Using calculus, one can show that the minimizers of RSS are:"}),e.jsx(i,{children:"\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}"}),e.jsx(i,{children:"\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}"}),e.jsxs("p",{className:"mt-2",children:["where ",e.jsx(s,{children:"\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i"})," and ",e.jsx(s,{children:"\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i"})," are the sample means."]})]}),e.jsxs(A,{title:"Advertising and Sales",children:[e.jsxs("p",{children:["Consider predicting ",e.jsx("strong",{children:"sales"})," based on ",e.jsx("strong",{children:"TV advertising budget"}),". Using the advertising dataset with 200 markets, the least squares fit gives:"]}),e.jsx(i,{children:"\\widehat{\\text{sales}} = 7.03 + 0.0475 \\times \\text{TV}"}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"Interpretation:"})," An additional $1,000 spent on TV advertising is associated with selling approximately 47.5 additional units of the product."]})]}),e.jsx("h2",{children:"Assessing the Accuracy of the Coefficient Estimates"}),e.jsxs("p",{children:["The true relationship between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"})," takes the form ",e.jsx(s,{children:"Y = f(X) + \\epsilon"})," for some unknown function ",e.jsx(s,{children:"f"}),". If ",e.jsx(s,{children:"f"})," is approximated by a linear function, we can write:"]}),e.jsx(i,{children:"Y = \\beta_0 + \\beta_1 X + \\epsilon"}),e.jsxs("p",{children:["The error term ",e.jsx(s,{children:"\\epsilon"})," is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that affect ",e.jsx(s,{children:"Y"}),", and there may be measurement error."]}),e.jsxs(x,{title:"Population Regression Line",children:[e.jsxs("p",{children:["The model ",e.jsx(s,{children:"Y = \\beta_0 + \\beta_1 X + \\epsilon"})," defines the ",e.jsx("em",{children:"population regression line"}),", which is the best linear approximation to the true relationship between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"}),"."]}),e.jsxs("p",{className:"mt-2",children:["The least squares regression line ",e.jsx(s,{children:"\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x"})," is an estimate of this population line, based on our sample of observations."]})]}),e.jsx("h3",{children:"Standard Errors"}),e.jsxs("p",{children:["If we estimate ",e.jsx(s,{children:"\\beta_0"})," and ",e.jsx(s,{children:"\\beta_1"})," using a large number of different data sets drawn from the same population, we would get different estimates each time. The ",e.jsx("em",{children:"standard error"})," tells us the average amount by which these estimates differ from the actual value."]}),e.jsxs(x,{title:"Standard Errors of Coefficient Estimates",children:[e.jsx(i,{children:"\\text{SE}(\\hat{\\beta}_0)^2 = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\right]"}),e.jsx(i,{children:"\\text{SE}(\\hat{\\beta}_1)^2 = \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}"}),e.jsxs("p",{className:"mt-2",children:["where ",e.jsx(s,{children:"\\sigma^2 = \\text{Var}(\\epsilon)"}),". In practice, ",e.jsx(s,{children:"\\sigma"})," is estimated using the ",e.jsx("em",{children:"residual standard error"}),":"]}),e.jsx(i,{children:"\\text{RSE} = \\sqrt{\\frac{\\text{RSS}}{n-2}}"})]}),e.jsx("h3",{children:"Confidence Intervals"}),e.jsxs("p",{children:["Standard errors can be used to compute ",e.jsx("em",{children:"confidence intervals"}),". A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter."]}),e.jsxs(x,{title:"95% Confidence Interval for Coefficients",children:[e.jsxs("p",{children:["For ",e.jsx(s,{children:"\\beta_1"}),", the approximate 95% confidence interval is:"]}),e.jsx(i,{children:"\\hat{\\beta}_1 \\pm 2 \\cdot \\text{SE}(\\hat{\\beta}_1)"}),e.jsxs("p",{className:"mt-2",children:["Similarly for ",e.jsx(s,{children:"\\beta_0"}),":"]}),e.jsx(i,{children:"\\hat{\\beta}_0 \\pm 2 \\cdot \\text{SE}(\\hat{\\beta}_0)"})]}),e.jsx("h3",{children:"Hypothesis Tests"}),e.jsxs("p",{children:["Standard errors can also be used to perform ",e.jsx("em",{children:"hypothesis tests"})," on the coefficients. The most common hypothesis test involves testing:"]}),e.jsxs("div",{className:"my-6 p-4 bg-dark-800/50 rounded-xl border border-dark-700",children:[e.jsxs("div",{className:"grid grid-cols-2 gap-4",children:[e.jsxs("div",{children:[e.jsx("h4",{className:"text-dark-400 text-sm font-semibold mb-1",children:"Null Hypothesis"}),e.jsx(i,{children:"H_0: \\beta_1 = 0"})]}),e.jsxs("div",{children:[e.jsx("h4",{className:"text-dark-400 text-sm font-semibold mb-1",children:"Alternative Hypothesis"}),e.jsx(i,{children:"H_a: \\beta_1 \\neq 0"})]})]}),e.jsxs("p",{className:"text-dark-400 text-sm mt-4",children:[e.jsx(s,{children:"H_0"})," corresponds to no relationship between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"}),"."]})]}),e.jsxs(x,{title:"t-Statistic",children:[e.jsxs("p",{children:["To test the null hypothesis, we compute a ",e.jsx("em",{children:"t-statistic"}),":"]}),e.jsx(i,{children:"t = \\frac{\\hat{\\beta}_1 - 0}{\\text{SE}(\\hat{\\beta}_1)} = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}"}),e.jsxs("p",{className:"mt-2",children:["This measures the number of standard deviations that ",e.jsx(s,{children:"\\hat{\\beta}_1"})," is away from 0. If there truly is no relationship, we expect this to have a ",e.jsx(s,{children:"t"}),"-distribution with ",e.jsx(s,{children:"n-2"})," degrees of freedom."]})]}),e.jsxs(_,{type:"info",children:[e.jsx("strong",{children:"p-value:"})," The p-value is the probability of observing a value of ",e.jsx(s,{children:"|t|"})," equal to or larger than what we observed, assuming ",e.jsx(s,{children:"H_0"})," is true. A small p-value indicates that it is unlikely to observe such a substantial association between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"})," due to chance alone."]}),e.jsx("h2",{children:"Assessing the Accuracy of the Model"}),e.jsxs("p",{children:["Once we have rejected the null hypothesis and concluded that there is a relationship between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"}),", we want to quantify how well the model fits the data. Two related quantities are commonly used:"]}),e.jsx("h3",{children:"Residual Standard Error (RSE)"}),e.jsxs(x,{title:"Residual Standard Error",children:[e.jsx(i,{children:"\\text{RSE} = \\sqrt{\\frac{1}{n-2}\\text{RSS}} = \\sqrt{\\frac{1}{n-2}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}"}),e.jsxs("p",{className:"mt-2",children:["The RSE is an estimate of the standard deviation of ",e.jsx(s,{children:"\\epsilon"}),". Roughly speaking, it is the average amount that the response will deviate from the true regression line."]})]}),e.jsxs("p",{children:["The RSE is measured in the units of ",e.jsx(s,{children:"Y"}),". In the advertising example, RSE = 3.26, meaning actual sales deviate from the true regression line by approximately 3,260 units on average."]}),e.jsx("h3",{children:"R-squared (R²)"}),e.jsxs(x,{title:"R-squared",children:[e.jsx(i,{children:"R^2 = \\frac{\\text{TSS} - \\text{RSS}}{\\text{TSS}} = 1 - \\frac{\\text{RSS}}{\\text{TSS}}"}),e.jsxs("p",{className:"mt-2",children:["where ",e.jsx("strong",{children:"TSS"})," (Total Sum of Squares) = ",e.jsx(s,{children:"\\sum(y_i - \\bar{y})^2"})," measures the total variance in the response ",e.jsx(s,{children:"Y"}),", and RSS measures the variance that is left unexplained after performing the regression."]}),e.jsxs("p",{className:"mt-2",children:["Hence, ",e.jsx(s,{children:"R^2"})," measures the ",e.jsx("strong",{children:"proportion of variance explained"})," by the model."]})]}),e.jsxs("div",{className:"my-6 p-5 bg-dark-800/50 rounded-xl border border-dark-700",children:[e.jsx("h4",{className:"text-dark-200 font-semibold mb-3",children:"Interpreting R²"}),e.jsxs("ul",{className:"space-y-2 text-dark-300",children:[e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-emerald-400 mt-1",children:"→"}),e.jsxs("span",{children:[e.jsx(s,{children:"R^2 = 0"}),": The model explains none of the variability in ",e.jsx(s,{children:"Y"})]})]}),e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-emerald-400 mt-1",children:"→"}),e.jsxs("span",{children:[e.jsx(s,{children:"R^2 = 1"}),": The model explains all of the variability in ",e.jsx(s,{children:"Y"})]})]}),e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-amber-400 mt-1",children:"→"}),e.jsxs("span",{children:[e.jsx(s,{children:"R^2"})," close to 1: Regression explains most of the variance (good fit)"]})]}),e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-red-400 mt-1",children:"→"}),e.jsxs("span",{children:[e.jsx(s,{children:"R^2"})," close to 0: Regression explains little of the variance (poor fit)"]})]})]})]}),e.jsxs(_,{type:"warning",children:[e.jsx("strong",{children:"R² and Correlation:"})," In simple linear regression with one predictor,",e.jsx(s,{children:"R^2 = r^2"})," where ",e.jsx(s,{children:"r"})," is the correlation between ",e.jsx(s,{children:"X"})," and ",e.jsx(s,{children:"Y"}),". This relationship does not extend to multiple regression."]}),e.jsx("h2",{children:"R Code Example"}),e.jsx("p",{children:"Here's how to fit a simple linear regression model in R:"}),e.jsx(M,{title:"Simple Linear Regression in R",output:`Call:
lm(formula = sales ~ TV, data = Advertising)

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 7.032594   0.457843  15.360  < 2e-16 ***
TV          0.047537   0.002691  17.668  < 2e-16 ***
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.259 on 198 degrees of freedom
Multiple R-squared: 0.6119`,children:`# Load the data
Advertising <- read.csv("Advertising.csv")

# Fit simple linear regression
lm.fit <- lm(sales ~ TV, data = Advertising)

# View the summary
summary(lm.fit)

# Get confidence intervals for coefficients
confint(lm.fit)

# Make predictions
predict(lm.fit, data.frame(TV = c(50, 100, 150)))`}),e.jsx("h2",{children:"Summary"}),e.jsx("p",{children:"This section covered the fundamentals of simple linear regression:"}),e.jsxs("ul",{className:"list-disc list-inside text-dark-300 space-y-2 my-4",children:[e.jsxs("li",{children:["The model: ",e.jsx(s,{children:"Y = \\beta_0 + \\beta_1 X + \\epsilon"})]}),e.jsx("li",{children:"Estimating coefficients by minimizing RSS (least squares)"}),e.jsx("li",{children:"Standard errors, confidence intervals, and hypothesis tests"}),e.jsxs("li",{children:["Assessing fit with RSE and ",e.jsx(s,{children:"R^2"})]})]}),e.jsxs(_,{type:"success",children:[e.jsx("strong",{children:"Next Steps:"})," In the next section, we'll extend these ideas to",e.jsx("em",{children:"multiple linear regression"}),", where we predict ",e.jsx(s,{children:"Y"})," using multiple predictors ",e.jsx(s,{children:"X_1, X_2, \\ldots, X_p"}),"."]}),e.jsx(X,{sectionId:6,questions:L,title:"Simple Linear Regression Quiz"})]})}export{Q as default};
