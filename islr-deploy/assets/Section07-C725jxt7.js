import{j as e}from"./index-D-anHz-v.js";import{L as n,C as i}from"./Callout-S0Ir82k9.js";import{D as r,E as a,R as l}from"./ContentBlocks-DqG_oog1.js";import{M as t,a as s}from"./MathBlock-D_BNZVWb.js";function x(){return e.jsxs(n,{sectionId:7,children:[e.jsx("h2",{children:"Multiple Linear Regression"}),e.jsx("p",{children:"Simple linear regression is a useful approach for predicting a response on the basis of a single predictor variable. However, in practice we often have more than one predictor. We now extend simple linear regression to accommodate multiple predictors."}),e.jsxs(r,{title:"Multiple Linear Regression Model",children:[e.jsx("p",{children:"Instead of fitting a separate simple linear regression model for each predictor, we can extend our model to include multiple predictors:"}),e.jsx(t,{children:"Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p + \\epsilon"}),e.jsxs("p",{className:"mt-2",children:["where ",e.jsx(s,{children:"X_j"})," represents the ",e.jsx(s,{children:"j"}),"th predictor and ",e.jsx(s,{children:"\\beta_j"})," quantifies the association between that predictor and the response."]}),e.jsxs("p",{className:"mt-2",children:["We interpret ",e.jsx(s,{children:"\\beta_j"})," as the ",e.jsx("em",{children:"average"})," effect on ",e.jsx(s,{children:"Y"})," of a one unit increase in ",e.jsx(s,{children:"X_j"}),", ",e.jsx("strong",{children:"holding all other predictors fixed"}),"."]})]}),e.jsx("h2",{children:"Estimating the Regression Coefficients"}),e.jsxs("p",{children:["As with simple linear regression, the coefficients ",e.jsx(s,{children:"\\beta_0, \\beta_1, \\ldots, \\beta_p"})," are unknown and must be estimated. Given estimates ",e.jsx(s,{children:"\\hat\\beta_0, \\hat\\beta_1, \\ldots, \\hat\\beta_p"}),", we can make predictions using:"]}),e.jsx(t,{children:"\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\cdots + \\hat{\\beta}_p x_p"}),e.jsx("p",{children:"The parameters are estimated using the same least squares approach: we choose coefficients to minimize the residual sum of squares (RSS):"}),e.jsx(r,{title:"RSS for Multiple Regression",children:e.jsx(t,{children:"\\text{RSS} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} \\left( y_i - \\hat{\\beta}_0 - \\sum_{j=1}^{p} \\hat{\\beta}_j x_{ij} \\right)^2"})}),e.jsxs(i,{type:"info",children:[e.jsx("strong",{children:"Matrix Formulation:"})," Unlike simple linear regression, the formulas for the least squares coefficient estimates in multiple regression are most conveniently expressed using matrix algebra. In matrix form: ",e.jsx(s,{children:"\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}"})]}),e.jsxs(a,{title:"Advertising Data with Multiple Predictors",children:[e.jsx("p",{children:"Using the advertising data, we can regress sales onto TV, radio, and newspaper:"}),e.jsx(t,{children:"\\widehat{\\text{sales}} = 2.939 + 0.046 \\times \\text{TV} + 0.189 \\times \\text{radio} - 0.001 \\times \\text{newspaper}"}),e.jsxs("p",{className:"mt-2",children:[e.jsx("strong",{children:"Interpretation:"})," A $1,000 increase in TV advertising is associated with an increase in sales of about 46 units, holding radio and newspaper fixed. Similarly, spending an additional $1,000 on radio advertising is associated with an increase of about 189 units."]})]}),e.jsx("h2",{children:"Some Important Questions"}),e.jsx("p",{children:"When we perform multiple regression, we usually want to answer several important questions:"}),e.jsxs("div",{className:"space-y-4 my-6",children:[e.jsxs("div",{className:"p-4 bg-dark-800/50 rounded-xl border border-dark-700",children:[e.jsx("h4",{className:"text-emerald-400 font-semibold mb-2",children:"1. Is at least one predictor useful?"}),e.jsxs("p",{className:"text-dark-300 text-sm",children:["We test ",e.jsx(s,{children:"H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0"})," using the F-statistic."]})]}),e.jsxs("div",{className:"p-4 bg-dark-800/50 rounded-xl border border-dark-700",children:[e.jsx("h4",{className:"text-blue-400 font-semibold mb-2",children:"2. Which predictors are important?"}),e.jsx("p",{className:"text-dark-300 text-sm",children:"Examine individual t-statistics and p-values for each coefficient."})]}),e.jsxs("div",{className:"p-4 bg-dark-800/50 rounded-xl border border-dark-700",children:[e.jsx("h4",{className:"text-amber-400 font-semibold mb-2",children:"3. How well does the model fit?"}),e.jsxs("p",{className:"text-dark-300 text-sm",children:["Use ",e.jsx(s,{children:"R^2"})," and RSE to assess overall model quality."]})]}),e.jsxs("div",{className:"p-4 bg-dark-800/50 rounded-xl border border-dark-700",children:[e.jsx("h4",{className:"text-purple-400 font-semibold mb-2",children:"4. How accurate are predictions?"}),e.jsx("p",{className:"text-dark-300 text-sm",children:"Compute confidence intervals and prediction intervals."})]})]}),e.jsx("h3",{children:"The F-Statistic"}),e.jsx("p",{children:"To test whether at least one predictor is useful, we use the F-statistic:"}),e.jsxs(r,{title:"F-Statistic",children:[e.jsx(t,{children:"F = \\frac{(\\text{TSS} - \\text{RSS})/p}{\\text{RSS}/(n - p - 1)}"}),e.jsxs("p",{className:"mt-2",children:["where TSS = ",e.jsx(s,{children:"\\sum(y_i - \\bar{y})^2"})," and RSS = ",e.jsx(s,{children:"\\sum(y_i - \\hat{y}_i)^2"}),"."]}),e.jsxs("p",{className:"mt-2",children:["If ",e.jsx(s,{children:"H_0"})," is true and the errors are normally distributed, ",e.jsx(s,{children:"F"})," follows an F-distribution with ",e.jsx(s,{children:"(p, n-p-1)"})," degrees of freedom."]})]}),e.jsxs(i,{type:"warning",children:[e.jsx("strong",{children:"Why not just use individual t-tests?"})," When ",e.jsx(s,{children:"p"})," is large, about 5% of p-values will be below 0.05 by chance alone! The F-test avoids this multiple testing problem by testing all coefficients simultaneously."]}),e.jsx("h3",{children:"Deciding Which Variables to Include"}),e.jsxs("p",{children:["The task of determining which predictors are associated with the response is referred to as ",e.jsx("em",{children:"variable selection"}),". There are ",e.jsx(s,{children:"2^p"})," possible models containing subsets of the ",e.jsx(s,{children:"p"})," predictors!"]}),e.jsx("p",{children:"Common approaches include:"}),e.jsxs("ul",{className:"list-disc list-inside text-dark-300 space-y-2 my-4",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Forward selection:"})," Start with no predictors, add one at a time"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Backward selection:"})," Start with all predictors, remove one at a time"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Mixed selection:"})," Combination of forward and backward"]})]}),e.jsx("h2",{children:"Model Fit"}),e.jsx("h3",{children:"R² in Multiple Regression"}),e.jsxs(r,{title:"R² for Multiple Regression",children:[e.jsx(t,{children:"R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}} = \\frac{\\text{TSS} - \\text{RSS}}{\\text{TSS}}"}),e.jsxs("p",{className:"mt-2",children:["As in simple regression, ",e.jsx(s,{children:"R^2"})," measures the proportion of variance explained by the model. However, ",e.jsx(s,{children:"R^2"})," will ",e.jsx("em",{children:"always"})," increase when more variables are added, even if those variables are not truly associated with the response!"]})]}),e.jsxs(i,{type:"info",children:[e.jsx("strong",{children:"Adjusted R²:"})," To account for the number of predictors, we can use",e.jsx(s,{children:"\\text{Adjusted } R^2 = 1 - \\frac{\\text{RSS}/(n-p-1)}{\\text{TSS}/(n-1)}"}),". Unlike ",e.jsx(s,{children:"R^2"}),", adjusted ",e.jsx(s,{children:"R^2"})," can decrease if we add uninformative predictors."]}),e.jsxs(a,{title:"Advertising Model Comparison",children:[e.jsx("div",{className:"overflow-x-auto my-4",children:e.jsxs("table",{className:"w-full text-sm",children:[e.jsx("thead",{children:e.jsxs("tr",{className:"border-b border-dark-700",children:[e.jsx("th",{className:"text-left py-2 px-3 text-dark-300",children:"Model"}),e.jsx("th",{className:"text-left py-2 px-3 text-dark-300",children:"RSE"}),e.jsx("th",{className:"text-left py-2 px-3 text-dark-300",children:"R²"})]})}),e.jsxs("tbody",{className:"text-dark-400",children:[e.jsxs("tr",{className:"border-b border-dark-800",children:[e.jsx("td",{className:"py-2 px-3",children:"TV only"}),e.jsx("td",{className:"py-2 px-3",children:"3.26"}),e.jsx("td",{className:"py-2 px-3",children:"0.612"})]}),e.jsxs("tr",{className:"border-b border-dark-800",children:[e.jsx("td",{className:"py-2 px-3",children:"TV + Radio"}),e.jsx("td",{className:"py-2 px-3",children:"1.68"}),e.jsx("td",{className:"py-2 px-3",children:"0.897"})]}),e.jsxs("tr",{children:[e.jsx("td",{className:"py-2 px-3",children:"TV + Radio + Newspaper"}),e.jsx("td",{className:"py-2 px-3",children:"1.69"}),e.jsx("td",{className:"py-2 px-3",children:"0.897"})]})]})]})}),e.jsxs("p",{className:"text-dark-400 text-sm",children:["Adding newspaper to the model barely improves ",e.jsx(s,{children:"R^2"})," and actually increases RSE slightly!"]})]}),e.jsx("h2",{children:"R Code Example"}),e.jsx(l,{title:"Multiple Regression in R",output:`Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  2.93889    0.31191   9.422  < 2e-16 ***
TV           0.04576    0.00139  32.809  < 2e-16 ***
radio        0.18853    0.00861  21.893  < 2e-16 ***
newspaper   -0.00104    0.00587  -0.177    0.860    

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,	Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: < 2.2e-16`,children:`# Fit multiple regression model
lm.fit <- lm(sales ~ TV + radio + newspaper, data = Advertising)

# View the summary
summary(lm.fit)

# Get confidence intervals
confint(lm.fit)

# Compare models using anova
lm.fit1 <- lm(sales ~ TV + radio, data = Advertising)
anova(lm.fit1, lm.fit)`}),e.jsx("h2",{children:"Correlation Among Predictors"}),e.jsxs("p",{children:["In multiple regression, the coefficients can behave very differently than in simple regression due to ",e.jsx("em",{children:"correlation"})," (or ",e.jsx("em",{children:"collinearity"}),") among predictors."]}),e.jsxs(a,{title:"Simple vs. Multiple Regression Coefficients",children:[e.jsx("div",{className:"overflow-x-auto my-4",children:e.jsxs("table",{className:"w-full text-sm",children:[e.jsx("thead",{children:e.jsxs("tr",{className:"border-b border-dark-700",children:[e.jsx("th",{className:"text-left py-2 px-3 text-dark-300",children:"Variable"}),e.jsx("th",{className:"text-left py-2 px-3 text-dark-300",children:"Simple Regression"}),e.jsx("th",{className:"text-left py-2 px-3 text-dark-300",children:"Multiple Regression"})]})}),e.jsxs("tbody",{className:"text-dark-400",children:[e.jsxs("tr",{className:"border-b border-dark-800",children:[e.jsx("td",{className:"py-2 px-3",children:"TV"}),e.jsx("td",{className:"py-2 px-3",children:"0.048 ***"}),e.jsx("td",{className:"py-2 px-3",children:"0.046 ***"})]}),e.jsxs("tr",{className:"border-b border-dark-800",children:[e.jsx("td",{className:"py-2 px-3",children:"Radio"}),e.jsx("td",{className:"py-2 px-3",children:"0.203 ***"}),e.jsx("td",{className:"py-2 px-3",children:"0.189 ***"})]}),e.jsxs("tr",{children:[e.jsx("td",{className:"py-2 px-3",children:"Newspaper"}),e.jsx("td",{className:"py-2 px-3 text-amber-400",children:"0.055 ***"}),e.jsx("td",{className:"py-2 px-3 text-dark-500",children:"-0.001"})]})]})]})}),e.jsx("p",{className:"text-dark-400 text-sm",children:'Newspaper appears significant in simple regression but not in multiple regression! This is because newspaper spending is correlated with radio spending. The simple regression coefficient for newspaper is "borrowing" the effect of radio.'})]}),e.jsxs(i,{type:"warning",children:[e.jsx("strong",{children:"Interpreting Correlated Predictors:"})," When predictors are correlated, it can be difficult to determine the individual contribution of each. The coefficient for one variable represents its effect ",e.jsx("em",{children:"holding others constant"}),", which may not reflect real-world scenarios where variables change together."]}),e.jsx("h2",{children:"Summary"}),e.jsx("p",{children:"Multiple linear regression extends simple linear regression to include multiple predictors:"}),e.jsxs("ul",{className:"list-disc list-inside text-dark-300 space-y-2 my-4",children:[e.jsxs("li",{children:["Each coefficient ",e.jsx(s,{children:"\\beta_j"})," represents the effect of ",e.jsx(s,{children:"X_j"})," holding other predictors fixed"]}),e.jsx("li",{children:"The F-statistic tests whether at least one predictor is useful"}),e.jsxs("li",{children:[e.jsx(s,{children:"R^2"})," always increases with more predictors; use adjusted ",e.jsx(s,{children:"R^2"})," for comparison"]}),e.jsx("li",{children:"Correlation among predictors can make interpretation challenging"}),e.jsx("li",{children:"Variable selection helps identify the most important predictors"})]}),e.jsxs(i,{type:"success",children:[e.jsx("strong",{children:"Next:"})," We'll explore other important considerations in regression, including qualitative predictors, interaction effects, and potential problems like non-linearity and outliers."]})]})}export{x as default};
