const i=[{id:"sec00-q1",type:"multiple-choice",question:"Why does the equation $p^2 = 2$ have no solution in the rational numbers $\\mathbb{Q}$?",options:["Because the square root function is not defined for rationals","Because $2$ is larger than $1$","Because $2$ is a prime number","Because assuming $p = m/n$ in lowest terms leads to both $m$ and $n$ being even, a contradiction"],correctIndex:3,difficulty:"medium",explanation:"If $p = m/n$ with $\\gcd(m,n) = 1$, then $p^2 = 2$ implies $m^2 = 2n^2$. This means $m^2$ is even, so $m$ is even. Writing $m = 2k$, we get $4k^2 = 2n^2$, so $n^2 = 2k^2$, making $n$ even. But then $\\gcd(m,n) \\geq 2$, contradicting our assumption."},{id:"sec00-q2",type:"multiple-choice",question:"Consider the set $A = \\{p \\in \\mathbb{Q} : p^2 < 2\\}$. Which statement is true?",options:["$A$ is empty","$A$ has a largest element in $\\mathbb{Q}$","$A$ has upper bounds in $\\mathbb{Q}$ but no least upper bound in $\\mathbb{Q}$","$A$ has no upper bound in $\\mathbb{Q}$"],correctIndex:2,difficulty:"hard",explanation:"Any rational $q > \\sqrt{2}$ is an upper bound for $A$. However, since $\\sqrt{2} \\notin \\mathbb{Q}$, there is no least upper bound in $\\mathbb{Q}$. For any rational upper bound $q$, we can find a smaller rational still greater than $\\sqrt{2}$."},{id:"sec00-q3",type:"multiple-choice",question:"The gap in $\\mathbb{Q}$ demonstrated by $\\sqrt{2}$ shows that the rationals lack which property?",options:["Closure under addition","Density","The least upper bound property (completeness)","The Archimedean property"],correctIndex:2,difficulty:"medium",explanation:"The rationals are dense and satisfy the Archimedean property. However, the set $\\{q \\in \\mathbb{Q} : q^2 < 2\\}$ is bounded above but has no least upper bound in $\\mathbb{Q}$. This is the least upper bound (or completeness) property that $\\mathbb{Q}$ lacks."},{id:"sec00-q4",type:"multiple-choice",question:"If $p$ is a positive rational with $p^2 < 2$, which expression gives a larger rational $q$ with $q^2 < 2$?",options:["$q = p + 1$","$q = \\frac{2p + 2}{p + 2}$","$q = p^2$","$q = 2p$"],correctIndex:1,difficulty:"hard",explanation:"Rudin shows that $q = \\frac{2p + 2}{p + 2} = \\frac{2(p+1)}{p+2}$ satisfies $q > p$ and $q^2 < 2$ when $p^2 < 2$. This is derived from examining $q^2 - 2 = \\frac{2(p^2 - 2)}{(p+2)^2}$, which is negative when $p^2 < 2$."},{id:"sec00-q5",type:"multiple-choice",question:"What is the fundamental inadequacy of $\\mathbb{Q}$ that motivates the construction of $\\mathbb{R}$?",options:["$\\mathbb{Q}$ does not contain zero","$\\mathbb{Q}$ contains too many elements","Bounded sets in $\\mathbb{Q}$ may lack suprema in $\\mathbb{Q}$","$\\mathbb{Q}$ is not closed under division"],correctIndex:2,difficulty:"easy",explanation:'The rationals are an ordered field, but they have "gaps"—bounded sets without least upper bounds. The real numbers $\\mathbb{R}$ are constructed precisely to fill these gaps and satisfy the least upper bound property.'}],t=[{id:"sec01-q1",type:"multiple-choice",question:"Let $S$ be a nonempty subset of an ordered set. What is the definition of $\\sup S$?",options:["An upper bound $\\alpha$ of $S$ such that $\\gamma < \\alpha$ implies $\\gamma$ is not an upper bound of $S$","The average of all elements in $S$","Any upper bound of $S$","The largest element of $S$"],correctIndex:0,difficulty:"medium",explanation:"The supremum (least upper bound) $\\alpha = \\sup S$ is an upper bound with the property that no smaller element is also an upper bound. Equivalently, $\\alpha$ is an upper bound and for every $\\varepsilon > 0$, there exists $x \\in S$ with $x > \\alpha - \\varepsilon$."},{id:"sec01-q2",type:"multiple-choice",question:"If $S = (0, 1) = \\{x \\in \\mathbb{R} : 0 < x < 1\\}$, what are $\\sup S$ and $\\inf S$?",options:["$\\sup S = 1$, $\\inf S = 0$, and both belong to $S$","$\\sup S = 0.999...$, $\\inf S = 0.001$","$\\sup S = 1$, $\\inf S = 0$, and neither belongs to $S$","$\\sup S$ and $\\inf S$ do not exist"],correctIndex:2,difficulty:"easy",explanation:"For the open interval $(0,1)$, the supremum is $1$ and the infimum is $0$. Neither endpoint belongs to the set, but they are still the least upper bound and greatest lower bound respectively."},{id:"sec01-q3",type:"multiple-choice",question:"An ordered set $S$ has the least upper bound property if:",options:["Every subset of $S$ has a supremum","$S$ contains both a maximum and minimum element","$S$ is finite","Every nonempty subset of $S$ that is bounded above has a supremum in $S$"],correctIndex:3,difficulty:"medium",explanation:"The least upper bound property (or completeness) states that every nonempty subset that is bounded above has a least upper bound (supremum) within $S$. This is the key property that distinguishes $\\mathbb{R}$ from $\\mathbb{Q}$."},{id:"sec01-q4",type:"multiple-choice",question:"If $S$ has the least upper bound property and $B \\subset S$ is nonempty and bounded below, what can we conclude?",options:["$B$ must be finite","$B$ has a minimum element","$\\inf B$ exists and belongs to $S$","$B$ has no infimum"],correctIndex:2,difficulty:"hard",explanation:"Rudin proves that the LUB property implies the GLB (greatest lower bound) property. If $L$ is the set of lower bounds of $B$, then $L$ is nonempty and bounded above (by any element of $B$). Thus $\\sup L$ exists and equals $\\inf B$."},{id:"sec01-q5",type:"multiple-choice",question:"Let $A = \\{1/n : n \\in \\mathbb{Z}^+\\}$. What is $\\inf A$?",options:["The infimum does not exist","$1/2$","$1$","$0$"],correctIndex:3,difficulty:"easy",explanation:"The set $A = \\{1, 1/2, 1/3, 1/4, \\ldots\\}$ is bounded below by $0$. Since $1/n \\to 0$ as $n \\to \\infty$, no positive number can be a lower bound. Thus $\\inf A = 0$, though $0 \\notin A$."}],n=[{id:"sec02-q1",type:"multiple-choice",question:"Which of the following is NOT a field axiom?",options:["$x + y = y + x$ for all $x, y$ (commutativity of addition)","Every element has a multiplicative inverse","There exists an element $0$ such that $x + 0 = x$ for all $x$","$x \\cdot (y + z) = x \\cdot y + x \\cdot z$ (distributive law)"],correctIndex:1,difficulty:"medium",explanation:"Not every element has a multiplicative inverse—specifically, $0$ has no multiplicative inverse. The correct axiom states that every nonzero element has a multiplicative inverse."},{id:"sec02-q2",type:"multiple-choice",question:"In a field $F$, why is $0 \\cdot x = 0$ for all $x \\in F$?",options:["Because multiplication is commutative","It is an axiom of fields","Because $0 \\cdot x = (0 + 0) \\cdot x = 0 \\cdot x + 0 \\cdot x$, so $0 \\cdot x = 0$","Because $0$ has no multiplicative inverse"],correctIndex:2,difficulty:"medium",explanation:"Using distributivity: $0 \\cdot x = (0 + 0) \\cdot x = 0 \\cdot x + 0 \\cdot x$. Adding the additive inverse of $0 \\cdot x$ to both sides gives $0 = 0 \\cdot x$."},{id:"sec02-q3",type:"multiple-choice",question:"An ordered field is a field $F$ with an order relation $<$ such that:",options:["Every element is either positive or negative","$x < y$ if and only if $x - y < 0$","$x < y$ implies $x + z < y + z$, and $x > 0, y > 0$ implies $xy > 0$","The field is finite"],correctIndex:2,difficulty:"medium",explanation:"An ordered field requires the order to be compatible with field operations: translation preserves order ($x < y \\Rightarrow x+z < y+z$) and the product of positive elements is positive."},{id:"sec02-q4",type:"multiple-choice",question:"In an ordered field, if $x \\neq 0$, what can we conclude about $x^2$?",options:["$x^2$ could be positive, negative, or zero","$x^2 = 1$","$x^2 < 0$","$x^2 > 0$"],correctIndex:3,difficulty:"easy",explanation:"If $x > 0$, then $x \\cdot x > 0$ (product of positives). If $x < 0$, then $-x > 0$, so $(-x)(-x) = x^2 > 0$. Either way, $x^2 > 0$ for $x \\neq 0$."},{id:"sec02-q5",type:"multiple-choice",question:"Why can the complex numbers $\\mathbb{C}$ not be made into an ordered field?",options:["Because $i^2 = -1 < 0$, but $i^2$ should be positive if $i \\neq 0$","Because $\\mathbb{C}$ is not a field","Because $\\mathbb{C}$ is uncountable","Because complex numbers cannot be compared"],correctIndex:0,difficulty:"hard",explanation:"In any ordered field, $x^2 > 0$ for $x \\neq 0$. But in $\\mathbb{C}$, $i \\neq 0$ and $i^2 = -1$. If $\\mathbb{C}$ were ordered, we would need $i^2 > 0$, meaning $-1 > 0$, a contradiction."}],o=[{id:"sec03-q1",type:"multiple-choice",question:"The real number system $\\mathbb{R}$ is characterized as:",options:["The only ordered field","An ordered field with the least upper bound property","The completion of the integers","The set of all decimal expansions"],correctIndex:1,difficulty:"easy",explanation:"$\\mathbb{R}$ is an ordered field that satisfies the least upper bound property: every nonempty set bounded above has a supremum. This property, combined with being an ordered field, essentially characterizes $\\mathbb{R}$ uniquely (up to isomorphism)."},{id:"sec03-q2",type:"multiple-choice",question:"The Archimedean property of $\\mathbb{R}$ states that:",options:["Every real number has a square root","Between any two reals there is a rational","For any $x, y \\in \\mathbb{R}$ with $x > 0$, there exists $n \\in \\mathbb{Z}^+$ such that $nx > y$","$\\mathbb{R}$ is uncountable"],correctIndex:2,difficulty:"medium",explanation:"The Archimedean property says there are no infinitely large or infinitesimally small elements: given any $x > 0$ and any $y$, we can find a positive integer $n$ with $nx > y$. This follows from the LUB property."},{id:"sec03-q3",type:"multiple-choice",question:"Which statement about the density of $\\mathbb{Q}$ in $\\mathbb{R}$ is correct?",options:["Between any two distinct reals there is a rational","Both of the above","Between any two distinct rationals there is an irrational","Neither of the above"],correctIndex:1,difficulty:"medium",explanation:"Both $\\mathbb{Q}$ and $\\mathbb{R} \\setminus \\mathbb{Q}$ are dense in $\\mathbb{R}$. Between any two distinct real numbers, we can find both a rational number and an irrational number."},{id:"sec03-q4",type:"multiple-choice",question:"For $x > 0$ and $n \\in \\mathbb{Z}^+$, the existence of a unique $y > 0$ with $y^n = x$ follows from:",options:["The Archimedean property alone","The definition of exponentiation","The least upper bound property","The field axioms alone"],correctIndex:2,difficulty:"hard",explanation:"Rudin proves that $n$th roots exist by considering $E = \\{t > 0 : t^n < x\\}$. This set is nonempty and bounded above, so $y = \\sup E$ exists by the LUB property. One then shows $y^n = x$."},{id:"sec03-q5",type:"multiple-choice",question:"If $x, y \\in \\mathbb{R}$ with $x < y$, which of the following is guaranteed to exist in the interval $(x, y)$?",options:["A rational number","Both a rational and an irrational number","An irrational number","An integer"],correctIndex:1,difficulty:"medium",explanation:"By density, there exists $q \\in \\mathbb{Q}$ with $x < q < y$. For the irrational, consider $x/\\sqrt{2} < y/\\sqrt{2}$; there exists rational $r$ between them, so $r\\sqrt{2}$ is irrational and lies in $(x, y)$ (with care for signs)."}],a=[{id:"sec04-q1",type:"multiple-choice",question:"The extended real number system is defined as:",options:["The closure of $\\mathbb{R}$ under limits","$\\mathbb{R} \\cup \\{i, -i\\}$","All complex numbers with real part in $\\mathbb{R}$","$\\mathbb{R} \\cup \\{+\\infty, -\\infty\\}$"],correctIndex:3,difficulty:"easy",explanation:"The extended real numbers add two symbols $+\\infty$ and $-\\infty$ to $\\mathbb{R}$, with the convention that $-\\infty < x < +\\infty$ for all $x \\in \\mathbb{R}$."},{id:"sec04-q2",type:"multiple-choice",question:"In the extended reals, which expression is NOT defined?",options:["$\\infty \\cdot \\infty$","$\\infty + \\infty$","$\\infty - \\infty$","$x + \\infty$ for $x \\in \\mathbb{R}$"],correctIndex:2,difficulty:"medium",explanation:"The expression $\\infty - \\infty$ is indeterminate and left undefined. Similarly, $0 \\cdot \\infty$ and $\\infty/\\infty$ are undefined. However, $\\infty + \\infty = \\infty$, $\\infty \\cdot \\infty = \\infty$, and $x + \\infty = \\infty$ for real $x$."},{id:"sec04-q3",type:"multiple-choice",question:"In the extended reals, if $x > 0$, then $x \\cdot (+\\infty) = $?",options:["$0$","Undefined","$x$","$+\\infty$"],correctIndex:3,difficulty:"easy",explanation:"For $x > 0$, we define $x \\cdot (+\\infty) = +\\infty$. Similarly, $x \\cdot (-\\infty) = -\\infty$ for $x > 0$."},{id:"sec04-q4",type:"multiple-choice",question:"What is the main advantage of the extended real number system?",options:["It allows division by zero","Every subset has both a supremum and infimum","It simplifies complex number arithmetic","It makes $\\mathbb{R}$ into a field"],correctIndex:1,difficulty:"medium",explanation:"In the extended reals, every subset $E$ has $\\sup E$ and $\\inf E$ (possibly $\\pm\\infty$). If $E$ is unbounded above, $\\sup E = +\\infty$; if $E$ is empty, $\\sup E = -\\infty$. This simplifies many statements."},{id:"sec04-q5",type:"multiple-choice",question:"In the extended reals, what is $(-3) \\cdot (-\\infty)$?",options:["$+\\infty$","$3$","$-\\infty$","Undefined"],correctIndex:0,difficulty:"easy",explanation:"For $x < 0$, we have $x \\cdot (-\\infty) = +\\infty$ and $x \\cdot (+\\infty) = -\\infty$. Since $-3 < 0$, $(-3) \\cdot (-\\infty) = +\\infty$."}],s=[{id:"sec05-q1",type:"multiple-choice",question:"A complex number $z = a + bi$ has modulus $|z|$ defined as:",options:["$|a| + |b|$","$a + b$","$\\sqrt{a^2 + b^2}$","$a^2 + b^2$"],correctIndex:2,difficulty:"easy",explanation:"The modulus (or absolute value) of $z = a + bi$ is $|z| = \\sqrt{a^2 + b^2}$, which represents the distance from $z$ to the origin in the complex plane."},{id:"sec05-q2",type:"multiple-choice",question:"For complex numbers $z$ and $w$, which identity holds?",options:["$|z - w| = ||z| - |w||$","$|z + w| = |z| + |w|$","$|z/w| = |z| - |w|$","$|zw| = |z| \\cdot |w|$"],correctIndex:3,difficulty:"medium",explanation:"The modulus is multiplicative: $|zw| = |z| \\cdot |w|$. The triangle inequality gives $|z + w| \\leq |z| + |w|$ (not equality in general)."},{id:"sec05-q3",type:"multiple-choice",question:"The complex conjugate of $z = a + bi$ is $\\bar{z} = a - bi$. What is $z \\cdot \\bar{z}$?",options:["$2a$","$a^2 + b^2$","$2bi$","$a^2 - b^2$"],correctIndex:1,difficulty:"easy",explanation:"$z \\cdot \\bar{z} = (a + bi)(a - bi) = a^2 - (bi)^2 = a^2 - b^2i^2 = a^2 + b^2 = |z|^2$."},{id:"sec05-q4",type:"multiple-choice",question:"The triangle inequality for complex numbers states:",options:["$|z + w| = |z| + |w|$ if and only if $z = w$","$|z + w| \\geq |z| + |w|$","$|z - w| \\geq |z| - |w|$","$|z + w| \\leq |z| + |w|$"],correctIndex:3,difficulty:"medium",explanation:"The triangle inequality states $|z + w| \\leq |z| + |w|$. Equality holds if and only if one of $z, w$ is a nonnegative real multiple of the other."},{id:"sec05-q5",type:"multiple-choice",question:"If $|z| = 1$, then $z^{-1}$ equals:",options:["$1/\\bar{z}$","$z$","$-z$","$\\bar{z}$"],correctIndex:3,difficulty:"medium",explanation:"Since $z \\cdot \\bar{z} = |z|^2 = 1$ when $|z| = 1$, we have $z^{-1} = \\bar{z}$. In general, $z^{-1} = \\bar{z}/|z|^2$."}],$=[{id:"sec06-q1",type:"multiple-choice",question:"For vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^k$, the inner product $\\mathbf{x} \\cdot \\mathbf{y}$ is defined as:",options:["$\\sum_{i=1}^{k} |x_i - y_i|$","$\\sum_{i=1}^{k} x_i y_i$","$\\max_i |x_i y_i|$","$(x_1 y_1, x_2 y_2, \\ldots, x_k y_k)$"],correctIndex:1,difficulty:"easy",explanation:"The inner product (dot product) of $\\mathbf{x} = (x_1, \\ldots, x_k)$ and $\\mathbf{y} = (y_1, \\ldots, y_k)$ is $\\mathbf{x} \\cdot \\mathbf{y} = \\sum_{i=1}^{k} x_i y_i$."},{id:"sec06-q2",type:"multiple-choice",question:"The Euclidean norm $|\\mathbf{x}|$ of a vector $\\mathbf{x} \\in \\mathbb{R}^k$ satisfies:",options:["$|\\mathbf{x}| = \\sum_i |x_i|$","$|\\mathbf{x}|^2 = \\mathbf{x} \\cdot \\mathbf{x}$","$|\\mathbf{x}| = \\mathbf{x} \\cdot \\mathbf{x}$","$|\\mathbf{x}| = \\max_i |x_i|$"],correctIndex:1,difficulty:"easy",explanation:"The Euclidean norm is $|\\mathbf{x}| = \\sqrt{\\mathbf{x} \\cdot \\mathbf{x}} = \\sqrt{\\sum x_i^2}$, so $|\\mathbf{x}|^2 = \\mathbf{x} \\cdot \\mathbf{x}$."},{id:"sec06-q3",type:"multiple-choice",question:"The Schwarz inequality states that for $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^k$:",options:["$|\\mathbf{x} \\cdot \\mathbf{y}| \\leq |\\mathbf{x}| |\\mathbf{y}|$","$|\\mathbf{x} \\cdot \\mathbf{y}| = |\\mathbf{x}| + |\\mathbf{y}|$","$|\\mathbf{x} \\cdot \\mathbf{y}| \\geq |\\mathbf{x}| |\\mathbf{y}|$","$|\\mathbf{x} + \\mathbf{y}| = |\\mathbf{x}| |\\mathbf{y}|$"],correctIndex:0,difficulty:"medium",explanation:"The Schwarz (Cauchy-Schwarz) inequality: $|\\mathbf{x} \\cdot \\mathbf{y}| \\leq |\\mathbf{x}| |\\mathbf{y}|$. Equality holds if and only if one vector is a scalar multiple of the other."},{id:"sec06-q4",type:"multiple-choice",question:"The triangle inequality in $\\mathbb{R}^k$ states:",options:["$|\\mathbf{x} \\cdot \\mathbf{y}| \\leq |\\mathbf{x} + \\mathbf{y}|$","$|\\mathbf{x} + \\mathbf{y}| \\geq |\\mathbf{x}| + |\\mathbf{y}|$","$|\\mathbf{x} - \\mathbf{y}| = |\\mathbf{x}| - |\\mathbf{y}|$","$|\\mathbf{x} + \\mathbf{y}| \\leq |\\mathbf{x}| + |\\mathbf{y}|$"],correctIndex:3,difficulty:"easy",explanation:"The triangle inequality $|\\mathbf{x} + \\mathbf{y}| \\leq |\\mathbf{x}| + |\\mathbf{y}|$ follows from the Schwarz inequality. It gets its name from the geometric fact that any side of a triangle is at most the sum of the other two."},{id:"sec06-q5",type:"multiple-choice",question:"If $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^k$ with $\\mathbf{x} \\cdot \\mathbf{y} = 0$, then:",options:["$|\\mathbf{x} + \\mathbf{y}|^2 = |\\mathbf{x}|^2 + |\\mathbf{y}|^2$","$\\mathbf{x} = \\mathbf{y}$","$|\\mathbf{x}| = |\\mathbf{y}|$","$\\mathbf{x} = \\mathbf{0}$ or $\\mathbf{y} = \\mathbf{0}$"],correctIndex:0,difficulty:"medium",explanation:"If $\\mathbf{x} \\cdot \\mathbf{y} = 0$ (orthogonal vectors), then $|\\mathbf{x} + \\mathbf{y}|^2 = (\\mathbf{x} + \\mathbf{y}) \\cdot (\\mathbf{x} + \\mathbf{y}) = |\\mathbf{x}|^2 + 2\\mathbf{x}\\cdot\\mathbf{y} + |\\mathbf{y}|^2 = |\\mathbf{x}|^2 + |\\mathbf{y}|^2$. This is the Pythagorean theorem."}],r=[{id:"sec07-q1",type:"multiple-choice",question:"A Dedekind cut is a subset $\\alpha \\subset \\mathbb{Q}$ satisfying which conditions?",options:["$\\alpha$ is finite and nonempty","$\\alpha$ is an interval with rational endpoints","$\\alpha$ contains exactly half of the rationals","$\\alpha$ is nonempty, $\\alpha \\neq \\mathbb{Q}$, $\\alpha$ is closed downward, and $\\alpha$ has no largest element"],correctIndex:3,difficulty:"medium",explanation:"A Dedekind cut $\\alpha$ is: (i) nonempty, (ii) not all of $\\mathbb{Q}$, (iii) if $p \\in \\alpha$ and $q < p$ then $q \\in \\alpha$, and (iv) $\\alpha$ has no maximum element."},{id:"sec07-q2",type:"multiple-choice",question:"The Dedekind cut representing $\\sqrt{2}$ is:",options:["$\\{p \\in \\mathbb{Q} : p > \\sqrt{2}\\}$","$\\{p \\in \\mathbb{Q} : p \\leq \\sqrt{2}\\}$","$\\{p \\in \\mathbb{Q} : p^2 = 2\\}$","$\\{p \\in \\mathbb{Q} : p < 0 \\text{ or } p^2 < 2\\}$"],correctIndex:3,difficulty:"hard",explanation:"Since $\\sqrt{2} \\notin \\mathbb{Q}$, we define its cut as $\\alpha = \\{p \\in \\mathbb{Q} : p < 0\\} \\cup \\{p \\in \\mathbb{Q} : p \\geq 0 \\text{ and } p^2 < 2\\}$. This has no maximum and is closed downward."},{id:"sec07-q3",type:"multiple-choice",question:"If $\\alpha$ and $\\beta$ are cuts, we define $\\alpha < \\beta$ when:",options:["$\\sup \\alpha < \\sup \\beta$ in $\\mathbb{Q}$","$\\alpha \\supset \\beta$","$\\alpha \\cap \\beta = \\emptyset$","$\\alpha \\subset \\beta$ (proper subset)"],correctIndex:3,difficulty:"medium",explanation:'For Dedekind cuts, $\\alpha < \\beta$ means $\\alpha$ is a proper subset of $\\beta$. Larger cuts contain more rationals (they go further "right" on the number line).'},{id:"sec07-q4",type:"multiple-choice",question:"To define addition of cuts $\\alpha + \\beta$, we set:",options:["$\\alpha + \\beta = \\{pq : p \\in \\alpha, q \\in \\beta\\}$","$\\alpha + \\beta = \\alpha \\cup \\beta$","$\\alpha + \\beta = \\{p + q : p \\in \\alpha, q \\in \\beta\\}$","$\\alpha + \\beta = \\alpha \\cap \\beta$"],correctIndex:2,difficulty:"medium",explanation:"The sum of cuts is defined pointwise: $\\alpha + \\beta = \\{r + s : r \\in \\alpha, s \\in \\beta\\}$. One must verify this is again a cut."},{id:"sec07-q5",type:"multiple-choice",question:"The main purpose of the Dedekind cut construction is to:",options:["Prove that $\\mathbb{Q}$ is countable","Show that $\\sqrt{2}$ is irrational","Define the complex numbers","Construct $\\mathbb{R}$ from $\\mathbb{Q}$ and prove the LUB property"],correctIndex:3,difficulty:"easy",explanation:"The Dedekind cut construction rigorously builds $\\mathbb{R}$ from $\\mathbb{Q}$. Each real number is identified with a cut, and one proves the resulting ordered field satisfies the least upper bound property."}],c=[{id:"sec08-q1",type:"multiple-choice",question:"A set $A$ is countable if:",options:["$A$ has the same cardinality as $\\mathbb{R}$","There exists a bijection from $A$ to a subset of $\\mathbb{Z}^+$","$A$ contains only integers","$A$ is finite"],correctIndex:1,difficulty:"easy",explanation:"A set is countable if it is finite or countably infinite (in bijection with $\\mathbb{Z}^+$). Equivalently, $A$ is countable if there exists an injection from $A$ into $\\mathbb{Z}^+$."},{id:"sec08-q2",type:"multiple-choice",question:"Which of the following sets is uncountable?",options:["$\\mathbb{Q}$ (the rationals)","The set of all finite subsets of $\\mathbb{N}$","$\\mathbb{Z}$ (the integers)","$\\mathbb{R}$ (the reals)"],correctIndex:3,difficulty:"easy",explanation:"$\\mathbb{Z}$, $\\mathbb{Q}$, and the finite subsets of $\\mathbb{N}$ are all countable. Cantor's diagonal argument proves $\\mathbb{R}$ is uncountable."},{id:"sec08-q3",type:"multiple-choice",question:"Cantor's diagonal argument shows that the interval $(0,1)$ is uncountable by:",options:["Proving $(0,1)$ is not bounded","Constructing a real number in $(0,1)$ not in any proposed listing","Showing $(0,1)$ is an open set","Showing $(0,1)$ contains $\\mathbb{Q}$"],correctIndex:1,difficulty:"medium",explanation:"Given any listing $x_1, x_2, x_3, \\ldots$ of reals in $(0,1)$, Cantor constructs a number whose $n$-th decimal digit differs from the $n$-th digit of $x_n$. This number is in $(0,1)$ but not in the list."},{id:"sec08-q4",type:"multiple-choice",question:"The union of countably many countable sets is:",options:["Countable","Empty","Finite","Always uncountable"],correctIndex:0,difficulty:"medium",explanation:"If $A_1, A_2, A_3, \\ldots$ are each countable, then $\\bigcup_{n=1}^{\\infty} A_n$ is countable. This is proven using a diagonal enumeration argument."},{id:"sec08-q5",type:"multiple-choice",question:"Why is $\\mathbb{Q}$ countable?",options:["Because $\\mathbb{Q}$ is a countable union of countable sets (e.g., $\\{m/n : m \\in \\mathbb{Z}\\}$ for each $n$)","Because $\\mathbb{Q}$ is a subset of $\\mathbb{R}$","Because $\\mathbb{Q}$ is dense in $\\mathbb{R}$","Because every rational is an integer"],correctIndex:0,difficulty:"medium",explanation:"We can write $\\mathbb{Q} = \\bigcup_{n=1}^{\\infty} \\{m/n : m \\in \\mathbb{Z}\\}$. Each set $\\{m/n : m \\in \\mathbb{Z}\\}$ is countable (it bijects with $\\mathbb{Z}$), and a countable union of countable sets is countable."}],l=[{id:"sec09-q1",type:"multiple-choice",question:"A metric space is a set $X$ with a function $d: X \\times X \\to \\mathbb{R}$ satisfying:",options:["$d(x,y) = |x - y|$ always","$d$ must be continuous","$d(x,y) \\geq 0$, $d(x,y) = 0 \\Leftrightarrow x = y$, $d(x,y) = d(y,x)$, and $d(x,z) \\leq d(x,y) + d(y,z)$","$d(x,y) > 0$ for all $x, y$"],correctIndex:2,difficulty:"medium",explanation:"A metric satisfies: (i) positivity: $d(x,y) \\geq 0$, (ii) identity: $d(x,y) = 0 \\iff x = y$, (iii) symmetry: $d(x,y) = d(y,x)$, and (iv) triangle inequality: $d(x,z) \\leq d(x,y) + d(y,z)$."},{id:"sec09-q2",type:"multiple-choice",question:"A set $E$ in a metric space is open if:",options:["$E$ contains all its limit points","Its complement is finite","$E$ is bounded","Every point of $E$ is an interior point"],correctIndex:3,difficulty:"easy",explanation:"$E$ is open if every $x \\in E$ is an interior point, meaning there exists $r > 0$ such that the ball $B_r(x) = \\{y : d(x,y) < r\\} \\subset E$."},{id:"sec09-q3",type:"multiple-choice",question:"A set $E$ is closed if and only if:",options:["$E$ is bounded","$E$ is the complement of a bounded set","$E$ contains all its limit points","$E$ is finite"],correctIndex:2,difficulty:"medium",explanation:"$E$ is closed if and only if $E$ contains every limit point of $E$. Equivalently, $E$ is closed if its complement is open."},{id:"sec09-q4",type:"multiple-choice",question:"In $\\mathbb{R}$, which of the following is both open and closed?",options:["The singleton $\\{0\\}$","The interval $(0, 1)$","The interval $[0, 1]$","$\\mathbb{R}$ itself"],correctIndex:3,difficulty:"medium",explanation:"In any metric space, $\\emptyset$ and the whole space are both open and closed (clopen). In a connected space like $\\mathbb{R}$, these are the only clopen sets."},{id:"sec09-q5",type:"multiple-choice",question:"The closure $\\bar{E}$ of a set $E$ is:",options:["The boundary of $E$","The interior of $E$","$E$ together with all its limit points","The complement of $E$"],correctIndex:2,difficulty:"easy",explanation:"The closure $\\bar{E} = E \\cup E'$ where $E'$ is the set of limit points of $E$. Equivalently, $\\bar{E}$ is the smallest closed set containing $E$."}],f=[{id:"sec10-q1",type:"multiple-choice",question:"A set $K$ in a metric space is compact if:",options:["$K$ is bounded","$K$ is closed","Every open cover of $K$ has a finite subcover","Every sequence in $K$ is bounded"],correctIndex:2,difficulty:"medium",explanation:"$K$ is compact if every open cover $\\{V_\\alpha\\}$ of $K$ (meaning $K \\subset \\bigcup V_\\alpha$) contains a finite subcover. This is the defining property of compactness."},{id:"sec10-q2",type:"multiple-choice",question:"The Heine-Borel theorem states that in $\\mathbb{R}^k$, a set is compact if and only if it is:",options:["Closed and bounded","Open and bounded","Closed and connected","Connected and bounded"],correctIndex:0,difficulty:"easy",explanation:"The Heine-Borel theorem: A subset of $\\mathbb{R}^k$ is compact if and only if it is closed and bounded. This characterization does not hold in general metric spaces."},{id:"sec10-q3",type:"multiple-choice",question:"Is the interval $(0, 1)$ compact in $\\mathbb{R}$?",options:["Yes, because it is bounded","No, because it is not closed","No, because it is not connected","Yes, because it is an interval"],correctIndex:1,difficulty:"easy",explanation:"By Heine-Borel, $(0,1)$ is not compact because it is not closed. Alternatively, the open cover $\\{(1/n, 1) : n \\geq 2\\}$ has no finite subcover."},{id:"sec10-q4",type:"multiple-choice",question:"If $K$ is compact and $F \\subset K$ is closed, then:",options:["$F$ is compact","$F$ is open","$K \\setminus F$ is compact","$F$ is unbounded"],correctIndex:0,difficulty:"medium",explanation:"A closed subset of a compact set is compact. This follows because any open cover of $F$ can be extended to an open cover of $K$ by adding $F^c$, which then has a finite subcover."},{id:"sec10-q5",type:"multiple-choice",question:"In a compact set $K$, every infinite subset:",options:["Is countable","Is closed","Is also compact","Has a limit point in $K$"],correctIndex:3,difficulty:"hard",explanation:"Every infinite subset of a compact set has a limit point in that set. This is equivalent to sequential compactness: every sequence in $K$ has a convergent subsequence with limit in $K$."}],u=[{id:"sec11-q1",type:"multiple-choice",question:"A set $P$ is perfect if:",options:["$P$ is open","$P$ is finite","$P$ is closed and every point of $P$ is a limit point of $P$","$P$ contains all rationals"],correctIndex:2,difficulty:"medium",explanation:"A perfect set is closed and has no isolated points—every point is a limit point. This means $P = P'$ where $P'$ is the set of limit points."},{id:"sec11-q2",type:"multiple-choice",question:"The Cantor set is constructed by:",options:["Taking all irrationals in $[0,1]$","Taking all rationals in $[0,1]$","Repeatedly removing the open middle third from each remaining interval","Taking the union of all intervals of length $1/3^n$"],correctIndex:2,difficulty:"easy",explanation:"The Cantor set starts with $[0,1]$, removes $(1/3, 2/3)$, then removes the middle thirds of remaining intervals, and continues. The Cantor set is what remains after infinitely many steps."},{id:"sec11-q3",type:"multiple-choice",question:"The Cantor set is:",options:["Empty","Countable and not perfect","Countable and perfect","Uncountable and perfect"],correctIndex:3,difficulty:"medium",explanation:"The Cantor set is uncountable (it bijects with all sequences of 0s and 2s in base 3) and perfect (closed with no isolated points)."},{id:"sec11-q4",type:"multiple-choice",question:'What is the "total length" (Lebesgue measure) of the Cantor set?',options:["$1$","$1/3$","$\\infty$","$0$"],correctIndex:3,difficulty:"hard",explanation:"The removed intervals have total length $1/3 + 2/9 + 4/27 + \\cdots = (1/3)/(1 - 2/3) = 1$. So the Cantor set has measure $1 - 1 = 0$, yet it is uncountable."},{id:"sec11-q5",type:"multiple-choice",question:"Every nonempty perfect set in $\\mathbb{R}^k$ is:",options:["Uncountable","Finite","Open","Countable"],correctIndex:0,difficulty:"hard",explanation:"Rudin proves that every nonempty perfect set in $\\mathbb{R}^k$ is uncountable. The proof uses the fact that perfect sets cannot be written as a countable union of singletons, combined with the Baire category theorem ideas."}],d=[{id:"sec12-q1",type:"multiple-choice",question:"A metric space $X$ is connected if:",options:["$X$ is bounded","$X$ is compact","Every point of $X$ is a limit point","$X$ cannot be written as the union of two nonempty disjoint open sets"],correctIndex:3,difficulty:"medium",explanation:"$X$ is connected if there do not exist nonempty open sets $A$ and $B$ with $A \\cap B = \\emptyset$ and $A \\cup B = X$. Equivalently, the only clopen sets are $\\emptyset$ and $X$."},{id:"sec12-q2",type:"multiple-choice",question:"Which of the following subsets of $\\mathbb{R}$ is connected?",options:["$[0, 1]$","$\\mathbb{Q}$ (the rationals)","$\\{1/n : n \\in \\mathbb{Z}^+\\}$","$\\{0\\} \\cup \\{1\\}$"],correctIndex:0,difficulty:"easy",explanation:"In $\\mathbb{R}$, the connected subsets are exactly the intervals. $[0,1]$ is an interval and hence connected. The other sets are not intervals."},{id:"sec12-q3",type:"multiple-choice",question:"If $E \\subset \\mathbb{R}$ is connected and $x, y \\in E$ with $x < y$, then:",options:["$E$ contains only rationals between $x$ and $y$","Every $z$ with $x < z < y$ is in $E$","Only $x$ and $y$ are in $E$","$E$ must be finite"],correctIndex:1,difficulty:"medium",explanation:"Connected subsets of $\\mathbb{R}$ are intervals. If $x, y \\in E$, then every point between them must also be in $E$, otherwise $E$ could be split into two separated pieces."},{id:"sec12-q4",type:"multiple-choice",question:"The image of a connected set under a continuous function is:",options:["Compact","Closed","Open","Connected"],correctIndex:3,difficulty:"medium",explanation:"Continuous functions preserve connectedness: if $f: X \\to Y$ is continuous and $X$ is connected, then $f(X)$ is connected. This is because the preimages of a separation would give a separation of $X$."},{id:"sec12-q5",type:"multiple-choice",question:"Which statement characterizes connected subsets of $\\mathbb{R}$?",options:["A subset $E$ is connected iff $E$ is closed","A subset $E$ is connected iff $E$ is compact","A subset $E$ is connected iff $E$ is an interval","A subset $E$ is connected iff $E$ is perfect"],correctIndex:2,difficulty:"easy",explanation:"In $\\mathbb{R}$, a set is connected if and only if it is an interval (bounded, unbounded, open, closed, or half-open). This is a special characterization that holds in $\\mathbb{R}$ but not in higher dimensions."}],h=[{id:"sec13-q1",type:"multiple-choice",question:"A sequence $\\{p_n\\}$ in a metric space converges to $p$ if:",options:["The sequence is bounded","The sequence is monotonic","$p_n = p$ for infinitely many $n$","For every $\\varepsilon > 0$, there exists $N$ such that $n \\geq N$ implies $d(p_n, p) < \\varepsilon$"],correctIndex:3,difficulty:"easy",explanation:"Convergence means that eventually all terms are arbitrarily close to the limit: for any $\\varepsilon > 0$, there is an $N$ such that $d(p_n, p) < \\varepsilon$ for all $n \\geq N$."},{id:"sec13-q2",type:"multiple-choice",question:"If $\\{p_n\\}$ converges in a metric space, the limit is:",options:["Unique","Always in the sequence","Always rational","Not necessarily unique"],correctIndex:0,difficulty:"easy",explanation:"Limits are unique in metric spaces. If $p_n \\to p$ and $p_n \\to q$, then $d(p, q) \\leq d(p, p_n) + d(p_n, q)$, which can be made arbitrarily small, so $p = q$."},{id:"sec13-q3",type:"multiple-choice",question:"A convergent sequence is:",options:["Unbounded","Eventually constant","Monotonic","Bounded"],correctIndex:3,difficulty:"easy",explanation:"If $p_n \\to p$, then for large $n$, $d(p_n, p) < 1$, so $p_n$ is within distance $1$ of $p$. The finitely many initial terms are also at finite distances, so the whole sequence is bounded."},{id:"sec13-q4",type:"multiple-choice",question:"In $\\mathbb{R}^k$, a sequence $\\{\\mathbf{x}_n\\}$ converges to $\\mathbf{x}$ if and only if:",options:["At least one coordinate converges","The first coordinate converges","Each coordinate sequence converges to the corresponding coordinate of $\\mathbf{x}$","The norms $|\\mathbf{x}_n|$ converge to $|\\mathbf{x}|$"],correctIndex:2,difficulty:"medium",explanation:"In $\\mathbb{R}^k$, convergence is equivalent to coordinate-wise convergence: $\\mathbf{x}_n \\to \\mathbf{x}$ iff $(x_n)_j \\to x_j$ for each $j = 1, \\ldots, k$."},{id:"sec13-q5",type:"multiple-choice",question:"If $E$ is a closed set and $\\{p_n\\}$ is a sequence in $E$ converging to $p$, then:",options:["The sequence must be eventually constant","$p$ is an interior point of $E$","$p$ may or may not be in $E$","$p \\in E$"],correctIndex:3,difficulty:"medium",explanation:"Closed sets contain all their limit points. If $p_n \\in E$ for all $n$ and $p_n \\to p$, then $p$ is a limit point of $E$ (or in $E$ already), so $p \\in E$ since $E$ is closed."}],m=[{id:"sec14-q1",type:"multiple-choice",question:"A subsequence of $\\{p_n\\}$ is:",options:["Any sequence whose terms come from $\\{p_n\\}$","The first $N$ terms of $\\{p_n\\}$","The odd-indexed terms only","A sequence $\\{p_{n_k}\\}$ where $n_1 < n_2 < n_3 < \\cdots$"],correctIndex:3,difficulty:"easy",explanation:"A subsequence is $\\{p_{n_k}\\}$ where the indices form a strictly increasing sequence: $n_1 < n_2 < n_3 < \\cdots$. This ensures we pick terms in order, possibly skipping some."},{id:"sec14-q2",type:"multiple-choice",question:"The Bolzano-Weierstrass theorem states that:",options:["Every convergent sequence is bounded","Every sequence converges","Every bounded sequence in $\\mathbb{R}^k$ has a convergent subsequence","Every monotonic sequence converges"],correctIndex:2,difficulty:"medium",explanation:"Bolzano-Weierstrass: Every bounded sequence in $\\mathbb{R}^k$ contains a convergent subsequence. This is a fundamental compactness result."},{id:"sec14-q3",type:"multiple-choice",question:"If $\\{p_n\\}$ converges to $p$, then every subsequence:",options:["Converges to $p$","Converges to a different limit","Diverges","Is unbounded"],correctIndex:0,difficulty:"easy",explanation:"If $p_n \\to p$, then any subsequence $\\{p_{n_k}\\}$ also converges to $p$. This follows directly from the definition since subsequence indices $n_k \\geq k$."},{id:"sec14-q4",type:"multiple-choice",question:"Let $E$ be the set of subsequential limits of $\\{p_n\\}$. If $\\{p_n\\}$ is bounded, then $E$ is:",options:["Open","Countable","Nonempty and closed","Empty"],correctIndex:2,difficulty:"hard",explanation:"By Bolzano-Weierstrass, a bounded sequence has at least one convergent subsequence, so $E \\neq \\emptyset$. The set $E$ of subsequential limits is always closed."},{id:"sec14-q5",type:"multiple-choice",question:"A sequence in a compact set $K$:",options:["Has a subsequence converging to a point in $K$","Is always monotonic","Always converges","Must be eventually constant"],correctIndex:0,difficulty:"medium",explanation:"In a compact metric space, every sequence has a convergent subsequence with limit in the space. This is sequential compactness, equivalent to compactness in metric spaces."}],p=[{id:"sec15-q1",type:"multiple-choice",question:"A sequence $\\{p_n\\}$ in a metric space is Cauchy if:",options:["Each term equals the previous term","For every $\\varepsilon > 0$, there exists $N$ such that $m, n \\geq N$ implies $d(p_m, p_n) < \\varepsilon$","The sequence is bounded","The sequence converges"],correctIndex:1,difficulty:"medium",explanation:"A Cauchy sequence has terms that become arbitrarily close to each other: for any $\\varepsilon > 0$, eventually $d(p_m, p_n) < \\varepsilon$ for all large $m, n$."},{id:"sec15-q2",type:"multiple-choice",question:"In $\\mathbb{R}^k$, a sequence is Cauchy if and only if:",options:["It is monotonic","It converges","It has a convergent subsequence","It is bounded"],correctIndex:1,difficulty:"medium",explanation:"$\\mathbb{R}^k$ is complete: every Cauchy sequence converges. Conversely, every convergent sequence is Cauchy. So in $\\mathbb{R}^k$, Cauchy $\\Leftrightarrow$ convergent."},{id:"sec15-q3",type:"multiple-choice",question:"A metric space is complete if:",options:["It contains $\\mathbb{Q}$","It is bounded","It is compact","Every Cauchy sequence converges (to a point in the space)"],correctIndex:3,difficulty:"easy",explanation:"Completeness means Cauchy sequences converge within the space. $\\mathbb{R}^k$ is complete, but $\\mathbb{Q}$ is not (the Cauchy sequence $(1.4, 1.41, 1.414, \\ldots)$ has limit $\\sqrt{2} \\notin \\mathbb{Q}$)."},{id:"sec15-q4",type:"multiple-choice",question:"Every Cauchy sequence is:",options:["Eventually constant","Convergent","Bounded","Monotonic"],correctIndex:2,difficulty:"medium",explanation:"Every Cauchy sequence is bounded: for $\\varepsilon = 1$, there exists $N$ such that $d(p_m, p_n) < 1$ for $m, n \\geq N$. All terms are within distance $1$ of $p_N$, plus finitely many initial terms."},{id:"sec15-q5",type:"multiple-choice",question:"Which space is NOT complete?",options:["$\\mathbb{Q}$ with the standard metric","A compact metric space","$\\mathbb{R}^n$ with the Euclidean metric","$\\mathbb{R}$ with the standard metric"],correctIndex:0,difficulty:"easy",explanation:"$\\mathbb{Q}$ is not complete. For example, a sequence of rationals approximating $\\sqrt{2}$ is Cauchy but does not converge in $\\mathbb{Q}$. Compact spaces and $\\mathbb{R}^n$ are complete."}],y=[{id:"sec16-q1",type:"multiple-choice",question:"For a sequence $\\{s_n\\}$ of real numbers, $\\limsup_{n \\to \\infty} s_n$ is defined as:",options:["$\\sup_n s_n$","The average of all terms","The largest term of the sequence","$\\lim_{n \\to \\infty} (\\sup_{k \\geq n} s_k)$"],correctIndex:3,difficulty:"medium",explanation:"Let $a_n = \\sup_{k \\geq n} s_k$. This sequence is decreasing and $\\limsup s_n = \\lim_{n \\to \\infty} a_n$. It equals the largest subsequential limit."},{id:"sec16-q2",type:"multiple-choice",question:"If $\\{s_n\\}$ is bounded, then $\\limsup s_n$ is:",options:["Necessarily equal to $\\lim s_n$","Undefined","$+\\infty$","The largest limit of any convergent subsequence"],correctIndex:3,difficulty:"medium",explanation:"For a bounded sequence, $\\limsup s_n$ equals the largest subsequential limit (which exists by Bolzano-Weierstrass). Similarly, $\\liminf s_n$ is the smallest subsequential limit."},{id:"sec16-q3",type:"multiple-choice",question:"The sequence $\\{s_n\\}$ converges to $s$ if and only if:",options:["$\\limsup s_n > \\liminf s_n$","$\\limsup s_n = +\\infty$","$\\limsup s_n = \\liminf s_n = s$","$\\liminf s_n = -\\infty$"],correctIndex:2,difficulty:"medium",explanation:"Convergence to $s$ means all subsequential limits equal $s$, which happens iff $\\limsup s_n = \\liminf s_n = s$."},{id:"sec16-q4",type:"multiple-choice",question:"For $s_n = (-1)^n$, what are $\\limsup s_n$ and $\\liminf s_n$?",options:["$\\limsup = 0$, $\\liminf = 0$","$\\limsup = -1$, $\\liminf = 1$","$\\limsup = 1$, $\\liminf = -1$","$\\limsup = 1$, $\\liminf = 1$"],correctIndex:2,difficulty:"easy",explanation:"The sequence alternates: $-1, 1, -1, 1, \\ldots$. The subsequential limits are $\\{-1, 1\\}$, so $\\limsup = 1$ and $\\liminf = -1$."},{id:"sec16-q5",type:"multiple-choice",question:"For any sequence, $\\liminf s_n \\leq \\limsup s_n$:",options:["Is true only for bounded sequences","Is always true","Is true only for convergent sequences","Is always false"],correctIndex:1,difficulty:"easy",explanation:"By definition, $\\liminf s_n \\leq \\limsup s_n$ always. The sequence converges iff equality holds (and both are finite)."}],x=[{id:"sec17-q1",type:"multiple-choice",question:"What is $\\lim_{n \\to \\infty} \\frac{1}{n}$?",options:["$0$","Does not exist","$\\infty$","$1$"],correctIndex:0,difficulty:"easy",explanation:"By the Archimedean property, for any $\\varepsilon > 0$, there exists $N$ with $1/N < \\varepsilon$. Thus $1/n \\to 0$."},{id:"sec17-q2",type:"multiple-choice",question:"If $|x| < 1$, what is $\\lim_{n \\to \\infty} x^n$?",options:["$1$","$x$","$0$","Does not exist"],correctIndex:2,difficulty:"easy",explanation:"For $|x| < 1$, the sequence $|x|^n$ decreases geometrically to $0$. Hence $x^n \\to 0$."},{id:"sec17-q3",type:"multiple-choice",question:"What is $\\lim_{n \\to \\infty} n^{1/n}$?",options:["$1$","$\\infty$","$0$","$e$"],correctIndex:0,difficulty:"medium",explanation:"Let $y_n = n^{1/n}$. Taking logarithms: $\\ln y_n = \\frac{\\ln n}{n} \\to 0$ as $n \\to \\infty$. Thus $y_n \\to e^0 = 1$."},{id:"sec17-q4",type:"multiple-choice",question:"What is $\\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n}\\right)^n$?",options:["$1$","$2$","$e$","$\\infty$"],correctIndex:2,difficulty:"easy",explanation:"This is the definition of $e$: $\\lim_{n \\to \\infty} (1 + 1/n)^n = e \\approx 2.718$."},{id:"sec17-q5",type:"multiple-choice",question:"If $p > 0$, what is $\\lim_{n \\to \\infty} \\frac{n^p}{(1+r)^n}$ for $r > 0$?",options:["$0$","Depends on $p$ and $r$","$\\infty$","$1$"],correctIndex:0,difficulty:"medium",explanation:"Exponential growth beats polynomial growth: $(1+r)^n$ grows faster than $n^p$ for any fixed $p$. Thus $n^p/(1+r)^n \\to 0$."}],b=[{id:"sec18-q1",type:"multiple-choice",question:"The series $\\sum_{n=1}^{\\infty} a_n$ converges if:",options:["The partial sums $s_N = \\sum_{n=1}^{N} a_n$ converge","$|a_n| < 1$ for all $n$","$a_n \\to 0$","$a_n$ is decreasing"],correctIndex:0,difficulty:"easy",explanation:"By definition, $\\sum a_n$ converges if the sequence of partial sums $s_N = a_1 + a_2 + \\cdots + a_N$ converges as $N \\to \\infty$."},{id:"sec18-q2",type:"multiple-choice",question:"If $\\sum a_n$ converges, then:",options:["The series converges absolutely","$|a_n| < 1$ eventually","$a_n \\to 1$","$a_n \\to 0$"],correctIndex:3,difficulty:"easy",explanation:"A necessary (but not sufficient) condition for convergence: if $\\sum a_n$ converges, then $a_n \\to 0$. The converse is false: $\\sum 1/n$ diverges even though $1/n \\to 0$."},{id:"sec18-q3",type:"multiple-choice",question:"The Cauchy criterion for series states that $\\sum a_n$ converges iff:",options:["The terms are positive","The terms are bounded","For every $\\varepsilon > 0$, there exists $N$ such that $|\\sum_{k=m}^{n} a_k| < \\varepsilon$ for all $n \\geq m \\geq N$","$a_n \\to 0$"],correctIndex:2,difficulty:"hard",explanation:"The Cauchy criterion: $\\sum a_n$ converges iff for every $\\varepsilon > 0$, there exists $N$ such that $|a_{m} + a_{m+1} + \\cdots + a_n| < \\varepsilon$ for $n \\geq m \\geq N$."},{id:"sec18-q4",type:"multiple-choice",question:"The geometric series $\\sum_{n=0}^{\\infty} r^n$ converges if and only if:",options:["$r \\neq 1$","$|r| < 1$","$r > 0$","$r < 1$"],correctIndex:1,difficulty:"easy",explanation:"The geometric series converges iff $|r| < 1$, in which case $\\sum_{n=0}^{\\infty} r^n = 1/(1-r)$. For $|r| \\geq 1$, the terms do not approach zero."},{id:"sec18-q5",type:"multiple-choice",question:"Which statement about the harmonic series $\\sum_{n=1}^{\\infty} \\frac{1}{n}$ is true?",options:["It converges to $\\ln 2$","It converges because $1/n \\to 0$","It converges to $e$","It diverges"],correctIndex:3,difficulty:"medium",explanation:"The harmonic series diverges despite $1/n \\to 0$. One proof: $1 + 1/2 + (1/3 + 1/4) + (1/5 + \\cdots + 1/8) + \\cdots > 1 + 1/2 + 1/2 + 1/2 + \\cdots$."}],g=[{id:"sec19-q1",type:"multiple-choice",question:"The comparison test states: if $0 \\leq a_n \\leq b_n$ and $\\sum b_n$ converges, then:",options:["$\\sum a_n$ converges","Nothing can be concluded","$\\sum a_n = \\sum b_n$","$\\sum a_n$ diverges"],correctIndex:0,difficulty:"easy",explanation:"If $0 \\leq a_n \\leq b_n$ and $\\sum b_n$ converges, then $\\sum a_n$ converges (and $\\sum a_n \\leq \\sum b_n$). This is because the partial sums of $\\sum a_n$ are increasing and bounded."},{id:"sec19-q2",type:"multiple-choice",question:"If $0 \\leq a_n \\leq b_n$ and $\\sum a_n$ diverges, then:",options:["$\\sum b_n$ converges","$\\sum b_n$ diverges","$\\sum b_n$ may converge or diverge","$a_n = b_n$ for all $n$"],correctIndex:1,difficulty:"medium",explanation:"If a smaller series diverges, the larger one must also diverge. This is the contrapositive of the comparison test."},{id:"sec19-q3",type:"multiple-choice",question:"The $p$-series $\\sum_{n=1}^{\\infty} \\frac{1}{n^p}$ converges if and only if:",options:["$p = 2$","$p > 1$","$p \\geq 1$","$p > 0$"],correctIndex:1,difficulty:"medium",explanation:"The $p$-series converges iff $p > 1$. For $p \\leq 1$, comparison with the harmonic series shows divergence. For $p > 1$, the integral test proves convergence."},{id:"sec19-q4",type:"multiple-choice",question:"Which series converges?",options:["$\\sum \\frac{1}{n \\ln n}$ for $n \\geq 2$","$\\sum \\frac{1}{n^2}$","$\\sum \\frac{1}{\\sqrt{n}}$","$\\sum \\frac{1}{n}$"],correctIndex:1,difficulty:"easy",explanation:"$\\sum 1/n^2$ is a $p$-series with $p = 2 > 1$, so it converges. The others are $p \\leq 1$ or comparable to divergent series."},{id:"sec19-q5",type:"multiple-choice",question:"For series with nonnegative terms, convergence of partial sums to a finite limit is equivalent to:",options:["The terms being decreasing","The partial sums being bounded above","The partial sums being increasing","The terms going to zero"],correctIndex:1,difficulty:"medium",explanation:"For nonnegative $a_n$, partial sums $s_N$ are increasing. They converge iff bounded above (monotone convergence theorem). Boundedness is the key criterion."}],v=[{id:"sec20-q1",type:"multiple-choice",question:"The number $e$ is defined as:",options:["$\\lim_{n \\to \\infty} n!$","$\\sum_{n=0}^{\\infty} n!$","$\\sum_{n=0}^{\\infty} \\frac{1}{n!}$","$\\prod_{n=1}^{\\infty} (1 + 1/n)$"],correctIndex:2,difficulty:"easy",explanation:"$e = \\sum_{n=0}^{\\infty} \\frac{1}{n!} = 1 + 1 + \\frac{1}{2} + \\frac{1}{6} + \\cdots \\approx 2.71828$. Equivalently, $e = \\lim_{n \\to \\infty} (1 + 1/n)^n$."},{id:"sec20-q2",type:"multiple-choice",question:"The series $\\sum_{n=0}^{\\infty} \\frac{1}{n!}$ converges because:",options:["The terms are decreasing","It is an alternating series","The terms are positive","$1/n! \\leq 1/2^n$ for $n \\geq 1$, and $\\sum 1/2^n$ converges"],correctIndex:3,difficulty:"medium",explanation:"For $n \\geq 1$: $n! \\geq 2^{n-1}$, so $1/n! \\leq 2/2^n$. Since $\\sum 1/2^n$ converges, so does $\\sum 1/n!$ by comparison."},{id:"sec20-q3",type:"multiple-choice",question:"The number $e$ is:",options:["Rational","Irrational","An integer","Negative"],correctIndex:1,difficulty:"medium",explanation:"Rudin proves $e$ is irrational. If $e = p/q$ with $q \\geq 2$, then $q!(e - \\sum_{n=0}^{q} 1/n!)$ would be a positive integer less than $1$, a contradiction."},{id:"sec20-q4",type:"multiple-choice",question:"What is $\\lim_{n \\to \\infty} \\left(1 + \\frac{x}{n}\\right)^n$ for any real $x$?",options:["$1$","$e^x$","Does not exist","$x$"],correctIndex:1,difficulty:"hard",explanation:"This limit equals $e^x$. For $x = 1$, we get $e$. The general result follows from $\\ln(1 + x/n)^n = n \\ln(1 + x/n) \\to x$ as $n \\to \\infty$."},{id:"sec20-q5",type:"multiple-choice",question:"Between which two integers does $e$ lie?",options:["$1$ and $2$","$3$ and $4$","$0$ and $1$","$2$ and $3$"],correctIndex:3,difficulty:"easy",explanation:"$e = 1 + 1 + 1/2 + 1/6 + \\cdots$. The first three terms already give $2.5$, and the full sum is approximately $2.71828$. So $2 < e < 3$."}],_=[{id:"sec21-q1",type:"multiple-choice",question:"The root test: if $\\limsup_{n \\to \\infty} \\sqrt[n]{|a_n|} = L$, then $\\sum a_n$:",options:["Always converges","Converges if $L < 1$, diverges if $L > 1$","Converges if $L > 1$, diverges if $L < 1$","Always diverges"],correctIndex:1,difficulty:"medium",explanation:"Root test: if $\\limsup \\sqrt[n]{|a_n|} < 1$, the series converges absolutely. If $> 1$, it diverges. If $= 1$, the test is inconclusive."},{id:"sec21-q2",type:"multiple-choice",question:"The ratio test: if $\\lim_{n \\to \\infty} |a_{n+1}/a_n| = L$, then $\\sum a_n$:",options:["Is inconclusive for all $L$","Diverges if $L < 1$","Converges absolutely if $L < 1$, diverges if $L > 1$","Converges if $L > 1$"],correctIndex:2,difficulty:"medium",explanation:"Ratio test: if the limit is $L < 1$, the series converges absolutely. If $L > 1$, it diverges. If $L = 1$, the test is inconclusive."},{id:"sec21-q3",type:"multiple-choice",question:"Apply the ratio test to $\\sum \\frac{n!}{n^n}$. The series:",options:["Diverges","Converges","Converges conditionally but not absolutely","The ratio test is inconclusive"],correctIndex:1,difficulty:"hard",explanation:"$\\frac{a_{n+1}}{a_n} = \\frac{(n+1)!}{(n+1)^{n+1}} \\cdot \\frac{n^n}{n!} = \\frac{n^n}{(n+1)^n} = \\left(\\frac{n}{n+1}\\right)^n \\to 1/e < 1$. So the series converges."},{id:"sec21-q4",type:"multiple-choice",question:"For which series is both the root and ratio test inconclusive?",options:["$\\sum \\frac{1}{n!}$","$\\sum 2^n$","$\\sum \\frac{1}{n^2}$","$\\sum \\frac{1}{2^n}$"],correctIndex:2,difficulty:"hard",explanation:"For $\\sum 1/n^2$: $\\sqrt[n]{1/n^2} = 1/n^{2/n} \\to 1$ and $a_{n+1}/a_n = n^2/(n+1)^2 \\to 1$. Both tests give $L = 1$, inconclusive. (The series converges by the $p$-test.)"},{id:"sec21-q5",type:"multiple-choice",question:"Which statement is true about the root and ratio tests?",options:["The root test is at least as powerful as the ratio test","They always give the same result","Neither test can prove convergence","The ratio test is always more powerful than the root test"],correctIndex:0,difficulty:"hard",explanation:"If the ratio test limit exists and is $L$, then so is the root test limit. But the root test can sometimes detect convergence when the ratio test is inconclusive (limsup vs limit)."}],q=[{id:"sec22-q1",type:"multiple-choice",question:"A power series is an expression of the form:",options:["$\\sum_{n=0}^{\\infty} c_n$","$\\sum_{n=0}^{\\infty} c_n x^n$","$\\sum_{n=0}^{\\infty} n^x$","$\\prod_{n=0}^{\\infty} c_n x^n$"],correctIndex:1,difficulty:"easy",explanation:"A power series centered at $0$ has the form $\\sum_{n=0}^{\\infty} c_n x^n$, where $c_n$ are coefficients and $x$ is the variable."},{id:"sec22-q2",type:"multiple-choice",question:"The radius of convergence $R$ of a power series $\\sum c_n x^n$ is defined by:",options:["$R = \\lim_{n \\to \\infty} c_n$","$R = |c_0|$","$1/R = \\limsup_{n \\to \\infty} \\sqrt[n]{|c_n|}$","$R = \\sum |c_n|$"],correctIndex:2,difficulty:"medium",explanation:"By the root test, the series converges for $|x| \\limsup \\sqrt[n]{|c_n|} < 1$, i.e., $|x| < 1/\\limsup \\sqrt[n]{|c_n|} = R$."},{id:"sec22-q3",type:"multiple-choice",question:"If a power series $\\sum c_n x^n$ has radius of convergence $R$, then it:",options:["Converges absolutely for $|x| < R$ and diverges for $|x| > R$","Converges for $|x| = R$","Converges for all $x$","Converges only at $x = 0$"],correctIndex:0,difficulty:"medium",explanation:"Inside the radius ($|x| < R$): absolute convergence. Outside ($|x| > R$): divergence. At the boundary ($|x| = R$): could go either way, needs separate analysis."},{id:"sec22-q4",type:"multiple-choice",question:"What is the radius of convergence of $\\sum_{n=0}^{\\infty} x^n$?",options:["$0$","$e$","$\\infty$","$1$"],correctIndex:3,difficulty:"easy",explanation:"This is the geometric series. $c_n = 1$, so $\\limsup \\sqrt[n]{1} = 1$. Thus $R = 1$. It converges for $|x| < 1$ to $1/(1-x)$."},{id:"sec22-q5",type:"multiple-choice",question:"What is the radius of convergence of $\\sum_{n=0}^{\\infty} \\frac{x^n}{n!}$?",options:["$0$","$e$","$\\infty$","$1$"],correctIndex:2,difficulty:"medium",explanation:"Here $c_n = 1/n!$. $\\sqrt[n]{1/n!} \\to 0$ (since $n! > (n/e)^n$). Thus $1/R = 0$, so $R = \\infty$. The series converges for all $x$ (to $e^x$)."}],T=[{id:"sec23-q1",type:"multiple-choice",question:"Summation by parts is the discrete analog of:",options:["The chain rule","Integration by parts","The product rule","L'H\\^opital's rule"],correctIndex:1,difficulty:"easy",explanation:"Summation by parts: $\\sum a_n b_n = A_N b_N - \\sum A_n (b_{n+1} - b_n)$ where $A_n = \\sum_{k=1}^n a_k$. This mirrors $\\int u\\,dv = uv - \\int v\\,du$."},{id:"sec23-q2",type:"multiple-choice",question:"Abel's theorem concerns:",options:["Continuity of power series at boundary points where they converge","Compact sets in $\\mathbb{R}^n$","The irrationality of $e$","The divergence of the harmonic series"],correctIndex:0,difficulty:"medium",explanation:"Abel's theorem: if $\\sum c_n$ converges to $s$, then $\\lim_{x \\to 1^-} \\sum c_n x^n = s$. The power series extends continuously to $x = 1$."},{id:"sec23-q3",type:"multiple-choice",question:"Dirichlet's test for convergence requires:",options:["$\\sum a_n$ and $\\sum b_n$ both converge","$\\{a_n\\}$ with bounded partial sums and $\\{b_n\\}$ monotonically decreasing to $0$","$a_n$ and $b_n$ both positive","$a_n b_n \\to 0$"],correctIndex:1,difficulty:"hard",explanation:"Dirichlet's test: if partial sums $A_n = \\sum_{k=1}^n a_k$ are bounded and $b_n \\downarrow 0$, then $\\sum a_n b_n$ converges. Proved using summation by parts."},{id:"sec23-q4",type:"multiple-choice",question:"The alternating series $\\sum (-1)^n / n$ converges by:",options:["The Leibniz (alternating series) test or Dirichlet's test","The ratio test","The comparison test","The root test"],correctIndex:0,difficulty:"medium",explanation:"Take $a_n = (-1)^n$ (bounded partial sums: $0$ or $-1$) and $b_n = 1/n \\downarrow 0$. Dirichlet's test applies. Equivalently, use the alternating series test."},{id:"sec23-q5",type:"multiple-choice",question:"Using Abel's theorem, $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n}$ equals:",options:["$e$","$\\ln 2$","$1$","$\\pi$"],correctIndex:1,difficulty:"hard",explanation:"We know $\\ln(1+x) = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1} x^n}{n}$ for $|x| < 1$. The series at $x = 1$ converges. By Abel's theorem, it equals $\\lim_{x \\to 1^-} \\ln(1+x) = \\ln 2$."}],I=[{id:"sec24-q1",type:"multiple-choice",question:"A series $\\sum a_n$ converges absolutely if:",options:["$\\sum |a_n|$ converges","$a_n$ is monotonic","$a_n \\to 0$","The partial sums are bounded"],correctIndex:0,difficulty:"easy",explanation:"Absolute convergence means $\\sum |a_n| < \\infty$. This is stronger than ordinary (conditional) convergence."},{id:"sec24-q2",type:"multiple-choice",question:"If $\\sum a_n$ converges absolutely, then:",options:["The series can be rearranged to diverge","$\\sum a_n$ converges","$\\sum a_n$ diverges","$a_n$ does not approach zero"],correctIndex:1,difficulty:"easy",explanation:"Absolute convergence implies convergence: if $\\sum |a_n|$ converges, then $\\sum a_n$ converges (and to a specific value independent of ordering)."},{id:"sec24-q3",type:"multiple-choice",question:"The series $\\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n}$:",options:["Oscillates without converging","Converges absolutely","Converges conditionally (but not absolutely)","Diverges"],correctIndex:2,difficulty:"medium",explanation:"The alternating harmonic series converges (by the alternating series test) to $\\ln 2$. But $\\sum 1/n$ diverges, so convergence is conditional, not absolute."},{id:"sec24-q4",type:"multiple-choice",question:"Which series converges absolutely?",options:["$\\sum \\frac{(-1)^n}{n^2}$","$\\sum \\frac{(-1)^n}{n}$","$\\sum \\frac{(-1)^n}{\\ln n}$","$\\sum \\frac{(-1)^n}{\\sqrt{n}}$"],correctIndex:0,difficulty:"medium",explanation:"For $\\sum (-1)^n/n^2$, we have $\\sum |(-1)^n/n^2| = \\sum 1/n^2$, which is a convergent $p$-series ($p = 2 > 1$). So absolute convergence holds."},{id:"sec24-q5",type:"multiple-choice",question:"Why is absolute convergence a stronger property than conditional convergence?",options:["Absolutely convergent series have larger sums","Absolutely convergent series can be rearranged without changing the sum","Conditionally convergent series always diverge","Absolute convergence only applies to positive series"],correctIndex:1,difficulty:"hard",explanation:"Absolutely convergent series can be rearranged in any order with the same sum. Conditionally convergent series can be rearranged to converge to any value or to diverge (Riemann rearrangement theorem)."}],w=[{id:"sec25-q1",type:"multiple-choice",question:"The Cauchy product of $\\sum a_n$ and $\\sum b_n$ is $\\sum c_n$ where:",options:["$c_n = a_n / b_n$","$c_n = a_n + b_n$","$c_n = \\sum_{k=0}^{n} a_k b_{n-k}$","$c_n = a_n b_n$"],correctIndex:2,difficulty:"medium",explanation:"The Cauchy product is defined by $c_n = \\sum_{k=0}^{n} a_k b_{n-k}$. This corresponds to the product of formal power series: $(\\sum a_n x^n)(\\sum b_n x^n) = \\sum c_n x^n$."},{id:"sec25-q2",type:"multiple-choice",question:"If $\\sum a_n$ and $\\sum b_n$ both converge absolutely, then their Cauchy product:",options:["May diverge","Converges to $(\\sum a_n)(\\sum b_n)$","Converges conditionally only","Equals $\\sum a_n b_n$"],correctIndex:1,difficulty:"medium",explanation:"Mertens' theorem: if at least one series converges absolutely, the Cauchy product converges to the product of the sums. With both absolutely convergent, the result is absolute as well."},{id:"sec25-q3",type:"multiple-choice",question:"The Cauchy product of $\\sum_{n=0}^{\\infty} x^n$ with itself gives:",options:["$\\sum_{n=0}^{\\infty} 2^n x^n$","$\\sum_{n=0}^{\\infty} x^{2n}$","$\\sum_{n=0}^{\\infty} x^n / n!$","$\\sum_{n=0}^{\\infty} (n+1)x^n$"],correctIndex:3,difficulty:"hard",explanation:"With $a_n = b_n = 1$, $c_n = \\sum_{k=0}^{n} 1 \\cdot 1 = n + 1$. So $(\\sum x^n)^2 = \\sum (n+1)x^n = 1/(1-x)^2$ for $|x| < 1$."},{id:"sec25-q4",type:"multiple-choice",question:"Using the Cauchy product, $e^x \\cdot e^y$ equals:",options:["$e^{xy}$","$(e^x)^y$","$e^x + e^y$","$e^{x+y}$"],correctIndex:3,difficulty:"medium",explanation:"The Cauchy product of $e^x = \\sum x^n/n!$ and $e^y = \\sum y^n/n!$ gives $\\sum (x+y)^n/n! = e^{x+y}$ by the binomial theorem."},{id:"sec25-q5",type:"multiple-choice",question:"If $\\sum a_n$ converges conditionally and $\\sum b_n$ also converges conditionally, their Cauchy product:",options:["Always equals zero","May diverge","Always converges","Converges absolutely"],correctIndex:1,difficulty:"hard",explanation:"The Cauchy product of two conditionally convergent series may diverge. A classic example is the Cauchy square of $\\sum (-1)^n/\\sqrt{n+1}$, which diverges."}],A=[{id:"sec26-q1",type:"multiple-choice",question:"A rearrangement of a series $\\sum a_n$ is:",options:["Multiplying each term by a constant","Reversing the order of the first $N$ terms","Taking every other term","A series $\\sum a_{\\sigma(n)}$ where $\\sigma: \\mathbb{Z}^+ \\to \\mathbb{Z}^+$ is a bijection"],correctIndex:3,difficulty:"medium",explanation:"A rearrangement uses a bijection $\\sigma$ to reorder the terms. Every term appears exactly once, just in a different order."},{id:"sec26-q2",type:"multiple-choice",question:"If $\\sum a_n$ converges absolutely, then any rearrangement:",options:["Converges to the same sum","May converge to a different sum","Converges conditionally","Diverges"],correctIndex:0,difficulty:"medium",explanation:"Absolutely convergent series are unconditionally convergent: any rearrangement converges to the same sum. This is a key property distinguishing absolute from conditional convergence."},{id:"sec26-q3",type:"multiple-choice",question:"The Riemann rearrangement theorem states that if $\\sum a_n$ converges conditionally, then:",options:["All rearrangements converge to the same sum","Rearrangements can converge to any real number, or diverge","The series converges absolutely","No rearrangement exists"],correctIndex:1,difficulty:"hard",explanation:"Riemann's theorem: a conditionally convergent series can be rearranged to converge to any given real number $L$, or to diverge to $+\\infty$, $-\\infty$, or oscillate."},{id:"sec26-q4",type:"multiple-choice",question:"The alternating harmonic series can be rearranged to converge to:",options:["Only $\\ln 2$","Any real number","Any positive number","Only integers"],correctIndex:1,difficulty:"hard",explanation:"The alternating harmonic series converges conditionally. By Riemann's theorem, it can be rearranged to sum to any real number. For example, certain rearrangements give $3\\ln 2/2$ instead of $\\ln 2$."},{id:"sec26-q5",type:"multiple-choice",question:"Why can rearrangements change the sum of a conditionally convergent series?",options:["Because the terms are not decreasing","Because the limit is irrational","Because $\\sum a_n^+ = \\infty$ and $\\sum a_n^- = \\infty$ (both positive and negative parts diverge)","Because the series has infinitely many terms"],correctIndex:2,difficulty:"hard",explanation:"Conditional convergence means $\\sum |a_n| = \\infty$. Split: $a_n^+ = \\max(a_n, 0)$ and $a_n^- = \\max(-a_n, 0)$. Both $\\sum a_n^+$ and $\\sum a_n^-$ diverge, allowing arbitrary rearrangement sums."}],R=[{id:"sec27-q1",type:"multiple-choice",question:"Let $f: E \\to \\mathbb{R}$ and $p$ be a limit point of $E$. We say $\\lim_{x \\to p} f(x) = q$ if:",options:["For every $\\varepsilon > 0$, there exists $\\delta > 0$ such that $0 < |x - p| < \\delta$ and $x \\in E$ implies $|f(x) - q| < \\varepsilon$","$q$ is in the range of $f$","$f(p) = q$","$f$ is continuous at $p$"],correctIndex:0,difficulty:"medium",explanation:"The $\\varepsilon$-$\\delta$ definition of limit: $f(x)$ can be made arbitrarily close to $q$ by taking $x$ sufficiently close to (but not equal to) $p$."},{id:"sec27-q2",type:"multiple-choice",question:"The condition $0 < |x - p|$ in the limit definition means:",options:["$x$ must be positive","$x$ must equal $p$","$|x - p|$ must be an integer","$x \\neq p$ (we exclude the point $p$ itself)"],correctIndex:3,difficulty:"easy",explanation:"The strict inequality $0 < |x - p|$ means $x \\neq p$. The limit depends only on the behavior of $f$ near $p$, not at $p$. Indeed, $f(p)$ need not even be defined."},{id:"sec27-q3",type:"multiple-choice",question:"If $\\lim_{x \\to p} f(x) = A$ and $\\lim_{x \\to p} g(x) = B$, then $\\lim_{x \\to p} (f(x) + g(x)) =$",options:["$A + B$","Does not exist","$AB$","$A/B$"],correctIndex:0,difficulty:"easy",explanation:"Limits respect arithmetic operations: $\\lim(f + g) = \\lim f + \\lim g$, provided both limits exist. Similarly for products and quotients (when denominator limit is nonzero)."},{id:"sec27-q4",type:"multiple-choice",question:"The sequential characterization of limits: $\\lim_{x \\to p} f(x) = q$ if and only if:",options:["$f(p) = q$","$f$ is bounded near $p$","$f$ is monotonic near $p$","For every sequence $\\{p_n\\} \\to p$ with $p_n \\neq p$, we have $f(p_n) \\to q$"],correctIndex:3,difficulty:"medium",explanation:"The $\\varepsilon$-$\\delta$ limit equals $q$ iff for every sequence $p_n \\to p$ (with $p_n \\neq p$), the sequence $f(p_n) \\to q$. This links limits of functions to limits of sequences."},{id:"sec27-q5",type:"multiple-choice",question:"If $\\lim_{x \\to p} f(x)$ exists, it is:",options:["Not necessarily unique","Unique","Always equal to $f(p)$","Always rational"],correctIndex:1,difficulty:"easy",explanation:"Limits, when they exist, are unique. If $\\lim_{x \\to p} f(x) = q_1$ and $= q_2$, then for any $\\varepsilon$, $|q_1 - q_2| \\leq |q_1 - f(x)| + |f(x) - q_2| < 2\\varepsilon$, so $q_1 = q_2$."}],E=[{id:"sec28-q1",type:"multiple-choice",question:"A function $f: E \\to Y$ is continuous at $p \\in E$ if:",options:["For every $\\varepsilon > 0$, there exists $\\delta > 0$ such that $d_E(x, p) < \\delta$ implies $d_Y(f(x), f(p)) < \\varepsilon$","$f$ is bounded near $p$","$f(p)$ is the maximum of $f$ on $E$","$f$ is differentiable at $p$"],correctIndex:0,difficulty:"medium",explanation:"Continuity at $p$: $f(x)$ is close to $f(p)$ whenever $x$ is close to $p$. Unlike limits, we include $x = p$ and require $f(p)$ to be defined."},{id:"sec28-q2",type:"multiple-choice",question:"If $p$ is a limit point of $E$, then $f$ is continuous at $p$ if and only if:",options:["$\\lim_{x \\to p} f(x) = f(p)$","$f(p) = 0$","$f$ is bounded","$\\lim_{x \\to p} f(x)$ does not exist"],correctIndex:0,difficulty:"medium",explanation:"At a limit point, continuity is equivalent to: the limit exists and equals the function value. $\\lim_{x \\to p} f(x) = f(p)$ combines the limit definition with the value at $p$."},{id:"sec28-q3",type:"multiple-choice",question:"If $f$ and $g$ are continuous at $p$, then $f + g$ is:",options:["Continuous at $p$","Continuous only if $f = g$","Not defined at $p$","Discontinuous at $p$"],correctIndex:0,difficulty:"easy",explanation:"Sums (and products, quotients with nonzero denominator) of continuous functions are continuous. This follows from the corresponding limit laws."},{id:"sec28-q4",type:"multiple-choice",question:"The composition of continuous functions is:",options:["Always differentiable","Not necessarily continuous","Defined only for polynomial functions","Continuous"],correctIndex:3,difficulty:"easy",explanation:"If $f$ is continuous at $p$ and $g$ is continuous at $f(p)$, then $g \\circ f$ is continuous at $p$. Composition preserves continuity."},{id:"sec28-q5",type:"multiple-choice",question:"A function $f: X \\to Y$ is continuous (on all of $X$) if and only if:",options:["$f$ is one-to-one","The preimage of every open set in $Y$ is open in $X$","The image of every open set in $X$ is open in $Y$","$f$ is bounded"],correctIndex:1,difficulty:"hard",explanation:"The topological characterization: $f$ is continuous iff $f^{-1}(V)$ is open in $X$ whenever $V$ is open in $Y$. This global definition is equivalent to pointwise continuity."}],k=[{id:1,type:"multiple-choice",question:"A function $f: K \\to \\mathbb{R}$ is uniformly continuous on a compact set $K$ if and only if:",options:["It is continuous at each point of $K$","It is bounded on $K$","It is differentiable on $K$","It has a continuous derivative on $K$"],correctIndex:0,difficulty:"medium",explanation:"Rudin's Theorem 4.19 states that if $K$ is compact and $f: K \\to \\mathbb{R}$ is continuous, then $f$ is uniformly continuous on $K$. The key insight is that continuity on a compact set automatically implies uniform continuity."},{id:2,type:"multiple-choice",question:"Which function is NOT uniformly continuous on $(0, 1)$?",options:["$f(x) = \\sin(x)$","$f(x) = x^2$","$f(x) = \\sqrt{x}$","$f(x) = \\frac{1}{x}$"],correctIndex:3,difficulty:"medium",explanation:"The function $f(x) = \\frac{1}{x}$ is not uniformly continuous on $(0, 1)$ because as $x \\to 0^+$, the function grows without bound. For any $\\delta > 0$, we can find points $x, y$ with $|x - y| < \\delta$ but $|f(x) - f(y)|$ arbitrarily large near $0$."},{id:3,type:"multiple-choice",question:"The definition of uniform continuity differs from pointwise continuity because:",options:["The choice of $\\delta$ depends only on $\\epsilon$, not on the point","The domain must be an interval","The function must be differentiable","The function must be bounded"],correctIndex:0,difficulty:"easy",explanation:"In uniform continuity, given $\\epsilon > 0$, we find $\\delta > 0$ such that $|x - y| < \\delta$ implies $|f(x) - f(y)| < \\epsilon$ for ALL pairs $x, y$. The $\\delta$ works uniformly across the entire domain, independent of the particular point."},{id:4,type:"multiple-choice",question:"If $f$ is uniformly continuous on $(a, b)$, then:",options:["$f$ can be extended to a continuous function on $[a, b]$","$f$ must be bounded on $(a, b)$","$f$ must be differentiable on $(a, b)$","Both A and B are true"],correctIndex:3,difficulty:"hard",explanation:"If $f$ is uniformly continuous on $(a, b)$, then $\\lim_{x \\to a^+} f(x)$ and $\\lim_{x \\to b^-} f(x)$ both exist (by the Cauchy criterion applied to sequences). Thus $f$ extends continuously to $[a, b]$, and continuous functions on compact sets are bounded."},{id:5,type:"multiple-choice",question:"Let $f(x) = x \\sin(1/x)$ for $x \\neq 0$. On which set is $f$ uniformly continuous?",options:["$(0, 1)$","$[1, \\infty)$","$f$ is not uniformly continuous on any interval","$(0, \\infty)$"],correctIndex:1,difficulty:"hard",explanation:"On $[1, \\infty)$, we have $|f'(x)| = |\\sin(1/x) - (1/x)\\cos(1/x)| \\leq 1 + 1 = 2$. A function with bounded derivative on an interval is Lipschitz, hence uniformly continuous. On $(0, 1)$, the oscillations near $0$ prevent uniform continuity."}],F=[{id:1,type:"multiple-choice",question:"The Intermediate Value Theorem requires that the domain be:",options:["Connected","Open","Compact","Bounded"],correctIndex:0,difficulty:"medium",explanation:"The IVT states that continuous images of connected sets are connected. In $\\mathbb{R}$, connected sets are intervals, so a continuous function on an interval takes all values between any two of its values."},{id:2,type:"multiple-choice",question:"If $f: [0, 1] \\to \\mathbb{R}$ is continuous with $f(0) = -1$ and $f(1) = 1$, which statement must be true?",options:["$f$ is monotonic on $[0, 1]$","There exists at least one $c \\in (0, 1)$ with $f(c) = 0$","$f$ is differentiable at some point in $(0, 1)$","There exists exactly one $c \\in (0, 1)$ with $f(c) = 0$"],correctIndex:1,difficulty:"easy",explanation:"By the IVT, since $f(0) < 0 < f(1)$ and $f$ is continuous, there exists at least one $c \\in (0, 1)$ where $f(c) = 0$. There may be multiple such points (consider $f(x) = \\sin(10\\pi x) + 2x - 1$)."},{id:3,type:"multiple-choice",question:"A continuous function $f: \\mathbb{R} \\to \\mathbb{R}$ maps connected sets to:",options:["Compact sets","Open sets","Connected sets","Closed sets"],correctIndex:2,difficulty:"easy",explanation:"Theorem 4.22 in Rudin: If $f$ is continuous and $E$ is connected, then $f(E)$ is connected. This is the topological generalization of the Intermediate Value Theorem."},{id:4,type:"multiple-choice",question:"Which function demonstrates that the converse of the IVT is false?",options:["$f(x) = \\begin{cases} \\sin(1/x) & x \\neq 0 \\\\ 0 & x = 0 \\end{cases}$","$f(x) = |x|$","$f(x) = \\begin{cases} x & x < 0 \\\\ x + 1 & x \\geq 0 \\end{cases}$","$f(x) = x^3$"],correctIndex:0,difficulty:"hard",explanation:"The topologist's sine curve $f(x) = \\sin(1/x)$ (extended by $f(0) = 0$) satisfies the intermediate value property on any interval containing $0$, but is discontinuous at $x = 0$. This shows having the IVP does not imply continuity."},{id:5,type:"multiple-choice",question:"If $f: [a, b] \\to [a, b]$ is continuous, then:",options:["$f$ has at least one fixed point","$f$ is a contraction mapping","$f$ has exactly one fixed point","$f$ may have no fixed points"],correctIndex:0,difficulty:"medium",explanation:"Consider $g(x) = f(x) - x$. Then $g(a) = f(a) - a \\geq 0$ (since $f(a) \\geq a$) and $g(b) = f(b) - b \\leq 0$ (since $f(b) \\leq b$). By the IVT, there exists $c \\in [a, b]$ with $g(c) = 0$, i.e., $f(c) = c$."}],C=[{id:1,type:"multiple-choice",question:"A discontinuity at $x = c$ is called a discontinuity of the first kind (simple discontinuity) if:",options:["The limit $\\lim_{x \\to c} f(x)$ exists but differs from $f(c)$","The function is unbounded near $c$","The function oscillates infinitely near $c$","Both one-sided limits $f(c^+)$ and $f(c^-)$ exist and are finite"],correctIndex:3,difficulty:"medium",explanation:"A simple discontinuity (first kind) occurs when both one-sided limits exist and are finite. This includes jump discontinuities (where $f(c^+) \\neq f(c^-)$) and removable discontinuities (where $f(c^+) = f(c^-) \\neq f(c)$)."},{id:2,type:"multiple-choice",question:"The function $f(x) = \\sin(1/x)$ for $x \\neq 0$ has what type of discontinuity at $x = 0$?",options:["Discontinuity of the second kind","Jump discontinuity","No discontinuity (can be made continuous)","Removable discontinuity"],correctIndex:0,difficulty:"medium",explanation:"As $x \\to 0$, $\\sin(1/x)$ oscillates between $-1$ and $1$ infinitely often, so neither $\\lim_{x \\to 0^+}$ nor $\\lim_{x \\to 0^-}$ exists. This is a discontinuity of the second kind."},{id:3,type:"multiple-choice",question:"If $f$ has a jump discontinuity at $c$, which statement is true?",options:["$f(c^+)$ and $f(c^-)$ both exist but $f(c^+) \\neq f(c^-)$","The discontinuity can be removed by redefining $f(c)$","$f(c^+) - f(c^-) = 0$","$f$ is unbounded in every neighborhood of $c$"],correctIndex:0,difficulty:"easy",explanation:'A jump discontinuity is characterized by both one-sided limits existing but being unequal: $f(c^+) \\neq f(c^-)$. The "jump" is the difference $f(c^+) - f(c^-)$.'},{id:4,type:"multiple-choice",question:"A monotonic function $f: (a, b) \\to \\mathbb{R}$ can have:",options:["Discontinuities of the second kind","Uncountably many discontinuities","Only finitely many discontinuities","At most countably many discontinuities, all of the first kind"],correctIndex:3,difficulty:"hard",explanation:"Theorem 4.30 in Rudin: Monotonic functions have only discontinuities of the first kind (jumps), and the set of discontinuities is at most countable. This follows because each jump corresponds to a disjoint interval in the range, and $\\mathbb{R}$ has only countably many disjoint intervals of positive length."},{id:5,type:"multiple-choice",question:"Consider $f(x) = \\begin{cases} x & x \\in \\mathbb{Q} \\\\ 0 & x \\notin \\mathbb{Q} \\end{cases}$. At which points is $f$ continuous?",options:["Nowhere","All irrational points","Only at $x = 0$","All rational points"],correctIndex:2,difficulty:"hard",explanation:"At $x = 0$: for any sequence $x_n \\to 0$, we have $|f(x_n)| \\leq |x_n| \\to 0$, so $f$ is continuous at $0$. At any $c \\neq 0$: if $c \\in \\mathbb{Q}$, take irrationals $x_n \\to c$, then $f(x_n) = 0 \\neq c = f(c)$. If $c \\notin \\mathbb{Q}$, take rationals $x_n \\to c$, then $f(x_n) = x_n \\to c \\neq 0 = f(c)$."}],z=[{id:1,type:"multiple-choice",question:"If $f: (a, b) \\to \\mathbb{R}$ is monotonically increasing, then at each point $x \\in (a, b)$:",options:["$f$ is differentiable","Both $f(x^+)$ and $f(x^-)$ exist, with $f(x^-) \\leq f(x) \\leq f(x^+)$","$f$ is uniformly continuous","$f$ is continuous"],correctIndex:1,difficulty:"medium",explanation:"For monotonically increasing $f$, the left and right limits always exist at interior points, and we have $f(x^-) \\leq f(x) \\leq f(x^+)$. The function is continuous at $x$ if and only if $f(x^-) = f(x^+)$."},{id:2,type:"multiple-choice",question:"The set of discontinuities of a monotonic function on $(a, b)$ is:",options:["At most countable","Always finite","Possibly uncountable","Always empty"],correctIndex:0,difficulty:"medium",explanation:'Each discontinuity of a monotonic function corresponds to a "jump" which occupies a non-empty open interval in the range. Since disjoint open intervals in $\\mathbb{R}$ can be put in bijection with rationals they contain, there can be at most countably many such jumps.'},{id:3,type:"multiple-choice",question:"If $f$ is strictly increasing on $[a, b]$, then $f^{-1}$:",options:["May not exist","Exists but may be discontinuous","Exists and is continuous on $f([a, b])$","Exists only if $f$ is differentiable"],correctIndex:2,difficulty:"medium",explanation:"A strictly increasing function is injective, so $f^{-1}$ exists on the range. Since $f$ is continuous and strictly increasing on the compact set $[a, b]$, $f([a, b]) = [f(a), f(b)]$, and $f^{-1}$ is also strictly increasing and continuous on this interval."},{id:4,type:"multiple-choice",question:"Which statement about monotonic functions is FALSE?",options:["A monotonic function is uniformly continuous on any bounded interval","A monotonic function is Riemann integrable on any closed bounded interval","A monotonic function is differentiable almost everywhere","A monotonic function has one-sided limits at every point"],correctIndex:0,difficulty:"hard",explanation:"Consider a monotonic function with infinitely many jump discontinuities accumulating at a point (e.g., $f(x) = \\sum_{n: 1/n < x} 2^{-n}$). Such a function is not uniformly continuous on intervals containing the accumulation point. The other statements are all true."},{id:5,type:"multiple-choice",question:"Let $f$ be increasing on $(a, b)$ and let $E = \\{x : f(x^-) < f(x^+)\\}$. Then:",options:["$E$ is finite","$\\sum_{x \\in E} (f(x^+) - f(x^-)) \\leq f(b^-) - f(a^+)$","$E$ is uncountable","$E$ is empty"],correctIndex:1,difficulty:"hard",explanation:"The jumps correspond to disjoint intervals in the range of $f$, so the sum of all jump sizes is bounded by the total variation of $f$ on $(a, b)$, which is at most $f(b^-) - f(a^+)$ for an increasing function."}],B=[{id:1,type:"multiple-choice",question:"What does $\\lim_{x \\to a} f(x) = +\\infty$ mean precisely?",options:["$f$ is increasing near $a$","For every $M > 0$, there exists $\\delta > 0$ such that $0 < |x - a| < \\delta$ implies $f(x) > M$","The function $f$ is unbounded near $a$","The function $f(a) = +\\infty$"],correctIndex:1,difficulty:"easy",explanation:"The precise definition: $\\lim_{x \\to a} f(x) = +\\infty$ means for every $M > 0$ (no matter how large), there exists $\\delta > 0$ such that whenever $0 < |x - a| < \\delta$, we have $f(x) > M$."},{id:2,type:"multiple-choice",question:"If $\\lim_{x \\to a} f(x) = +\\infty$ and $\\lim_{x \\to a} g(x) = +\\infty$, what can we say about $\\lim_{x \\to a} (f(x) - g(x))$?",options:["It equals $0$","It does not exist","It equals $+\\infty$","It could be any real number, $+\\infty$, $-\\infty$, or not exist"],correctIndex:3,difficulty:"medium",explanation:"The expression $\\infty - \\infty$ is an indeterminate form. Examples: $x^2 - x \\to +\\infty$, $x - x \\to 0$, $x - x^2 \\to -\\infty$, and $x - x\\sin(1/x)$ may not have a limit."},{id:3,type:"multiple-choice",question:"For $f(x) = \\frac{1}{(x-1)^2}$, evaluate $\\lim_{x \\to 1} f(x)$:",options:["Does not exist (left and right limits differ)","$+\\infty$","$-\\infty$","$0$"],correctIndex:1,difficulty:"easy",explanation:"As $x \\to 1$, $(x-1)^2 \\to 0^+$ (always positive), so $\\frac{1}{(x-1)^2} \\to +\\infty$. Both one-sided limits are $+\\infty$, so the limit is $+\\infty$."},{id:4,type:"multiple-choice",question:"Which statement about limits at infinity is correct?",options:["$\\lim_{x \\to \\infty} \\frac{\\sin(x)}{x} = 0$","$\\lim_{x \\to \\infty} x\\sin(1/x) = 0$","$\\lim_{x \\to \\infty} \\sin(x)/\\sin(x) = 1$ proves that $\\lim_{x \\to \\infty} \\sin(x)$ exists","$\\lim_{x \\to \\infty} \\sin(x) = 0$"],correctIndex:0,difficulty:"medium",explanation:"Since $|\\sin(x)| \\leq 1$ for all $x$, we have $|\\sin(x)/x| \\leq 1/|x| \\to 0$ as $x \\to \\infty$. By the squeeze theorem, $\\lim_{x \\to \\infty} \\frac{\\sin(x)}{x} = 0$."},{id:5,type:"multiple-choice",question:"If $\\lim_{x \\to \\infty} f(x) = L$ (finite), which statement must be true?",options:["$f$ is bounded on $[a, \\infty)$ for some $a$","$f$ is monotonic for large $x$","$f$ is uniformly continuous on $\\mathbb{R}$","$f$ is bounded on $\\mathbb{R}$"],correctIndex:0,difficulty:"medium",explanation:"If $\\lim_{x \\to \\infty} f(x) = L$, then for $\\epsilon = 1$, there exists $a$ such that $x > a$ implies $|f(x) - L| < 1$. Thus $|f(x)| < |L| + 1$ for $x > a$, so $f$ is bounded on $(a, \\infty)$."}],L=[{id:1,type:"multiple-choice",question:"The derivative $f'(x)$ is defined as:",options:["$\\lim_{h \\to 0} \\frac{f(x+h) + f(x)}{h}$","$\\lim_{h \\to 0} \\frac{f(x) - f(x-h)}{2h}$","$\\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$","$\\frac{f(b) - f(a)}{b - a}$"],correctIndex:2,difficulty:"easy",explanation:"The derivative is defined as $f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$, representing the instantaneous rate of change of $f$ at $x$, or equivalently the slope of the tangent line."},{id:2,type:"multiple-choice",question:"If $f$ is differentiable at $x$, then $f$ is:",options:["Monotonic near $x$","Continuous at $x$","Bounded near $x$","Differentiable in a neighborhood of $x$"],correctIndex:1,difficulty:"easy",explanation:"Theorem 5.2 in Rudin: If $f$ is differentiable at $x$, then $f$ is continuous at $x$. Proof: $f(x+h) - f(x) = h \\cdot \\frac{f(x+h) - f(x)}{h} \\to 0 \\cdot f'(x) = 0$ as $h \\to 0$."},{id:3,type:"multiple-choice",question:"The function $f(x) = |x|$ at $x = 0$:",options:["Is differentiable with $f'(0) = 1$","Is continuous but not differentiable","Is differentiable with $f'(0) = 0$","Is neither continuous nor differentiable"],correctIndex:1,difficulty:"easy",explanation:"The left derivative is $\\lim_{h \\to 0^-} \\frac{|h|}{h} = -1$ and the right derivative is $\\lim_{h \\to 0^+} \\frac{|h|}{h} = 1$. Since these differ, $f$ is not differentiable at $0$, but $f$ is clearly continuous there."},{id:4,type:"multiple-choice",question:"If $f$ and $g$ are differentiable at $x$ and $g(x) \\neq 0$, then $(f/g)'(x) = $",options:["$\\frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2}$","$\\frac{f'(x)g(x) + f(x)g'(x)}{g(x)^2}$","$\\frac{f(x)g'(x) - f'(x)g(x)}{g(x)^2}$","$\\frac{f'(x)}{g'(x)}$"],correctIndex:0,difficulty:"medium",explanation:"The quotient rule states $(f/g)'(x) = \\frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2}$. This follows from the product rule applied to $f \\cdot (1/g)$ along with the chain rule for $1/g$."},{id:5,type:"multiple-choice",question:"The function $f(x) = x^2 \\sin(1/x)$ for $x \\neq 0$ and $f(0) = 0$ is:",options:["Differentiable at $0$ with $f'(0) = 0$","Not continuous at $0$","Differentiable at $0$ with $f'(0) = 1$","Continuous but not differentiable at $0$"],correctIndex:0,difficulty:"hard",explanation:"$f'(0) = \\lim_{h \\to 0} \\frac{h^2 \\sin(1/h)}{h} = \\lim_{h \\to 0} h \\sin(1/h) = 0$ by the squeeze theorem (since $|h \\sin(1/h)| \\leq |h| \\to 0$). Note: $f'$ exists at $0$ but is not continuous there."}],Q=[{id:1,type:"multiple-choice",question:"Rolle's Theorem states that if $f$ is continuous on $[a,b]$, differentiable on $(a,b)$, and $f(a) = f(b)$, then:",options:["$f$ has a maximum at some $c \\in (a, b)$","There exists $c \\in (a, b)$ with $f'(c) = 0$","There exists $c \\in (a, b)$ with $f'(c) = \\frac{f(b) - f(a)}{b - a}$","$f$ is constant on $[a, b]$"],correctIndex:1,difficulty:"easy",explanation:"Rolle's Theorem guarantees a point $c \\in (a,b)$ where $f'(c) = 0$. Since $f(a) = f(b)$, the Mean Value Theorem reduces to Rolle's: there's a horizontal tangent somewhere in between."},{id:2,type:"multiple-choice",question:"The Mean Value Theorem guarantees that for $f$ continuous on $[a,b]$ and differentiable on $(a,b)$:",options:["$f'(c) = f(b) - f(a)$ for some $c \\in (a, b)$","$f'(c) = 0$ for some $c \\in (a, b)$","$f'(c) = \\frac{f(b) - f(a)}{b - a}$ for some $c \\in (a, b)$","$f'(x)$ is bounded on $(a, b)$"],correctIndex:2,difficulty:"easy",explanation:"The MVT states there exists $c \\in (a,b)$ such that $f'(c) = \\frac{f(b) - f(a)}{b - a}$. Geometrically, there's a point where the tangent line is parallel to the secant line connecting $(a, f(a))$ and $(b, f(b))$."},{id:3,type:"multiple-choice",question:"If $f'(x) > 0$ for all $x \\in (a, b)$, then on $[a, b]$:",options:["$f$ is strictly increasing","$f$ is constant","$f$ is convex","$f$ is bounded"],correctIndex:0,difficulty:"medium",explanation:"By the MVT, if $x_1 < x_2$ in $[a,b]$, then $f(x_2) - f(x_1) = f'(c)(x_2 - x_1)$ for some $c \\in (x_1, x_2)$. Since $f'(c) > 0$ and $x_2 - x_1 > 0$, we have $f(x_2) > f(x_1)$."},{id:4,type:"multiple-choice",question:"The Generalized Mean Value Theorem (Cauchy's MVT) states that for $f, g$ continuous on $[a,b]$, differentiable on $(a,b)$:",options:["$[f(b) - f(a)]g'(c) = [g(b) - g(a)]f'(c)$ for some $c \\in (a,b)$","$\\frac{f'(c)}{g'(c)} = \\frac{f(b) - f(a)}{g(b) - g(a)}$ for some $c \\in (a,b)$, if $g'(c) \\neq 0$","$f'(c) + g'(c) = \\frac{f(b) - f(a) + g(b) - g(a)}{b - a}$","$f'(c) \\cdot g'(c) = [f(b) - f(a)][g(b) - g(a)]$ for some $c \\in (a,b)$"],correctIndex:0,difficulty:"hard",explanation:"Cauchy's MVT: There exists $c \\in (a,b)$ such that $[f(b) - f(a)]g'(c) = [g(b) - g(a)]f'(c)$. This is the basis for L'Hospital's Rule. Note: we don't require $g'(c) \\neq 0$ in the statement."},{id:5,type:"multiple-choice",question:"If $f'(x) = 0$ for all $x \\in (a, b)$ and $f$ is continuous on $[a, b]$, then:",options:["$f$ is differentiable on $[a, b]$","$f(a) = 0$","$f$ is constant on $[a, b]$","$f$ may not be constant"],correctIndex:2,difficulty:"medium",explanation:"By the MVT, for any $x_1, x_2 \\in [a,b]$: $f(x_2) - f(x_1) = f'(c)(x_2 - x_1) = 0 \\cdot (x_2 - x_1) = 0$. Thus $f(x_1) = f(x_2)$ for all pairs, so $f$ is constant."}],S=[{id:1,type:"multiple-choice",question:"Darboux's Theorem states that if $f$ is differentiable on $[a, b]$, then $f'$:",options:["Is continuous on $[a, b]$","Is Riemann integrable on $[a, b]$","Is bounded on $[a, b]$","Has the intermediate value property on $[a, b]$"],correctIndex:3,difficulty:"medium",explanation:"Darboux's Theorem: If $f$ is differentiable on $[a,b]$, then $f'$ takes every value between $f'(a)$ and $f'(b)$, even though $f'$ need not be continuous. This is a remarkable property that derivatives share with continuous functions."},{id:2,type:"multiple-choice",question:"Which function can be a derivative on an interval?",options:["$g(x) = \\begin{cases} \\sin(1/x) & x \\neq 0 \\\\ 0 & x = 0 \\end{cases}$","$g(x) = \\begin{cases} 1 & x \\geq 0 \\\\ -1 & x < 0 \\end{cases}$","$g(x) = x$","$g(x) = \\begin{cases} 1 & x \\in \\mathbb{Q} \\\\ 0 & x \\notin \\mathbb{Q} \\end{cases}$"],correctIndex:2,difficulty:"medium",explanation:"By Darboux's Theorem, derivatives have the IVP. The sign function (A) jumps from $-1$ to $1$ without passing through $0$, so it cannot be a derivative. The Dirichlet-like function (B) also violates the IVP. Option (D), $g(x) = x$, is the derivative of $x^2/2$."},{id:3,type:"multiple-choice",question:"Let $f(x) = x^2\\sin(1/x)$ for $x \\neq 0$ and $f(0) = 0$. Then $f'$:",options:["Exists everywhere and is continuous everywhere","Does not exist at $x = 0$","Exists only at $x = 0$","Exists everywhere but is discontinuous at $x = 0$"],correctIndex:3,difficulty:"hard",explanation:"We have $f'(0) = 0$ (shown by the limit definition). For $x \\neq 0$: $f'(x) = 2x\\sin(1/x) - \\cos(1/x)$. As $x \\to 0$, $\\cos(1/x)$ oscillates, so $\\lim_{x \\to 0} f'(x)$ does not exist. Thus $f'$ exists everywhere but is discontinuous at $0$."},{id:4,type:"multiple-choice",question:"If $f$ is differentiable on $(a, b)$ and $f'$ has a discontinuity at $c \\in (a, b)$, then the discontinuity:",options:["Must be an essential discontinuity where $f'$ is unbounded","Must be a removable discontinuity","Cannot be a jump discontinuity (by Darboux's Theorem)","Must be a jump discontinuity"],correctIndex:2,difficulty:"hard",explanation:`By Darboux's Theorem, $f'$ has the IVP, so $f'$ cannot have a jump discontinuity (which would skip intermediate values). Discontinuities of derivatives must be of the "oscillatory" type, like in $x^2\\sin(1/x)$.`},{id:5,type:"multiple-choice",question:"If $f'$ exists on $(a, b)$ and $f'$ is continuous on $(a, b)$, then:",options:["$f''$ exists on $(a, b)$","$f$ is uniformly continuous on $(a, b)$","$f'$ is bounded on $(a, b)$","$f$ is Lipschitz on every compact subinterval $[c, d] \\subset (a, b)$"],correctIndex:3,difficulty:"medium",explanation:"If $f'$ is continuous on $[c, d]$, then $|f'|$ attains a maximum $M$ on $[c, d]$. By MVT, $|f(x) - f(y)| = |f'(\\xi)||x - y| \\leq M|x - y|$, so $f$ is Lipschitz with constant $M$ on $[c, d]$."}],N=[{id:1,type:"multiple-choice",question:"L'Hospital's Rule applies when evaluating $\\lim_{x \\to a} \\frac{f(x)}{g(x)}$ if:",options:["$f(a) = g(a) = 0$ only","$\\lim_{x \\to a} f(x) = \\lim_{x \\to a} g(x) = \\pm\\infty$ only","Either both limits are $0$, or both are $\\pm\\infty$, and $\\lim \\frac{f'(x)}{g'(x)}$ exists","$f$ and $g$ are both continuous at $a$"],correctIndex:2,difficulty:"medium",explanation:"L'Hospital's Rule (Theorem 5.13) applies to indeterminate forms $0/0$ or $\\infty/\\infty$. If $\\lim_{x \\to a} \\frac{f'(x)}{g'(x)} = L$ (or $\\pm\\infty$), then $\\lim_{x \\to a} \\frac{f(x)}{g(x)} = L$ (or $\\pm\\infty$)."},{id:2,type:"multiple-choice",question:"Evaluate $\\lim_{x \\to 0} \\frac{e^x - 1}{x}$ using L'Hospital's Rule:",options:["Does not exist","$1$","$0$","$e$"],correctIndex:1,difficulty:"easy",explanation:"This is $0/0$ form. Applying L'Hospital: $\\lim_{x \\to 0} \\frac{e^x}{1} = e^0 = 1$. (This also equals the definition of the derivative of $e^x$ at $x=0$.)"},{id:3,type:"multiple-choice",question:"Evaluate $\\lim_{x \\to 0^+} x \\ln x$:",options:["$-\\infty$","$1$","$0$","$+\\infty$"],correctIndex:2,difficulty:"medium",explanation:"Write as $\\frac{\\ln x}{1/x}$ which is $-\\infty/\\infty$. By L'Hospital: $\\lim_{x \\to 0^+} \\frac{1/x}{-1/x^2} = \\lim_{x \\to 0^+} (-x) = 0$."},{id:4,type:"multiple-choice",question:"For $\\lim_{x \\to 0} \\frac{x - \\sin x}{x^3}$, how many applications of L'Hospital's Rule are needed?",options:["$1$","$2$","L'Hospital's Rule does not apply","$3$"],correctIndex:3,difficulty:"hard",explanation:"Apply L'Hospital three times: $\\frac{1 - \\cos x}{3x^2}$ (still $0/0$) $\\to$ $\\frac{\\sin x}{6x}$ (still $0/0$) $\\to$ $\\frac{\\cos x}{6} \\to \\frac{1}{6}$ as $x \\to 0$."},{id:5,type:"multiple-choice",question:"If $\\lim_{x \\to a} \\frac{f'(x)}{g'(x)}$ does not exist, can we conclude that $\\lim_{x \\to a} \\frac{f(x)}{g(x)}$ does not exist?",options:["Yes, if the indeterminate form is $0/0$","Yes, the original limit must also not exist","Yes, if the indeterminate form is $\\infty/\\infty$","No, the original limit may still exist"],correctIndex:3,difficulty:"hard",explanation:"L'Hospital's Rule is one-directional. Example: $\\lim_{x \\to \\infty} \\frac{x + \\sin x}{x} = 1$, but $\\frac{1 + \\cos x}{1}$ oscillates and has no limit. The original limit can exist even when the derivative ratio has no limit."}],j=[{id:1,type:"multiple-choice",question:"If $f$ has $n$ continuous derivatives on $[a, b]$, we write $f \\in$:",options:["$L^n[a, b]$","$C[a, b]$","$C^n[a, b]$","$D^n[a, b]$"],correctIndex:2,difficulty:"easy",explanation:"The notation $C^n[a,b]$ (or $C^n(a,b)$) denotes the class of functions with $n$ continuous derivatives. $C^0$ is just continuous functions, $C^1$ has a continuous first derivative, etc."},{id:2,type:"multiple-choice",question:"If $f^{(n)}(x)$ exists for all $x$ in an interval, which statement is TRUE?",options:["$f^{(n)}$ is continuous","$f^{(n+1)}$ exists","$f \\in C^n$","$f^{(n-1)}$ is continuous"],correctIndex:3,difficulty:"medium",explanation:"If $f^{(n)}$ exists, then $f^{(n-1)}$ must be differentiable, and differentiability implies continuity. However, $f^{(n)}$ itself need not be continuous (as in the $x^2\\sin(1/x)$ example)."},{id:3,type:"multiple-choice",question:"The $n$-th derivative of $e^{ax}$ is:",options:["$n! e^{ax}$","$a^n e^{ax}$","$a^n e^{anx}$","$e^{ax}$"],correctIndex:1,difficulty:"easy",explanation:"By induction: $(e^{ax})' = ae^{ax}$, $(e^{ax})'' = a^2 e^{ax}$, and in general $\\frac{d^n}{dx^n}(e^{ax}) = a^n e^{ax}$."},{id:4,type:"multiple-choice",question:"If $f(x) = x^n$ where $n$ is a positive integer, then $f^{(n+1)}(x) = $",options:["$1$","$x$","$n!$","$0$"],correctIndex:3,difficulty:"easy",explanation:"The $n$-th derivative of $x^n$ is $n!$ (a constant). The $(n+1)$-th derivative of a constant is $0$."},{id:5,type:"multiple-choice",question:"Leibniz's formula for the $n$-th derivative of a product $fg$ involves:",options:["A sum over binomial coefficients: $\\sum_{k=0}^{n} \\binom{n}{k} f^{(k)} g^{(n-k)}$","An integral of $f$ and $g$","Only $f^{(n)}$ and $g^{(n)}$","The product $f^{(n)} \\cdot g^{(n)}$"],correctIndex:0,difficulty:"medium",explanation:"Leibniz's formula: $(fg)^{(n)} = \\sum_{k=0}^{n} \\binom{n}{k} f^{(k)} g^{(n-k)}$. This generalizes the product rule and mirrors the binomial theorem structure."}],M=[{id:1,type:"multiple-choice",question:"Taylor's Theorem states that if $f \\in C^{n}$ on $[a, b]$ and $f^{(n+1)}$ exists on $(a, b)$, then for $x \\in [a, b]$:",options:["$f(x) = \\sum_{k=0}^{n} \\frac{f^{(k)}(a)}{k!}(x-a)^k + R_n(x)$ where $R_n$ involves $f^{(n+1)}$","$f(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(a)}{k!}(x-a)^k$","$f(x) = \\sum_{k=0}^{n} f^{(k)}(a)(x-a)^k$","$f(x) = \\sum_{k=0}^{n} \\frac{f^{(k)}(a)}{k!}(x-a)^k$ exactly"],correctIndex:0,difficulty:"medium",explanation:"Taylor's Theorem gives $f(x) = P_n(x) + R_n(x)$ where $P_n$ is the Taylor polynomial of degree $n$ and $R_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}$ for some $c$ between $a$ and $x$ (Lagrange form)."},{id:2,type:"multiple-choice",question:"The Lagrange form of the remainder in Taylor's Theorem is:",options:["$R_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}$ for some $c$ between $a$ and $x$","$R_n(x) = \\frac{f^{(n)}(c)}{n!}(x-a)^n$","$R_n(x) = \\int_a^x f^{(n+1)}(t) dt$","$R_n(x) = f(x) - f(a)$"],correctIndex:0,difficulty:"medium",explanation:"The Lagrange remainder is $R_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}$ where $c$ lies strictly between $a$ and $x$. This is proven using the Generalized Mean Value Theorem."},{id:3,type:"multiple-choice",question:"The Taylor series of $e^x$ centered at $0$ is:",options:["$\\sum_{n=0}^{\\infty} \\frac{x^n}{n!}$","$\\sum_{n=1}^{\\infty} \\frac{x^n}{n}$","$\\sum_{n=0}^{\\infty} \\frac{(-1)^n x^n}{n!}$","$\\sum_{n=0}^{\\infty} x^n$"],correctIndex:0,difficulty:"easy",explanation:"Since $\\frac{d^n}{dx^n}(e^x) = e^x$ and $e^0 = 1$, the Taylor coefficients are $\\frac{e^0}{n!} = \\frac{1}{n!}$. The series $\\sum_{n=0}^{\\infty} \\frac{x^n}{n!}$ converges to $e^x$ for all $x \\in \\mathbb{R}$."},{id:4,type:"multiple-choice",question:"If $f(x) = \\sum_{n=0}^{\\infty} a_n (x-a)^n$ converges for all $x$, then $a_n = $",options:["$f(a)$","$f^{(n)}(a)$","$\\frac{f^{(n)}(a)}{n!}$","$\\frac{f(a)}{n!}$"],correctIndex:2,difficulty:"medium",explanation:"If $f$ equals its Taylor series, then the coefficients must be $a_n = \\frac{f^{(n)}(a)}{n!}$. This follows from term-by-term differentiation and evaluating at $x = a$."},{id:5,type:"multiple-choice",question:"The function $f(x) = e^{-1/x^2}$ for $x \\neq 0$ and $f(0) = 0$ has the property that:",options:["Its Taylor series diverges for $x \\neq 0$","Its Taylor series at $0$ is identically $0$ but $f$ is not the zero function","It is not infinitely differentiable at $0$","Its Taylor series at $0$ converges to $f(x)$ for all $x$"],correctIndex:1,difficulty:"hard",explanation:"This is the classic example of a $C^\\infty$ function whose Taylor series at $0$ converges but not to $f$. One can show $f^{(n)}(0) = 0$ for all $n$, so the Taylor series is $0$. But $f(x) > 0$ for $x \\neq 0$."}],D=[{id:1,type:"multiple-choice",question:"For a function $\\mathbf{f}: [a,b] \\to \\mathbb{R}^k$ with components $f_1, \\ldots, f_k$, $\\mathbf{f}$ is differentiable at $t$ if and only if:",options:["$\\sum_{j=1}^k f_j(t)$ is differentiable at $t$","Each component $f_j$ is differentiable at $t$","The norm $\\|\\mathbf{f}(t)\\|$ is differentiable at $t$","At least one component $f_j$ is differentiable at $t$"],correctIndex:1,difficulty:"medium",explanation:"A vector-valued function $\\mathbf{f} = (f_1, \\ldots, f_k)$ is differentiable at $t$ if and only if each component $f_j$ is differentiable at $t$, and then $\\mathbf{f}'(t) = (f_1'(t), \\ldots, f_k'(t))$."},{id:2,type:"multiple-choice",question:"If $\\mathbf{f}, \\mathbf{g}: [a,b] \\to \\mathbb{R}^k$ are differentiable, then $(\\mathbf{f} \\cdot \\mathbf{g})'(t) = $",options:["$\\|\\mathbf{f}'(t)\\| \\|\\mathbf{g}'(t)\\|$","$\\mathbf{f}(t) \\times \\mathbf{g}'(t)$","$\\mathbf{f}'(t) \\cdot \\mathbf{g}(t) + \\mathbf{f}(t) \\cdot \\mathbf{g}'(t)$","$\\mathbf{f}'(t) \\cdot \\mathbf{g}'(t)$"],correctIndex:2,difficulty:"easy",explanation:"The product rule extends to dot products: $(\\mathbf{f} \\cdot \\mathbf{g})' = \\mathbf{f}' \\cdot \\mathbf{g} + \\mathbf{f} \\cdot \\mathbf{g}'$. This is proven by applying the usual product rule to each term $f_j g_j$ in the sum."},{id:3,type:"multiple-choice",question:"If $\\|\\mathbf{f}(t)\\|$ is constant for all $t$, and $\\mathbf{f}$ is differentiable, then:",options:["$\\|\\mathbf{f}'(t)\\|$ is also constant","$\\mathbf{f}'(t) = \\mathbf{0}$ for all $t$","$\\mathbf{f}(t)$ is parallel to $\\mathbf{f}'(t)$","$\\mathbf{f}'(t) \\cdot \\mathbf{f}(t) = 0$ for all $t$"],correctIndex:3,difficulty:"medium",explanation:"If $\\|\\mathbf{f}\\|^2 = \\mathbf{f} \\cdot \\mathbf{f} = c$ (constant), then differentiating: $2\\mathbf{f}' \\cdot \\mathbf{f} = 0$, so $\\mathbf{f}'(t) \\perp \\mathbf{f}(t)$ for all $t$. The derivative is always perpendicular to the position vector."},{id:4,type:"multiple-choice",question:"The Mean Value Theorem for vector-valued functions states:",options:["There exists $c$ with $\\|\\mathbf{f}'(c)\\| = \\frac{\\|\\mathbf{f}(b) - \\mathbf{f}(a)\\|}{b-a}$","There exists $c \\in (a,b)$ with $\\mathbf{f}(b) - \\mathbf{f}(a) = \\mathbf{f}'(c)(b-a)$","The MVT does not hold for vector-valued functions","$\\|\\mathbf{f}(b) - \\mathbf{f}(a)\\| \\leq (b-a) \\sup_{t \\in [a,b]} \\|\\mathbf{f}'(t)\\|$"],correctIndex:3,difficulty:"hard",explanation:"The equality form of MVT fails for vector functions (consider $\\mathbf{f}(t) = (\\cos t, \\sin t)$ on $[0, 2\\pi]$). However, we have the inequality $\\|\\mathbf{f}(b) - \\mathbf{f}(a)\\| \\leq (b-a) \\sup \\|\\mathbf{f}'\\|$."},{id:5,type:"multiple-choice",question:"For $\\mathbf{f}(t) = (\\cos t, \\sin t)$, the derivative $\\mathbf{f}'(t)$ is:",options:["$(\\sin t, \\cos t)$","$(\\cos t, \\sin t)$","$(-\\sin t, \\cos t)$","$(\\sin t, -\\cos t)$"],correctIndex:2,difficulty:"easy",explanation:"Differentiating component-wise: $\\frac{d}{dt}\\cos t = -\\sin t$ and $\\frac{d}{dt}\\sin t = \\cos t$. So $\\mathbf{f}'(t) = (-\\sin t, \\cos t)$. Note that $\\mathbf{f}' \\cdot \\mathbf{f} = 0$, confirming perpendicularity."}],P=[{id:1,type:"multiple-choice",question:"In the Riemann-Stieltjes integral $\\int_a^b f \\, d\\alpha$, the function $\\alpha$ is called:",options:["The antiderivative","The integrator","The integrand","The measure"],correctIndex:1,difficulty:"easy",explanation:"In $\\int_a^b f \\, d\\alpha$, $f$ is the integrand and $\\alpha$ is the integrator. When $\\alpha(x) = x$, we recover the ordinary Riemann integral $\\int_a^b f \\, dx$."},{id:2,type:"multiple-choice",question:"For a partition $P = \\{x_0, x_1, \\ldots, x_n\\}$ of $[a, b]$, the upper Riemann-Stieltjes sum is:",options:["$U(P, f, \\alpha) = \\sum_{i=1}^n f(x_i) \\alpha(x_i)$","$U(P, f, \\alpha) = \\sup_P \\sum_{i=1}^n f(x_i)$","$U(P, f, \\alpha) = \\sum_{i=1}^n M_i \\Delta x_i$ where $\\Delta x_i = x_i - x_{i-1}$","$U(P, f, \\alpha) = \\sum_{i=1}^n M_i \\Delta \\alpha_i$ where $\\Delta \\alpha_i = \\alpha(x_i) - \\alpha(x_{i-1})$"],correctIndex:3,difficulty:"medium",explanation:"The upper sum is $U(P, f, \\alpha) = \\sum_{i=1}^n M_i \\Delta\\alpha_i$ where $M_i = \\sup\\{f(x) : x \\in [x_{i-1}, x_i]\\}$ and $\\Delta\\alpha_i = \\alpha(x_i) - \\alpha(x_{i-1})$."},{id:3,type:"multiple-choice",question:"The function $f$ is Riemann-Stieltjes integrable with respect to $\\alpha$ on $[a, b]$ if:",options:["Both $f$ and $\\alpha$ are monotonic","$\\sup_P L(P, f, \\alpha) = \\inf_P U(P, f, \\alpha)$","$f$ is continuous on $[a, b]$","$\\alpha$ is continuous on $[a, b]$"],correctIndex:1,difficulty:"medium",explanation:"By definition, $f \\in \\mathscr{R}(\\alpha)$ on $[a,b]$ if and only if $\\sup_P L(P, f, \\alpha) = \\inf_P U(P, f, \\alpha)$, i.e., the lower integral equals the upper integral."},{id:4,type:"multiple-choice",question:"If $\\alpha$ has a jump discontinuity at $c \\in (a, b)$ and $f$ is continuous at $c$, then:",options:["$\\int_a^b f \\, d\\alpha$ does not exist","The integral equals the ordinary Riemann integral","$\\int_a^b f \\, d\\alpha = f(c)[\\alpha(c^+) - \\alpha(c^-)]$ plus integrals on $[a, c]$ and $[c, b]$","$\\int_a^b f \\, d\\alpha = 0$"],correctIndex:2,difficulty:"hard",explanation:"The jump in $\\alpha$ at $c$ contributes $f(c)[\\alpha(c^+) - \\alpha(c^-)]$ to the integral. This is why the Riemann-Stieltjes integral can represent sums: if $\\alpha$ is a step function, the integral becomes a weighted sum."},{id:5,type:"multiple-choice",question:"If $\\alpha(x) = x$, then $\\int_a^b f \\, d\\alpha$ equals:",options:["$0$","$\\alpha(b)f(b) - \\alpha(a)f(a)$","The ordinary Riemann integral $\\int_a^b f(x) \\, dx$","$f(b) - f(a)$"],correctIndex:2,difficulty:"easy",explanation:"When $\\alpha(x) = x$, we have $\\Delta\\alpha_i = x_i - x_{i-1} = \\Delta x_i$, so the Riemann-Stieltjes sums become ordinary Riemann sums, and $\\int_a^b f \\, d\\alpha = \\int_a^b f(x) \\, dx$."}],W=[{id:1,type:"multiple-choice",question:"If $f \\in \\mathscr{R}(\\alpha)$ on $[a, b]$ and $c \\in (a, b)$, then:",options:["The integral cannot be split","$\\int_a^b f \\, d\\alpha = \\int_a^c f \\, d\\alpha \\cdot \\int_c^b f \\, d\\alpha$","$\\int_a^b f \\, d\\alpha = \\int_c^b f \\, d\\alpha - \\int_a^c f \\, d\\alpha$","$\\int_a^b f \\, d\\alpha = \\int_a^c f \\, d\\alpha + \\int_c^b f \\, d\\alpha$"],correctIndex:3,difficulty:"easy",explanation:"Theorem 6.12(c): If $f \\in \\mathscr{R}(\\alpha)$ on $[a,b]$ and $c \\in (a,b)$, then $f \\in \\mathscr{R}(\\alpha)$ on $[a,c]$ and $[c,b]$, and $\\int_a^b f \\, d\\alpha = \\int_a^c f \\, d\\alpha + \\int_c^b f \\, d\\alpha$."},{id:2,type:"multiple-choice",question:"If $f \\in \\mathscr{R}(\\alpha)$ and $g \\in \\mathscr{R}(\\alpha)$ on $[a, b]$, then:",options:["$f + g$ may not be in $\\mathscr{R}(\\alpha)$","$fg$ may not be in $\\mathscr{R}(\\alpha)$","$f/g \\in \\mathscr{R}(\\alpha)$ always","$fg \\in \\mathscr{R}(\\alpha)$"],correctIndex:3,difficulty:"medium",explanation:"Theorem 6.13: If $f, g \\in \\mathscr{R}(\\alpha)$, then $fg \\in \\mathscr{R}(\\alpha)$. Also $f + g$, $cf$ (for constant $c$), and $|f|$ are in $\\mathscr{R}(\\alpha)$."},{id:3,type:"multiple-choice",question:"If $f$ is continuous and $\\alpha$ is monotonically increasing on $[a, b]$, then:",options:["The integral equals zero","$f \\in \\mathscr{R}(\\alpha)$","$f$ may not be integrable with respect to $\\alpha$","$\\alpha \\in \\mathscr{R}(f)$"],correctIndex:1,difficulty:"easy",explanation:"Theorem 6.8: If $f$ is continuous on $[a,b]$ and $\\alpha$ is monotonically increasing, then $f \\in \\mathscr{R}(\\alpha)$. Continuity ensures we can make upper and lower sums arbitrarily close."},{id:4,type:"multiple-choice",question:"Integration by parts for Riemann-Stieltjes integrals: If $f, \\alpha$ are appropriately integrable, then:",options:["$\\int_a^b f \\, d\\alpha \\cdot \\int_a^b \\alpha \\, df = f(b)\\alpha(b)$","$\\int_a^b f \\, d\\alpha = -\\int_a^b \\alpha \\, df$","$\\int_a^b f \\, d\\alpha = f(b)\\alpha(b)$","$\\int_a^b f \\, d\\alpha + \\int_a^b \\alpha \\, df = f(b)\\alpha(b) - f(a)\\alpha(a)$"],correctIndex:3,difficulty:"medium",explanation:"Theorem 6.22: $\\int_a^b f \\, d\\alpha + \\int_a^b \\alpha \\, df = f(b)\\alpha(b) - f(a)\\alpha(a)$. This is the integration by parts formula for Riemann-Stieltjes integrals."},{id:5,type:"multiple-choice",question:"If $f \\leq g$ on $[a, b]$ and $\\alpha$ is monotonically increasing, then:",options:["$\\int_a^b f \\, d\\alpha \\geq \\int_a^b g \\, d\\alpha$","$\\int_a^b f \\, d\\alpha \\leq \\int_a^b g \\, d\\alpha$","$\\int_a^b f \\, d\\alpha = \\int_a^b g \\, d\\alpha$","No comparison is possible"],correctIndex:1,difficulty:"easy",explanation:"Theorem 6.12(b): If $f \\leq g$ and $\\alpha$ is increasing, then $\\int_a^b f \\, d\\alpha \\leq \\int_a^b g \\, d\\alpha$. This follows because each $\\Delta\\alpha_i \\geq 0$."}],G=[{id:1,type:"multiple-choice",question:"The First Fundamental Theorem of Calculus states that if $f \\in \\mathscr{R}$ on $[a, b]$ and $F(x) = \\int_a^x f(t) \\, dt$, then:",options:["$F$ is monotonically increasing","$F'(x) = f(x)$ for all $x \\in [a, b]$","$F$ is continuous on $[a, b]$","$F$ is differentiable everywhere with $F' = f$"],correctIndex:2,difficulty:"medium",explanation:"Theorem 6.20: If $f \\in \\mathscr{R}$ on $[a,b]$, then $F(x) = \\int_a^x f(t)\\,dt$ is continuous on $[a,b]$. Furthermore, if $f$ is continuous at a point $x_0$, then $F$ is differentiable at $x_0$ with $F'(x_0) = f(x_0)$."},{id:2,type:"multiple-choice",question:"The Second Fundamental Theorem of Calculus states that if $F' = f$ and $f \\in \\mathscr{R}$ on $[a, b]$, then:",options:["$\\int_a^b F(x) \\, dx = f(b) - f(a)$","$\\int_a^b f(x) \\, dx = F(a) - F(b)$","$F(x) = \\int_a^x f(t) \\, dt$","$\\int_a^b f(x) \\, dx = F(b) - F(a)$"],correctIndex:3,difficulty:"easy",explanation:"Theorem 6.21: If $f \\in \\mathscr{R}$ on $[a,b]$ and there exists a differentiable function $F$ on $[a,b]$ with $F' = f$, then $\\int_a^b f(x)\\,dx = F(b) - F(a)$."},{id:3,type:"multiple-choice",question:"If $f$ has a removable discontinuity at $c \\in (a, b)$ but is otherwise continuous, and $F(x) = \\int_a^x f(t) \\, dt$, then:",options:["$F$ is discontinuous at $c$","$F$ is not differentiable at $c$","$F$ is differentiable at $c$ with $F'(c) = \\lim_{t \\to c} f(t)$","$F'(c) = f(c)$"],correctIndex:2,difficulty:"hard",explanation:`The key insight is that integration "smooths out" removable discontinuities. $F$ is differentiable at $c$ and $F'(c) = \\lim_{t \\to c} f(t)$, not $f(c)$. The value of $f$ at an isolated point doesn't affect the integral.`},{id:4,type:"multiple-choice",question:"If $g$ is continuous and $F(x) = \\int_a^{x^2} g(t) \\, dt$, then $F'(x) = $",options:["$\\int_a^{x^2} g'(t) \\, dt$","$g(x^2)$","$g(x^2) \\cdot 2x + g(a)$","$2x \\cdot g(x^2)$"],correctIndex:3,difficulty:"medium",explanation:"By the chain rule combined with FTC: Let $G(u) = \\int_a^u g(t)\\,dt$, so $F(x) = G(x^2)$. Then $F'(x) = G'(x^2) \\cdot 2x = g(x^2) \\cdot 2x$."},{id:5,type:"multiple-choice",question:"Which hypothesis is NOT required for the Second FTC to hold?",options:["$f$ is continuous on $[a, b]$","$F' = f$ on $[a, b]$","$f$ is Riemann integrable on $[a, b]$","$F$ is differentiable on $[a, b]$"],correctIndex:0,difficulty:"medium",explanation:"The Second FTC (Theorem 6.21) requires: (1) $f \\in \\mathscr{R}$, (2) $F$ differentiable with $F' = f$. It does NOT require $f$ to be continuous. For example, $f$ could be a step function with $F$ piecewise linear."}],H=[{id:1,type:"multiple-choice",question:"For $\\mathbf{f}: [a,b] \\to \\mathbb{R}^k$ with components $f_1, \\ldots, f_k$, the integral $\\int_a^b \\mathbf{f} \\, d\\alpha$ is defined as:",options:["The maximum of the component integrals","The product $\\prod_{j=1}^k \\int_a^b f_j \\, d\\alpha$","The sum $\\sum_{j=1}^k \\int_a^b f_j \\, d\\alpha$","The vector $(\\int_a^b f_1 \\, d\\alpha, \\ldots, \\int_a^b f_k \\, d\\alpha)$"],correctIndex:3,difficulty:"easy",explanation:"The integral of a vector-valued function is computed component-wise: $\\int_a^b \\mathbf{f} \\, d\\alpha = (\\int_a^b f_1 \\, d\\alpha, \\ldots, \\int_a^b f_k \\, d\\alpha)$."},{id:2,type:"multiple-choice",question:"If $\\mathbf{f} \\in \\mathscr{R}(\\alpha)$ on $[a, b]$ (vector-valued), then:",options:["No inequality holds in general","$\\|\\int_a^b \\mathbf{f} \\, d\\alpha\\| = \\int_a^b \\|\\mathbf{f}\\| \\, d\\alpha$","$\\|\\int_a^b \\mathbf{f} \\, d\\alpha\\| \\leq \\int_a^b \\|\\mathbf{f}\\| \\, d\\alpha$ when $\\alpha$ is increasing","$\\|\\int_a^b \\mathbf{f} \\, d\\alpha\\| \\geq \\int_a^b \\|\\mathbf{f}\\| \\, d\\alpha$"],correctIndex:2,difficulty:"medium",explanation:"Theorem 6.25: $\\|\\int_a^b \\mathbf{f} \\, d\\alpha\\| \\leq \\int_a^b \\|\\mathbf{f}\\| \\, d\\alpha$ when $\\alpha$ is monotonically increasing. This is the integral version of the triangle inequality."},{id:3,type:"multiple-choice",question:"The FTC for vector-valued functions states that if $\\mathbf{F}' = \\mathbf{f}$ componentwise and $\\mathbf{f} \\in \\mathscr{R}$, then:",options:["The FTC does not extend to vector functions","$\\int_a^b \\mathbf{f}(t) \\, dt = \\mathbf{F}(a) - \\mathbf{F}(b)$","$\\int_a^b \\mathbf{f}(t) \\, dt = \\mathbf{F}(b) - \\mathbf{F}(a)$","$\\int_a^b \\mathbf{F}(t) \\, dt = \\mathbf{f}(b) - \\mathbf{f}(a)$"],correctIndex:2,difficulty:"easy",explanation:"The FTC extends component-wise to vector-valued functions: $\\int_a^b \\mathbf{f}(t)\\,dt = \\mathbf{F}(b) - \\mathbf{F}(a)$, where $\\mathbf{F}' = \\mathbf{f}$."},{id:4,type:"multiple-choice",question:"If $\\mathbf{f}(t) = (\\cos t, \\sin t)$ for $t \\in [0, 2\\pi]$, then $\\int_0^{2\\pi} \\mathbf{f}(t) \\, dt = $",options:["$(2, 0)$","$(0, 0)$","$(1, 1)$","$(2\\pi, 2\\pi)$"],correctIndex:1,difficulty:"medium",explanation:"$\\int_0^{2\\pi} \\cos t \\, dt = [\\sin t]_0^{2\\pi} = 0$ and $\\int_0^{2\\pi} \\sin t \\, dt = [-\\cos t]_0^{2\\pi} = -1 + 1 = 0$. So the integral is $(0, 0)$."},{id:5,type:"multiple-choice",question:"For a curve $\\gamma: [a,b] \\to \\mathbb{R}^k$, if $\\gamma'$ is continuous, the arc length is given by:",options:["$\\int_a^b \\gamma'(t) \\, dt$","$\\int_a^b \\gamma(t) \\, dt$","$\\int_a^b \\|\\gamma'(t)\\| \\, dt$","$\\|\\gamma(b) - \\gamma(a)\\|$"],correctIndex:2,difficulty:"medium",explanation:`The arc length of a smooth curve $\\gamma$ is $\\int_a^b \\|\\gamma'(t)\\| \\, dt$. This measures the total "speed" integrated over time, giving the length of the path traced.`}],V=[{id:1,type:"multiple-choice",question:"A curve $\\gamma: [a, b] \\to \\mathbb{R}^k$ is called rectifiable if:",options:["$\\gamma$ is differentiable","The supremum of lengths of inscribed polygons is finite","$\\gamma$ is continuous","$\\gamma$ has bounded variation in each component"],correctIndex:1,difficulty:"medium",explanation:"A curve is rectifiable if $\\Lambda(\\gamma) = \\sup_P \\sum_{i=1}^n \\|\\gamma(t_i) - \\gamma(t_{i-1})\\| < \\infty$, where the supremum is over all partitions. This is the total arc length."},{id:2,type:"multiple-choice",question:"If $\\gamma' \\in \\mathscr{R}$ on $[a, b]$ (i.e., $\\gamma'$ exists and is Riemann integrable), then the arc length equals:",options:["$\\int_a^b \\|\\gamma'(t)\\| \\, dt$","$\\int_a^b \\gamma'(t) \\, dt$","$\\|\\gamma(b) - \\gamma(a)\\|$","$\\sup_{t \\in [a,b]} \\|\\gamma'(t)\\|$"],correctIndex:0,difficulty:"medium",explanation:"Theorem 6.27: If $\\gamma'$ is continuous (or more generally, in $\\mathscr{R}$), the arc length is $\\Lambda(\\gamma) = \\int_a^b \\|\\gamma'(t)\\| \\, dt$."},{id:3,type:"multiple-choice",question:"The curve $\\gamma(t) = (t, t^2)$ for $t \\in [0, 1]$ has arc length:",options:["$\\int_0^1 (1 + 2t) \\, dt$","$1$","$\\int_0^1 \\sqrt{1 + 4t^2} \\, dt$","$\\sqrt{2}$"],correctIndex:2,difficulty:"medium",explanation:"We have $\\gamma'(t) = (1, 2t)$, so $\\|\\gamma'(t)\\| = \\sqrt{1 + 4t^2}$. The arc length is $\\int_0^1 \\sqrt{1 + 4t^2} \\, dt$."},{id:4,type:"multiple-choice",question:"A continuous curve that is NOT rectifiable is:",options:["A space-filling curve (like the Peano curve)","The graph of a Lipschitz function","The unit circle","Any curve with a corner"],correctIndex:0,difficulty:"hard",explanation:"Space-filling curves like the Peano or Hilbert curves are continuous but have infinite length. Any inscribed polygon can be refined to get arbitrarily large total length. Lipschitz curves and curves with corners are rectifiable."},{id:5,type:"multiple-choice",question:"If $\\gamma$ is a rectifiable curve and $\\phi: [c, d] \\to [a, b]$ is a continuous strictly increasing function, then $\\gamma \\circ \\phi$:",options:["Has the same arc length as $\\gamma$","Is not a valid reparametrization","Has arc length multiplied by $\\sup |\\phi'|$","May not be rectifiable"],correctIndex:0,difficulty:"medium",explanation:"Reparametrization preserves arc length. If $\\phi$ is a valid change of parameter, then $\\Lambda(\\gamma \\circ \\phi) = \\Lambda(\\gamma)$. Arc length is a geometric property of the curve, independent of parametrization."}],U=[{id:1,type:"multiple-choice",question:'The "main problem" in Chapter 7 of Rudin concerns when we can interchange:',options:["Differentiation and integration","Real and complex analysis","Addition and multiplication","Limits with other operations (limits, integrals, derivatives, sums)"],correctIndex:3,difficulty:"easy",explanation:"Chapter 7 addresses when $\\lim_{n \\to \\infty} \\int f_n = \\int \\lim_{n \\to \\infty} f_n$, $\\lim_{n \\to \\infty} (f_n)' = (\\lim_{n \\to \\infty} f_n)'$, and similar interchanges. The key condition is usually uniform convergence."},{id:2,type:"multiple-choice",question:"The sequence $f_n(x) = x^n$ on $[0, 1]$ converges pointwise to:",options:["$f(x) = x$ for all $x \\in [0, 1]$","$f(x) = 0$ for $x \\in [0, 1)$ and $f(1) = 1$","$f(x) = 0$ for all $x \\in [0, 1]$","$f(x) = 1$ for all $x \\in [0, 1]$"],correctIndex:1,difficulty:"easy",explanation:"For $0 \\leq x < 1$: $\\lim_{n \\to \\infty} x^n = 0$. For $x = 1$: $\\lim_{n \\to \\infty} 1^n = 1$. The limit function is discontinuous at $x = 1$."},{id:3,type:"multiple-choice",question:"For $f_n(x) = x^n$ on $[0, 1]$, the pointwise limit is discontinuous even though each $f_n$ is continuous. This shows that:",options:["Uniform convergence fails for polynomials","The limit function is always discontinuous","Pointwise limits preserve continuity","Pointwise convergence may not preserve continuity"],correctIndex:3,difficulty:"medium",explanation:"This classic example shows that pointwise convergence does not preserve continuity. Each $f_n(x) = x^n$ is continuous, but the pointwise limit is discontinuous at $x = 1$. Uniform convergence is needed to preserve continuity."},{id:4,type:"multiple-choice",question:"Consider $f_n(x) = \\frac{nx}{1 + n^2x^2}$ on $[0, 1]$. Then $\\lim_{n \\to \\infty} \\int_0^1 f_n(x) \\, dx$ equals:",options:["$0$","$\\frac{1}{2} \\ln 2$, which is not $0$","$\\infty$","$\\int_0^1 \\lim_{n \\to \\infty} f_n(x) \\, dx = 0$"],correctIndex:1,difficulty:"hard",explanation:"We have $f_n(x) \\to 0$ pointwise for each $x > 0$, but $\\int_0^1 f_n \\, dx = \\frac{1}{2n}\\ln(1 + n^2) \\to \\frac{1}{2}\\ln(n^2)/n \\to 0$... Actually, let's compute: $\\int_0^1 \\frac{nx}{1+n^2x^2}dx = [\\frac{1}{2n}\\ln(1+n^2x^2)]_0^1 = \\frac{\\ln(1+n^2)}{2n}$. As $n \\to \\infty$ this goes to $0$. But this is a case where we need to be careful about interchanging limits."},{id:5,type:"multiple-choice",question:"The interchange $\\frac{d}{dx}\\sum_{n=1}^{\\infty} f_n(x) = \\sum_{n=1}^{\\infty} f_n'(x)$ is valid when:",options:["The series $\\sum f_n'$ converges uniformly","The series $\\sum f_n$ converges absolutely","Each $f_n$ is differentiable","The series $\\sum f_n$ converges pointwise"],correctIndex:0,difficulty:"medium",explanation:"To differentiate a series term-by-term, we need the series of derivatives $\\sum f_n'$ to converge uniformly (and $\\sum f_n$ to converge at least at one point). This ensures the limit of derivatives equals the derivative of the limit."}],O=[{id:1,type:"multiple-choice",question:"A sequence $\\{f_n\\}$ converges uniformly to $f$ on $E$ if:",options:["$\\sup_{x \\in E} f_n(x) \\to \\sup_{x \\in E} f(x)$","For each $\\epsilon > 0$, there exists $N$ such that $n \\geq N$ implies $|f_n(x) - f(x)| < \\epsilon$ for all $x \\in E$","For each $x \\in E$ and $\\epsilon > 0$, there exists $N$ such that $n \\geq N$ implies $|f_n(x) - f(x)| < \\epsilon$","$\\lim_{n \\to \\infty} f_n(x) = f(x)$ for all $x \\in E$"],correctIndex:1,difficulty:"medium",explanation:"Uniform convergence means the same $N$ works for ALL $x$ simultaneously: given $\\epsilon > 0$, there exists $N$ such that for all $n \\geq N$ and all $x \\in E$, $|f_n(x) - f(x)| < \\epsilon$."},{id:2,type:"multiple-choice",question:"Uniform convergence $f_n \\to f$ on $E$ is equivalent to:",options:["$f_n$ and $f$ have the same zeros","$\\lim_{n \\to \\infty} f_n(x) = f(x)$ for each $x$","$\\lim_{n \\to \\infty} \\sup_{x \\in E} |f_n(x) - f(x)| = 0$","$\\lim_{n \\to \\infty} \\int_E |f_n - f| = 0$"],correctIndex:2,difficulty:"medium",explanation:"The sup-norm criterion: $f_n \\to f$ uniformly on $E$ if and only if $\\|f_n - f\\|_\\infty = \\sup_{x \\in E}|f_n(x) - f(x)| \\to 0$."},{id:3,type:"multiple-choice",question:"The Weierstrass M-test states: if $|f_n(x)| \\leq M_n$ for all $x \\in E$ and $\\sum M_n < \\infty$, then:",options:["$\\sum f_n$ converges pointwise on $E$","Each $f_n$ is bounded","$\\sum f_n$ converges uniformly on $E$","$\\sum f_n$ converges absolutely but not uniformly"],correctIndex:2,difficulty:"medium",explanation:"The Weierstrass M-test (Theorem 7.10): If $|f_n(x)| \\leq M_n$ for all $x \\in E$ and $\\sum M_n$ converges, then $\\sum f_n$ converges uniformly (and absolutely) on $E$."},{id:4,type:"multiple-choice",question:"The sequence $f_n(x) = \\frac{x}{n}$ on $\\mathbb{R}$:",options:["Converges uniformly to $0$ on $\\mathbb{R}$","Converges uniformly on $[0, 1]$ but not on $\\mathbb{R}$","Does not converge pointwise","Converges pointwise but not uniformly to $0$ on $\\mathbb{R}$"],correctIndex:1,difficulty:"medium",explanation:"For each fixed $x$, $x/n \\to 0$. But $\\sup_{x \\in \\mathbb{R}} |x/n| = \\infty$ for each $n$, so convergence is not uniform on $\\mathbb{R}$. On $[0, 1]$: $\\sup_{x \\in [0,1]} |x/n| = 1/n \\to 0$, so convergence is uniform on $[0, 1]$."},{id:5,type:"multiple-choice",question:"The Cauchy criterion for uniform convergence states that $\\{f_n\\}$ converges uniformly on $E$ if and only if:",options:["For all $\\epsilon > 0$, there exists $N$ such that $m, n \\geq N$ implies $|f_n(x) - f_m(x)| < \\epsilon$ for all $x \\in E$","The sequence is uniformly bounded","$\\sum |f_n|$ converges","$\\{f_n\\}$ is equicontinuous"],correctIndex:0,difficulty:"hard",explanation:"Theorem 7.8: $\\{f_n\\}$ converges uniformly on $E$ if and only if for every $\\epsilon > 0$, there exists $N$ such that $m, n \\geq N$ implies $\\sup_{x \\in E}|f_n(x) - f_m(x)| < \\epsilon$."}],K=[{id:1,type:"multiple-choice",question:"If $\\{f_n\\}$ converges uniformly to $f$ on $E$ and each $f_n$ is continuous on $E$, then:",options:["$f$ is uniformly continuous on $E$","$f$ is continuous on $E$","$f$ may be discontinuous","$f$ is differentiable on $E$"],correctIndex:1,difficulty:"easy",explanation:"Theorem 7.12: The uniform limit of continuous functions is continuous. This is one of the most important consequences of uniform convergence."},{id:2,type:"multiple-choice",question:"The sequence $f_n(x) = x^n$ on $[0, 1]$ shows that:",options:["Pointwise limits of continuous functions are continuous","The convergence $x^n \\to \\chi_{\\{1\\}}(x)$ is uniform","Pointwise convergence does not preserve continuity","Uniform convergence is the same as pointwise convergence"],correctIndex:2,difficulty:"easy",explanation:"Each $f_n(x) = x^n$ is continuous, but the pointwise limit is $0$ for $x < 1$ and $1$ for $x = 1$, which is discontinuous. This shows pointwise convergence alone does not preserve continuity."},{id:3,type:"multiple-choice",question:"If $f_n \\to f$ uniformly on a compact set $K$ and each $f_n$ is continuous, then:",options:["$f$ is differentiable on $K$","$f$ is bounded but may not be continuous","$f$ is continuous but may not be uniformly continuous","$f$ is uniformly continuous on $K$"],correctIndex:3,difficulty:"medium",explanation:"Since $f$ is continuous on the compact set $K$ (by Theorem 7.12), $f$ is automatically uniformly continuous on $K$ (by Theorem 4.19). Compactness promotes continuity to uniform continuity."},{id:4,type:"multiple-choice",question:"Consider the series $\\sum_{n=1}^{\\infty} \\frac{x^n}{n^2}$ on $[-1, 1]$. The sum is:",options:["Continuous on $[-1, 1]$","Undefined at $x = \\pm 1$","Differentiable but not continuous","Discontinuous at $x = 1$"],correctIndex:0,difficulty:"medium",explanation:"By the Weierstrass M-test with $M_n = 1/n^2$, the series converges uniformly on $[-1, 1]$. Since each partial sum is continuous (polynomial), the uniform limit is continuous on $[-1, 1]$."},{id:5,type:"multiple-choice",question:"Suppose $f_n \\to f$ uniformly and $x_n \\to x$ where all are in $E$. Then:",options:["$f_n(x_n)$ may not converge","$f_n(x_n) \\to f(x)$ always","$f_n(x_n) \\to f(x)$ only if $x_n = x$ for all $n$","$f_n(x_n) \\to f(x)$ if each $f_n$ is continuous"],correctIndex:3,difficulty:"hard",explanation:"With uniform convergence and continuity: $|f_n(x_n) - f(x)| \\leq |f_n(x_n) - f(x_n)| + |f(x_n) - f(x)|$. The first term $\\to 0$ by uniform convergence; the second $\\to 0$ by continuity of $f$ (which follows from uniform convergence of continuous functions)."}],X=[{id:1,type:"multiple-choice",question:"If $f_n \\to f$ uniformly on $[a, b]$ and each $f_n \\in \\mathscr{R}$ on $[a, b]$, then:",options:["$f \\in \\mathscr{R}$ and $\\int_a^b f_n \\to \\int_a^b f$","$\\int_a^b f_n$ may not converge","$f$ may not be integrable","$f \\in \\mathscr{R}$ but $\\int_a^b f_n$ may not converge to $\\int_a^b f$"],correctIndex:0,difficulty:"medium",explanation:"Theorem 7.16: If $f_n \\in \\mathscr{R}(\\alpha)$, $f_n \\to f$ uniformly on $[a,b]$, and $\\alpha$ is monotonically increasing, then $f \\in \\mathscr{R}(\\alpha)$ and $\\lim \\int f_n \\, d\\alpha = \\int f \\, d\\alpha$."},{id:2,type:"multiple-choice",question:"For the series $\\sum_{n=1}^{\\infty} f_n(x)$, if $\\sum f_n$ converges uniformly on $[a, b]$ and each $f_n \\in \\mathscr{R}$, then:",options:["$\\int_a^b \\sum_{n=1}^{\\infty} f_n(x) \\, dx = \\sum_{n=1}^{\\infty} \\int_a^b f_n(x) \\, dx$","The sum may not be integrable","$\\sum \\int f_n$ diverges","Term-by-term integration may not be valid"],correctIndex:0,difficulty:"medium",explanation:"Uniform convergence allows term-by-term integration: $\\int \\sum f_n = \\sum \\int f_n$. This follows from applying Theorem 7.16 to partial sums."},{id:3,type:"multiple-choice",question:"Consider $f_n(x) = n x(1-x^2)^n$ on $[0, 1]$. The pointwise limit is $f(x) = 0$. Then:",options:["$\\lim_{n \\to \\infty} \\int_0^1 f_n(x) \\, dx = \\frac{1}{2}$","The limit of integrals does not exist","Convergence is uniform","$\\lim_{n \\to \\infty} \\int_0^1 f_n(x) \\, dx = 0$"],correctIndex:0,difficulty:"hard",explanation:"With $u = 1 - x^2$: $\\int_0^1 nx(1-x^2)^n dx = \\frac{n}{2}\\int_0^1 u^n du = \\frac{n}{2(n+1)} \\to \\frac{1}{2}$. But $f(x) = 0$ everywhere, so $\\int f = 0$. The convergence is NOT uniform (concentrated near $x = 0$)."},{id:4,type:"multiple-choice",question:"The interchange $\\lim_{n \\to \\infty} \\int_a^b f_n = \\int_a^b \\lim_{n \\to \\infty} f_n$ requires:",options:["Pointwise convergence only","Monotone convergence of $\\{f_n\\}$","Each $f_n$ continuous","Uniform convergence (sufficient but not necessary in general)"],correctIndex:3,difficulty:"medium",explanation:"Uniform convergence is a sufficient condition for interchanging limits and integrals. Other conditions (like dominated convergence in Lebesgue theory, or monotone convergence) also work but are not covered in Rudin's Riemann integral treatment."},{id:5,type:"multiple-choice",question:"If $\\sum_{n=1}^{\\infty} \\int_a^b |f_n(x)| \\, dx < \\infty$, can we conclude $\\sum f_n$ converges uniformly?",options:["No, this only implies pointwise convergence","No, uniform convergence requires $\\sup |f_n| \\leq M_n$ with $\\sum M_n < \\infty$","Yes, this is the integral form of the M-test","Yes, if each $f_n$ is continuous"],correctIndex:1,difficulty:"hard",explanation:"The Weierstrass M-test requires $|f_n(x)| \\leq M_n$ for ALL $x$, not just integrability of $|f_n|$. The integral condition ensures absolute convergence of $\\sum \\int f_n$ but not uniform convergence of $\\sum f_n$."}],J=[{id:1,type:"multiple-choice",question:"To differentiate a series $\\sum f_n(x)$ term by term, Theorem 7.17 requires:",options:["Each $f_n$ is differentiable","$\\sum f_n$ converges uniformly","$\\sum |f_n'|$ converges","$\\sum f_n'$ converges uniformly and $\\sum f_n(x_0)$ converges for some $x_0$"],correctIndex:3,difficulty:"hard",explanation:"Theorem 7.17: If $\\{f_n'\\}$ converges uniformly on $[a,b]$, each $f_n'$ is continuous, and $\\sum f_n(x_0)$ converges for some $x_0 \\in [a,b]$, then $\\sum f_n$ converges uniformly and $(\\sum f_n)' = \\sum f_n'$."},{id:2,type:"multiple-choice",question:"The condition for term-by-term differentiation is on the derivatives, not the original functions, because:",options:["Functions may not be differentiable","Differentiation is a local operation","The derivatives control the rate of convergence needed for the limit to be differentiable","Integration is easier than differentiation"],correctIndex:2,difficulty:"medium",explanation:`Differentiation is a "local" operation that can amplify small oscillations. For the derivative of the limit to equal the limit of derivatives, we need control over how the derivatives behave (uniform convergence of $f_n'$), not just the functions themselves.`},{id:3,type:"multiple-choice",question:"Consider $f_n(x) = \\frac{\\sin(nx)}{n}$ on $\\mathbb{R}$. Then $\\sum f_n$ converges uniformly but:",options:["$(\\sum f_n)'$ does not exist","$\\sum f_n'$ converges uniformly to $(\\sum f_n)'$","$\\sum f_n$ does not converge","$\\sum f_n'(x) = \\sum \\cos(nx)$ diverges for most $x$"],correctIndex:3,difficulty:"hard",explanation:"We have $f_n'(x) = \\cos(nx)$, and $\\sum \\cos(nx)$ diverges for most $x$ (the terms don't go to $0$). This shows that uniform convergence of $\\sum f_n$ does NOT imply we can differentiate term-by-term."},{id:4,type:"multiple-choice",question:"If $f_n \\to f$ uniformly on $[a, b]$, $f_n$ is differentiable, and $f_n' \\to g$ uniformly, then:",options:["$f' = g$ only at isolated points","$f$ is differentiable and $f' = g$","$f$ may not be differentiable","$g$ may not be continuous"],correctIndex:1,difficulty:"medium",explanation:"This is the sequence version of Theorem 7.17: uniform convergence of both $f_n$ and $f_n'$ (with $f_n'$ continuous) implies $f$ is differentiable with $f' = g$."},{id:5,type:"multiple-choice",question:"For a power series $\\sum a_n x^n$ with radius of convergence $R > 0$:",options:["It can be differentiated term-by-term for $|x| < R$, and the derivative has the same radius $R$","It can be differentiated term-by-term only at $x = 0$","Term-by-term differentiation is never valid","The derivative has radius of convergence $R - 1$"],correctIndex:0,difficulty:"medium",explanation:"Theorem 8.1: A power series can be differentiated term-by-term inside its radius of convergence, and the derived series $\\sum n a_n x^{n-1}$ has the same radius of convergence $R$."}],Z=[{id:1,type:"multiple-choice",question:"A family $\\mathscr{F}$ of functions on $E$ is equicontinuous if:",options:["Each function in $\\mathscr{F}$ is uniformly continuous","For every $\\epsilon > 0$, there exists $\\delta > 0$ such that $|x - y| < \\delta$ implies $|f(x) - f(y)| < \\epsilon$ for ALL $f \\in \\mathscr{F}$","The family has a convergent subsequence","The family is uniformly bounded"],correctIndex:1,difficulty:"medium",explanation:"Equicontinuity means the same $\\delta$ works for ALL functions in the family simultaneously. This is stronger than each function being merely uniformly continuous."},{id:2,type:"multiple-choice",question:"The Arzel\\`a-Ascoli Theorem states that a sequence $\\{f_n\\}$ of functions on a compact set $K$ has a uniformly convergent subsequence if:",options:["$\\{f_n\\}$ converges pointwise","$\\{f_n\\}$ is pointwise bounded","$\\{f_n\\}$ is uniformly bounded and equicontinuous","Each $f_n$ is differentiable"],correctIndex:2,difficulty:"medium",explanation:"Arzel\\`a-Ascoli (Theorem 7.25): If $K$ is compact, $\\{f_n\\}$ is pointwise bounded and equicontinuous, then $\\{f_n\\}$ has a uniformly convergent subsequence. The limit is automatically continuous."},{id:3,type:"multiple-choice",question:"The family $\\{f_n(x) = x^n : n \\in \\mathbb{N}\\}$ on $[0, 1]$ is:",options:["Uniformly bounded but not pointwise bounded","Not equicontinuous (fails near $x = 1$)","Equicontinuous","Has no convergent subsequence"],correctIndex:1,difficulty:"hard",explanation:"Near $x = 1$, $f_n(x) = x^n$ drops from $1$ to $0$ over increasingly small intervals as $n \\to \\infty$. For fixed $\\epsilon < 1$, no single $\\delta$ works for all $n$ near $x = 1$. The family is not equicontinuous."},{id:4,type:"multiple-choice",question:"If $\\{f_n\\}$ satisfies $|f_n'(x)| \\leq M$ for all $n$ and $x \\in [a, b]$, then $\\{f_n\\}$ is:",options:["Differentiable","Pointwise bounded","Equicontinuous","Uniformly convergent"],correctIndex:2,difficulty:"medium",explanation:"A uniform bound on derivatives gives equicontinuity: $|f_n(x) - f_n(y)| \\leq M|x - y|$ for all $n$ (by MVT). So for $\\epsilon > 0$, take $\\delta = \\epsilon/M$."},{id:5,type:"multiple-choice",question:"The Arzel\\`a-Ascoli Theorem is the function-space analogue of:",options:["The Fundamental Theorem of Calculus","The Intermediate Value Theorem","The Bolzano-Weierstrass Theorem (bounded sequences have convergent subsequences)","The Mean Value Theorem"],correctIndex:2,difficulty:"easy",explanation:"Bolzano-Weierstrass says bounded sequences in $\\mathbb{R}^n$ have convergent subsequences. Arzel\\`a-Ascoli is the analogue for function spaces: bounded + equicontinuous families have uniformly convergent subsequences."}],Y=[{id:1,type:"multiple-choice",question:"The Weierstrass Approximation Theorem states that on $[a, b]$, every continuous function can be uniformly approximated by:",options:["Polynomials","Step functions","Trigonometric polynomials","Piecewise linear functions"],correctIndex:0,difficulty:"easy",explanation:"Weierstrass Approximation: If $f$ is continuous on $[a,b]$, then for every $\\epsilon > 0$, there exists a polynomial $P$ such that $|f(x) - P(x)| < \\epsilon$ for all $x \\in [a,b]$."},{id:2,type:"multiple-choice",question:"The Stone-Weierstrass Theorem generalizes Weierstrass by allowing approximation on:",options:["Unbounded domains","Any compact Hausdorff space, using algebras that separate points and contain constants","Only intervals $[a, b]$","Only metric spaces"],correctIndex:1,difficulty:"hard",explanation:"Stone-Weierstrass (Theorem 7.32): If $\\mathscr{A}$ is an algebra of continuous real functions on a compact space $K$ that separates points and vanishes nowhere, then $\\mathscr{A}$ is dense in $C(K)$."},{id:3,type:"multiple-choice",question:'An algebra $\\mathscr{A}$ of functions "separates points" means:',options:["For distinct $x, y$, there exists $f \\in \\mathscr{A}$ with $f(x) \\neq f(y)$","For all $f \\in \\mathscr{A}$, $f$ is one-to-one","The functions in $\\mathscr{A}$ have disjoint supports","$\\mathscr{A}$ contains only injective functions"],correctIndex:0,difficulty:"medium",explanation:'Separating points means the algebra has "enough" functions to distinguish any two distinct points: given $x \\neq y$, some $f \\in \\mathscr{A}$ satisfies $f(x) \\neq f(y)$.'},{id:4,type:"multiple-choice",question:"Why can't polynomials approximate $|x|$ uniformly on $[-1, 1]$ in the sense of matching derivatives?",options:["Polynomials can approximate $|x|$ uniformly, but not in $C^1$ norm","$|x|$ is unbounded","$|x|$ is not continuous","Polynomials are not dense in $C[-1, 1]$"],correctIndex:0,difficulty:"hard",explanation:"Weierstrass guarantees uniform approximation of $|x|$ by polynomials. However, $|x|$ is not differentiable at $0$, while polynomials are smooth. Approximation is in sup-norm (uniform), not in $C^1$ or smoother norms."},{id:5,type:"multiple-choice",question:"The complex version of Stone-Weierstrass requires the algebra to be:",options:["Finite-dimensional","The same as the real version","Self-adjoint (closed under complex conjugation)","Containing only real-valued functions"],correctIndex:2,difficulty:"hard",explanation:"For complex-valued functions, Stone-Weierstrass (Theorem 7.33) requires the algebra to be self-adjoint: if $f \\in \\mathscr{A}$, then $\\bar{f} \\in \\mathscr{A}$. Without this, the theorem fails (consider polynomials in $z$ alone on the circle)."}],ee=[{id:1,type:"multiple-choice",question:"A power series $\\sum_{n=0}^{\\infty} c_n z^n$ converges:",options:["For all $z \\in \\mathbb{C}$","Only for real $z$","Only at $z = 0$","In a disk $|z| < R$ for some $0 \\leq R \\leq \\infty$ (the radius of convergence)"],correctIndex:3,difficulty:"easy",explanation:"Theorem 3.39: Every power series has a radius of convergence $R \\in [0, \\infty]$. The series converges absolutely for $|z| < R$ and diverges for $|z| > R$. Behavior at $|z| = R$ varies."},{id:2,type:"multiple-choice",question:"The radius of convergence $R$ of $\\sum c_n z^n$ satisfies:",options:["$R = \\lim |c_n/c_{n+1}|$ always","$R = 1$ always","$R = \\sum |c_n|$","$1/R = \\limsup_{n \\to \\infty} |c_n|^{1/n}$"],correctIndex:3,difficulty:"medium",explanation:"The Hadamard formula (Theorem 3.39): $1/R = \\limsup |c_n|^{1/n}$, with $R = 0$ if $\\limsup = \\infty$ and $R = \\infty$ if $\\limsup = 0$. The ratio test formula works when the limit exists."},{id:3,type:"multiple-choice",question:"Inside the radius of convergence, a power series defines a function that is:",options:["Continuous but may not be differentiable","Differentiable but may not be analytic","Infinitely differentiable (analytic)","Bounded but may not be continuous"],correctIndex:2,difficulty:"medium",explanation:'Power series are infinitely differentiable inside their radius of convergence, and can be differentiated term-by-term any number of times. The function equals its Taylor series - this is what "analytic" means.'},{id:4,type:"multiple-choice",question:"The power series $\\sum_{n=0}^{\\infty} x^n$ and its derivative $\\sum_{n=1}^{\\infty} n x^{n-1}$ have:",options:["The same radius of convergence $R = 1$","Radius $\\infty$ for both","Different radii of convergence","The derivative has larger radius"],correctIndex:0,difficulty:"easy",explanation:"Theorem 8.1: A power series and its term-by-term derivative have the same radius of convergence. For $\\sum x^n$, $R = 1$, and for $\\sum nx^{n-1}$, $R = 1$ as well."},{id:5,type:"multiple-choice",question:"Abel's theorem states that if $\\sum c_n$ converges and $f(x) = \\sum c_n x^n$ for $|x| < 1$, then:",options:["The series diverges at $x = 1$","$\\lim_{x \\to 1^-} f(x) = \\sum c_n$","$f$ is discontinuous at $x = 1$","$f(1) = \\sum c_n$"],correctIndex:1,difficulty:"hard",explanation:`Abel's Theorem (Theorem 8.2): If $\\sum c_n$ converges to $s$, then $\\lim_{x \\to 1^-} \\sum c_n x^n = s$. This gives continuity "from the left" at the boundary when the series converges there.`}],ie=[{id:1,type:"multiple-choice",question:"The exponential function $E(z) = \\sum_{n=0}^{\\infty} \\frac{z^n}{n!}$ satisfies:",options:["$E(z + w) = E(z) \\cdot E(w)$","$E(z)E(w) = E(z) + E(w)$","$E(z + w) = E(z) + E(w)$","$E(zw) = E(z) \\cdot E(w)$"],correctIndex:0,difficulty:"easy",explanation:"The fundamental property of the exponential is $E(z + w) = E(z)E(w)$. This follows from the Cauchy product of the two series and the binomial theorem."},{id:2,type:"multiple-choice",question:"The natural logarithm $L(x)$ is defined for $x > 0$ as:",options:["The inverse function of $E$ restricted to real numbers","The derivative of $E(x)$","$\\int_0^x E(t) \\, dt$","$\\sum_{n=1}^{\\infty} \\frac{x^n}{n}$"],correctIndex:0,difficulty:"easy",explanation:"Since $E: \\mathbb{R} \\to (0, \\infty)$ is strictly increasing (with $E' = E > 0$), it has an inverse function $L: (0, \\infty) \\to \\mathbb{R}$, the natural logarithm."},{id:3,type:"multiple-choice",question:"The derivative of $L(x)$ equals:",options:["$L(x)$","$1/x$","$x$","$E(x)$"],correctIndex:1,difficulty:"easy",explanation:"By the inverse function theorem: $L'(x) = 1/E'(L(x)) = 1/E(L(x)) = 1/x$. Alternatively, from $\\int_1^x (1/t)\\,dt = L(x)$."},{id:4,type:"multiple-choice",question:"For real $x$ and $y > 0$, $y^x$ is defined as:",options:["$y$ multiplied by itself $x$ times","$L(x \\cdot E(y))$","$x^y$","$E(x \\cdot L(y))$"],correctIndex:3,difficulty:"medium",explanation:"For arbitrary real exponents, we define $y^x = E(x \\cdot L(y)) = e^{x \\ln y}$. This extends the definition from rational to all real exponents while preserving the expected properties."},{id:5,type:"multiple-choice",question:"The limit $\\lim_{n \\to \\infty} (1 + 1/n)^n$ equals:",options:["$\\infty$","$2$","$e = E(1)$","$1$"],correctIndex:2,difficulty:"medium",explanation:"This is one of the classical definitions of $e$. Using $L(1 + 1/n)^n = n \\cdot L(1 + 1/n) \\to 1$ as $n \\to \\infty$ (since $L'(1) = 1$), we get $(1 + 1/n)^n \\to E(1) = e$."}],te=[{id:1,type:"multiple-choice",question:"Rudin defines $\\cos(x)$ and $\\sin(x)$ via:",options:["Geometric definitions using the unit circle","As solutions to $y'' + y = 0$","Power series: $\\cos x = \\sum \\frac{(-1)^n x^{2n}}{(2n)!}$, $\\sin x = \\sum \\frac{(-1)^n x^{2n+1}}{(2n+1)!}$","Inverse functions of arccos and arcsin"],correctIndex:2,difficulty:"easy",explanation:"Rudin defines trigonometric functions analytically via their power series (Definition 8.6). The geometric properties (periodicity, relation to the circle) are then derived as theorems."},{id:2,type:"multiple-choice",question:"Euler's formula states that for real $x$:",options:["$e^{ix} = \\cos x + i \\sin x$","$i^x = \\cos x + i \\sin x$","$e^x = \\cos x + \\sin x$","$e^{ix} = \\cos x - i \\sin x$"],correctIndex:0,difficulty:"easy",explanation:"Euler's formula $e^{ix} = \\cos x + i\\sin x$ follows directly from the power series definitions. The real part of $e^{ix}$ is $\\cos x$ and the imaginary part is $\\sin x$."},{id:3,type:"multiple-choice",question:"The number $\\pi$ is defined in Rudin as:",options:["The area of the unit circle","Twice the smallest positive zero of $\\cos$","The ratio of circumference to diameter of a circle","$4 \\arctan(1)$"],correctIndex:1,difficulty:"medium",explanation:"Rudin defines $\\pi$ analytically: he proves $\\cos$ has a smallest positive zero (call it $x_0$), and defines $\\pi = 2x_0$. The geometric interpretation follows as a theorem."},{id:4,type:"multiple-choice",question:"The functions $\\sin$ and $\\cos$ are periodic with period:",options:["$4\\pi$","$\\pi$","$2\\pi$","$\\pi/2$"],correctIndex:2,difficulty:"easy",explanation:"Both $\\sin$ and $\\cos$ have period $2\\pi$: $\\sin(x + 2\\pi) = \\sin x$ and $\\cos(x + 2\\pi) = \\cos x$. This follows from $e^{i(x + 2\\pi)} = e^{ix} \\cdot e^{2\\pi i} = e^{ix}$."},{id:5,type:"multiple-choice",question:"The identity $\\cos^2 x + \\sin^2 x = 1$ follows from:",options:["The intermediate value theorem","The power series having unit radius of convergence","$e^{ix} \\cdot e^{-ix} = e^0 = 1$, i.e., $|e^{ix}|^2 = 1$","The Pythagorean theorem"],correctIndex:2,difficulty:"medium",explanation:"Since $e^{ix} \\cdot \\overline{e^{ix}} = e^{ix} \\cdot e^{-ix} = e^0 = 1$, we have $|e^{ix}|^2 = (\\cos x)^2 + (\\sin x)^2 = 1$."}],ne=[{id:1,type:"multiple-choice",question:"The Fundamental Theorem of Algebra states that every non-constant polynomial with complex coefficients:",options:["Has exactly $n$ distinct roots where $n$ is the degree","Has at least one real root","Has at least one complex root","Has roots that are all algebraic numbers"],correctIndex:2,difficulty:"easy",explanation:"The Fundamental Theorem of Algebra: Every non-constant polynomial $p(z)$ with complex coefficients has at least one complex root. Equivalently, $\\mathbb{C}$ is algebraically closed."},{id:2,type:"multiple-choice",question:"Rudin's proof of the Fundamental Theorem of Algebra uses:",options:["The residue theorem from complex analysis","Properties of the exponential function and compactness arguments","Galois theory","Algebraic techniques only"],correctIndex:1,difficulty:"hard",explanation:"Rudin's proof (Theorem 8.8) uses analysis: if $p(z) \\neq 0$ for all $z$, then $1/p(z)$ is a bounded entire function. The proof shows $|p(z)| \\to \\infty$ as $|z| \\to \\infty$, so $|p|$ attains a minimum, which must be $0$."},{id:3,type:"multiple-choice",question:"A consequence of the FTA is that every polynomial of degree $n$ has exactly:",options:["$n$ distinct complex roots","$n$ real roots","At most $n$ complex roots","$n$ complex roots counting multiplicity"],correctIndex:3,difficulty:"medium",explanation:"By repeatedly factoring out roots (each application of FTA gives one root), a degree-$n$ polynomial can be written as $c(z - r_1)(z - r_2)\\cdots(z - r_n)$, giving exactly $n$ roots counting multiplicity."},{id:4,type:"multiple-choice",question:"The polynomial $p(z) = z^4 + 1$ over $\\mathbb{R}$:",options:["Factors into two irreducible quadratics over $\\mathbb{R}$","Has no complex roots","Has four real roots","Is irreducible over $\\mathbb{R}$"],correctIndex:0,difficulty:"hard",explanation:"$z^4 + 1 = (z^2 + \\sqrt{2}z + 1)(z^2 - \\sqrt{2}z + 1)$ over $\\mathbb{R}$. Each quadratic factor has complex conjugate roots (the 8th roots of unity: $e^{i\\pi/4}, e^{3i\\pi/4}, e^{5i\\pi/4}, e^{7i\\pi/4}$)."},{id:5,type:"multiple-choice",question:"The algebraic closure of $\\mathbb{R}$ is:",options:["$\\mathbb{R}$ itself","$\\mathbb{Q}$","The algebraic numbers","$\\mathbb{C}$"],correctIndex:3,difficulty:"easy",explanation:"By the FTA, every polynomial with real (hence complex) coefficients has all its roots in $\\mathbb{C}$. Since $\\mathbb{C} = \\mathbb{R}[i]$ (adjoining one root of $x^2 + 1$), $\\mathbb{C}$ is the algebraic closure of $\\mathbb{R}$."}],oe=[{id:1,type:"multiple-choice",question:"The Fourier series of a function $f$ on $[-\\pi, \\pi]$ is:",options:["$\\sum_{n=-\\infty}^{\\infty} c_n e^{inx}$ where $c_n = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} f(t)e^{-int}\\,dt$","$\\sum_{n=1}^{\\infty} \\frac{f^{(n)}(0)}{n!} x^n$","$\\sum_{n=0}^{\\infty} a_n x^n$","$\\int_{-\\pi}^{\\pi} f(t) \\, dt$"],correctIndex:0,difficulty:"medium",explanation:"The Fourier series represents $f$ in terms of complex exponentials $e^{inx}$ (or equivalently, sines and cosines). The coefficients $c_n$ are computed via the inner product with $e^{-inx}$."},{id:2,type:"multiple-choice",question:"The Fourier coefficients $c_n$ of $f$ satisfy Bessel's inequality:",options:["$\\sum_{n=-\\infty}^{\\infty} |c_n| < \\infty$","$\\sum_{n=-\\infty}^{\\infty} |c_n|^2 = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} |f(t)|^2 \\, dt$","$\\sum_{n=-\\infty}^{\\infty} |c_n|^2 \\leq \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} |f(t)|^2 \\, dt$","$|c_n| \\leq 1$ for all $n$"],correctIndex:2,difficulty:"medium",explanation:"Bessel's inequality states $\\sum |c_n|^2 \\leq \\frac{1}{2\\pi}\\int |f|^2$. Equality (Parseval) holds when $f$ equals its Fourier series in $L^2$ sense."},{id:3,type:"multiple-choice",question:"If $f$ is continuous and $2\\pi$-periodic, its Fourier series:",options:["May not converge to $f$ everywhere (but converges in $L^2$)","Diverges everywhere","Converges to $f(x)$ at every point","Always converges uniformly to $f$"],correctIndex:0,difficulty:"hard",explanation:"Continuity alone does not guarantee pointwise convergence of Fourier series everywhere (du Bois-Reymond constructed a continuous function whose Fourier series diverges at a point). However, Parseval guarantees $L^2$ convergence."},{id:4,type:"multiple-choice",question:"The partial sums $S_N(f; x) = \\sum_{n=-N}^{N} c_n e^{inx}$ can be written as:",options:["$\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} f(t) D_N(x - t) \\, dt$ where $D_N$ is the Dirichlet kernel","$f(x) - R_N(x)$ where $R_N \\to 0$","$N \\cdot c_0$","$\\int_{-\\pi}^{\\pi} f(t) \\, dt$"],correctIndex:0,difficulty:"hard",explanation:"The partial sums are convolutions with the Dirichlet kernel: $S_N(f; x) = (f * D_N)(x)$ where $D_N(t) = \\sum_{n=-N}^{N} e^{int} = \\frac{\\sin((N+1/2)t)}{\\sin(t/2)}$."},{id:5,type:"multiple-choice",question:"Parseval's theorem states that for $f \\in L^2[-\\pi, \\pi]$:",options:["$\\sum_{n=-\\infty}^{\\infty} |c_n|^2 = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} |f(t)|^2 \\, dt$","$c_n \\to 0$ as $|n| \\to \\infty$","The Fourier series converges uniformly","$f$ equals its Fourier series pointwise"],correctIndex:0,difficulty:"medium",explanation:`Parseval's theorem (equality in Bessel's inequality) says the $L^2$ norm of $f$ equals the $\\ell^2$ norm of its Fourier coefficients: $\\|f\\|_2^2 = 2\\pi \\sum |c_n|^2$. This is "conservation of energy."`}],ae=[{id:1,type:"multiple-choice",question:"The Gamma function $\\Gamma(x)$ is defined for $x > 0$ by which integral?",options:["$\\int_0^\\infty t^{x-1} e^{-t} \\, dt$","$\\int_0^\\infty t^x e^{-t} \\, dt$","$\\int_{-\\infty}^\\infty e^{-t^2} t^x \\, dt$","$\\int_0^1 t^{x-1} (1-t)^{x-1} \\, dt$"],correctIndex:0,difficulty:"medium",explanation:"The Gamma function is defined as $\\Gamma(x) = \\int_0^\\infty t^{x-1} e^{-t} \\, dt$ for $x > 0$. This integral converges absolutely for all positive real $x$."},{id:2,type:"multiple-choice",question:"What is the value of $\\Gamma(n+1)$ for a positive integer $n$?",options:["$n^n$","$(n+1)!$","$n!$","$(n-1)!$"],correctIndex:2,difficulty:"easy",explanation:"For positive integers, $\\Gamma(n+1) = n!$. This follows from the functional equation $\\Gamma(x+1) = x\\Gamma(x)$ and the fact that $\\Gamma(1) = 1$."},{id:3,type:"multiple-choice",question:"The functional equation satisfied by the Gamma function is:",options:["$\\Gamma(x)\\Gamma(1-x) = 1$","$\\Gamma(x+1) = x\\Gamma(x)$","$\\Gamma(x+1) = (x+1)\\Gamma(x)$","$\\Gamma(2x) = \\Gamma(x)^2$"],correctIndex:1,difficulty:"medium",explanation:"The fundamental functional equation is $\\Gamma(x+1) = x\\Gamma(x)$, proved by integration by parts. This generalizes the factorial relation $(n+1)! = (n+1) \\cdot n!$."},{id:4,type:"multiple-choice",question:"What is the value of $\\Gamma(1/2)$?",options:["$2\\sqrt{\\pi}$","$1/2$","$\\pi$","$\\sqrt{\\pi}$"],correctIndex:3,difficulty:"hard",explanation:"$\\Gamma(1/2) = \\int_0^\\infty t^{-1/2} e^{-t} \\, dt = \\sqrt{\\pi}$. This can be computed using the substitution $t = u^2$ and the Gaussian integral $\\int_{-\\infty}^\\infty e^{-u^2} du = \\sqrt{\\pi}$."},{id:5,type:"multiple-choice",question:"The Beta function $B(x,y)$ is related to the Gamma function by:",options:["$B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$","$B(x,y) = \\frac{\\Gamma(x+y)}{\\Gamma(x)\\Gamma(y)}$","$B(x,y) = \\Gamma(xy)$","$B(x,y) = \\Gamma(x)\\Gamma(y)$"],correctIndex:0,difficulty:"hard",explanation:"The Beta function $B(x,y) = \\int_0^1 t^{x-1}(1-t)^{y-1} dt$ satisfies $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$. This identity connects two important special functions."}],se=[{id:1,type:"multiple-choice",question:"A function $A: \\mathbb{R}^n \\to \\mathbb{R}^m$ is a linear transformation if and only if:",options:["$A(xy) = Ax \\cdot Ay$ for all $x,y \\in \\mathbb{R}^n$","$A(x+y) = Ax + Ay$ and $A(cx) = cAx$ for all $x,y \\in \\mathbb{R}^n$ and $c \\in \\mathbb{R}$","$A(x) = Mx$ for some scalar $M$","$\\|Ax\\| = \\|x\\|$ for all $x \\in \\mathbb{R}^n$"],correctIndex:1,difficulty:"easy",explanation:"A linear transformation preserves vector addition and scalar multiplication. These two conditions are equivalent to $A(cx + dy) = cAx + dAy$ for all vectors and scalars."},{id:2,type:"multiple-choice",question:"The set $L(\\mathbb{R}^n, \\mathbb{R}^m)$ of all linear transformations from $\\mathbb{R}^n$ to $\\mathbb{R}^m$ is:",options:["A vector space of dimension $\\max(m,n)$","Not a vector space","A vector space of dimension $m+n$","A vector space of dimension $mn$"],correctIndex:3,difficulty:"medium",explanation:"$L(\\mathbb{R}^n, \\mathbb{R}^m)$ is a vector space isomorphic to the space of $m \\times n$ matrices, which has dimension $mn$."},{id:3,type:"multiple-choice",question:"For a linear transformation $A \\in L(\\mathbb{R}^n, \\mathbb{R}^m)$, the operator norm $\\|A\\|$ is defined as:",options:["$\\sum_{i,j} |a_{ij}|$","$\\sup\\{|Ax| : x \\in \\mathbb{R}^n, |x| \\leq 1\\}$","$\\sqrt{\\sum_{i,j} a_{ij}^2}$","$\\max_{i,j} |a_{ij}|$"],correctIndex:1,difficulty:"medium",explanation:"The operator norm is defined as the supremum of $|Ax|$ over the unit ball. This makes $L(\\mathbb{R}^n, \\mathbb{R}^m)$ a normed vector space."},{id:4,type:"multiple-choice",question:"If $A \\in L(\\mathbb{R}^n, \\mathbb{R}^m)$ and $B \\in L(\\mathbb{R}^m, \\mathbb{R}^k)$, then $\\|BA\\|$ satisfies:",options:["$\\|BA\\| = \\|B\\| + \\|A\\|$","$\\|BA\\| \\geq \\|B\\| \\|A\\|$","$\\|BA\\| \\leq \\|B\\| \\|A\\|$","$\\|BA\\| = \\|B\\| \\|A\\|$"],correctIndex:2,difficulty:"medium",explanation:"The operator norm is submultiplicative: $\\|BA\\| \\leq \\|B\\| \\|A\\|$. This follows from $|BAx| \\leq \\|B\\| |Ax| \\leq \\|B\\| \\|A\\| |x|$."},{id:5,type:"multiple-choice",question:"A linear transformation $A: \\mathbb{R}^n \\to \\mathbb{R}^n$ is invertible if and only if:",options:["$\\|A\\| > 0$","Both A and C are correct","$A$ maps some basis to a basis","$A$ is one-to-one (equivalently, onto)"],correctIndex:1,difficulty:"hard",explanation:"For finite-dimensional spaces, a linear map is invertible iff it is one-to-one iff it is onto. Also, $A$ is invertible iff it maps every basis to a basis. Note that $\\|A\\| > 0$ only means $A \\neq 0$."}],$e=[{id:1,type:"multiple-choice",question:"A function $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ is differentiable at $x$ if there exists a linear transformation $A$ such that:",options:["$f(x+h) = f(x) + Ah$ for small $h$","$\\frac{\\partial f}{\\partial x_i}$ exists for all $i$","$\\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h} = A$","$\\lim_{h \\to 0} \\frac{|f(x+h) - f(x) - Ah|}{|h|} = 0$"],correctIndex:3,difficulty:"medium",explanation:"The definition of differentiability requires the error $f(x+h) - f(x) - Ah$ to go to zero faster than $|h|$. This linear transformation $A$ is called the derivative $f'(x)$."},{id:2,type:"multiple-choice",question:"If $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ is differentiable at $x$, its derivative $f'(x)$ is:",options:["A linear transformation in $L(\\mathbb{R}^n, \\mathbb{R}^m)$","A vector in $\\mathbb{R}^m$","A scalar","An $n \\times n$ matrix"],correctIndex:0,difficulty:"easy",explanation:"The derivative $f'(x)$ is a linear transformation from $\\mathbb{R}^n$ to $\\mathbb{R}^m$. It can be represented by the $m \\times n$ Jacobian matrix of partial derivatives."},{id:3,type:"multiple-choice",question:"The chain rule for differentiable functions states that if $g$ is differentiable at $x$ and $f$ is differentiable at $g(x)$, then:",options:["$(f \\circ g)'(x) = f'(x) \\circ g'(x)$","$(f \\circ g)'(x) = f'(g(x)) \\circ g'(x)$","$(f \\circ g)'(x) = g'(x) \\circ f'(g(x))$","$(f \\circ g)'(x) = f'(g(x)) + g'(x)$"],correctIndex:1,difficulty:"medium",explanation:"The chain rule states $(f \\circ g)'(x) = f'(g(x)) \\circ g'(x)$, where the composition is of linear transformations. In matrix form, this is matrix multiplication."},{id:4,type:"multiple-choice",question:"For $f: \\mathbb{R}^n \\to \\mathbb{R}$, the gradient $\\nabla f(x)$ is related to the derivative by:",options:["$f'(x) = \\nabla f(x) \\times h$","$f'(x)h = \\nabla f(x) \\cdot h$ for all $h \\in \\mathbb{R}^n$","$\\nabla f(x) = (f'(x))^T f'(x)$","$f'(x) = |\\nabla f(x)|$"],correctIndex:1,difficulty:"medium",explanation:"For scalar-valued functions, the derivative $f'(x)$ is a linear functional that acts on vectors $h$ by the dot product $\\nabla f(x) \\cdot h$. The gradient vector represents this linear functional."},{id:5,type:"multiple-choice",question:"If $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ is differentiable at $x$, then:",options:["$f'$ is continuous at $x$","$f$ is twice differentiable at $x$","All partial derivatives of $f$ are continuous at $x$","$f$ is continuous at $x$"],correctIndex:3,difficulty:"easy",explanation:"Differentiability implies continuity. The converse is false: a function can be continuous without being differentiable. Also, existence of partial derivatives does not imply differentiability."}],re=[{id:1,type:"multiple-choice",question:"A mapping $\\varphi: X \\to X$ on a complete metric space is a contraction if:",options:["$\\varphi$ is continuous and bounded","$\\|\\varphi'(x)\\| < 1$ for all $x$","$d(\\varphi(x), \\varphi(y)) < d(x,y)$ for all $x \\neq y$","There exists $c < 1$ such that $d(\\varphi(x), \\varphi(y)) \\leq c \\cdot d(x,y)$ for all $x,y$"],correctIndex:3,difficulty:"medium",explanation:"A contraction requires a uniform constant $c < 1$ such that distances shrink by at least factor $c$. The condition $d(\\varphi(x), \\varphi(y)) < d(x,y)$ is weaker and does not guarantee a fixed point."},{id:2,type:"multiple-choice",question:"The Contraction Mapping Principle states that a contraction on a complete metric space:",options:["Has finitely many fixed points","Has at least one fixed point","Has a fixed point only if the space is compact","Has exactly one fixed point"],correctIndex:3,difficulty:"easy",explanation:"The Contraction Mapping Principle (Banach Fixed Point Theorem) guarantees existence and uniqueness of a fixed point for any contraction on a complete metric space."},{id:3,type:"multiple-choice",question:"If $\\varphi$ is a contraction with constant $c$ and fixed point $x^*$, the iteration $x_{n+1} = \\varphi(x_n)$ satisfies:",options:["$d(x_n, x^*) \\leq c^n d(x_0, x^*)$","$d(x_n, x^*) \\leq \\frac{c^n}{1-c} d(x_0, x_1)$","$d(x_n, x^*) \\leq n \\cdot c \\cdot d(x_0, x^*)$","$d(x_n, x^*) = c^n d(x_0, x^*)$"],correctIndex:1,difficulty:"hard",explanation:"The error bound $d(x_n, x^*) \\leq \\frac{c^n}{1-c} d(x_0, x_1)$ gives a computable estimate using only the first step. This is derived from the geometric series and the triangle inequality."},{id:4,type:"multiple-choice",question:"Which of the following is NOT required for the Contraction Mapping Principle?",options:["The contraction constant must be strictly less than 1","The mapping must be a contraction","The space must be complete","The space must be compact"],correctIndex:3,difficulty:"medium",explanation:"Compactness is not required. The theorem requires completeness of the metric space and a contraction constant $c < 1$. Compactness is a stronger condition that implies other fixed point theorems."},{id:5,type:"multiple-choice",question:"The Contraction Mapping Principle is used to prove:",options:["The Fundamental Theorem of Calculus","The Bolzano-Weierstrass Theorem","The Heine-Borel Theorem","The Inverse Function Theorem and existence theorems for ODEs"],correctIndex:3,difficulty:"medium",explanation:"The Contraction Mapping Principle is a fundamental tool for proving existence and uniqueness results, including the Inverse Function Theorem, Implicit Function Theorem, and Picard's theorem for ODEs."}],ce=[{id:1,type:"multiple-choice",question:"The Inverse Function Theorem requires that at the point $a$, the derivative $f'(a)$:",options:["Is an invertible linear transformation","Has determinant equal to 1","Has all positive eigenvalues","Is symmetric"],correctIndex:0,difficulty:"easy",explanation:"The key hypothesis is that $f'(a)$ must be invertible (equivalently, $\\det f'(a) \\neq 0$). This ensures the linear approximation is locally bijective."},{id:2,type:"multiple-choice",question:"If $f: \\mathbb{R}^n \\to \\mathbb{R}^n$ is $C^1$ and $f'(a)$ is invertible, the Inverse Function Theorem guarantees:",options:["$f$ is globally invertible","$f'$ is constant near $a$","$f$ is locally invertible near $a$ with $C^1$ inverse","$f$ is a linear map"],correctIndex:2,difficulty:"medium",explanation:"The theorem provides local invertibility: there exist neighborhoods $U$ of $a$ and $V$ of $f(a)$ such that $f: U \\to V$ is a bijection with $C^1$ inverse."},{id:3,type:"multiple-choice",question:"If $f$ is $C^k$ ($k \\geq 1$) and $f'(a)$ is invertible, then the local inverse $g = f^{-1}$ is:",options:["Only continuous","$C^\\infty$","$C^1$ but not necessarily $C^k$","$C^k$"],correctIndex:3,difficulty:"medium",explanation:"The Inverse Function Theorem preserves differentiability class: if $f$ is $C^k$, so is its local inverse. This is proven by differentiating the relation $g(f(x)) = x$."},{id:4,type:"multiple-choice",question:"The derivative of the inverse function $g = f^{-1}$ satisfies:",options:["$g'(y) = -f'(g(y))$","$g'(y) = [f'(y)]^{-1}$","$g'(y) = [f'(g(y))]^{-1}$","$g'(y) = f'(g(y))^T$"],correctIndex:2,difficulty:"hard",explanation:"By the chain rule applied to $g(f(x)) = x$, we get $g'(f(x)) f'(x) = I$, so $g'(y) = [f'(g(y))]^{-1}$ where $y = f(x)$."},{id:5,type:"multiple-choice",question:"The proof of the Inverse Function Theorem uses:",options:["The Bolzano-Weierstrass Theorem","The Contraction Mapping Principle","Rolle's Theorem","The Intermediate Value Theorem"],correctIndex:1,difficulty:"medium",explanation:"The standard proof constructs the inverse using fixed point iteration. For each $y$ near $f(a)$, the equation $f(x) = y$ is reformulated as finding a fixed point of a contraction."}],le=[{id:1,type:"multiple-choice",question:"The Implicit Function Theorem considers an equation $F(x,y) = 0$ where $F: \\mathbb{R}^{n+m} \\to \\mathbb{R}^m$. The key hypothesis is:",options:["The partial derivative $\\frac{\\partial F}{\\partial y}$ is invertible at the point","The partial derivative $\\frac{\\partial F}{\\partial x}$ is invertible at the point","$F$ is a linear function","Both partial derivatives are zero"],correctIndex:0,difficulty:"medium",explanation:"The Implicit Function Theorem requires that $\\frac{\\partial F}{\\partial y}$, the $m \\times m$ matrix of partial derivatives with respect to $y$, be invertible. This allows solving for $y$ as a function of $x$."},{id:2,type:"multiple-choice",question:"If $F(a,b) = 0$ and the hypotheses of the Implicit Function Theorem hold, then:",options:["There exists a unique $C^1$ function $g$ with $g(a) = b$ and $F(x, g(x)) = 0$ near $a$","There exists a global function $g$ with $F(x, g(x)) = 0$ for all $x$","$F$ can be written as a product of functions of $x$ and $y$ separately","The level set $F^{-1}(0)$ is a linear subspace"],correctIndex:0,difficulty:"medium",explanation:"The theorem guarantees local existence and uniqueness of a function $g$ such that $F(x, g(x)) = 0$ in a neighborhood of $a$, with $g$ having the same smoothness as $F$."},{id:3,type:"multiple-choice",question:"The derivative of the implicitly defined function $g$ in $F(x,g(x)) = 0$ is:",options:["$g'(x) = -\\frac{\\partial F}{\\partial x} / \\frac{\\partial F}{\\partial y}$","$g'(x) = -\\left(\\frac{\\partial F}{\\partial y}\\right)^{-1} \\frac{\\partial F}{\\partial x}$","$g'(x) = \\frac{\\partial F}{\\partial y} / \\frac{\\partial F}{\\partial x}$","$g'(x) = -\\frac{\\partial F}{\\partial y}$"],correctIndex:1,difficulty:"hard",explanation:"Differentiating $F(x, g(x)) = 0$ gives $\\frac{\\partial F}{\\partial x} + \\frac{\\partial F}{\\partial y} g'(x) = 0$, so $g'(x) = -\\left(\\frac{\\partial F}{\\partial y}\\right)^{-1} \\frac{\\partial F}{\\partial x}$."},{id:4,type:"multiple-choice",question:"The Implicit Function Theorem is proved using:",options:["The Intermediate Value Theorem","The Extreme Value Theorem","The Inverse Function Theorem","The Mean Value Theorem"],correctIndex:2,difficulty:"medium",explanation:"The Implicit Function Theorem is typically derived from the Inverse Function Theorem by considering the map $(x,y) \\mapsto (x, F(x,y))$ and applying the Inverse Function Theorem."},{id:5,type:"multiple-choice",question:"For $F: \\mathbb{R}^2 \\to \\mathbb{R}$ with $F(a,b) = 0$ and $\\frac{\\partial F}{\\partial y}(a,b) \\neq 0$, the level curve $F(x,y) = 0$ near $(a,b)$:",options:["Cannot be parameterized","Is a straight line","Is the graph of a $C^1$ function $y = g(x)$","Is a circle"],correctIndex:2,difficulty:"easy",explanation:"When $\\frac{\\partial F}{\\partial y} \\neq 0$, the implicit function theorem guarantees the level curve is locally the graph of a smooth function $y = g(x)$."}],fe=[{id:1,type:"multiple-choice",question:"The rank of a linear transformation $A: \\mathbb{R}^n \\to \\mathbb{R}^m$ is:",options:["The number of nonzero entries in the matrix","The dimension of the null space of $A$","Always equal to $\\min(m,n)$","The dimension of the range (image) of $A$"],correctIndex:3,difficulty:"easy",explanation:"The rank is the dimension of the image (range) of the linear map. By the rank-nullity theorem, rank$(A)$ + nullity$(A) = n$."},{id:2,type:"multiple-choice",question:"The Rank Theorem states that if $f$ has constant rank $r$ near $a$, then locally $f$ is equivalent to:",options:["A rotation","A linear map of rank $r$","The identity map","The projection $(x_1, \\ldots, x_n) \\mapsto (x_1, \\ldots, x_r, 0, \\ldots, 0)$"],correctIndex:3,difficulty:"hard",explanation:"The Rank Theorem says that near a point where $f$ has constant rank $r$, there exist coordinate changes making $f$ look like the standard projection onto the first $r$ coordinates."},{id:3,type:"multiple-choice",question:"If $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ is $C^1$ and $f'(a)$ has rank $r$, then the rank of $f'(x)$ for $x$ near $a$:",options:["Is at most $r$","Can be any value between 0 and $\\min(m,n)$","Is at least $r$","Is exactly $r$"],correctIndex:2,difficulty:"medium",explanation:"Rank is lower semicontinuous: if $f'(a)$ has rank $r$, then $f'(x)$ has rank $\\geq r$ for $x$ sufficiently close to $a$. The rank can increase but not decrease nearby."},{id:4,type:"multiple-choice",question:"A $C^1$ map $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ is a submersion at $a$ if:",options:["$f'(a) = 0$","$f'(a)$ is surjective (has rank $m$)","$f'(a)$ is an isomorphism","$f'(a)$ is injective (has rank $n$)"],correctIndex:1,difficulty:"medium",explanation:"A submersion has surjective derivative (rank $m$). An immersion has injective derivative (rank $n$). When $m = n$ and the derivative is bijective, $f$ is a local diffeomorphism."},{id:5,type:"multiple-choice",question:"If $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ is a submersion at $a$ with $f(a) = c$, then $f^{-1}(c)$ near $a$ is:",options:["A single point","A smooth manifold of dimension $n - m$","A smooth manifold of dimension $m$","An open set"],correctIndex:1,difficulty:"hard",explanation:"The preimage theorem states that if $f$ is a submersion at all points of $f^{-1}(c)$, then $f^{-1}(c)$ is a smooth manifold of dimension $n - m$ (the codimension of the image)."}],ue=[{id:1,type:"multiple-choice",question:"The determinant of a linear transformation $A: \\mathbb{R}^n \\to \\mathbb{R}^n$ can be characterized as:",options:["The product of all entries","The signed ratio of volumes: $\\det(A) = \\text{vol}(A(E)) / \\text{vol}(E)$ for any region $E$","The largest eigenvalue","The sum of the diagonal entries"],correctIndex:1,difficulty:"medium",explanation:"The determinant measures how $A$ scales volumes (with sign indicating orientation). If $E$ is a region with volume $V$, then $A(E)$ has volume $|\\det(A)| \\cdot V$."},{id:2,type:"multiple-choice",question:"The determinant function $\\det: M_n(\\mathbb{R}) \\to \\mathbb{R}$ is:",options:["Linear in the matrix entries","Always positive","Continuous but not differentiable","Multilinear and alternating in the rows (or columns)"],correctIndex:3,difficulty:"medium",explanation:"The determinant is the unique function that is multilinear (linear in each row), alternating (changes sign when rows are swapped), and satisfies $\\det(I) = 1$."},{id:3,type:"multiple-choice",question:"For matrices $A$ and $B$ in $M_n(\\mathbb{R})$, $\\det(AB) = $:",options:["$\\det(A) + \\det(B)$","$\\det(A) / \\det(B)$","$\\det(A + B)$","$\\det(A) \\det(B)$"],correctIndex:3,difficulty:"easy",explanation:"The determinant is multiplicative: $\\det(AB) = \\det(A)\\det(B)$. This reflects the fact that composing transformations multiplies their volume scaling factors."},{id:4,type:"multiple-choice",question:"A matrix $A$ is invertible if and only if:",options:["$\\det(A) \\neq 0$","$\\det(A) = 1$","$\\det(A) = \\det(A^T)$","$\\det(A) > 0$"],correctIndex:0,difficulty:"easy",explanation:"A matrix is invertible iff its determinant is nonzero. When $\\det(A) \\neq 0$, the inverse satisfies $\\det(A^{-1}) = 1/\\det(A)$."},{id:5,type:"multiple-choice",question:"For an $n \\times n$ matrix with columns $a_1, \\ldots, a_n$, $|\\det(A)|$ equals:",options:["The area of the triangle with vertices $a_1, \\ldots, a_n$","The product $|a_1| \\cdots |a_n|$","The sum of the lengths $|a_1| + \\cdots + |a_n|$","The $n$-dimensional volume of the parallelepiped spanned by $a_1, \\ldots, a_n$"],correctIndex:3,difficulty:"medium",explanation:"The absolute value of the determinant gives the volume of the parallelepiped whose edges are the column vectors. The sign indicates orientation."}],de=[{id:1,type:"multiple-choice",question:"For a $C^2$ function $f: \\mathbb{R}^n \\to \\mathbb{R}$, the second partial derivatives satisfy:",options:["$\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} + \\frac{\\partial^2 f}{\\partial x_j \\partial x_i} = 0$","The mixed partials are always positive","$\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} = \\frac{\\partial^2 f}{\\partial x_j \\partial x_i}$ (Clairaut's theorem)","$\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} = 0$ when $i \\neq j$"],correctIndex:2,difficulty:"easy",explanation:"Clairaut's theorem (symmetry of second derivatives) states that if the mixed partial derivatives are continuous, they are equal: $f_{xy} = f_{yx}$."},{id:2,type:"multiple-choice",question:"The Hessian matrix of $f: \\mathbb{R}^n \\to \\mathbb{R}$ at a point is:",options:["The $n \\times n$ matrix of all second partial derivatives","The Jacobian matrix","The determinant of the matrix of first derivatives","The gradient vector"],correctIndex:0,difficulty:"easy",explanation:"The Hessian $H_f$ is the $n \\times n$ symmetric matrix with entries $(H_f)_{ij} = \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}$. It represents the second derivative as a bilinear form."},{id:3,type:"multiple-choice",question:"If $f$ is $C^2$ and has a local minimum at $a$ with $\\nabla f(a) = 0$, then the Hessian $H_f(a)$ is:",options:["Negative definite","Positive semidefinite","Indefinite","Positive definite"],correctIndex:1,difficulty:"medium",explanation:"At a local minimum, the Hessian must be positive semidefinite. If the Hessian is positive definite, it guarantees a strict local minimum (sufficient condition)."},{id:4,type:"multiple-choice",question:"Taylor's theorem for $f: \\mathbb{R}^n \\to \\mathbb{R}$ of class $C^2$ gives:",options:["$f(a+h) = \\sum_{n=0}^\\infty \\frac{f^{(n)}(a)}{n!} h^n$","$f(a+h) = f(a) + \\nabla f(a) \\cdot h$","$f(a+h) = f(a) + f'(a)h + f''(a)h^2$","$f(a+h) = f(a) + \\nabla f(a) \\cdot h + \\frac{1}{2} h^T H_f(a) h + o(|h|^2)$"],correctIndex:3,difficulty:"hard",explanation:"The second-order Taylor expansion involves the gradient (first-order term) and the Hessian quadratic form (second-order term), with error $o(|h|^2)$."},{id:5,type:"multiple-choice",question:"A $C^k$ function $f$ has the property that all partial derivatives up to order $k$:",options:["Exist but may be discontinuous","Exist and are continuous","Are zero","Are constant"],correctIndex:1,difficulty:"easy",explanation:"$C^k$ means continuously differentiable $k$ times: all partial derivatives up to order $k$ exist and are continuous. $C^\\infty$ means smooth (infinitely differentiable)."}],he=[{id:1,type:"multiple-choice",question:"For $F(x) = \\int_a^x f(t) \\, dt$ where $f$ is continuous, $F'(x) = $:",options:["$f(x) - f(a)$","$f(x)$","$\\int_a^x f'(t) \\, dt$","$f(a)$"],correctIndex:1,difficulty:"easy",explanation:"This is the First Fundamental Theorem of Calculus: differentiating an integral with respect to its upper limit gives back the integrand."},{id:2,type:"multiple-choice",question:"For $G(x) = \\int_a^{g(x)} f(t) \\, dt$ where $f$ and $g$ are $C^1$, $G'(x) = $:",options:["$f(g(x))$","$f(g(x)) \\cdot g'(x)$","$\\int_a^{g(x)} f'(t) \\, dt$","$f'(g(x)) \\cdot g'(x)$"],correctIndex:1,difficulty:"medium",explanation:"By the chain rule combined with the Fundamental Theorem: $G'(x) = f(g(x)) \\cdot g'(x)$. This is Leibniz's rule for differentiation under the integral sign."},{id:3,type:"multiple-choice",question:"If $F(x) = \\int_{a(x)}^{b(x)} f(t) \\, dt$, then $F'(x) = $:",options:["$b'(x) - a'(x)$","$f(b(x)) - f(a(x))$","$\\int_{a(x)}^{b(x)} f'(t) \\, dt$","$f(b(x)) b'(x) - f(a(x)) a'(x)$"],correctIndex:3,difficulty:"medium",explanation:"When both limits depend on $x$, we get contributions from both: $F'(x) = f(b(x))b'(x) - f(a(x))a'(x)$ by applying the chain rule to each limit."},{id:4,type:"multiple-choice",question:"For $\\Phi(x) = \\int_a^b f(x,t) \\, dt$, the Leibniz integral rule states $\\Phi'(x) = $:",options:["$f(x,b) - f(x,a)$","$\\int_a^b \\frac{\\partial f}{\\partial x}(x,t) \\, dt$ (under suitable conditions)","$\\frac{\\partial}{\\ partial t} \\int_a^b f(x,t) \\, dt$","$\\int_a^b f(x,t) \\, dt$"],correctIndex:1,difficulty:"hard",explanation:"Leibniz integral rule: when $f$ and $\\partial f/\\partial x$ are continuous, differentiation and integration commute: $\\frac{d}{dx}\\int_a^b f(x,t)dt = \\int_a^b \\frac{\\partial f}{\\partial x}(x,t)dt$."},{id:5,type:"multiple-choice",question:"The conditions for differentiating under the integral sign (Leibniz rule) require:",options:["That the integral converges absolutely","That $f$ be independent of $x$","Only that $f(x,t)$ be integrable","$f(x,t)$ continuous and $\\frac{\\partial f}{\\partial x}$ continuous on the domain"],correctIndex:3,difficulty:"medium",explanation:"For finite intervals, continuity of $f$ and $\\partial f/\\partial x$ suffices. For improper integrals, additional uniform convergence conditions are needed."}],me=[{id:1,type:"multiple-choice",question:"A $k$-cell in $\\mathbb{R}^n$ is:",options:["A product of $k$ closed intervals $[a_i, b_i]$","A $k$-dimensional linear subspace","A sphere of dimension $k$","Any bounded subset of $\\mathbb{R}^k$"],correctIndex:0,difficulty:"easy",explanation:'A $k$-cell is a "box" in $\\mathbb{R}^k$: the Cartesian product $[a_1,b_1] \\times \\cdots \\times [a_k, b_k]$ of closed intervals.'},{id:2,type:"multiple-choice",question:"The integral of a continuous function $f$ over a $k$-cell is defined using:",options:["Contour integration","Measure theory and Lebesgue integration","The Fundamental Theorem of Calculus directly","Partitions and Riemann sums, taking limits as the mesh goes to zero"],correctIndex:3,difficulty:"medium",explanation:"The Riemann integral over a $k$-cell uses partitions of the cell into sub-cells, forming Riemann sums, and taking limits as the partition becomes finer."},{id:3,type:"multiple-choice",question:"Fubini's theorem states that for continuous $f$ on $[a,b] \\times [c,d]$:",options:["$\\int\\int f(x,y) \\, dA = \\int_a^b \\left(\\int_c^d f(x,y) \\, dy\\right) dx = \\int_c^d \\left(\\int_a^b f(x,y) \\, dx\\right) dy$","The integral depends on the path of integration","The order of integration cannot be changed","The double integral equals zero"],correctIndex:0,difficulty:"medium",explanation:"Fubini's theorem allows computing double integrals as iterated single integrals, and the order of integration can be exchanged for continuous functions."},{id:4,type:"multiple-choice",question:"A function $f$ on a rectangle is Riemann integrable if and only if:",options:["$f$ is bounded","$f$ is continuous everywhere","The set of discontinuities of $f$ has measure zero","$f$ is monotonic"],correctIndex:2,difficulty:"hard",explanation:"The Lebesgue criterion: a bounded function is Riemann integrable iff its set of discontinuities has measure zero. Continuous functions and monotone functions satisfy this."},{id:5,type:"multiple-choice",question:"For integration over more general sets, we typically:",options:["Use polar coordinates exclusively","Extend $f$ to be zero outside the set and integrate over a containing cell","Require the set to be open","Only consider convex sets"],correctIndex:1,difficulty:"medium",explanation:'To integrate over a region $E \\subset I$ (where $I$ is a cell), we extend $f$ by zero outside $E$ and integrate over $I$. This works when $E$ has a "nice" boundary.'}],pe=[{id:1,type:"multiple-choice",question:"A primitive mapping is a $C^1$ map $G: \\mathbb{R}^n \\to \\mathbb{R}^n$ of the form:",options:["Any bijective map","A map whose Jacobian is constant","A linear map with determinant 1","$G(x) = (x_1, \\ldots, x_{m-1}, g(x), x_{m+1}, \\ldots, x_n)$ for some index $m$ and function $g$"],correctIndex:3,difficulty:"hard",explanation:"A primitive mapping changes only one coordinate, replacing $x_m$ with a function $g(x)$ of all variables. The other coordinates are unchanged."},{id:2,type:"multiple-choice",question:"The Jacobian determinant of a primitive mapping $G(x) = (x_1, \\ldots, g(x), \\ldots, x_n)$ is:",options:["$1$","$\\frac{\\partial g}{\\partial x_m}$","$\\det(DG)$ where $DG$ is the full Jacobian matrix","$g(x)$"],correctIndex:1,difficulty:"medium",explanation:"For a primitive mapping changing coordinate $m$, the Jacobian matrix is nearly the identity, with the $m$-th row being the gradient of $g$. The determinant is $\\partial g/\\partial x_m$."},{id:3,type:"multiple-choice",question:"Any $C^1$ diffeomorphism can locally be written as:",options:["A rotation followed by a translation","A composition of primitive mappings","A linear transformation","A single primitive mapping"],correctIndex:1,difficulty:"hard",explanation:"This is a key structural result: any sufficiently smooth diffeomorphism can be decomposed into a composition of primitive mappings, each changing only one coordinate."},{id:4,type:"multiple-choice",question:"The significance of primitive mappings in integration theory is:",options:["They preserve volume","They commute with all other maps","They are the only maps for which the Jacobian can be computed","They simplify the proof of the change of variables formula"],correctIndex:3,difficulty:"medium",explanation:"Primitive mappings are useful because the change of variables formula is easy to verify for them, and general diffeomorphisms decompose into primitive ones."},{id:5,type:"multiple-choice",question:"If $G$ is a primitive mapping with $\\frac{\\partial g}{\\partial x_m} > 0$, then $G$ is:",options:["A contraction","Volume-preserving","Always a global diffeomorphism","Locally a diffeomorphism (orientation-preserving)"],correctIndex:3,difficulty:"medium",explanation:"When $\\partial g/\\partial x_m > 0$, the Jacobian determinant is positive, so $G$ is locally invertible and orientation-preserving. It may not be global."}],ye=[{id:1,type:"multiple-choice",question:"A partition of unity subordinate to an open cover $\\{U_\\alpha\\}$ of a set $K$ is:",options:["A single function that equals 1 on $K$","A collection of functions $\\{\\psi_i\\}$ with $\\sum \\psi_i = 1$, each supported in some $U_\\alpha$","A collection of characteristic functions","A division of $K$ into disjoint pieces"],correctIndex:1,difficulty:"medium",explanation:"A partition of unity is a collection of non-negative smooth functions that sum to 1, with each function's support contained in one of the open sets of the cover."},{id:2,type:"multiple-choice",question:"Partitions of unity exist for any open cover of a compact set $K$ in $\\mathbb{R}^n$ because:",options:["The cover has only finitely many sets","$K$ is finite","$\\mathbb{R}^n$ is paracompact and smooth bump functions exist","Continuous functions can always be constructed"],correctIndex:2,difficulty:"hard",explanation:"The existence relies on paracompactness (every open cover has a locally finite refinement) and the existence of smooth bump functions in $\\mathbb{R}^n$."},{id:3,type:"multiple-choice",question:"A key property required of each function $\\psi_i$ in a smooth partition of unity is:",options:["$\\psi_i \\geq 0$ and $\\psi_i \\in C^\\infty$","$\\psi_i$ is linear","$\\psi_i$ has compact support equal to $K$","$\\psi_i$ takes only values 0 and 1"],correctIndex:0,difficulty:"easy",explanation:"Each $\\psi_i$ must be non-negative, smooth, and have compact support contained in one of the open sets. The functions sum to 1."},{id:4,type:"multiple-choice",question:"Partitions of unity are used in analysis to:",options:["Define the Riemann integral","Localize problems and patch together local solutions","Construct polynomial approximations","Prove the Mean Value Theorem"],correctIndex:1,difficulty:"medium",explanation:"Partitions of unity allow breaking a global problem into local pieces, solving locally, and combining solutions. They are essential in differential geometry and PDE theory."},{id:5,type:"multiple-choice",question:"If $\\{\\psi_1, \\ldots, \\psi_N\\}$ is a partition of unity and $f$ is continuous on $K$, then:",options:["$\\int_K f = \\sum_i \\int_K \\psi_i$","$f = \\max_i \\psi_i f$","$f$ must be smooth","$f = \\sum_{i=1}^N \\psi_i f$ on $K$"],correctIndex:3,difficulty:"easy",explanation:"Since $\\sum \\psi_i = 1$, we have $f = f \\cdot 1 = f \\cdot \\sum \\psi_i = \\sum \\psi_i f$. This decomposes $f$ into pieces supported in each open set."}],xe=[{id:1,type:"multiple-choice",question:"The change of variables formula states that if $T: U \\to V$ is a $C^1$ diffeomorphism, then:",options:["$\\int_V f(y) \\, dy = \\int_U f(T(x)) \\, dx$","$\\int_V f(y) \\, dy = \\int_U f(T(x)) \\det T'(x) \\, dx$","$\\int_V f(y) \\, dy = \\int_U f(T(x)) |\\det T'(x)| \\, dx$","$\\int_V f(y) \\, dy = \\int_U f(x) |\\det T'(x)| \\, dx$"],correctIndex:2,difficulty:"medium",explanation:"The change of variables formula requires the absolute value of the Jacobian determinant as the volume scaling factor. This accounts for the change in the volume element."},{id:2,type:"multiple-choice",question:"In polar coordinates $(r, \\theta)$, the Jacobian determinant is:",options:["$r^2$","$2\\pi r$","$r$","$1$"],correctIndex:2,difficulty:"easy",explanation:"For $(x,y) = (r\\cos\\theta, r\\sin\\theta)$, the Jacobian is $\\begin{vmatrix} \\cos\\theta & -r\\sin\\theta \\\\ \\sin\\theta & r\\cos\\theta \\end{vmatrix} = r$. So $dx\\,dy = r\\,dr\\,d\\theta$."},{id:3,type:"multiple-choice",question:"In spherical coordinates $(\\rho, \\phi, \\theta)$ where $x = \\rho\\sin\\phi\\cos\\theta$, the volume element is:",options:["$\\rho \\sin\\phi \\, d\\rho \\, d\\phi \\, d\\theta$","$d\\rho \\, d\\phi \\, d\\theta$","$\\rho^2 \\sin\\phi \\, d\\rho \\, d\\phi \\, d\\theta$","$\\rho^2 \\, d\\rho \\, d\\phi \\, d\\theta$"],correctIndex:2,difficulty:"medium",explanation:"The Jacobian for spherical coordinates is $\\rho^2 \\sin\\phi$, giving the volume element $dV = \\rho^2 \\sin\\phi \\, d\\rho \\, d\\phi \\, d\\theta$."},{id:4,type:"multiple-choice",question:"The change of variables formula requires $T$ to be:",options:["Any continuous function","A $C^1$ diffeomorphism (bijective with $C^1$ inverse)","A linear transformation","Measure-preserving"],correctIndex:1,difficulty:"medium",explanation:"The formula requires $T$ to be a $C^1$ diffeomorphism so that the Jacobian is well-defined and nonzero, and the inverse mapping exists."},{id:5,type:"multiple-choice",question:"The Jacobian determinant $|\\det T'(x)|$ represents:",options:["The local volume magnification factor of the transformation","The derivative of the volume function","The speed of the transformation","The curvature of the transformation"],correctIndex:0,difficulty:"easy",explanation:"The Jacobian determinant measures how infinitesimal volumes are scaled by the transformation. A small region of volume $dV$ maps to a region of volume approximately $|\\det T'| dV$."}],be=[{id:1,type:"multiple-choice",question:"A differential $k$-form on $\\mathbb{R}^n$ is:",options:["A polynomial of degree $k$","An alternating multilinear function of $k$ vectors that varies smoothly over points","A vector field with $k$ components","A $k$-times differentiable function"],correctIndex:1,difficulty:"medium",explanation:"A $k$-form assigns to each point an alternating multilinear function on $k$ tangent vectors. It can be written as a sum of terms like $f(x) dx_{i_1} \\wedge \\cdots \\wedge dx_{i_k}$."},{id:2,type:"multiple-choice",question:"The wedge product $\\omega \\wedge \\eta$ of a $k$-form and an $\\ell$-form is:",options:["A $(k \\cdot \\ell)$-form","A $(k+\\ell)$-form satisfying $\\omega \\wedge \\eta = (-1)^{k\\ell} \\eta \\wedge \\omega$","Always zero","A $(k-\\ell)$-form"],correctIndex:1,difficulty:"medium",explanation:"The wedge product combines forms, increasing the degree. It is associative and graded-commutative: swapping forms introduces a sign $(-1)^{k\\ell}$."},{id:3,type:"multiple-choice",question:"The exterior derivative $d$ of a $k$-form is:",options:["Always zero for $k > 0$","A $k$-form","A $(k-1)$-form","A $(k+1)$-form, and $d^2 = 0$"],correctIndex:3,difficulty:"medium",explanation:"The exterior derivative $d$ increases degree by 1 and satisfies $d(d\\omega) = 0$ for any form $\\omega$. This is analogous to $\\text{curl}(\\text{grad}) = 0$ in vector calculus."},{id:4,type:"multiple-choice",question:"For $f$ a 0-form (smooth function), $df = $:",options:["$\\nabla f$","$\\Delta f$","$f' dx$","$\\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i} dx_i$"],correctIndex:3,difficulty:"easy",explanation:"The exterior derivative of a function is the 1-form $df = \\sum \\frac{\\partial f}{\\partial x_i} dx_i$. This corresponds to the gradient, but as a 1-form rather than a vector."},{id:5,type:"multiple-choice",question:"In $\\mathbb{R}^3$, the 2-form $dx \\wedge dy$ represents:",options:["The function $xy$","A curve in the $xy$-plane","An oriented area element in the $xy$-plane","The vector $\\hat{k}$"],correctIndex:2,difficulty:"medium",explanation:"$dx \\wedge dy$ is the standard area 2-form for the $xy$-plane. Integrating a 2-form over a surface gives a signed area or flux."}],ge=[{id:1,type:"multiple-choice",question:"A $k$-simplex in $\\mathbb{R}^n$ is:",options:["Any $k$-dimensional submanifold","A sphere of dimension $k$","The convex hull of $k+1$ affinely independent points","A $k$-dimensional cube"],correctIndex:2,difficulty:"medium",explanation:"A $k$-simplex is the convex hull of $k+1$ points in general position: a 0-simplex is a point, 1-simplex is a line segment, 2-simplex is a triangle, 3-simplex is a tetrahedron."},{id:2,type:"multiple-choice",question:"The standard $k$-simplex $\\sigma_k$ in $\\mathbb{R}^k$ is:",options:["The unit ball in $\\mathbb{R}^k$","The unit cube $[0,1]^k$","$\\{(t_1, \\ldots, t_k) : t_i \\geq 0, \\sum t_i \\leq 1\\}$","$\\{(t_1, \\ldots, t_k) : \\sum t_i = 1\\}$"],correctIndex:2,difficulty:"medium",explanation:"The standard $k$-simplex has vertices at the origin and the $k$ standard basis vectors. It is the set of points with non-negative coordinates summing to at most 1."},{id:3,type:"multiple-choice",question:"A $k$-chain is:",options:["A sequence of $k$ connected simplices","A formal linear combination of $k$-simplices with integer coefficients","A single simplex with orientation","A $k$-dimensional manifold"],correctIndex:1,difficulty:"medium",explanation:"Chains are formal sums $\\sum n_i \\sigma_i$ where $\\sigma_i$ are singular simplices and $n_i$ are integers. They form a group under addition."},{id:4,type:"multiple-choice",question:"The boundary operator $\\partial$ on a $k$-simplex produces:",options:["A $(k+1)$-chain","A $(k-1)$-chain consisting of the faces with alternating signs","Zero","A single $(k-1)$-simplex"],correctIndex:1,difficulty:"hard",explanation:"The boundary of a $k$-simplex is the alternating sum of its $(k-1)$-dimensional faces: $\\partial[p_0, \\ldots, p_k] = \\sum_i (-1)^i [p_0, \\ldots, \\hat{p}_i, \\ldots, p_k]$."},{id:5,type:"multiple-choice",question:"A fundamental property of the boundary operator is:",options:["$\\partial$ commutes with all linear maps","$\\partial^2 = \\text{id}$","$\\partial$ is injective","$\\partial^2 = 0$ (the boundary of a boundary is zero)"],correctIndex:3,difficulty:"easy",explanation:"The identity $\\partial \\partial = 0$ is fundamental to algebraic topology. It means cycles (chains with zero boundary) contain all boundaries, enabling homology theory."}],ve=[{id:1,type:"multiple-choice",question:"Stokes' theorem in its general form states that for a $k$-form $\\omega$ and $(k+1)$-chain $c$:",options:["$\\int_c d\\omega = d\\int_{\\partial c} \\omega$","$\\int_c d\\omega = \\int_{\\partial c} \\omega$","$\\int_c \\omega = \\int_{\\partial c} d\\omega$","$d\\int_c \\omega = \\int_{\\partial c} \\omega$"],correctIndex:1,difficulty:"medium",explanation:"Stokes' theorem equates the integral of $d\\omega$ over a chain to the integral of $\\omega$ over its boundary. This unifies many classical theorems."},{id:2,type:"multiple-choice",question:"The Fundamental Theorem of Calculus $\\int_a^b f'(x) dx = f(b) - f(a)$ is a special case of Stokes' theorem when:",options:["Applied to a closed curve","Applied to a 2-dimensional surface","$\\omega = f$ is a 0-form on a 1-chain (interval)","$\\omega = f dx$ is a 1-form"],correctIndex:2,difficulty:"medium",explanation:"For a 0-form (function) $f$, $df = f' dx$. The boundary of $[a,b]$ is $\\{b\\} - \\{a\\}$ with orientations. Stokes gives $\\int_a^b df = f(b) - f(a)$."},{id:3,type:"multiple-choice",question:"Green's theorem (relating a line integral to a double integral) is Stokes' theorem in:",options:["Dimension 1","Dimension 2, with a 1-form on a 2-chain (region)","Dimension 3, with a 2-form","Dimension 4"],correctIndex:1,difficulty:"medium",explanation:"Green's theorem is Stokes' theorem for 1-forms in $\\mathbb{R}^2$: $\\oint_{\\partial R} P\\,dx + Q\\,dy = \\iint_R (Q_x - P_y) dA$."},{id:4,type:"multiple-choice",question:"The classical divergence theorem (Gauss) is Stokes' theorem applied to:",options:["A 3-form on a 4-chain","A 2-form on a 3-chain (solid region) in $\\mathbb{R}^3$","A 1-form on a 2-chain in $\\mathbb{R}^3$","A 0-form on a 1-chain"],correctIndex:1,difficulty:"hard",explanation:"The divergence theorem $\\iiint_V \\nabla \\cdot F\\, dV = \\iint_{\\partial V} F \\cdot n\\, dS$ is Stokes' theorem for the 2-form associated to the vector field $F$."},{id:5,type:"multiple-choice",question:"If $\\omega$ is a closed form ($d\\omega = 0$) and $c$ is a cycle ($\\partial c = 0$), then:",options:["$\\int_c \\omega$ depends only on the homology class of $c$","$\\int_c \\omega = 1$","$\\omega$ must be exact","$\\int_c \\omega = 0$"],correctIndex:0,difficulty:"hard",explanation:"For closed forms, $\\int_c \\omega$ is unchanged if $c$ is replaced by a homologous cycle. This is because $\\int_{c+\\partial b} \\omega = \\int_c \\omega + \\int_{\\partial b} \\omega = \\int_c \\omega + \\int_b d\\omega = \\int_c \\omega$."}],_e=[{id:1,type:"multiple-choice",question:"A differential form $\\omega$ is called closed if:",options:["$d\\omega = 0$","$\\int_c \\omega = 0$ for all cycles $c$","$\\omega$ has compact support","$\\omega = df$ for some function $f$"],correctIndex:0,difficulty:"easy",explanation:"A form is closed if its exterior derivative vanishes: $d\\omega = 0$. This is a local condition analogous to a vector field being curl-free."},{id:2,type:"multiple-choice",question:"A differential form $\\omega$ is called exact if:",options:["$d\\omega = 0$","$\\omega = d\\eta$ for some form $\\eta$","$\\omega$ is a polynomial in the coordinate differentials","$\\omega$ integrates to zero over any closed curve"],correctIndex:1,difficulty:"easy",explanation:"A form is exact if it is the exterior derivative of another form: $\\omega = d\\eta$. Exact forms are analogous to conservative vector fields."},{id:3,type:"multiple-choice",question:"Every exact form is closed because:",options:["Closed forms have compact support","Exactness implies smoothness","The integral over boundaries vanishes","$d^2 = 0$, so $d(d\\eta) = 0$"],correctIndex:3,difficulty:"easy",explanation:"If $\\omega = d\\eta$, then $d\\omega = d(d\\eta) = 0$ by the fundamental property $d^2 = 0$. So every exact form is automatically closed."},{id:4,type:"multiple-choice",question:"The Poincaré lemma states that on a contractible domain:",options:["Every exact form is closed","No form is exact","Every closed form is exact","Every form is closed"],correctIndex:2,difficulty:"medium",explanation:'The Poincaré lemma says that on contractible (star-shaped) domains, closed = exact. This fails on domains with "holes," like $\\mathbb{R}^2 \\setminus \\{0\\}$.'},{id:5,type:"multiple-choice",question:"The 1-form $\\omega = \\frac{-y\\,dx + x\\,dy}{x^2 + y^2}$ on $\\mathbb{R}^2 \\setminus \\{0\\}$ is:",options:["Closed but not exact","Exact","Not defined","Neither closed nor exact"],correctIndex:0,difficulty:"hard",explanation:"This form equals $d\\theta$ locally (where $\\theta = \\arctan(y/x)$), so it is closed. But $\\int_{\\text{circle}} \\omega = 2\\pi \\neq 0$, so it is not exact on the punctured plane."}],qe=[{id:1,type:"multiple-choice",question:"The gradient of a scalar field $f$ in vector calculus corresponds to:",options:["The divergence of $f$","A 2-form","The exterior derivative $df$ (a 1-form)","The Laplacian $\\Delta f$"],correctIndex:2,difficulty:"easy",explanation:"The gradient $\\nabla f$ corresponds to the 1-form $df = \\sum \\frac{\\partial f}{\\partial x_i} dx_i$. The vector field is obtained using the metric."},{id:2,type:"multiple-choice",question:"In $\\mathbb{R}^3$, the curl of a vector field $F$ corresponds to:",options:["The divergence of $F$","The Laplacian of $F$","The exterior derivative of the 1-form associated to $F$, converted back to a vector","The gradient of a scalar"],correctIndex:2,difficulty:"medium",explanation:"If $\\omega_F$ is the 1-form for $F$, then $d\\omega_F$ is a 2-form. Using the Hodge star in $\\mathbb{R}^3$, this converts to a 1-form, giving curl $F$."},{id:3,type:"multiple-choice",question:"The divergence of a vector field $F$ in $\\mathbb{R}^3$ corresponds to:",options:["The exterior derivative of the 1-form $\\omega_F$","The curl of another field","A 0-form directly","The exterior derivative of the 2-form $*\\omega_F$, yielding a 3-form proportional to $\\text{div}(F)\\,dV$"],correctIndex:3,difficulty:"hard",explanation:"Divergence is captured by taking $d$ of the 2-form associated to $F$ via the Hodge star. The result is a 3-form $\\text{div}(F) dx \\wedge dy \\wedge dz$."},{id:4,type:"multiple-choice",question:"The identity $\\text{curl}(\\nabla f) = 0$ corresponds to:",options:["Green's theorem","$d(df) = 0$ (since $d^2 = 0$)","The mean value theorem","The divergence theorem"],correctIndex:1,difficulty:"easy",explanation:"The curl of a gradient is zero because the curl corresponds to $d$ of a 1-form, and $df$ is already the $d$ of the 0-form $f$. So $d(df) = d^2 f = 0$."},{id:5,type:"multiple-choice",question:"The identity $\\text{div}(\\text{curl } F) = 0$ corresponds to:",options:["The product rule","$d^2 = 0$ applied to the 1-form of $F$","Stokes' theorem","Conservation of mass"],correctIndex:1,difficulty:"medium",explanation:"Div of curl corresponds to applying $d$ twice (in the appropriate form language), which gives zero by $d^2 = 0$."}],Te=[{id:1,type:"multiple-choice",question:"A set function $\\phi$ on a ring of sets $\\mathcal{R}$ is additive if:",options:["$\\phi(A) \\leq \\phi(B)$ when $A \\subset B$","$\\phi(A \\cup B) = \\phi(A) + \\phi(B)$ for all $A, B$","$\\phi(A \\cap B) = \\phi(A)\\phi(B)$","$\\phi(A \\cup B) = \\phi(A) + \\phi(B)$ when $A$ and $B$ are disjoint"],correctIndex:3,difficulty:"easy",explanation:"Additivity (or finite additivity) means the measure of a disjoint union equals the sum of measures. This extends to finite disjoint unions by induction."},{id:2,type:"multiple-choice",question:"A set function is countably additive (or $\\sigma$-additive) if:",options:["$\\phi(\\emptyset) = 0$","$\\phi(\\bigcup_{n=1}^\\infty A_n) = \\sum_{n=1}^\\infty \\phi(A_n)$ for pairwise disjoint $A_n$","$\\phi(A) \\geq 0$ for all $A$","$\\phi$ is defined on all subsets"],correctIndex:1,difficulty:"medium",explanation:"Countable additivity extends finite additivity to countably infinite disjoint unions. This is the key property distinguishing measures from merely finitely additive set functions."},{id:3,type:"multiple-choice",question:"A ring of sets $\\mathcal{R}$ is closed under:",options:["Only intersections","All set operations including complements","Finite unions and set differences","Countable unions only"],correctIndex:2,difficulty:"medium",explanation:"A ring is closed under finite unions, intersections, and set differences. A $\\sigma$-ring is also closed under countable unions. An algebra also contains the whole space."},{id:4,type:"multiple-choice",question:"The outer measure $\\mu^*$ is defined by:",options:["$\\mu^*(E) = 0$ for all $E$","$\\mu^*(E) = \\sup\\{\\mu(A) : A \\subset E, A \\in \\mathcal{R}\\}$","$\\mu^*(E) = \\inf\\{\\sum \\mu(A_n) : E \\subset \\bigcup A_n, A_n \\in \\mathcal{R}\\}$","$\\mu^*(E) = \\mu(E)$ when $E \\in \\mathcal{R}$"],correctIndex:2,difficulty:"hard",explanation:"Outer measure covers $E$ by countable unions of sets from $\\mathcal{R}$ and takes the infimum of the sum of their measures. It may exceed the inner measure."},{id:5,type:"multiple-choice",question:"A set function $\\mu$ is monotone if:",options:["$\\mu(A \\cup B) \\leq \\mu(A) + \\mu(B)$","$\\mu(A) = \\mu(B)$ when $|A| = |B|$","$\\mu$ is non-negative","$A \\subset B$ implies $\\mu(A) \\leq \\mu(B)$"],correctIndex:3,difficulty:"easy",explanation:"Monotonicity means larger sets have larger (or equal) measure. For additive non-negative set functions, monotonicity follows from additivity."}],Ie=[{id:1,type:"multiple-choice",question:"Lebesgue measure $m$ on $\\mathbb{R}$ is characterized by:",options:["$m(A) = $ number of elements in $A$","$m(A) = 1$ for all non-empty sets","$m([a,b]) = |b - a|^2$","$m([a,b]) = b - a$ and countable additivity"],correctIndex:3,difficulty:"easy",explanation:"Lebesgue measure extends length: intervals have measure equal to their length, and the measure is countably additive on measurable sets."},{id:2,type:"multiple-choice",question:"A set $E \\subset \\mathbb{R}$ has Lebesgue measure zero if:",options:["$E$ is countable","$E$ is finite","For every $\\varepsilon > 0$, $E$ can be covered by intervals with total length $< \\varepsilon$","$E$ is bounded"],correctIndex:2,difficulty:"medium",explanation:"Measure zero means $E$ can be covered by countably many intervals of arbitrarily small total length. Countable sets have measure zero, but some uncountable sets do too (like the Cantor set)."},{id:3,type:"multiple-choice",question:"The Cantor set $C$ is an example of a set that is:",options:["Uncountable with Lebesgue measure zero","Finite with measure zero","Uncountable with positive measure","Countable with positive measure"],correctIndex:0,difficulty:"medium",explanation:"The Cantor set is constructed by removing middle thirds. It is uncountable (has cardinality $2^{\\aleph_0}$) but has measure zero (the removed intervals have total length 1)."},{id:4,type:"multiple-choice",question:"A set $E \\subset \\mathbb{R}^n$ is Lebesgue measurable if:",options:["For every $A$, $m^*(A) = m^*(A \\cap E) + m^*(A \\cap E^c)$ (Carathéodory criterion)","$m^*(E) < \\infty$","$E$ is bounded","$E$ is open or closed"],correctIndex:0,difficulty:"hard",explanation:"The Carathéodory criterion defines measurability: $E$ is measurable if it splits every set $A$ additively with respect to outer measure."},{id:5,type:"multiple-choice",question:"Lebesgue measure is translation invariant, meaning:",options:["$m(E) = m(-E)$","$m(E + x) = m(E)$ for all $E$ and $x \\in \\mathbb{R}^n$","$m(E \\cup F) = m(E) + m(F)$","$m(cE) = c \\cdot m(E)$ for $c > 0$"],correctIndex:1,difficulty:"easy",explanation:"Translation invariance: shifting a set does not change its measure. Combined with countable additivity and normalization on intervals, this characterizes Lebesgue measure."}],we=[{id:1,type:"multiple-choice",question:"A measure space is a triple $(X, \\mathcal{M}, \\mu)$ where:",options:["$X$ is a set, $\\mathcal{M}$ is a $\\sigma$-algebra, and $\\mu$ is a countably additive measure on $\\mathcal{M}$","$X = \\mathbb{R}$, $\\mathcal{M}$ is the Borel sets, $\\mu$ is Lebesgue measure","$X$ is a metric space, $\\mathcal{M}$ is the open sets, $\\mu$ is any function","$X$ is finite, $\\mathcal{M} = 2^X$, $\\mu$ is counting measure"],correctIndex:0,difficulty:"medium",explanation:"A measure space consists of a set, a $\\sigma$-algebra of measurable sets, and a countably additive non-negative measure. This is the abstract framework for integration."},{id:2,type:"multiple-choice",question:"A $\\sigma$-algebra $\\mathcal{M}$ on $X$ must satisfy:",options:["Is a finite collection","Contains only open sets","Closed under finite unions only","$X \\in \\mathcal{M}$, closed under complements, and closed under countable unions"],correctIndex:3,difficulty:"medium",explanation:"A $\\sigma$-algebra contains the whole space, is closed under complementation, and is closed under countable unions (hence also countable intersections)."},{id:3,type:"multiple-choice",question:"A measure $\\mu$ is called $\\sigma$-finite if:",options:["$\\mathcal{M}$ is countable","$\\mu(E) < \\infty$ for all $E \\in \\mathcal{M}$","$X = \\bigcup_{n=1}^\\infty E_n$ with $\\mu(E_n) < \\infty$ for all $n$","$\\mu(X) < \\infty$"],correctIndex:2,difficulty:"medium",explanation:"$\\sigma$-finiteness means $X$ is a countable union of sets with finite measure. Lebesgue measure on $\\mathbb{R}^n$ is $\\sigma$-finite but not finite."},{id:4,type:"multiple-choice",question:"A measure is complete if:",options:["The measure takes only values 0 and 1","$\\mu(X) = 1$","Every set is measurable","Every subset of a null set is measurable (and has measure zero)"],correctIndex:3,difficulty:"hard",explanation:"Completeness means null sets have all their subsets measurable. Lebesgue measure is complete, but Borel measure is not (there are non-Borel subsets of Borel null sets)."},{id:5,type:"multiple-choice",question:"The Borel $\\sigma$-algebra on $\\mathbb{R}^n$ is:",options:["The smallest $\\sigma$-algebra containing all open sets","Only the open and closed sets","The set of all subsets of $\\mathbb{R}^n$","The Lebesgue measurable sets"],correctIndex:0,difficulty:"easy",explanation:"The Borel $\\sigma$-algebra is generated by the open sets. It contains all open, closed, $G_\\delta$, $F_\\sigma$ sets, etc., but is smaller than the Lebesgue $\\sigma$-algebra."}],Ae=[{id:1,type:"multiple-choice",question:"A function $f: X \\to \\mathbb{R}$ (or $\\overline{\\mathbb{R}}$) is measurable if:",options:["$f$ is continuous","$f^{-1}((a, \\infty))$ is measurable for all $a \\in \\mathbb{R}$","$f^{-1}(\\{a\\})$ is measurable for all $a$","$f$ is bounded"],correctIndex:1,difficulty:"medium",explanation:"Measurability means preimages of simple sets (like rays $(a,\\infty)$) are measurable. Equivalently, preimages of all Borel sets are measurable."},{id:2,type:"multiple-choice",question:"If $f$ and $g$ are measurable functions, then:",options:["None of the above are necessarily measurable","Only $f + g$ is measurable","$f/g$ is always measurable","$f + g$, $fg$, $\\max(f,g)$, and $\\min(f,g)$ are all measurable"],correctIndex:3,difficulty:"medium",explanation:"Measurable functions form an algebra: sums, products, max, min of measurable functions are measurable. Quotients are measurable where the denominator is nonzero."},{id:3,type:"multiple-choice",question:"If $\\{f_n\\}$ is a sequence of measurable functions, then:",options:["$\\sup_n f_n$, $\\inf_n f_n$, $\\limsup_n f_n$, and $\\liminf_n f_n$ are all measurable","Measurability is not preserved under suprema","Only finite suprema are measurable","The limit may not be measurable"],correctIndex:0,difficulty:"hard",explanation:"Measurability is preserved under countable suprema, infima, and limits. This is why $\\limsup$ and $\\liminf$ (hence pointwise limits) of measurable functions are measurable."},{id:4,type:"multiple-choice",question:"Every continuous function $f: \\mathbb{R}^n \\to \\mathbb{R}$ is:",options:["Not necessarily measurable","Borel measurable (hence Lebesgue measurable)","Measurable only on compact sets","Measurable only if bounded"],correctIndex:1,difficulty:"easy",explanation:"Continuous functions are measurable because preimages of open sets are open. Since open sets are Borel (hence Lebesgue) measurable, continuous functions are measurable."},{id:5,type:"multiple-choice",question:"A function $f$ is measurable if and only if:",options:["$\\{x : f(x) > a\\}$ is measurable for every $a \\in \\mathbb{R}$","$f$ is bounded","$f$ is the limit of continuous functions","$\\{x : f(x) = a\\}$ is measurable for every $a \\in \\mathbb{R}$"],correctIndex:0,difficulty:"medium",explanation:"The standard characterization: $f$ is measurable iff all upper level sets $\\{f > a\\}$ are measurable. Equivalent conditions use $\\{f \\geq a\\}$, $\\{f < a\\}$, or $\\{f \\leq a\\}$."}],Re=[{id:1,type:"multiple-choice",question:"A simple function is:",options:["A function with simple (non-repeated) roots","A measurable function taking only finitely many values","Any step function","A continuous function"],correctIndex:1,difficulty:"easy",explanation:"A simple function has the form $s = \\sum_{i=1}^n a_i \\chi_{E_i}$ where $a_i$ are distinct values and $E_i$ are measurable sets. It takes finitely many values."},{id:2,type:"multiple-choice",question:"Every non-negative measurable function is:",options:["Continuous","A simple function","The pointwise limit of an increasing sequence of simple functions","Bounded"],correctIndex:2,difficulty:"medium",explanation:"This approximation theorem is fundamental: any non-negative measurable $f$ can be approximated from below by simple functions $s_n \\nearrow f$ pointwise."},{id:3,type:"multiple-choice",question:"The integral of a simple function $s = \\sum_{i=1}^n a_i \\chi_{E_i}$ is defined as:",options:["$\\int s \\, d\\mu = \\max_i a_i$","$\\int s \\, d\\mu = \\sum_{i=1}^n a_i$","$\\int s \\, d\\mu = n \\cdot \\mu(X)$","$\\int s \\, d\\mu = \\sum_{i=1}^n a_i \\mu(E_i)$"],correctIndex:3,difficulty:"easy",explanation:"The integral of a simple function is the weighted sum of its values, where each value $a_i$ is weighted by the measure of the set where $s = a_i$."},{id:4,type:"multiple-choice",question:"If $s$ and $t$ are simple functions with $s \\leq t$ pointwise, then:",options:["The integrals cannot be compared","$\\int s \\, d\\mu \\leq \\int t \\, d\\mu$","$\\int s \\, d\\mu \\geq \\int t \\, d\\mu$","$\\int s \\, d\\mu = \\int t \\, d\\mu$"],correctIndex:1,difficulty:"easy",explanation:"The integral of simple functions is monotone: if $s \\leq t$ pointwise, then $\\int s \\leq \\int t$. This monotonicity extends to the Lebesgue integral."},{id:5,type:"multiple-choice",question:"The standard representation of a simple function $s$ taking values $\\{a_1, \\ldots, a_n\\}$ is:",options:["A Fourier series","Any sum of characteristic functions","A polynomial representation","$s = \\sum_{i=1}^n a_i \\chi_{E_i}$ where $E_i = s^{-1}(\\{a_i\\})$ are disjoint"],correctIndex:3,difficulty:"medium",explanation:"The standard (canonical) representation uses the disjoint level sets $E_i = \\{x : s(x) = a_i\\}$. This representation is unique up to ordering."}],Ee=[{id:1,type:"multiple-choice",question:"The Lebesgue integral of a non-negative measurable function $f$ is defined as:",options:["The area under the graph of $f$","$\\lim_{n \\to \\infty} \\sum_{k=1}^n f(x_k) \\Delta x$","$\\int f \\, d\\mu = \\sup\\{\\int s \\, d\\mu : 0 \\leq s \\leq f, s \\text{ simple}\\}$","$\\int_a^b f(x) \\, dx$ using Riemann sums"],correctIndex:2,difficulty:"medium",explanation:"The Lebesgue integral of $f \\geq 0$ is the supremum of integrals of simple functions bounded above by $f$. This definition extends naturally to signed and complex functions."},{id:2,type:"multiple-choice",question:"The Monotone Convergence Theorem states that if $0 \\leq f_1 \\leq f_2 \\leq \\cdots$ and $f_n \\to f$ pointwise, then:",options:["The integrals need not converge","$\\int f_n \\, d\\mu \\to \\int f \\, d\\mu$","$\\int f_n \\, d\\mu$ is bounded","$\\int f \\, d\\mu \\leq \\liminf \\int f_n \\, d\\mu$"],correctIndex:1,difficulty:"medium",explanation:"MCT: for an increasing sequence of non-negative measurable functions converging to $f$, the integrals converge to $\\int f$. No domination hypothesis is needed."},{id:3,type:"multiple-choice",question:"Fatou's Lemma states that for non-negative measurable $f_n$:",options:["$\\int \\lim f_n = \\lim \\int f_n$","$\\int f_n$ converges","$\\int \\limsup f_n \\, d\\mu \\geq \\limsup \\int f_n \\, d\\mu$","$\\int \\liminf f_n \\, d\\mu \\leq \\liminf \\int f_n \\, d\\mu$"],correctIndex:3,difficulty:"hard",explanation:"Fatou's Lemma: $\\int \\liminf f_n \\leq \\liminf \\int f_n$. The inequality can be strict. This is a key tool when the sequence is not monotone."},{id:4,type:"multiple-choice",question:"The Dominated Convergence Theorem requires:",options:["$f_n$ be continuous","$f_n \\to f$ uniformly","$f_n \\to f$ pointwise and $|f_n| \\leq g$ for some integrable $g$","$f_n$ be bounded by a constant"],correctIndex:2,difficulty:"medium",explanation:"DCT: if $f_n \\to f$ pointwise and $|f_n| \\leq g$ with $\\int g < \\infty$, then $\\int f_n \\to \\int f$. The dominating function $g$ must be integrable."},{id:5,type:"multiple-choice",question:"A measurable function $f$ is Lebesgue integrable if:",options:["The Riemann integral exists","$\\int |f| \\, d\\mu < \\infty$","$f$ is continuous","$f$ is bounded"],correctIndex:1,difficulty:"easy",explanation:"Integrability means the integral of $|f|$ is finite. We then define $\\int f = \\int f^+ - \\int f^-$ where $f^\\pm$ are the positive/negative parts."}],ke=[{id:1,type:"multiple-choice",question:"Every Riemann integrable function on $[a,b]$ is:",options:["Not necessarily Lebesgue integrable","Lebesgue integrable but may have different integral","Lebesgue integrable with the same integral value","Continuous"],correctIndex:2,difficulty:"easy",explanation:"The Lebesgue integral extends the Riemann integral: every Riemann integrable function is Lebesgue integrable, and the integrals agree."},{id:2,type:"multiple-choice",question:"A bounded function on $[a,b]$ is Riemann integrable if and only if:",options:["It is continuous","It is monotonic","Its set of discontinuities has Lebesgue measure zero","It has at most countably many discontinuities"],correctIndex:2,difficulty:"medium",explanation:"Lebesgue's criterion: a bounded function is Riemann integrable iff it is continuous almost everywhere (discontinuities form a set of measure zero)."},{id:3,type:"multiple-choice",question:"The characteristic function $\\chi_\\mathbb{Q}$ of the rationals on $[0,1]$ is:",options:["Both Riemann and Lebesgue integrable","Lebesgue integrable (with integral 0) but not Riemann integrable","Riemann integrable but not Lebesgue integrable","Neither Riemann nor Lebesgue integrable"],correctIndex:1,difficulty:"medium",explanation:"$\\chi_\\mathbb{Q}$ is discontinuous everywhere, so not Riemann integrable. But $\\mathbb{Q}$ has measure zero, so $\\int \\chi_\\mathbb{Q} = 0$ in the Lebesgue sense."},{id:4,type:"multiple-choice",question:"The main advantage of Lebesgue integration over Riemann integration is:",options:["Easier computation of integrals","Better convergence theorems (MCT, DCT) and larger class of integrable functions","Does not require measure theory","Works only for continuous functions"],correctIndex:1,difficulty:"medium",explanation:"Lebesgue integration allows powerful limit theorems (Monotone, Dominated Convergence) and integrates more functions. This makes it essential for modern analysis."},{id:5,type:"multiple-choice",question:"For improper Riemann integrals like $\\int_1^\\infty \\frac{\\sin x}{x} dx$:",options:["It exists as both Riemann and Lebesgue integral","It is Lebesgue integrable but not Riemann integrable","It does not exist in any sense","It exists as improper Riemann but the function is not Lebesgue integrable"],correctIndex:3,difficulty:"hard",explanation:"The integral $\\int_1^\\infty \\frac{\\sin x}{x} dx$ converges conditionally as an improper Riemann integral, but $\\int_1^\\infty |\\frac{\\sin x}{x}| dx = \\infty$, so it is not Lebesgue integrable."}],Fe=[{id:1,type:"multiple-choice",question:"A complex-valued function $f = u + iv$ is Lebesgue integrable if:",options:["Both real functions $u$ and $v$ are Lebesgue integrable","$f$ is continuous","$|f|$ is bounded","Only $u$ is integrable"],correctIndex:0,difficulty:"easy",explanation:"Complex integrability means both real and imaginary parts are integrable. Equivalently, $\\int |f| < \\infty$ since $|u|, |v| \\leq |f| \\leq |u| + |v|$."},{id:2,type:"multiple-choice",question:"The integral of a complex function satisfies:",options:["Complex functions cannot be integrated","$\\int |f|^2 = |\\int f|^2$","$\\int (u + iv) = \\int u + i \\int v$","$\\int \\overline{f} = \\overline{\\int f}$ always fails"],correctIndex:2,difficulty:"easy",explanation:"Complex integration is defined component-wise: integrate the real and imaginary parts separately and combine. This preserves linearity over $\\mathbb{C}$."},{id:3,type:"multiple-choice",question:"For complex integrable $f$, the inequality $|\\int f| \\leq \\int |f|$ is called:",options:["The triangle inequality for integrals","Cauchy-Schwarz inequality","Jensen's inequality","The modulus inequality"],correctIndex:0,difficulty:"medium",explanation:"The integral version of the triangle inequality: $|\\int f| \\leq \\int |f|$. This follows from writing $\\int f = re^{i\\theta}$ and integrating $e^{-i\\theta}f$."},{id:4,type:"multiple-choice",question:"The Dominated Convergence Theorem applies to complex functions when:",options:["Only for real functions","$f_n$ are uniformly bounded","$f_n$ converge uniformly","$f_n \\to f$ pointwise and $|f_n| \\leq g$ for integrable real $g$"],correctIndex:3,difficulty:"medium",explanation:"DCT works for complex functions using the same hypothesis: pointwise convergence dominated by an integrable function. Apply to real and imaginary parts."},{id:5,type:"multiple-choice",question:"The space of complex integrable functions $L^1(\\mu)$ is:",options:["A real vector space only","Complete only for finite measures","Not a vector space","A complex vector space with norm $\\|f\\|_1 = \\int |f| d\\mu$"],correctIndex:3,difficulty:"medium",explanation:"$L^1$ is a complex Banach space (complete normed vector space) under the $L^1$ norm. Completeness follows from the fact that Cauchy sequences have convergent subsequences."}],Ce=[{id:1,type:"multiple-choice",question:"The space $L^2(\\mu)$ consists of:",options:["All measurable functions","Measurable functions $f$ with $\\int |f|^2 d\\mu < \\infty$ (identified if equal a.e.)","All square functions","Continuous functions with compact support"],correctIndex:1,difficulty:"easy",explanation:"$L^2$ is the space of square-integrable functions. Functions equal almost everywhere are identified, making $L^2$ a proper vector space (not just a set)."},{id:2,type:"multiple-choice",question:"The inner product on $L^2(\\mu)$ is defined as:",options:["$\\langle f, g \\rangle = \\sup f \\cdot \\sup g$","$\\langle f, g \\rangle = \\int fg \\, d\\mu$","$\\langle f, g \\rangle = \\int f \\overline{g} \\, d\\mu$","$\\langle f, g \\rangle = \\int |f| |g| \\, d\\mu$"],correctIndex:2,difficulty:"medium",explanation:"The $L^2$ inner product uses complex conjugation: $\\langle f, g \\rangle = \\int f \\bar{g}$. This makes $\\langle f, f \\rangle = \\int |f|^2 \\geq 0$."},{id:3,type:"multiple-choice",question:"The Cauchy-Schwarz inequality in $L^2$ states:",options:["$|\\langle f, g \\rangle| \\leq \\|f\\|_2 \\|g\\|_2$","$\\|fg\\|_1 \\leq \\|f\\|_2 \\|g\\|_2$","$\\|f + g\\|_2 \\leq \\|f\\|_2 + \\|g\\|_2$","$\\int fg = \\int f \\cdot \\int g$"],correctIndex:0,difficulty:"medium",explanation:"Cauchy-Schwarz: $|\\int f\\bar{g}| \\leq (\\int |f|^2)^{1/2}(\\int |g|^2)^{1/2}$. Equality holds iff $f$ and $g$ are proportional."},{id:4,type:"multiple-choice",question:"The space $L^2(\\mu)$ is:",options:["Not a vector space","A complete inner product space (Hilbert space)","An incomplete inner product space","Complete only for finite measures"],correctIndex:1,difficulty:"medium",explanation:"The Riesz-Fischer theorem: $L^2$ is complete, making it a Hilbert space. This is fundamental for Fourier analysis and quantum mechanics."},{id:5,type:"multiple-choice",question:"If $\\{e_n\\}$ is an orthonormal basis for $L^2[0,2\\pi]$ (e.g., $e_n = \\frac{1}{\\sqrt{2\\pi}}e^{inx}$), then for any $f \\in L^2$:",options:["The series diverges","$f = \\sum_{n} \\langle f, e_n \\rangle e_n$ converging in $L^2$ norm","$f$ equals a finite sum","$f = \\sum_n \\langle f, e_n \\rangle e_n$ converging pointwise everywhere"],correctIndex:1,difficulty:"hard",explanation:"In a Hilbert space with orthonormal basis, every element has a unique expansion converging in the norm. This is the basis of Fourier series in $L^2$."}],ze={0:i,1:t,2:n,3:o,4:a,5:s,6:$,7:r,8:c,9:l,10:f,11:u,12:d,13:h,14:m,15:p,16:y,17:x,18:b,19:g,20:v,21:_,22:q,23:T,24:I,25:w,26:A,27:R,28:E,29:k,30:F,31:C,32:z,33:B,34:L,35:Q,36:S,37:N,38:j,39:M,40:D,41:P,42:W,43:G,44:H,45:V,46:U,47:O,48:K,49:X,50:J,51:Z,52:Y,53:ee,54:ie,55:te,56:ne,57:oe,58:ae,59:se,60:$e,61:re,62:ce,63:le,64:fe,65:ue,66:de,67:he,68:me,69:pe,70:ye,71:xe,72:be,73:ge,74:ve,75:_e,76:qe,77:Te,78:Ie,79:we,80:Ae,81:Re,82:Ee,83:ke,84:Fe,85:Ce};function Be(e){return ze[e]??null}export{Be as g};
